{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T09:51:18.011005Z",
     "iopub.status.busy": "2022-08-10T09:51:18.010001Z",
     "iopub.status.idle": "2022-08-10T09:51:18.872816Z",
     "shell.execute_reply": "2022-08-10T09:51:18.871807Z"
    }
   },
   "outputs": [],
   "source": [
    "YEAR_START = 2013\n",
    "YEAR_NOW = 2021\n",
    "\n",
    "\n",
    "#NOW PLOT IT\n",
    "#try using plotly\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.validators.scatter.marker import SymbolValidator\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "### LOAD CONFIG ####\n",
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "config[\"reverted_merge_dict\"] = dict()\n",
    "for key, values in config[\"merge_dict\"].items():\n",
    "    for value in values:\n",
    "        config[\"reverted_merge_dict\"][value] = key\n",
    "\n",
    "\n",
    "#Defining Plotting Function\n",
    "def prep_data(ito, anchor, group=False, max_n_split=100, write_level_keys=False):\n",
    "\n",
    "    #Read input\n",
    "    input_file_name=f\"data/sota_{ito}.csv\"\n",
    "    sota = pd.read_csv(input_file_name)\n",
    "\n",
    "    sota[\"date\"] = pd.to_datetime(sota[\"date\"])\n",
    "    sota = sota[sota[\"date\"] >= datetime.datetime(YEAR_START,1,1)]\n",
    "    sota = sota[sota[\"date\"] <= datetime.datetime(YEAR_NOW,12,31)]\n",
    "    sota = sota.sort_values(by=\"date\")\n",
    "\n",
    "    #metricName causing some problems. Removed!\n",
    "    sota = sota[sota[\"metric\"]!=\"Parameters\"]\n",
    "\n",
    "\n",
    "    def agg_(ex):\n",
    "\n",
    "        # calculate ratio\n",
    "        min_ = ex[\"result\"].min()\n",
    "        max_ = ex[\"result\"].max()\n",
    "        assert ex[\"result\"].iloc[0] == min_\n",
    "        assert ex[\"result\"].iloc[-1] == max_\n",
    "\n",
    "        # add previous result (offset 1)\n",
    "        ex[\"prev_result\"] = ex[\"result\"].shift(periods=1, fill_value=-1)\n",
    "\n",
    "        # calculate ratio using prev result\n",
    "        ex[\"ratio\"] = (ex[\"result\"] - ex[\"prev_result\"]) / (max_ - min_)\n",
    "\n",
    "        # set all anchors to -1\n",
    "        ex.loc[ex[\"prev_result\"] == -1, \"ratio\"] = -1\n",
    "\n",
    "        # remove prev result from df again\n",
    "        ex.drop('prev_result', axis=1, inplace=True)\n",
    "        \n",
    "        if len(ex) <= 2:\n",
    "            return ex.head(0)\n",
    "\n",
    "        return ex\n",
    "    \n",
    "    # key for grouping\n",
    "    grp = [\"l1\", \"l2\", \"l3\", \"task\", \"dataset\", \"metric\"]\n",
    "    # aggregate groups\n",
    "    sota = sota.groupby(grp, as_index=False, dropna=False).apply(agg_).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "\n",
    "    if group:\n",
    "        n_sota = len(sota)\n",
    "        # determine level\n",
    "        def det_lvl(ex, lvl):\n",
    "            \"\"\"\n",
    "            if ex[f\"l{lvl+1}\"].all() == False:\n",
    "                assert lvl != 1\n",
    "                ex[\"level\"] = lvl - 1\n",
    "                ex[\"level_key\"] = \"-\".join([x for x in range(1,lvl - 1)]\n",
    "            \"\"\"\n",
    "            lvls = [f\"l{lvl_}\" for lvl_ in range(1,lvl+1)]\n",
    "\n",
    "            lookup = set()  # a temporary lookup set\n",
    "            level_key = \" // \".join([x for x in list(ex[lvls].iloc[0]) if x not in lookup and lookup.add(x) is None])\n",
    "            if (level_key not in config[\"expand_list\"]) and ((lvl == 3) or (len(ex[lvls + [\"date\", \"task\", \"dataset\", \"metric\", \"ratio\"]].drop_duplicates()) < max_n_split) or (ex[f\"l{lvl+1}\"].all() == False)):\n",
    "                ex[\"level\"] = lvl\n",
    "                ex[\"level_key\"] = level_key\n",
    "                return ex\n",
    "            else:\n",
    "                next_level = ex.groupby([f\"l{lvl+1}\"], as_index=False).apply(det_lvl, lvl+1).reset_index(drop=True)\n",
    "                return next_level\n",
    "        sota = sota.groupby([\"l1\"], as_index=False).apply(det_lvl, 1).reset_index(drop=True)\n",
    "        assert len(sota) == n_sota\n",
    "        sota = sota.drop_duplicates(subset=[\"level_key\", \"date\", \"task\", \"dataset\", \"metric\", \"ratio\"])\n",
    "    else:\n",
    "        sota[\"level\"] = 3\n",
    "        lookup = set()  # a temporary lookup set\n",
    "        sota[\"level_key\"] = \" // \".join([x for x in list(sota[[\"l1\", \"l2\", \"l3\"]].iloc[0]) if x not in lookup and lookup.add(x) is None]) + \": \" + sota[\"task\"]\n",
    "\n",
    "    #FILTER trajectories based on yml config\n",
    "    # remove unwanted trajectories\n",
    "    sota = sota[~sota[\"level_key\"].isin(config[\"remove_list\"])]\n",
    "    # merge\n",
    "    sota[\"level_key\"] = sota[\"level_key\"].apply(lambda x: config[\"reverted_merge_dict\"].get(x, x))\n",
    "    # shorten\n",
    "    for key, value in config[\"shortening_dict\"].items():\n",
    "        sota[\"level_key\"] = sota[\"level_key\"].str.replace(value, key)\n",
    "\n",
    "    sota = sota.sort_values('level_key')\n",
    "\n",
    "    if write_level_keys:\n",
    "        sota[[\"level_key\", \"l1\", \"l2\", \"l3\", \"task\"]].drop_duplicates().to_csv(f\"./data/global_map_level_keys_{ito}.csv\", index=False) \n",
    "    \n",
    "    # Filter datasets containing single entry\n",
    "    # sota = filter_entries_count(sota, lambda x: sota[\"dataset\"] + \" - \" + sota[\"task\"] + \" - \" + sota[\"l3\"] + \" - \" + sota[\"l2\"] + \" - \" + sota[\"l1\"])\n",
    "\n",
    "    # Filter tasks containing single entry\n",
    "    # sota = filter_entries_count(sota, lambda x: x[\"superclass\"] if not group else x[\"superclass\"] + \": \" + x[\"task\"])\n",
    "      \n",
    "    trajectories = sota[sota[\"ratio\"] != -1]\n",
    "    trajectories[\"ratio\"] = trajectories[\"ratio\"].apply(lambda x: round(x, 4))\n",
    "\n",
    "    # filter pre aggregation\n",
    "    # This block will take the values from average_summary_IN and delete those that have only one arrow per trajectories.\n",
    "    # if(anchor==0):\n",
    "    #    trajectories = filter_entries_count(trajectories, lambda x: x[\"superclass\"] if not group else x[\"superclass\"] + \": \" + x[\"task\"])\n",
    "    def agg(ex):\n",
    "      ex[\"dataset\"] = \"  \" + (\"\" if not group else (ex[\"task\"] + \" - \" )) + ex[\"dataset\"] + \": \" + ex[\"metric\"] + \"<BR>\"\n",
    "      return pd.Series({\"dataset\": \"\".join(ex[\"dataset\"].sort_values().unique()), \"ratio\": ex[\"ratio\"].max()})      # CHANGE BY MATTHIAS: .mean() ->  .max()\n",
    "    trajectories = pd.DataFrame(trajectories.groupby([\"level_key\", \"date\"])[\"task\", \"dataset\", \"metric\", \"ratio\"].apply(agg))\n",
    "    trajectories.sort_values(by=[\"date\"], ascending=True)\n",
    "    trajectories.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    if(anchor==0):\n",
    "        trajectories = filter_entries_count(trajectories, lambda x: x[\"level_key\"])\n",
    "    \n",
    "    anchors = sota[sota[\"ratio\"] == -1]\n",
    "    anchors = pd.DataFrame(anchors.groupby([\"level_key\", \"date\"])[\"task\", \"dataset\", \"metric\", \"ratio\"].apply(agg))\n",
    "    anchors.sort_values(by=[\"date\"], ascending=True)\n",
    "    anchors.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "        \n",
    "    return anchors, trajectories\n",
    "\n",
    "def filter_entries_count(df, fn, gt=1):\n",
    "    df[\"foo\"] = fn(df)\n",
    "    count_df = pd.DataFrame(df[\"foo\"].value_counts())\n",
    "    df = df[df[\"foo\"].isin(count_df[count_df[\"foo\"] > gt].index)]\n",
    "    df = df.drop(\"foo\", axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_global_map(level_keys, anchors, trajectories, class_label, ito, anchor, grp=False, page=None):\n",
    "\n",
    "    anchors=anchors[anchors[\"level_key\"].isin(level_keys)].copy()\n",
    "    trajectories=trajectories[trajectories[\"level_key\"].isin(level_keys)].copy()\n",
    "    \n",
    "    rows = len(trajectories[\"level_key\"].unique())*25\n",
    "\n",
    "    ## ADD Lines\n",
    "    trajectories = trajectories.sort_values(by=[\"level_key\"], ascending=False)\n",
    "    fig_traj = px.line(\n",
    "                       x=trajectories[\"date\"], \n",
    "                       y=trajectories[\"level_key\"], \n",
    "                       color=trajectories[\"level_key\"], \n",
    "                       )\n",
    "    trajectories = trajectories.sort_values(by=[\"level_key\", \"date\"])\n",
    "    \n",
    "    ## ADD ANCHORS\n",
    "    #select anchors that belong to selected trajectories\n",
    "    fig_traj.add_trace(\n",
    "        go.Scatter(\n",
    "            x=anchors[\"date\"],\n",
    "            y=anchors[\"level_key\"],\n",
    "            #facet_row=\"task\",\n",
    "            #facet_row_spacing=0.009, \n",
    "            mode=\"markers\",\n",
    "            name=None,\n",
    "            marker=dict(\n",
    "                symbol=42, \n",
    "                size=20,\n",
    "                line=dict(\n",
    "                    width=2\n",
    "                ),\n",
    "                \n",
    "            ),\n",
    "            hovertemplate=\n",
    "            \"<BR>task: \"\n",
    "            + anchors[\"level_key\"]\n",
    "            + \"<BR>date: \"\n",
    "            + anchors[\"date\"].astype(\"string\")\n",
    "            + \"<BR>Anchor.\"\n",
    "            + \"<BR>benchmarks:<BR>\"\n",
    "            + anchors[\"dataset\"].astype(\"string\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ## ADD Trajectories\n",
    "    fig_traj.add_trace(\n",
    "        go.Scatter(\n",
    "            x=trajectories[\"date\"],\n",
    "            y=trajectories[\"level_key\"],\n",
    "            #facet_row=\"task\",\n",
    "            #facet_row_spacing=0.009, \n",
    "            mode=\"markers\",\n",
    "            name=None,\n",
    "            hovertemplate=\n",
    "            \"<BR>task: \"\n",
    "            + trajectories[\"level_key\"]\n",
    "            + \"<BR>date: \"\n",
    "            + trajectories[\"date\"].astype(\"string\")\n",
    "            + \"<BR>ratio: \"\n",
    "            + trajectories[\"ratio\"].astype(\"string\")\n",
    "            + \"<BR>benchmarks:<BR>\"\n",
    "            + trajectories[\"dataset\"].astype(\"string\"),\n",
    "            marker=dict(\n",
    "                size=17,  \n",
    "                symbol=\"diamond-tall\",  # https://plotly.com/python/marker-style/\n",
    "                opacity=0.7,  # alpha ratio\n",
    "                color=trajectories[\"ratio\"],  # set color equal to a variable\n",
    "                colorscale=\"YlGn\",  # one of plotly colorscales\n",
    "                colorbar=dict(title=\"ratio\", lenmode=\"pixels\", len=500, thickness=10, x=-0.1),\n",
    "                showscale=True,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "   \n",
    "    fig_traj.update_traces(\n",
    "        marker=dict(line=dict(color=\"gray\", width=1)),\n",
    "        line  =dict(width=0, color=\"black\")        \n",
    "    )\n",
    "\n",
    "    fig_traj.update_xaxes(showgrid=True, gridcolor=\"lightBlue\", title=\"Year\")\n",
    "    #title=ito+\": \"+class_label\n",
    "    fig_traj.update_yaxes(showgrid=True, gridcolor=\"lightBlue\", title=None)\n",
    "    \n",
    "    # font_size 14, height=rows*1.5\n",
    "    # cv, single traces --> height=rows*1.5\n",
    "    fig_traj.update_layout(\n",
    "        #title=\"Trajectory for ratio (task per year)\",\n",
    "        title_text=class_label,\n",
    "        showlegend=False,\n",
    "        font_size=14,\n",
    "        plot_bgcolor=\"white\",\n",
    "        height=(rows*(1 if (anchor and ito == \"ITO_00101\") else 1)) if not grp else 1.35*rows,\n",
    "        width=1500,\n",
    "        xaxis=dict(\n",
    "            tickmode=\"auto\",\n",
    "        ),\n",
    "        yaxis={'side': 'right'}\n",
    "        \n",
    "    )  \n",
    "\n",
    "    \n",
    "    fig_traj.update_layout(\n",
    "\n",
    "        title={\n",
    "            'y':0.995,            \n",
    "            })\n",
    "\n",
    "    fig_traj.write_html(f\"artefacts/{class_label.replace(' ', '_').lower()}{'_single_arrow' if anchor else ''}{'_grp' if grp else ''}{'_' + str(page) if page is not None else ''}.html\", include_plotlyjs=\"cdn\")\n",
    "    fig_traj.write_image(f\"artefacts/{class_label.replace(' ', '_').lower()}{'_single_arrow' if anchor else ''}{'_grp' if grp else ''}{'_' + str(page) if page is not None else ''}.svg\", scale=2)\n",
    "    fig_traj.write_image(f\"artefacts/{class_label.replace(' ', '_').lower()}{'_single_arrow' if anchor else ''}{'_grp' if grp else ''}{'_' + str(page) if page is not None else ''}.png\", scale=2)\n",
    "\n",
    "    return fig_traj\n",
    "\n",
    "#Define get statistics function\n",
    "def get_statistics(traj_df):\n",
    "  results=pd.DataFrame(columns=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "  #traj_df = traj_df_bkp.copy()\n",
    "\n",
    "  traj_df['date'] = pd.to_datetime(traj_df['date'])\n",
    "  traj_df['date'] = traj_df['date'].dt.strftime('%Y')\n",
    "\n",
    "  for date in traj_df[\"date\"].unique():\n",
    "    \n",
    "    df = traj_df[traj_df[\"date\"]==date].copy()\n",
    "    ts = df.get(['date','ratio'])\n",
    "    ts['date']= pd.to_datetime(ts['date'])\n",
    "    ts['date'] = ts['date'].dt.strftime('%Y-%m')\n",
    "    \n",
    "    \n",
    "    #print(results.index)\n",
    "    year = ts.describe()\n",
    "    year[\"ratio\"]=year[\"ratio\"].astype('float').round(3)\n",
    "\n",
    "    year = year.T\n",
    "    year.index=[date]\n",
    "    results=results.append(year)\n",
    "\n",
    "  #year[\"ratio\"].values.round(3).astype('float')\\\n",
    "  results = results.sort_index()\n",
    "  return results\n",
    "\n",
    "#Define get boxplots\n",
    "def get_boxplot(traj_df):\n",
    "\n",
    "  traj_df['date'] = pd.to_datetime(traj_df['date'])\n",
    "  traj_df['date'] = traj_df['date'].dt.strftime('%Y')\n",
    "\n",
    "  c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, 20)] #here controls the colors\n",
    "\n",
    "\n",
    "  fig = go.Figure()\n",
    "  # Use x instead of y argument for horizontal plot\n",
    "  i=0\n",
    "  for date in traj_df[\"date\"].unique():\n",
    "    i=i+1\n",
    "    df = traj_df[traj_df[\"date\"]==date].copy()\n",
    "    ts = df.get(['date','ratio'])\n",
    "\n",
    "    ts['date']= pd.to_datetime(ts['date'])\n",
    "    ts['date'] = ts['date'].dt.strftime('%Y-%m')\n",
    "    #fig.add_trace(go.Box(x=ts[\"ratio\"], name=task))\n",
    "    fig.add_trace(go.Box(y=ts[\"ratio\"], \n",
    "              boxpoints='all',\n",
    "              jitter=0.8,\n",
    "              whiskerwidth=0.1,\n",
    "              marker_size=3, \n",
    "              line_width=2,\n",
    "              name=int(date), \n",
    "              marker_color=\"Blue\"))\n",
    "    \n",
    "  fig.update_layout(height=400, width=1000, showlegend=False,\n",
    "                    font_size=20,\n",
    "                    xaxis=dict(tickmode='linear'))\n",
    "  \n",
    "  fig.update_xaxes(categoryorder='array', categoryarray=list(range(YEAR_START,YEAR_NOW)))\n",
    "                  \n",
    "  return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated superclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:126: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\ottsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:135: FutureWarning:\n",
      "\n",
      "Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "\n",
      "C:\\Users\\ottsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:144: FutureWarning:\n",
      "\n",
      "Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values - Natural Language Processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:126: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\ottsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:135: FutureWarning:\n",
      "\n",
      "Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "\n",
      "C:\\Users\\ottsi\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:144: FutureWarning:\n",
      "\n",
      "Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values - Vision process\n"
     ]
    }
   ],
   "source": [
    "for ito, class_label in [(\"ITO_00141\", \"Natural Language Processing\"), (\"ITO_00101\", \"Vision process\")]:\n",
    "    anchor = 0\n",
    "    anchors, trajectories = prep_data(ito, anchor, True, 500, write_level_keys=True)\n",
    "\n",
    "    max_rows_per_page = 35\n",
    "    level_keys_pages = anchors[\"level_key\"].sort_values().unique()\n",
    "    level_keys_pages = [level_keys_pages[i:i+max_rows_per_page] for i in range(0,len(level_keys_pages), max_rows_per_page)]\n",
    "\n",
    "    for page, level_keys in enumerate(level_keys_pages):\n",
    "        global_plt = plot_global_map(level_keys, anchors, trajectories, class_label, ito, anchor, True, None if len(level_keys_pages) == 1 else page)\n",
    "\n",
    "    #boxplots = get_boxplot(trajectories)\n",
    "    #results = get_statistics(trajectories)\n",
    "\n",
    "    print(f\"Comparative yearly distribution of state-of-the-art (SOTA) averaged gain ratio values - {class_label}\")\n",
    "    # global_plt.show()\n",
    "    # boxplots.show()\n",
    "    # display(results.T.style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "84e8978afb7f63c6ee27450fa6ee2e656ae864757fb7210e0f2225ddad31e255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
