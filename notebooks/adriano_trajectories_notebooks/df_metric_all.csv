categories,task,datasets,metrics,ranking,value
"Computer Vision', 'Natural Language Processing",Handwriting Recognition,BanglaLekha Isolated Dataset,Accuracy,1,96.8
"Computer Vision', 'Natural Language Processing",Handwriting Recognition,BanglaLekha Isolated Dataset,Cross Entropy Loss,1,0.21612
"Computer Vision', 'Natural Language Processing",Handwriting Recognition,BanglaLekha Isolated Dataset,Epochs,1,11
"Computer Vision', 'Natural Language Processing",Handwritten Digit Recognition,MNIST,Accuracy,1,96.95
"Computer Vision', 'Natural Language Processing",Handwritten Digit Recognition,MNIST,PERCENTAGE ERROR,2,0.91
"Computer Vision', 'Miscellaneous', 'Time Series",Trajectory Forecasting,ForkingPaths,ADE,1,168.9
"Computer Vision', 'Miscellaneous', 'Time Series",Trajectory Forecasting,TrajNet++,COL,1,5.31
"Computer Vision', 'Miscellaneous', 'Time Series",Trajectory Forecasting,TrajNet++,FDE,1,1.14
"Computer Vision', 'Miscellaneous', 'Time Series",Trajectory Forecasting,TrajNet++,COL,2,6.560
"Computer Vision', 'Miscellaneous', 'Time Series",Trajectory Forecasting,TrajNet++,FDE,2,1.150
"Computer Vision', 'Miscellaneous', 'Time Series",Trajectory Forecasting,ActEV,ADE-8/12,1,17.99
Computer Vision,Monocular Depth Estimation,KITTI Eigen split unsupervised,absolute relative error,1,0.079
Computer Vision,Monocular Depth Estimation,KITTI Eigen split unsupervised,absolute relative error,2,0.087
Computer Vision,Monocular Depth Estimation,Make3D,Abs Rel,1,0.377
Computer Vision,Monocular Depth Estimation,Make3D,RMSE,1,8.388
Computer Vision,Monocular Depth Estimation,Make3D,Sq Rel,1,4.9
Computer Vision,Monocular Depth Estimation,Make3D,Abs Rel,2,0.322
Computer Vision,Monocular Depth Estimation,Make3D,RMSE,2,7.417
Computer Vision,Monocular Depth Estimation,Make3D,Sq Rel,2,3.589
Computer Vision,Monocular Depth Estimation,IBims-1,D3R,1,0.3222
Computer Vision,Monocular Depth Estimation,IBims-1,ORD,1,0.3938
Computer Vision,Monocular Depth Estimation,IBims-1,RMSE,1,0.1598
Computer Vision,Monocular Depth Estimation,IBims-1,δ1.25,1,0.6390
Computer Vision,Monocular Depth Estimation,IBims-1,D3R,2,0.4671
Computer Vision,Monocular Depth Estimation,IBims-1,ORD,2,0.5538
Computer Vision,Monocular Depth Estimation,IBims-1,RMSE,2,
Computer Vision,Monocular Depth Estimation,IBims-1,δ1.25,2,
Computer Vision,Monocular Depth Estimation,NYU-Depth V2,RMSE,1,0.357
Computer Vision,Monocular Depth Estimation,NYU-Depth V2,Delta < 1.25,2,0.903
Computer Vision,Monocular Depth Estimation,NYU-Depth V2,Delta < 1.25^2,2,0.984
Computer Vision,Monocular Depth Estimation,NYU-Depth V2,Delta < 1.25^3,2,0.997
Computer Vision,Monocular Depth Estimation,NYU-Depth V2,RMSE,2,0.364
Computer Vision,Monocular Depth Estimation,NYU-Depth V2,absolute relative error,2,0.103
Computer Vision,Monocular Depth Estimation,UASOL,RMSE,1,8.119
Computer Vision,Monocular Depth Estimation,Middlebury 2014,D3R,1,0.1578
Computer Vision,Monocular Depth Estimation,Middlebury 2014,ORD ,1,0.3467
Computer Vision,Monocular Depth Estimation,Middlebury 2014,RMSE,1,0.1557
Computer Vision,Monocular Depth Estimation,Middlebury 2014,δ1.25,1,0.7406
Computer Vision,Monocular Depth Estimation,Middlebury 2014,D3R,2,0.2324
Computer Vision,Monocular Depth Estimation,Middlebury 2014,ORD ,2,0.3879
Computer Vision,Monocular Depth Estimation,Middlebury 2014,RMSE,2,0.1973
Computer Vision,Monocular Depth Estimation,Middlebury 2014,δ1.25,2,0.7891
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,Delta < 1.25,1,0.964
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,Delta < 1.25^2,1,0.995
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,Delta < 1.25^3,1,0.999
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,RMSE,1,2.360
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,RMSE log,1,0.088
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,absolute relative error,1,0.058
Computer Vision,Monocular Depth Estimation,KITTI Eigen split,absolute relative error,2,0.059
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,Abs Rel,1,0.1425
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,RMSE,1,8.8641
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,RMSE log,1,0.24571
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,SQ Rel,1,3.6798
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,Abs Rel,2,0.2410
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,RMSE,2,12.599
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,RMSE log,2,0.3618
Computer Vision,Monocular Depth Estimation,Mid-Air Dataset,SQ Rel,2,5.5321
Computer Vision,Stereo Depth Estimation,sceneflow,Average End-Point Error,1,1.1
Computer Vision,Stereo Depth Estimation,KITTI2015, three pixel error,1,2.43
Computer Vision,Stereo Depth Estimation,KITTI2015, three pixel error,2,6.2
Computer Vision,Stereo Depth Estimation,KITTI2012, three pixel error,1,6.1
Computer Vision,Stereo-LiDAR Fusion,KITTI Depth Completion Validation,RMSE,1,636.2
Computer Vision,Stereo-LiDAR Fusion,KITTI Depth Completion Validation,RMSE,2,725.43
Computer Vision,Indoor Monocular Depth Estimation,DIODE,Delta < 1.25^3,1,0.7945
Time Series,Stock Price Prediction,2019_test set,10 fold Cross validation,1,22
Time Series,Stock Trend Prediction,FI-2010,Accuracy (H50),1,0.8202
Time Series,Stock Trend Prediction,FI-2010,F1 (H50),1,0.8088
Computer Vision,Image Super-Resolution,Middlebury - 4x upscaling,PSNR,1,28.63
Computer Vision,Image Super-Resolution,BSD100 - 8x upscaling,PSNR,1,25.06
Computer Vision,Image Super-Resolution,BSD100 - 8x upscaling,SSIM,1,0.607
Computer Vision,Image Super-Resolution,BSD100 - 8x upscaling,PSNR,2,25.04
Computer Vision,Image Super-Resolution,BSD100 - 8x upscaling,SSIM,2,0.6075
Computer Vision,Image Super-Resolution,BSDS100 - 2x upscaling,PSNR,1,32.31
Computer Vision,Image Super-Resolution,BSDS100 - 2x upscaling,SSIM,1,0.901
Computer Vision,Image Super-Resolution,BSDS100 - 2x upscaling,PSNR,2,32.21
Computer Vision,Image Super-Resolution,BSDS100 - 2x upscaling,SSIM,2,0.9001
Computer Vision,Image Super-Resolution,KITTI 2015 - 2x upscaling,PSNR,1,29.78
Computer Vision,Image Super-Resolution,Manga109 - 3x upscaling,PSNR,1,34.94
Computer Vision,Image Super-Resolution,Manga109 - 3x upscaling,SSIM,1,0.9518
Computer Vision,Image Super-Resolution,Manga109 - 3x upscaling,PSNR,2,34.87
Computer Vision,Image Super-Resolution,Manga109 - 3x upscaling,SSIM,2,0.9509
Computer Vision,Image Super-Resolution,Sun80 - 4x upscaling,PSNR,1,28.54
Computer Vision,Image Super-Resolution,Set14 - 8x upscaling,PSNR,1,25.41
Computer Vision,Image Super-Resolution,Set14 - 8x upscaling,SSIM,1,0.657
Computer Vision,Image Super-Resolution,Set14 - 8x upscaling,PSNR,2,25.4
Computer Vision,Image Super-Resolution,Set14 - 8x upscaling,SSIM,2,0.6547
Computer Vision,Image Super-Resolution,PIRM-test,NIQE,1,2.51
Computer Vision,Image Super-Resolution,PIRM-test,NIQE,2,2.55
Computer Vision,Image Super-Resolution,CUFED5 - 4x upscaling,PSNR,1,26.24
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,FID,1,5.36
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,MS-SSIM,1,0.971
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,PSNR,1,28.65
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,SSIM,1,0.816
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,FID,2,74.43
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,MS-SSIM,2,0.958
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,PSNR,2,27.42
Computer Vision,Image Super-Resolution,FFHQ 256 x 256 - 4x upscaling,SSIM,2,0.816
Computer Vision,Image Super-Resolution,BSD100 - 3x upscaling,PSNR,1,29.41
Computer Vision,Image Super-Resolution,BSD100 - 3x upscaling,SSIM,1,0.8116
Computer Vision,Image Super-Resolution,BSD100 - 3x upscaling,PSNR,2,29.4
Computer Vision,Image Super-Resolution,BSD100 - 3x upscaling,SSIM,2,0.8125
Computer Vision,Image Super-Resolution,BSDS100 - 8x upscaling,PSNR,1,25.05
Computer Vision,Image Super-Resolution,BSDS100 - 8x upscaling,SSIM,1,0.607
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,FID,1,1.978
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,MS-SSIM,1,0.975
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,PSNR,1,33.04
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,SSIM,1,0.875
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,FID,2,12.4
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,MS-SSIM,2,0.971
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,PSNR,2,34.1
Computer Vision,Image Super-Resolution,FFHQ 1024 x 1024 - 4x upscaling,SSIM,2,0.906
Computer Vision,Image Super-Resolution,Manga109 - 4x upscaling,PSNR,1,31.66
Computer Vision,Image Super-Resolution,Manga109 - 4x upscaling,SSIM,1,0.9222
Computer Vision,Image Super-Resolution,Manga109 - 4x upscaling,PSNR,2,31.78
Computer Vision,Image Super-Resolution,Manga109 - 4x upscaling,SSIM,2,0.9211
Computer Vision,Image Super-Resolution,WebFace - 8x upscaling,PSNR,1,27.21
Computer Vision,Image Super-Resolution,WebFace - 8x upscaling,PSNR,2,27.11
Computer Vision,Image Super-Resolution,DIV2K val - 4x upscaling,PSNR,1,32.82
Computer Vision,Image Super-Resolution,DIV2K val - 4x upscaling,SSIM,1,0.8837
Computer Vision,Image Super-Resolution,Set5 - 4x upscaling,PSNR,1,32.75
Computer Vision,Image Super-Resolution,Set5 - 4x upscaling,SSIM,1,0.9016
Computer Vision,Image Super-Resolution,Set5 - 4x upscaling,PSNR,2,32.74
Computer Vision,Image Super-Resolution,Set5 - 4x upscaling,SSIM,2,0.9021
Computer Vision,Image Super-Resolution,Middlebury - 2x upscaling,PSNR,1,34.05
Computer Vision,Image Super-Resolution,Set5 - 8x upscaling,PSNR,1,29.03
Computer Vision,Image Super-Resolution,Set5 - 8x upscaling,SSIM,1,0.8299
Computer Vision,Image Super-Resolution,Set5 - 8x upscaling,PSNR,2,27.51
Computer Vision,Image Super-Resolution,Set5 - 8x upscaling,SSIM,2,0.793
Computer Vision,Image Super-Resolution,Manga109 - 16x upscaling,PSNR,1,21.25
Computer Vision,Image Super-Resolution,Manga109 - 16x upscaling,SSIM,1,0.673
Computer Vision,Image Super-Resolution,Urban100 - 4x upscaling,PSNR,1,29.28
Computer Vision,Image Super-Resolution,Urban100 - 4x upscaling,SSIM,1,0.8711
Computer Vision,Image Super-Resolution,Urban100 - 4x upscaling,PSNR,2,27.3
Computer Vision,Image Super-Resolution,Urban100 - 4x upscaling,SSIM,2,0.818
Computer Vision,Image Super-Resolution,BSD100 - 2x upscaling,PSNR,1,33.83
Computer Vision,Image Super-Resolution,BSD100 - 2x upscaling,SSIM,1,0.9262
Computer Vision,Image Super-Resolution,BSD100 - 2x upscaling,PSNR,2,32.47
Computer Vision,Image Super-Resolution,BSD100 - 2x upscaling,SSIM,2,0.9032
Computer Vision,Image Super-Resolution,Urban100 - 16x upscaling,PSNR,1,20.39
Computer Vision,Image Super-Resolution,Urban100 - 16x upscaling,SSIM,1,0.515
Computer Vision,Image Super-Resolution,Urban100 - 2x upscaling,PSNR,1,35.24
Computer Vision,Image Super-Resolution,Urban100 - 2x upscaling,SSIM,1,0.9572
Computer Vision,Image Super-Resolution,Urban100 - 2x upscaling,PSNR,2,33.54
Computer Vision,Image Super-Resolution,Urban100 - 2x upscaling,SSIM,2,0.9402
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,FED,1,0.0716
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,FID,1,1.898
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,LLE,1,2.071
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,LPIPS,1,0.0723
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,MS-SSIM,1,0.971
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,NIQE,1,6.961
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,PSNR,1,30.824
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,SSIM,1,0.838
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,FED,2,0.0843
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,FID,2,20.605
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,LLE,2,2.003
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,LPIPS,2,0.2475
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,MS-SSIM,2,0.961
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,NIQE,2,13.636
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,PSNR,2,30.188
Computer Vision,Image Super-Resolution,FFHQ 512 x 512 - 4x upscaling,SSIM,2,0.824
Computer Vision,Image Super-Resolution,BSD200 - 2x upscaling,PSNR,1,32.92
Computer Vision,Image Super-Resolution,BSD200 - 2x upscaling,SSIM,1,0.9122
Computer Vision,Image Super-Resolution,Set14 - 2x upscaling,PSNR,1,35.61
Computer Vision,Image Super-Resolution,Set14 - 2x upscaling,SSIM,1,0.9404
Computer Vision,Image Super-Resolution,Set14 - 2x upscaling,PSNR,2,34.43
Computer Vision,Image Super-Resolution,Set14 - 2x upscaling,SSIM,2,0.9247
Computer Vision,Image Super-Resolution,Set5 - 3x upscaling,PSNR,1,34.86
Computer Vision,Image Super-Resolution,Set5 - 3x upscaling,SSIM,1,0.9307
Computer Vision,Image Super-Resolution,Set5 - 3x upscaling,PSNR,2,34.85
Computer Vision,Image Super-Resolution,Set5 - 3x upscaling,SSIM,2,0.9300
Computer Vision,Image Super-Resolution,Manga109 - 8x upscaling,PSNR,1,25.71
Computer Vision,Image Super-Resolution,Manga109 - 8x upscaling,SSIM,1,0.813
Computer Vision,Image Super-Resolution,Manga109 - 8x upscaling,PSNR,2,25.55
Computer Vision,Image Super-Resolution,Manga109 - 8x upscaling,SSIM,2,0.8087
Computer Vision,Image Super-Resolution,Urban100 - 3x upscaling,PSNR,1,29.37
Computer Vision,Image Super-Resolution,Urban100 - 3x upscaling,SSIM,1,0.8746
Computer Vision,Image Super-Resolution,Urban100 - 3x upscaling,PSNR,2,29.21
Computer Vision,Image Super-Resolution,Urban100 - 3x upscaling,SSIM,2,0.8710
Computer Vision,Image Super-Resolution,DIV8K test - 16x upscaling,LPIPS,1,0.348
Computer Vision,Image Super-Resolution,DIV8K test - 16x upscaling,PSNR,1,23.38
Computer Vision,Image Super-Resolution,DIV2K val - 2x upscaling,PSNR,1,38.26
Computer Vision,Image Super-Resolution,DIV2K val - 2x upscaling,SSIM,1,0.9599
Computer Vision,Image Super-Resolution,KITTI 2012 - 2x upscaling,PSNR,1,30.65
Computer Vision,Image Super-Resolution,BSD100 - 4x upscaling,PSNR,1,29.15
Computer Vision,Image Super-Resolution,BSD100 - 4x upscaling,SSIM,1,0.8001
Computer Vision,Image Super-Resolution,BSD100 - 4x upscaling,PSNR,2,27.87
Computer Vision,Image Super-Resolution,BSD100 - 4x upscaling,SSIM,2,0.7453
Computer Vision,Image Super-Resolution,VggFace2 - 8x upscaling,PSNR,1,25.57
Computer Vision,Image Super-Resolution,VggFace2 - 8x upscaling,PSNR,2,24.10
Computer Vision,Image Super-Resolution,Urban100 - 8x upscaling,PSNR,1,23.24
Computer Vision,Image Super-Resolution,Urban100 - 8x upscaling,SSIM,1,0.6523
Computer Vision,Image Super-Resolution,Urban100 - 8x upscaling,PSNR,2,23.2
Computer Vision,Image Super-Resolution,Urban100 - 8x upscaling,SSIM,2,0.652
Computer Vision,Image Super-Resolution,Manga109 - 2x upscaling,PSNR,1,39.75
Computer Vision,Image Super-Resolution,Manga109 - 2x upscaling,SSIM,1,0.9792
Computer Vision,Image Super-Resolution,Manga109 - 2x upscaling,PSNR,2,39.62
Computer Vision,Image Super-Resolution,Manga109 - 2x upscaling,SSIM,2,0.9787
Computer Vision,Image Super-Resolution,BSD100 - 16x upscaling,PSNR,1,22.72
Computer Vision,Image Super-Resolution,BSD100 - 16x upscaling,SSIM,1,0.512
Computer Vision,Image Super-Resolution,Set14 - 4x upscaling,PSNR,1,30.31
Computer Vision,Image Super-Resolution,Set14 - 4x upscaling,SSIM,1,0.8382
Computer Vision,Image Super-Resolution,Set14 - 4x upscaling,PSNR,2,29.05
Computer Vision,Image Super-Resolution,Set14 - 4x upscaling,SSIM,2,0.7921
Computer Vision,Image Super-Resolution,DIV2K val - 16x upscaling,PSNR,1,24.38
Computer Vision,Image Super-Resolution,DIV2K val - 16x upscaling,SSIM,1,0.641
Computer Vision,Image Super-Resolution,KITTI 2015 - 4x upscaling,PSNR,1,25.43
Computer Vision,Image Super-Resolution,Celeb-HQ 4x upscaling,PSNR,1,28.23
Computer Vision,Image Super-Resolution,Celeb-HQ 4x upscaling,SSIM,1,0.912
Computer Vision,Image Super-Resolution,DIV8K val - 16x upscaling,LPIPS,1,0.321
Computer Vision,Image Super-Resolution,DIV8K val - 16x upscaling,LPIPS,2,0.345
Computer Vision,Image Super-Resolution,DIV8K val - 16x upscaling,PSNR,2,24.03
Computer Vision,Image Super-Resolution,Set14 - 3x upscaling,PSNR,1,30.8
Computer Vision,Image Super-Resolution,Set14 - 3x upscaling,SSIM,1,0.8498
Computer Vision,Image Super-Resolution,Set14 - 3x upscaling,PSNR,2,30.79
Computer Vision,Image Super-Resolution,Set14 - 3x upscaling,SSIM,2,0.8487
Computer Vision,Image Super-Resolution,BSDS100 - 4x upscaling,PSNR,1,27.82
Computer Vision,Image Super-Resolution,BSDS100 - 4x upscaling,SSIM,1,0.744
Computer Vision,Image Super-Resolution,Set5 - 2x upscaling,PSNR,1,38.94
Computer Vision,Image Super-Resolution,Set5 - 2x upscaling,SSIM,1,0.9658
Computer Vision,Image Super-Resolution,Set5 - 2x upscaling,PSNR,2,38.34
Computer Vision,Image Super-Resolution,Set5 - 2x upscaling,SSIM,2,0.9619
Computer Vision,Image Super-Resolution,KITTI 2012 - 4x upscaling,PSNR,1,26.26
Computer Vision,Image Super-Resolution,USR-248 - 4x upscaling,PSNR,1,24.62
Computer Vision,Image Super-Resolution,USR-248 - 4x upscaling,SSIM,1,0.69
Computer Vision,Image Super-Resolution,USR-248 - 4x upscaling,UIQM,1,2.48
Computer Vision,Video Super-Resolution,SPMCS - 4x upscaling,PSNR,1,29.84
Computer Vision,Video Super-Resolution,SPMCS - 4x upscaling,SSIM,1,0.8690
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,PSNR,1,27.43
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,SSIM,1,0.835
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,PSNR,2,27.31
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,SSIM,2,0.832
Computer Vision,Video Super-Resolution,Xiph HD - 4x upscaling,Average PSNR,1,31.67
Computer Vision,Video Super-Resolution,Xiph HD - 4x upscaling,Average PSNR,2,31.47
Computer Vision,Video Super-Resolution,TbD-3D,PSNR,1,26.23
Computer Vision,Video Super-Resolution,TbD-3D,SSIM,1,0.699
Computer Vision,Video Super-Resolution,TbD-3D,TIoU,1,0.879
Computer Vision,Video Super-Resolution,TbD-3D,PSNR,2,23.13
Computer Vision,Video Super-Resolution,TbD-3D,SSIM,2,0.651
Computer Vision,Video Super-Resolution,TbD-3D,TIoU,2,0.598
Computer Vision,Video Super-Resolution,UDM10 - 4x upscaling,PSNR,1,38.97
Computer Vision,Video Super-Resolution,UDM10 - 4x upscaling,SSIM,1,0.9534
Computer Vision,Video Super-Resolution,Vimeo90k,PSNR,1,40.17
Computer Vision,Video Super-Resolution,Ultra Video Group HD - 4x upscaling,Average PSNR,1,37.91
Computer Vision,Video Super-Resolution,Ultra Video Group HD - 4x upscaling,Average PSNR,2,37.52
Computer Vision,Video Super-Resolution,Falling Objects,PSNR,1,26.83
Computer Vision,Video Super-Resolution,Falling Objects,SSIM,1,0.753
Computer Vision,Video Super-Resolution,Falling Objects,TIoU,1,0.684
Computer Vision,Video Super-Resolution,Falling Objects,PSNR,2,23.42
Computer Vision,Video Super-Resolution,Falling Objects,SSIM,2,0.671
Computer Vision,Video Super-Resolution,Falling Objects,TIoU,2,0.539
Computer Vision,Video Super-Resolution,TbD,PSNR,1,25.21
Computer Vision,Video Super-Resolution,TbD,SSIM,1,0.674
Computer Vision,Video Super-Resolution,TbD,TIoU,1,0.542
Computer Vision,Video Super-Resolution,TbD,PSNR,2,23.22
Computer Vision,Video Super-Resolution,TbD,SSIM,2,0.605
Computer Vision,Video Super-Resolution,TbD,TIoU,2,0.542
"Time Series', 'Methodology",Attention Score Prediction,PhyAAt,MAE,1,29.65
"Time Series', 'Methodology",Noise Level Prediction,PhyAAt,MAE,1,4.75
"Time Series', 'Methodology",Semanticity prediction,PhyAAt,Accuracy,1,56
"Time Series', 'Methodology",LWR Classification,PhyAAt,Accuracy,1,81
"Medical', 'Knowledge Base",Breast Cancer Detection,Breast cancer Wisconsin_class 4,Accuracy,1,96.49
"Medical', 'Knowledge Base",Breast Cancer Detection,Breast cancer Wisconsin_class 4,Average Precision,1,0.95
"Medical', 'Knowledge Base",Breast Cancer Detection,Breast Cancer Coimbra Data Set,Mean Accuracy,1,79.17
Computer Vision,Single-View 3D Reconstruction,ShapeNet,3DIoU,1,64.97
Computer Vision,Single-View 3D Reconstruction,ShapeNet,3DIoU,2,64.64
Computer Vision,3D Human Reconstruction,Expressive hands and faces dataset (EHF).,All,1,54.5
Computer Vision,Single-Image-Based Hdr Reconstruction,City Scene Dataset,HDR-VDP2 Q SCORE,1,67.18
Computer Vision,Single-Image-Based Hdr Reconstruction,City Scene Dataset,PSNR,1,32.54
Computer Vision,Single-Image-Based Hdr Reconstruction,City Scene Dataset,SSIM,1,0.95
Computer Vision,Face Recognition,UND-X1,Rank-1,1,87.2
Computer Vision,Face Recognition,UND-X1,Rank-1,2,83.73
Computer Vision,Face Recognition,LFW (Online Open Set),Average Accuracy (10 times),1,76.46
Computer Vision,Face Recognition,LFW (Online Open Set),Average Accuracy (10 times),2,53.97
Computer Vision,Face Recognition,CFP-FF,Accuracy,1,99.886
Computer Vision,Face Recognition,CFP-FP,Accuracy,1,98.986
Computer Vision,Face Recognition,CFP-FP,Accuracy,2,0.9602
Computer Vision,Face Recognition,UHDB31,Rank-1,1,84.32
Computer Vision,Face Recognition,EURECOM,Rank-1,1,88.33
Computer Vision,Face Recognition,Color FERET (Online Open Set),Average Accuracy (10 times),1,83.79
Computer Vision,Face Recognition,Color FERET (Online Open Set),Average Accuracy (10 times),2,80.72
Computer Vision,Face Recognition,LFW,Accuracy,1,0.99833
Computer Vision,Face Recognition,LFW,Accuracy,2,0.9973
Computer Vision,Face Recognition,Carl,Rank-1,1,85
Computer Vision,Face Recognition,Carl,Rank-1,2,71
Computer Vision,Face Recognition,Adience (Online Open Set),Average Accuracy (10 times),1,84.3
Computer Vision,Face Recognition,Adience (Online Open Set),Average Accuracy (10 times),2,80.6
Computer Vision,Face Detection,PASCAL Face,AP,1,0.9909
Computer Vision,Face Detection,PASCAL Face,AP,2,0.990
Computer Vision,Face Detection,FDDB,AP,1,0.991
Computer Vision,Face Detection,FDDB,AP,2,0.990
Computer Vision,Face Detection,WIDER Face (Easy),AP,1,0.965
Computer Vision,Face Detection,WIDER Face (Easy),AP,2,0.960
Computer Vision,Face Detection,WIDER Face (Hard),AP,1,0.924
Computer Vision,Face Detection,WIDER Face (Hard),AP,2,0.914
Computer Vision,Face Detection,WIDER Face (Medium),AP,1,0.957
Computer Vision,Face Detection,WIDER Face (Medium),AP,2,0.953
Computer Vision,Face Detection,Annotated Faces in the Wild,AP,1,0.9987
Computer Vision,Face Detection,Annotated Faces in the Wild,AP,2,0.9985
Computer Vision,Face Verification,IIIT-D Viewed Sketch,TAR @ FAR=0.01,1,97.86
Computer Vision,Face Verification,MegaFace,Accuracy,1,98.95
Computer Vision,Face Verification,MegaFace,Accuracy,2,98.48
Computer Vision,Face Verification,Oulu-CASIA,Accuracy,1,96.50
Computer Vision,Face Verification,BUAA-VisNir,TAR @ FAR=0.001,1,97.3
Computer Vision,Face Verification,BUAA-VisNir,TAR @ FAR=0.01,1,98.5
Computer Vision,Face Verification,BUAA-VisNir,TAR @ FAR=0.001,2,96.9
Computer Vision,Face Verification,BUAA-VisNir,TAR @ FAR=0.01,2,98.5
Computer Vision,Face Verification,CFP-FP,Accuracy,1,0.985
Computer Vision,Face Verification,CFP-FP,Accuracy,2,0.9307
Computer Vision,Face Verification,IJB-B,TAR @ FAR=0.01,1,96.5
Computer Vision,Face Verification,IJB-B,TAR @ FAR=0.01,2,96.4
Computer Vision,Face Verification,IJB-A,TAR @ FAR=0.01,1,97.60
Computer Vision,Face Verification,IJB-A,TAR @ FAR=0.001,2,95.25
Computer Vision,Face Verification,IJB-A,TAR @ FAR=0.01,2,97.5
Computer Vision,Face Verification,IJB-C,TAR @ FAR=0.0001,1,97.7
Computer Vision,Face Verification,IJB-C,TAR @ FAR=0.0001,2,97.30
Computer Vision,Face Verification,IJB-C,TAR @ FAR=0.001,2,98.18
Computer Vision,Face Verification,IJB-C,TAR @ FAR=0.01,2,98.73
Computer Vision,Face Verification,CASIA NIR-VIS 2.0,TAR @ FAR=0.001,1,99.8
Computer Vision,Face Verification,CASIA NIR-VIS 2.0,TAR @ FAR=0.001,2,99.6
Computer Vision,Face Verification,2019_test set,99.46%,1,90
Computer Vision,Face Verification,Trillion Pairs Dataset,Accuracy,1,72.71
Computer Vision,Face Verification,Trillion Pairs Dataset,Accuracy,2,61.61
Computer Vision,Face Verification,Labeled Faces in the Wild,Accuracy,1,99.85
Computer Vision,Face Verification,Labeled Faces in the Wild,Accuracy,2,99.83
Computer Vision,Face Verification,AgeDB-30,Accuracy,1,0.9815
Computer Vision,Face Verification,AgeDB-30,Accuracy,2,0.97333
Computer Vision,Face Verification,CK+,Accuracy,1,93.80
Computer Vision,Face Verification,YouTube Faces DB,Accuracy,1,98.12
Computer Vision,Face Verification,YouTube Faces DB,Accuracy,2,98.02
Computer Vision,Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.001,1,92.9
Computer Vision,Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.01,1,98.5
Computer Vision,Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.001,2,84.9
Computer Vision,Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.01,2,97.2
Computer Vision,Face Alignment,300W,AUC0.08 private,1,64.40
Computer Vision,Face Alignment,300W,Failure private,1,0.33
Computer Vision,Face Alignment,300W,Fullset (public),1,3.07
Computer Vision,Face Alignment,300W,Mean Error Rate private,1,3.56
Computer Vision,Face Alignment,300W,Fullset (public),2,3.12
Computer Vision,Face Alignment,CelebA + AFLW Unaligned,MOS,1,3.73
Computer Vision,Face Alignment,CelebA + AFLW Unaligned,MS-SSIM,1,0.897
Computer Vision,Face Alignment,CelebA + AFLW Unaligned,PSNR,1,22.96
Computer Vision,Face Alignment,CelebA + AFLW Unaligned,SSIM,1,0.695
Computer Vision,Face Alignment,AFLW-PIFA (21 points),NME,1,2.63
Computer Vision,Face Alignment,CelebA Aligned,MOS,1,3.73
Computer Vision,Face Alignment,CelebA Aligned,MS-SSIM,1,0.902
Computer Vision,Face Alignment,CelebA Aligned,PSNR,1,22.66
Computer Vision,Face Alignment,CelebA Aligned,SSIM,1,0.685
Computer Vision,Face Alignment,MERL-RAV,NME,1,1.25
Computer Vision,Face Alignment,COFW,Mean Error Rate,1,4.94
Computer Vision,Face Alignment,COFW,Mean Error Rate,2,5.04
Computer Vision,Face Alignment,AFLW-PIFA (34 points),NME,1,2.96
Computer Vision,Face Alignment,AFLW2000-3D,Mean NME ,1,2.58
Computer Vision,Face Alignment,AFLW2000-3D,Mean NME ,2,3.51
Computer Vision,Face Alignment,300-VW (C),AUC0.07,1,64.1
Computer Vision,Face Alignment,AFLW-Full,Mean NME ,1,2.85
Computer Vision,Face Alignment,AFLW-Full,Mean NME,2,1.56
Computer Vision,Face Alignment,WFLW,AUC@0.1 (all),1,0.5913
Computer Vision,Face Alignment,WFLW,"FR@0.1(%, all)",1,4.08
Computer Vision,Face Alignment,WFLW,"ME (%, all) ",1,4.39
Computer Vision,Face Alignment,WFLW,AUC@0.1 (all),2,0.5755
Computer Vision,Face Alignment,WFLW,"FR@0.1(%, all)",2,3.55
Computer Vision,Face Alignment,WFLW,"ME (%, all) ",2,4.39
Computer Vision,Face Alignment,AFLW-LFPA,Mean NME ,1,2.93
Computer Vision,Face Alignment,AFLW-LFPA,Mean NME ,2,3.86
Computer Vision,Face Alignment,LS3D-W Balanced,AUC0.07,1,72.3
Computer Vision,Face Alignment,3DFAW,CVGTCE,1,3.4767
Computer Vision,Face Alignment,3DFAW,GTE,1,4.5623
Computer Vision,Face Alignment,IBUG,Mean Error Rate,1,6.73
Computer Vision,Face Alignment,IBUG,Mean Error Rate,2,7.54
Computer Vision,Face Alignment,AFLW,Mean NME,1,4.43
Computer Vision,Face Alignment,AFLW,Mean NME,2,4.55
Computer Vision,Face Alignment,AFLW2000,Error rate,1,4.70
Computer Vision,Face Alignment,AFLW2000,Error rate,2,5.38
Computer Vision,Facial Expression Recognition,Real-World Affective Faces,Accuracy,1,87.0
Computer Vision,Facial Expression Recognition,DISFA,ICC,1,0.598
Computer Vision,Facial Expression Recognition,FERPlus,Accuracy,1,89.75
Computer Vision,Facial Expression Recognition,FERPlus,Accuracy,2,89.257
Computer Vision,Facial Expression Recognition,FERG,Accuracy,1,99.3
Computer Vision,Facial Expression Recognition,BP4D,ICC,1,0.719
Computer Vision,Facial Expression Recognition,FER2013,Accuracy,1,76.82
Computer Vision,Facial Expression Recognition,FER2013,Accuracy,2,74.14
Computer Vision,Facial Expression Recognition,Acted Facial Expressions In The Wild (AFEW),Accuracy(on validation set),1,65.5
Computer Vision,Facial Expression Recognition,Acted Facial Expressions In The Wild (AFEW),Accuracy(on validation set),2,65.5
Computer Vision,Facial Expression Recognition,MMI,Accuracy,1,98.63
Computer Vision,Facial Expression Recognition,MMI,Accuracy,2,82.74
Computer Vision,Facial Expression Recognition,AffectNet,Accuracy (8 emotion),1,61.72
Computer Vision,Facial Expression Recognition,AffectNet,Accuracy (7 emotion),2,65.4
Computer Vision,Facial Expression Recognition,AffectNet,Accuracy (8 emotion),2,61.60
Computer Vision,Facial Expression Recognition,JAFFE,Accuracy,1,92.8
Computer Vision,Facial Expression Recognition,JAFFE,Accuracy,2,91.8
Computer Vision,Facial Expression Recognition,CK+,Accuracy (10-fold),1,99.7
Computer Vision,Facial Expression Recognition,CK+,Accuracy (10-fold),2,98.6
Computer Vision,Facial Expression Recognition,Cohn-Kanade,Accuracy,1,88.7
Computer Vision,Facial Expression Recognition,SFEW,Accuracy,1,58.71
Computer Vision,Facial Expression Recognition,SFEW,Accuracy,2,56.4
Computer Vision,Facial Expression Recognition,Oulu-CASIA,Accuracy (10-fold),1,89.6
Computer Vision,Facial Expression Recognition,Oulu-CASIA,Accuracy (10-fold),2,84.59
Computer Vision,Facial Expression Recognition, Static Facial Expressions in the Wild,Accuracy,1,58.14
Computer Vision,Facial Expression Recognition, Static Facial Expressions in the Wild,Accuracy,2,54.82
Computer Vision,Facial Expression Recognition,FER+,Accuracy,1,89.257
Computer Vision,Facial Expression Recognition,FER+,Accuracy,2,87.15
Computer Vision,Facial Expression Recognition,RAF-DB,Avg. Accuracy,1,86.28
Computer Vision,Facial Expression Recognition,RAF-DB,Overall Accuracy,1,92.05
Computer Vision,Facial Expression Recognition,RAF-DB,Overall Accuracy,2,89.075
Computer Vision,Face Swapping,FaceForensics++,SSIM,1,0.73
Computer Vision,Face Swapping,FaceForensics++,landmarks,1,0.73
Computer Vision,Face Swapping,FaceForensics++,perceptual loss,1,0.39
Computer Vision,Face Swapping,FaceForensics++,pose,1,1.12
Computer Vision,Face Swapping,FaceForensics++,verification,1,0.61
Computer Vision,Face Swapping,FaceForensics++,pose,2,1.22
Computer Vision,Facial Landmark Detection,300W (Full),Mean NME ,1,3.49
Computer Vision,Facial Landmark Detection,300W,NME,1,3.13
Computer Vision,Facial Landmark Detection,300W,NME,2,3.24
Computer Vision,Facial Landmark Detection,AFLW-Full,Mean NME ,1,1.91
Computer Vision,Facial Landmark Detection,AFLW-Full,Mean NME ,2,2.17
Computer Vision,Facial Landmark Detection,AFLW-Front,Mean NME,1,1.38
Computer Vision,Facial Landmark Detection,AFLW-Front,Mean NME ,2,1.85
Computer Vision,Facial Landmark Detection,AFLW2000-3D,GTE,1,7.28
Computer Vision,Facial Landmark Detection,300-VW (C),AUC0.08 private,1,59.39
Computer Vision,Facial Landmark Detection,300-VW (C),AUC0.08 private,2,58.22
Computer Vision,3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.91
Computer Vision,3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,2.08
Computer Vision,3D Face Reconstruction,AFLW2000-3D,Mean NME ,1,3.56
Computer Vision,3D Face Reconstruction,AFLW2000-3D,Mean NME ,2,3.9625
Computer Vision,3D Face Reconstruction,Florence,Mean NME ,1,3.56
Computer Vision,3D Face Reconstruction,Florence,Mean NME ,2,3.7551
Computer Vision,3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.89
Computer Vision,3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,1.91
Computer Vision,3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),1,1.38
Computer Vision,3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),2,1.53
Computer Vision,Face Identification,Trillion Pairs Dataset,Accuracy,1,73.56
Computer Vision,Face Identification,Trillion Pairs Dataset,Accuracy,2,61.80
Computer Vision,Face Identification,IJB-A,Accuracy,1,94.60
Computer Vision,Face Identification,IJB-A,Accuracy,2,91.4
Computer Vision,Face Identification,MegaFace,Accuracy,1,99.10
Computer Vision,Face Identification,MegaFace,Accuracy,2,98.78
Computer Vision,Face Identification,IJB-B,Accuracy,1,91.1
Computer Vision,Face Anti-Spoofing,CASIA-MFSD,EER,1,4.92
Computer Vision,Face Anti-Spoofing,CASIA-MFSD,EER,2,2.22
Computer Vision,Face Anti-Spoofing,CASIA-MFSD,HTER,2,1.67
Computer Vision,Face Anti-Spoofing,Replay-Attack,EER,1,2.14
Computer Vision,Face Anti-Spoofing,Replay-Attack,EER,2,0.40
Computer Vision,Face Anti-Spoofing,Replay-Attack,HTER,2,2.90
Computer Vision,Face Anti-Spoofing,MSU-MFSD,Equal Error Rate,1,7.5
Computer Vision,Face Anti-Spoofing,MSU-MFSD,Equal Error Rate,2,10.8
Computer Vision,Face Anti-Spoofing,MLFP,HTER,1,3.4
Computer Vision,Face Anti-Spoofing,Replay Mobile,HTER,1,0
Computer Vision,Age Estimation,FGNET,MAE,1,2.95
Computer Vision,Age Estimation,FGNET,MAE,2,3.62
Computer Vision,Age Estimation,CACD,MAE,1,4.60
Computer Vision,Age Estimation,CACD,MAE,2,5.35
Computer Vision,Age Estimation,UTKFace,MAE,1,4.55
Computer Vision,Age Estimation,UTKFace,MAE,2,5.39
Computer Vision,Age Estimation,MORPH Album2 (SE),MAE,1,2.53
Computer Vision,Age Estimation,AFAD,MAE,1,3.48
Computer Vision,Age Estimation,ChaLearn 2016,MAE,1,3.452
Computer Vision,Age Estimation,MORPH Album2 (RS),MAE,1,1.13
Computer Vision,Age Estimation,MORPH Album2,MAE,1,1.969
Computer Vision,Age Estimation,MORPH Album2,MAE,2,2.42±0.01
Computer Vision,Age Estimation,ChaLearn 2015,MAE,1,3.135
Computer Vision,Age Estimation,ChaLearn 2015,MAE,2,3.51
Computer Vision,Age Estimation,MORPH,MAE,1,1.48
Computer Vision,Gender Prediction,FotW Gender,Accuracy (%),1,92.93
Computer Vision,Gender Prediction,FotW Gender,Accuracy (%),2,92.69
Computer Vision,Face Hallucination,FFHQ 512 x 512 - 16x upscaling,FID,1,11.389
Computer Vision,Face Hallucination,FFHQ 512 x 512 - 16x upscaling,LPIPS,1,0.2449
Computer Vision,Face Hallucination,FFHQ 512 x 512 - 16x upscaling,NIQE,1,6.767
Computer Vision,Face Hallucination,FFHQ 512 x 512 - 16x upscaling,FID,2,50.901
Computer Vision,Face Hallucination,FFHQ 512 x 512 - 16x upscaling,LPIPS,2,0.3928
Computer Vision,Face Hallucination,FFHQ 512 x 512 - 16x upscaling,NIQE,2,15.383
Computer Vision,Age And Gender Classification,Adience Age,Accuracy (5-fold),1,67.47
Computer Vision,Age And Gender Classification,Adience Age,Accuracy (5-fold),2,67.3
Computer Vision,Age And Gender Classification,Adience Gender,Accuracy (5-fold),1,89.66
Computer Vision,Age And Gender Classification,Adience Gender,Accuracy (5-fold),2,89.08
Computer Vision,Facial Inpainting,FFHQ, SSIM,1,0.8985
Computer Vision,Facial Inpainting,FFHQ,LPIPS,1,0.0457
Computer Vision,Facial Inpainting,FFHQ,PSNR,1,26.49
Computer Vision,Facial Inpainting,VggFace2,PSNR,1,27.81
Computer Vision,Facial Inpainting,WebFace,PSNR,1,27.22
Computer Vision,Facial Action Unit Detection,BP4D,Average Accuracy,1,81.8
Computer Vision,Facial Action Unit Detection,BP4D,F1,1,57.7
Computer Vision,Facial Action Unit Detection,BP4D,Average Accuracy,2,56.1
Computer Vision,Facial Action Unit Detection,BP4D,F1,2,45.2
Computer Vision,Face Sketch Synthesis,CUHK,FSIM,1,74.23
Computer Vision,Face Sketch Synthesis,CUHK,SSIM,1,63.28
Computer Vision,Face Sketch Synthesis,CUHK,FSIM,2,73.61
Computer Vision,Face Sketch Synthesis,CUHK,SSIM,2,61.56
Computer Vision,Face Sketch Synthesis,CUFSF,FID,1,18.2
Computer Vision,Face Sketch Synthesis,CUFSF,FSIM,1,72.9
Computer Vision,Face Sketch Synthesis,CUFSF,NLDA,1,78
Computer Vision,Face Sketch Synthesis,CUFSF,FID,2,19.6
Computer Vision,Face Sketch Synthesis,CUFSF,FSIM,2,72.7
Computer Vision,Face Sketch Synthesis,CUFSF,NLDA,2,78.1
Computer Vision,Face Sketch Synthesis,CUFS,FSIM,1,72.56
Computer Vision,Face Sketch Synthesis,CUFS,SSIM,1,54.63
Computer Vision,Face Sketch Synthesis,CUFS,FID,2,34.2
Computer Vision,Face Sketch Synthesis,CUFS,FSIM,2,71.6
Computer Vision,Face Sketch Synthesis,CUFS,NLDA,2,95.7
Computer Vision,Action Unit Detection,BP4D,Avg F1,1,63.1
Computer Vision,Heterogeneous Face Recognition,CMU-MPIE,16x16 Accuracy,1,92.4
Computer Vision,Heterogeneous Face Recognition,CMU-MPIE,24x24 Accuracy,1,92.6
Computer Vision,Heterogeneous Face Recognition,CMU-MPIE,32x32 Accuracy,1,92.8
Computer Vision,Heterogeneous Face Recognition,CMU-MPIE,48x48 Accuracy,1,92.9
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @0.1% FAR Impersonation,1,75.38
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @0.1% FAR Obfuscation,1,72.13
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @0.1% FAR Overall,1,72.72
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @1% FAR Impersonation,1,95.73
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @1% FAR Obfuscation,1,88.97
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @1% FAR Overall,1,89.3
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @0.1% FAR Impersonation,2,69.27
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @0.1% FAR Obfuscation,2,93.08
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @0.1% FAR Overall,2,93.01
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @1% FAR Impersonation,2,99.01
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @1% FAR Obfuscation,2,95.93
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild,GAR @1% FAR Overall,2,95.99
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Impersonation,1,54.40
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Obfuscation,1,97.20
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Overall,1,96.18
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Plastic Surgery,1,96.00
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Impersonation,1,79.2
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Obfuscation,1,99.00
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Overall,1,98.63
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Plastic Surgery,1,98.80
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Impersonation,2,52.80
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Obfuscation,2,94.02
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Overall,2,93.06
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.01% FAR Plastic Surgery,2,92.00
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Impersonation,2,76.40
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Obfuscation,2,96.84
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Overall,2,95.96
Computer Vision,Heterogeneous Face Recognition,Disguised Faces in the Wild 2019,GAR @0.1% FAR Plastic Surgery,2,95.20
Computer Vision,Facial Attribute Classification,FairFace,age-top1,1,59.7
Computer Vision,Facial Attribute Classification,FairFace,gender-top1,1,94.2
Computer Vision,Facial Attribute Classification,FairFace,race-top1,1,93.7
Computer Vision,Facial Beauty Prediction,ECCV HotOrNot,Pearson Correlation,1,0.468
Computer Vision,Facial Beauty Prediction,SCUT-FBP,MAE,1,0.2595
Computer Vision,Facial Beauty Prediction,SCUT-FBP,MAE,2,0.3931
Computer Vision,Autonomous Driving,Town05 Long,RC,1,69.17
Computer Vision,Autonomous Driving,Town05 Long,DS,2,33.15
Computer Vision,Autonomous Driving,Town05 Long,RC,2,56.36
Computer Vision,Autonomous Driving,Town05 Short,RC,1,86.91
Computer Vision,Autonomous Driving,Town05 Short,DS,2,54.52
Computer Vision,Autonomous Driving,Town05 Short,RC,2,78.41
Computer Vision,Autonomous Driving,ApolloCar3D,A3DP,1,20.21
Computer Vision,Autonomous Driving,CARLA Leaderboard,Driving Score,1,31.37
Computer Vision,Autonomous Driving,CARLA Leaderboard,Route Completion,1,57.65
Computer Vision,Autonomous Driving,CARLA Leaderboard,Driving Score,2,13.03
Computer Vision,Autonomous Driving,CARLA Leaderboard,Route Completion,2,42.98
Computer Vision,Pedestrian Detection,Caltech,Reasonable Miss Rate,1,1.76
Computer Vision,Pedestrian Detection,Caltech,Reasonable Miss Rate,2,3.46
Computer Vision,Pedestrian Detection,CityPersons,Bare MR^-2,1,6.2
Computer Vision,Pedestrian Detection,CityPersons,Heavy MR^-2,1,33.9
Computer Vision,Pedestrian Detection,CityPersons,Large MR^-2,1,4.3
Computer Vision,Pedestrian Detection,CityPersons,Medium MR^-2,1,3.0
Computer Vision,Pedestrian Detection,CityPersons,Partial MR^-2,1,5.7
Computer Vision,Pedestrian Detection,CityPersons,Reasonable MR^-2,1,7.5
Computer Vision,Pedestrian Detection,CityPersons,Small MR^-2,1,8.0
Computer Vision,Pedestrian Detection,CityPersons,Bare MR^-2,2,4.9
Computer Vision,Pedestrian Detection,CityPersons,Heavy MR^-2,2,42.5
Computer Vision,Pedestrian Detection,CityPersons,Partial MR^-2,2,6.9
Computer Vision,Pedestrian Detection,CityPersons,Reasonable MR^-2,2,7.6
Computer Vision,Lane Detection,CULane,F1 score,1,79.48
Computer Vision,Lane Detection,CULane,F1 score,2,78.8
Computer Vision,Lane Detection,LLAMAS,F1,1,0.9601
Computer Vision,Lane Detection,LLAMAS,F1,2,0.9374
Computer Vision,Lane Detection,BDD100K,Accuracy,1,36.56
Computer Vision,Lane Detection,TuSimple,Accuracy,1,96.92
Computer Vision,Lane Detection,TuSimple,Accuracy,2,96.82
Computer Vision,Lane Detection,TuSimple,F1 score,2,96.93
Computer Vision,Lane Detection,Caltech Lanes Cordova,F1,1,0.884
Computer Vision,Lane Detection,Caltech Lanes Cordova,F1,2,0.866
Computer Vision,Lane Detection,Caltech Lanes Washington,F1,1,0.869
Computer Vision,Lane Detection,Caltech Lanes Washington,F1,2,0.861
Computer Vision,Traffic Sign Recognition,Tsinghua-Tencent 100K,MAP,1,0.32
Computer Vision,Traffic Sign Recognition,Tsinghua-Tencent 100K,MAP,2,0.31
Computer Vision,Traffic Sign Recognition,GTSRB,Accuracy,1,99.71
Computer Vision,Traffic Sign Recognition,GTSRB,Accuracy,2,99.68
Computer Vision,Traffic Sign Recognition, Swedish traffic-sign dataset (STSD),mAP@0.50,1,95.2
Computer Vision,Traffic Sign Recognition, Swedish traffic-sign dataset (STSD),mAP@0.50,2,94.3
Computer Vision,Traffic Sign Recognition,DFG traffic-sign dataset,mAP @0.5:0.95,1,84.4
Computer Vision,Traffic Sign Recognition,DFG traffic-sign dataset,mAP@0.50,1,95.5
Computer Vision,Traffic Sign Recognition,DFG traffic-sign dataset,mAP @0.5:0.95,2,82.0
Computer Vision,Traffic Sign Recognition,DFG traffic-sign dataset,mAP@0.50,2,95.2
Computer Vision,Traffic Sign Recognition,Bosch Small Traffic Lights,MAP,1,0.46
Computer Vision,Traffic Sign Recognition,Bosch Small Traffic Lights,MAP,2,0.45
Computer Vision,Pedestrian Attribute Recognition,PA-100K,Accuracy,1,78.84
Computer Vision,Pedestrian Attribute Recognition,PA-100K,Accuracy,2,77.08
Computer Vision,Pedestrian Attribute Recognition,PETA,Accuracy,1,79.52
Computer Vision,Pedestrian Attribute Recognition,PETA,Accuracy,2,76.13
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,Backpack,1,63.9
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,Gender,1,75.0
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,Hat,1,67.2
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,LCC,1,54.6
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,LCS,1,68.9
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,UCC,1,49.8
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,UCS,1,73.0
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,Backpack,2,63.5
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,Gender,2,74.7
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,Hat,2,65.2
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,LCC,2,49.7
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,LCS,2,69.3
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,UCC,2,44.4
Computer Vision,Pedestrian Attribute Recognition,UAV-Human,UCS,2,68.9
Computer Vision,Pedestrian Attribute Recognition,RAP,Accuracy,1,68.17
Computer Vision,Pedestrian Attribute Recognition,RAP,Accuracy,2,65.39
Computer Vision,3D Car Instance Understanding,ApolloCar3D,A3DP,1,20.21
Computer Vision,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,Classification Accuracy,1,90.4
Computer Vision,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,Classification Accuracy,2,84.4
Computer Vision,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,PSNR,1,21.65
Computer Vision,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,PSNR,2,18.57
Computer Vision,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,mIoU,1,57.5
Computer Vision,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,mIoU,2,56.1
Computer Vision,Synthetic-to-Real Translation,Syn2Real-C,Accuracy,1,79.8
Computer Vision,Synthetic-to-Real Translation,Syn2Real-C,Accuracy,2,74.8
Computer Vision,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,MIoU (13 classes),1,62.0
Computer Vision,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,MIoU (16 classes),1,55.5
Computer Vision,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,MIoU (13 classes),2,62.8
Computer Vision,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,MIoU (16 classes),2,55.0
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,Diversity,1,0.175
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,Quality,1,50.0
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,Diversity,2,0.140
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,Quality,2,51.2
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,Diversity,1,0.109
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,Quality,1,50.0
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,Diversity,2,0.104
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,Quality,2,56.7
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,AFHQ,FID,1,16.2
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,AFHQ,FID,2,41.5
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,CIS,1,1.039
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,IS,1,
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,CIS,2,0.115
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,IS,2,0.826
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,PSNR,1,23.11
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,PSNR,2,17.38
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,FID,1,13.73
Computer Vision,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,FID,2,31.4
Computer Vision,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,FID,1,17.3
Computer Vision,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,Kernel Inception Distance,1,0.00053
Computer Vision,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,FID,2,20.7
Computer Vision,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,Kernel Inception Distance,2,0.00392
Computer Vision,Cross-View Image-to-Image Translation,Dayton (64×64) - aerial-to-ground,SSIM,1,0.6865
Computer Vision,Cross-View Image-to-Image Translation,Dayton (64×64) - aerial-to-ground,SSIM,2,0.5171
Computer Vision,Cross-View Image-to-Image Translation,Dayton (64x64) - ground-to-aerial,SSIM,1,0.5118
Computer Vision,Cross-View Image-to-Image Translation,Dayton (64x64) - ground-to-aerial,SSIM,2,0.3682
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - aerial-to-ground,SSIM,1,0.5938
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - aerial-to-ground,KL,2,2.18
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - aerial-to-ground,PSNR,2,22.9949
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - aerial-to-ground,SD,2,19.6145
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - aerial-to-ground,SSIM,2,0.5457
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - ground-to-aerial,SSIM,1,0.3284
Computer Vision,Cross-View Image-to-Image Translation,Dayton (256×256) - ground-to-aerial,SSIM,2,0.2763
Computer Vision,Cross-View Image-to-Image Translation,Cam2BEV,Mean IoU,1,71.92
Computer Vision,Cross-View Image-to-Image Translation,cvusa,KL,1,2.6
Computer Vision,Cross-View Image-to-Image Translation,cvusa,PSNR,1,22.8223
Computer Vision,Cross-View Image-to-Image Translation,cvusa,SD,1,19.8276
Computer Vision,Cross-View Image-to-Image Translation,cvusa,SSIM,1,0.5366
Computer Vision,Cross-View Image-to-Image Translation,cvusa,SSIM,2,0.5323
Computer Vision,Cross-View Image-to-Image Translation,Ego2Top,SSIM,1,0.6024
Computer Vision,Cross-View Image-to-Image Translation,Ego2Top,SSIM,2,0.2740
Computer Vision,Facial Makeup Transfer,CPM-Synt-2,MS-SSIM,1,0.977
Computer Vision,Facial Makeup Transfer,CPM-Synt-1,mIOU,1,0.788
Computer Vision,Face Sketch Synthesis,CUHK,FSIM,1,74.23
Computer Vision,Face Sketch Synthesis,CUHK,SSIM,1,63.28
Computer Vision,Face Sketch Synthesis,CUHK,FSIM,2,73.61
Computer Vision,Face Sketch Synthesis,CUHK,SSIM,2,61.56
Computer Vision,Face Sketch Synthesis,CUFSF,FID,1,18.2
Computer Vision,Face Sketch Synthesis,CUFSF,FSIM,1,72.9
Computer Vision,Face Sketch Synthesis,CUFSF,NLDA,1,78
Computer Vision,Face Sketch Synthesis,CUFSF,FID,2,19.6
Computer Vision,Face Sketch Synthesis,CUFSF,FSIM,2,72.7
Computer Vision,Face Sketch Synthesis,CUFSF,NLDA,2,78.1
Computer Vision,Face Sketch Synthesis,CUFS,FSIM,1,72.56
Computer Vision,Face Sketch Synthesis,CUFS,SSIM,1,54.63
Computer Vision,Face Sketch Synthesis,CUFS,FID,2,34.2
Computer Vision,Face Sketch Synthesis,CUFS,FSIM,2,71.6
Computer Vision,Face Sketch Synthesis,CUFS,NLDA,2,95.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Portraits (over time),Accuracy (%),1,83.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,mAP,1,30.6
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,rank-1,1,61.4
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,rank-10,1,78.2
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,rank-5,1,73.3
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,mAP,2,25.4
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,rank-1,2,51.6
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,rank-10,2,69.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to MSMT,rank-5,2,64.3
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,mAP,1,71.0
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,rank-1,1,83.4
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,rank-10,1,93.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,rank-5,1,91.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,mAP,2,68.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,rank-1,2,82.9
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,rank-10,2,92.5
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Market to Duke,rank-5,2,90.1
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,VisDA2017,Accuracy,1,75.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Office-Home,Accuracy,1,76.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Office-Home,Accuracy,2,76.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,ImageNet-A,Top 1 Error,1,14.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,mAP,1,80.6
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,rank-1,1,92.9
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,rank-10,1,98.2
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,rank-5,1,97.2
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,mAP,2,76.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,rank-1,2,90.3
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,rank-10,2,97.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to Market,rank-5,2,96.2
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,mAP,1,30.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,rank-1,1,62.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,rank-10,1,79.0
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,rank-5,1,74.5
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,mAP,2,26.5
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,rank-1,2,53.1
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,rank-10,2,70.5
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Duke to MSMT,rank-5,2,65.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,SIM10K to BDD100K,mAP@0.5,1,45.3
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,SIM10K to BDD100K,mAP@0.5,2,42.9
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Office-31,Avg accuracy,1,88.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Office-Home (RS-UT imbalance),Average Per-Class Accuracy,1,61.67
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Office-Home (RS-UT imbalance),Average Per-Class Accuracy,2,58.4
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,PreSIL to KITTI,AP@0.7,1,17.1
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,PreSIL to KITTI,AP@0.7,2,16.5
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Cityscapes to Foggy Cityscapes,mAP@0.5,1,40.9
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,Cityscapes to Foggy Cityscapes,mAP@0.5,2,38.8
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,MSCOCO to FLIR ADAS,Accuracy (%),1,91.2
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,ImageNet-R,Top 1 Error,1,17.4
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,ImageNet-R,Top 1 Error,2,19.7
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,ImageNet-C,mean Corruption Error (mCE),1,22.0
"Computer Vision', 'Methodology",Unsupervised Domain Adaptation,ImageNet-C,mean Corruption Error (mCE),2,23.0
"Computer Vision', 'Methodology",Domain Generalization,WildDash,Mean IoU,1,31.2
"Computer Vision', 'Methodology",Domain Generalization,ImageNet-C,mean Corruption Error (mCE),1,46.8
"Computer Vision', 'Methodology",Domain Generalization,ImageNet-C,mean Corruption Error (mCE),2,49.4
"Computer Vision', 'Methodology",Domain Generalization,ImageNet-A,Top-1 accuracy %,1,28.5
"Computer Vision', 'Methodology",Domain Generalization,ImageNet-A,Top-1 accuracy %,2,25.7
"Computer Vision', 'Methodology",Domain Generalization,DomainNet,Average Accuracy,1,46.5
"Computer Vision', 'Methodology",Domain Generalization,DomainNet,Average Accuracy,2,43.63
"Computer Vision', 'Methodology",Domain Generalization,LipitK,Accuracy,1,87.3
"Computer Vision', 'Methodology",Domain Generalization,VLCS,Average Accuracy,1,79.1
"Computer Vision', 'Methodology",Domain Generalization,VLCS,Average Accuracy,2,77.53
"Computer Vision', 'Methodology",Domain Generalization,Rotated Fashion-MNIST,Accuracy,1,82.8
"Computer Vision', 'Methodology",Domain Generalization,Rotated Fashion-MNIST,Accuracy,2,78.9
"Computer Vision', 'Methodology",Domain Generalization,Office-Home,Average Accuracy,1,70.6
"Computer Vision', 'Methodology",Domain Generalization,Office-Home,Average Accuracy,2,68.56
"Computer Vision', 'Methodology",Domain Generalization,ImageNet-R,Top-1 Error Rate,1,51.3
"Computer Vision', 'Methodology",Domain Generalization,ImageNet-R,Top-1 Error Rate,2,52.3
"Computer Vision', 'Methodology",Domain Generalization,TerraIncognita,Average Accuracy,1,50.0
"Computer Vision', 'Methodology",Domain Generalization,PACS,Average Accuracy,1,88.1
"Computer Vision', 'Methodology",Domain Generalization,PACS,Average Accuracy,2,87.83
"Computer Vision', 'Methodology",Partial Domain Adaptation,Office-31,Accuracy (%),1,98.38
"Computer Vision', 'Methodology",Partial Domain Adaptation,Office-31,Accuracy (%),2,97.90
"Computer Vision', 'Methodology",Partial Domain Adaptation,ImageNet-Caltech,Accuracy (%),1,83.7
"Computer Vision', 'Methodology",Partial Domain Adaptation,ImageNet-Caltech,Accuracy (%),2,81.86
"Computer Vision', 'Methodology",Partial Domain Adaptation,Office-Home,Accuracy (%),1,78.3
"Computer Vision', 'Methodology",Partial Domain Adaptation,Office-Home,Accuracy (%),2,76.0
"Computer Vision', 'Methodology",Partial Domain Adaptation,VisDA2017,Accuracy (%),1,84.61
"Computer Vision', 'Methodology",Continuously Indexed Domain Adaptation,Circle,Accuracy (%),1,94
"Computer Vision', 'Methodology",Continuously Indexed Domain Adaptation,Sine,Accuracy (%),1,95
"Computer Vision', 'Methodology",Continuously Indexed Domain Adaptation,Indexed Rotating MNIST,Accuracy (%),1,87.1
"Computer Vision', 'Methodology",Continuously Indexed Domain Adaptation,Indexed Rotating MNIST,Accuracy (%),2,85.7
"Computer Vision', 'Methodology",Wildly Unsupervised Domain Adaptation,Noisy-Amazon (45%),Average Accuracy,1,56.01
"Computer Vision', 'Methodology",Wildly Unsupervised Domain Adaptation,Noisy-SYND-to-MNIST,Average Accuracy,1,94.09
"Computer Vision', 'Methodology",Wildly Unsupervised Domain Adaptation,Noisy-Amazon (20%),Average Accuracy,1,71.53
"Computer Vision', 'Methodology",Wildly Unsupervised Domain Adaptation,Noisy-MNIST-to-SYND,Average Accuracy,1,57.55
Speech,Distant Speech Recognition,DIRHA English WSJ,Word Error Rate (WER),1,23.9
Speech,Distant Speech Recognition,DIRHA English WSJ,Word Error Rate (WER),2,29.8
Speech,Distant Speech Recognition,CHiME-4 real 6ch,Word Error Rate (WER),1,1.99
Speech,Distant Speech Recognition,CHiME-4 real 6ch,Word Error Rate (WER),2,2.74
Speech,Accented Speech Recognition,VoxForge Commonwealth,Percentage error,1,13.56
Speech,Accented Speech Recognition,VoxForge Commonwealth,Percentage error,2,28.46
Speech,Accented Speech Recognition,VoxForge American-Canadian,Percentage error,1,7.55
Speech,Accented Speech Recognition,VoxForge American-Canadian,Percentage error,2,15.01
Speech,Accented Speech Recognition,VoxForge European,Percentage error,1,17.55
Speech,Accented Speech Recognition,VoxForge European,Percentage error,2,31.20
Speech,Accented Speech Recognition,VoxForge Indian,Percentage error,1,22.44
Speech,Accented Speech Recognition,VoxForge Indian,Percentage error,2,45.35
Speech,Noisy Speech Recognition,CHiME real,Percentage error,1,7.8
Speech,Noisy Speech Recognition,CHiME real,Percentage error,2,11.4
Speech,Noisy Speech Recognition,CHiME clean,Percentage error,1,3.34
Speech,Noisy Speech Recognition,CHiME clean,Percentage error,2,6.3
"Speech', 'Natural Language Processing",Dialogue Generation,Amazon-5,1 in 10 R@2,1,5
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Activity),F1,1,11.43
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Activity),Precision,1,16.84
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Activity),Recall,1,9.72
"Speech', 'Natural Language Processing",Dialogue Generation,Reddit (multi-ref),interest (human),1,2.53
"Speech', 'Natural Language Processing",Dialogue Generation,Reddit (multi-ref),relevance (human),1,2.72
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Entity),F1,1,3.72
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Entity),Precision,1,4.91
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Entity),Recall,1,3.36
"Speech', 'Natural Language Processing",Dialogue Generation,Twitter Dialogue (Noun),F1,1,4.63
"Speech', 'Natural Language Processing",Dialogue Generation,Twitter Dialogue (Noun),Precision,1,4.82
"Speech', 'Natural Language Processing",Dialogue Generation,Twitter Dialogue (Noun),Recall,1,5.22
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Tense),Accuracy,1,29.01
"Speech', 'Natural Language Processing",Dialogue Generation,Ubuntu Dialogue (Cmd),Accuracy,1,95.04
"Speech', 'Natural Language Processing",Dialogue Generation,Persona-Chat,Avg F1,1,19.77
"Speech', 'Natural Language Processing",Dialogue Generation,Persona-Chat,Avg F1,2,19.09
"Speech', 'Natural Language Processing",Dialogue Generation,Twitter Dialogue (Tense),Accuracy,1,34.48
"Speech', 'Natural Language Processing",Task-Oriented Dialogue Systems,KVRET,BLEU,1,14.4
"Speech', 'Natural Language Processing",Task-Oriented Dialogue Systems,KVRET,Entity F1,1,62.7
"Speech', 'Natural Language Processing",Task-Oriented Dialogue Systems,KVRET,BLEU,2,14.79
"Speech', 'Natural Language Processing",Task-Oriented Dialogue Systems,KVRET,Entity F1,2,59.97
"Speech', 'Natural Language Processing",Task-Oriented Dialogue Systems,SGD,METEOR,1,0.331
"Speech', 'Natural Language Processing",Task-Oriented Dialogue Systems,SGD,METEOR,2,0.089
"Speech', 'Natural Language Processing",Dialogue State Tracking,Second dialogue state tracking challenge,Joint,1,75.5
"Speech', 'Natural Language Processing",Dialogue State Tracking,Second dialogue state tracking challenge,Area,2,
"Speech', 'Natural Language Processing",Dialogue State Tracking,Second dialogue state tracking challenge,Food,2,
"Speech', 'Natural Language Processing",Dialogue State Tracking,Second dialogue state tracking challenge,Joint,2,74.5
"Speech', 'Natural Language Processing",Dialogue State Tracking,Second dialogue state tracking challenge,Price,2,
"Speech', 'Natural Language Processing",Dialogue State Tracking,Second dialogue state tracking challenge,Request,2,97.5
"Speech', 'Natural Language Processing",Dialogue State Tracking,Wizard-of-Oz,Joint,1,90.5
"Speech', 'Natural Language Processing",Dialogue State Tracking,Wizard-of-Oz,Request,1,97.6
"Speech', 'Natural Language Processing",Dialogue State Tracking,Wizard-of-Oz,Joint,2,88.9
"Speech', 'Natural Language Processing",Visual Dialog,ConvAI2,BLEU-4,1,1.1
"Speech', 'Natural Language Processing",Visual Dialog,ConvAI2,F1,1,18.4
"Speech', 'Natural Language Processing",Visual Dialog,ConvAI2,ROUGE-L,1,22.6
"Speech', 'Natural Language Processing",Visual Dialog,BlendedSkillTalk,BLEU-4,1,1
"Speech', 'Natural Language Processing",Visual Dialog,BlendedSkillTalk,F1,1,17.8
"Speech', 'Natural Language Processing",Visual Dialog,BlendedSkillTalk,ROUGE-L,1,19.3
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,MRR,1,0.7124
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,Mean Rank,1,2.96
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,R@1,1,58.28
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,R@10,1,94.45
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,R@5,1,87.55
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,MRR,2,0.7041
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,Mean Rank,2,3.66
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,NDCG,2,72.16
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,R@1,2,58.18
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,R@10,2,90.83
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v1.0 test-std,R@5,2,83.85
"Speech', 'Natural Language Processing",Visual Dialog,Wizard of Wikipedia,BLEU-4,1,2.2
"Speech', 'Natural Language Processing",Visual Dialog,Wizard of Wikipedia,F1,1,18.6
"Speech', 'Natural Language Processing",Visual Dialog,Wizard of Wikipedia,ROUGE-L,1,17.4
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,MRR,1,68.92
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,Mean Rank,1,3.39
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,R@1,1,55.16
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,R@10,1,92.95
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,R@5,1,86.26
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,MRR,2,66.38
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,Mean Rank,2,4.04
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,R@1,2,53.33
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,R@10,2,90.38
"Speech', 'Natural Language Processing",Visual Dialog,VisDial v0.9 val,R@5,2,82.42
"Speech', 'Natural Language Processing",Visual Dialog,Image-Chat,BLEU-4,1,40
"Speech', 'Natural Language Processing",Visual Dialog,Image-Chat,F1,1,13.1
"Speech', 'Natural Language Processing",Visual Dialog,Image-Chat,ROUGE-L,1,18
"Speech', 'Natural Language Processing",Visual Dialog,EmpatheticDialogues,BLEU-4,1,1.5
"Speech', 'Natural Language Processing",Visual Dialog,EmpatheticDialogues,F1,1,19.2
"Speech', 'Natural Language Processing",Visual Dialog,EmpatheticDialogues,ROUGE-L,1,24.5
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,MRR (x 100),1,56.2
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,Mean,1,5.41
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,NDCG (x 100),1,77.92
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,R@1,1,44.45
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,R@10,1,83.78
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,R@5,1,68.9
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,MRR (x 100),2,56.05
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,Mean,2,5.72
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,NDCG (x 100),2,76.14
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,R@1,2,44.75
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,R@10,2,82.75
"Speech', 'Natural Language Processing",Visual Dialog,Visual Dialog v1.0 test-std,R@5,2,68.4
"Speech', 'Natural Language Processing",Goal-Oriented Dialog,Kvret,BLEU,1,0.1831
"Speech', 'Natural Language Processing",Goal-Oriented Dialog,Kvret,Embedding Average,1,95.5
"Speech', 'Natural Language Processing",Goal-Oriented Dialog,Kvret,Greedy Matching,1,62.5
"Speech', 'Natural Language Processing",Goal-Oriented Dialog,Kvret,Vector Extrema,1,97.4
"Speech', 'Natural Language Processing",Dialogue Act Classification,Switchboard corpus,Accuracy,1,85.0
"Speech', 'Natural Language Processing",Dialogue Act Classification,Switchboard corpus,Accuracy,2,82.9
"Speech', 'Natural Language Processing",Dialogue Act Classification,ICSI Meeting Recorder Dialog Act (MRDA) corpus,Accuracy,1,92.4
"Speech', 'Natural Language Processing",Dialogue Act Classification,ICSI Meeting Recorder Dialog Act (MRDA) corpus,Accuracy,2,91.7
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.1,BLEU,1,18.3
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.1,MultiWOZ (Inform),1,78.1
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.1,MultiWOZ (Success),1,67.1
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.1,BLEU,2,17.2
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.1,MultiWOZ (Inform),2,91.4
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.1,MultiWOZ (Success),2,72.9
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.0,BLEU,1,18.6
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.0,MultiWOZ (Inform),1,76.3
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.0,MultiWOZ (Success),1,60.4
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.0,BLEU,2,17.2
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.0,MultiWOZ (Inform),2,90.2
"Speech', 'Natural Language Processing",End-To-End Dialogue Modelling,MULTIWOZ 2.0,MultiWOZ (Success),2,75.5
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,F,1,46.8
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,P,1,44.3
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,R,1,49.6
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,VI,1,93.3
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,1-1,2,76.0
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,F,2,38.0
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,P,2,36.3
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,R,2,39.7
"Speech', 'Natural Language Processing",Conversation Disentanglement,irc-disentanglement,VI,2,91.5
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Kummerfeld),1-1,1,59.7
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Kummerfeld),Local,1,80.8
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Kummerfeld),Shen F-1,1,63.0
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Kummerfeld),1-1,2,59.7
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Elsner),1-1,1,53.1
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Elsner),Local,1,81.9
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Elsner),Shen F-1,1,55.1
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Elsner),1-1,2,52.1
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Elsner),Local,2,77.8
"Speech', 'Natural Language Processing",Conversation Disentanglement,Linux IRC (Ch2 Elsner),Shen F-1,2,53.8
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Coherent,1,2.8017
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Consistent,1,0.9390
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Diversity,1,2.7441
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Error Recovery,1,
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Flexible,1,2.8000
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Informative,1,2.7881
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Inquisitive,1,2.7949
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Likeable,1,2.7878
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Overall Human Rating,1,4.15
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Topic Depth,1,2.7678
"Speech', 'Natural Language Processing",Interactive Evaluation of Dialog,DSTC9 Track 3 - Task 2,Understanding,1,2.8285
"Speech', 'Natural Language Processing",Prosody Prediction,Helsinki Prosody Corpus,Accuracy,1,83.2
"Speech', 'Natural Language Processing",Prosody Prediction,Helsinki Prosody Corpus,Accuracy,2,82.1
Natural Language Processing,Relation Classification,DRI Corpus,Macro F1,1,37.72
Natural Language Processing,Relation Classification,CDCP,Macro F1,1,42.95
Natural Language Processing,Relation Classification,SemEval 2010 Task 8,F1,1,86.3
Natural Language Processing,Relation Classification,SemEval 2010 Task 8,F1,2,86.1
Natural Language Processing,Relation Classification,AbstRCT - Neoplasm,Macro F1,1,70.92
Natural Language Processing,Joint Entity and Relation Extraction,NYT,F1,1,92.5
Natural Language Processing,Joint Entity and Relation Extraction,ACE 2005,Relation F1,1,62.2
Natural Language Processing,Joint Entity and Relation Extraction,SciERC,Relation F1,1,50.84
Natural Language Processing,Joint Entity and Relation Extraction,SciERC,Entity F1,2,67.50
Natural Language Processing,Joint Entity and Relation Extraction,SciERC,Relation F1,2,48.40
Natural Language Processing,Joint Entity and Relation Extraction,WebNLG,F1,1,93.4
Natural Language Processing,Joint Entity and Relation Extraction,DocRED,Relation F1,1,40.38
Natural Language Processing,Relationship Extraction (Distant Supervised),NYT,P@100,1,0.939
Natural Language Processing,Relationship Extraction (Distant Supervised),NYT,P@200,1,0.889
Natural Language Processing,Relationship Extraction (Distant Supervised),NYT,P@300,1,0.873
Natural Language Processing,Relationship Extraction (Distant Supervised),NYT,PR AUC,1,0.595
Natural Language Processing,Relationship Extraction (Distant Supervised),New York Times Corpus,P@10%,1,92.3
Natural Language Processing,Relationship Extraction (Distant Supervised),New York Times Corpus,P@30%,1,86.7
Natural Language Processing,Relationship Extraction (Distant Supervised),New York Times Corpus,P@10%,2,87.5
Natural Language Processing,Relationship Extraction (Distant Supervised),New York Times Corpus,P@30%,2,74.1
Natural Language Processing,Dialog Relation Extraction,DialogRE,F1 (v2),1,69.1
Natural Language Processing,Dialog Relation Extraction,DialogRE,F1c (v2),1,66.5
Natural Language Processing,Dialog Relation Extraction,DialogRE,F1 (v1),2,67.3
Natural Language Processing,Dialog Relation Extraction,DialogRE,F1 (v2),2,67.1
Natural Language Processing,Dialog Relation Extraction,DialogRE,F1c (v1),2,61.4
Natural Language Processing,Dialog Relation Extraction,DialogRE,F1c (v2),2,61.1
Natural Language Processing,Dialog Relation Extraction,DDRel,Pair-level 13-class Acc,1,39.73
Natural Language Processing,Dialog Relation Extraction,DDRel,Pair-level 4-class Acc,1,58.13
Natural Language Processing,Dialog Relation Extraction,DDRel,Pair-level 6-class Acc,1,42.33
Natural Language Processing,Dialog Relation Extraction,DDRel,Session-level 13-class Acc,1,39.4
Natural Language Processing,Dialog Relation Extraction,DDRel,Session-level 4-class Acc,1,47.1
Natural Language Processing,Dialog Relation Extraction,DDRel,Session-level 6-class Acc,1,41.87
Computer Vision,Video Alignment,UPenn Action,Kendall's Tau,1,0.7672
Computer Vision,Video Alignment,UPenn Action,Kendall's Tau,2,0.7476
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Average MPJPE (mm),1,44.1
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Frames Needed,1,243
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Need Ground Truth 2D Pose,1,No
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Use Video Sequence,1,Yes
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Average MPJPE (mm),2,45.1
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Frames Needed,2,243
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Need Ground Truth 2D Pose,2,No
Computer Vision,Monocular 3D Human Pose Estimation,Human3.6M,Use Video Sequence,2,Yes
Computer Vision,Pose Prediction,Gaming 3D (G3D),MAE,1,1.1101
Computer Vision,Pose Prediction,Gaming 3D (G3D),MSE,1,0.1199
Computer Vision,Pose Prediction,Gaming 3D (G3D),MAE,2,1.4038
Computer Vision,Pose Prediction,Gaming 3D (G3D),MSE,2,0.1434
Computer Vision,Pose Prediction,Filtered NTU RGB+D,MAE,1,1.1651
Computer Vision,Pose Prediction,Filtered NTU RGB+D,MSE,1,0.1210
Computer Vision,Pose Prediction,Filtered NTU RGB+D,MAE,2,1.4063
Computer Vision,Pose Prediction,Filtered NTU RGB+D,MSE,2,0.1354
Computer Vision,Pose Prediction,SUN-Mem,AP50,1,89
Computer Vision,Pose Prediction,SUN-Mem,AUPRC,1,89
Computer Vision,Pose Prediction,SUN-Mem,AUROC,1,0.914
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,3D Annotations,1,S1
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,Average MPJPE (mm),1,56.7
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,Number of Frames Per View,1,1
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,Number of Views,1,1
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,3D Annotations,2,S1
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,Average MPJPE (mm),2,60.8
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,Number of Frames Per View,2,1
Computer Vision,Weakly-supervised 3D Human Pose Estimation,Human3.6M,Number of Views,2,1
Computer Vision,3D Multi-Person Pose Estimation,CMU Panoptic Studio Dataset,Average MPJPE (mm),1,7.3
Computer Vision,3D Multi-Person Pose Estimation,CMU Panoptic Studio Dataset,Average MPJPE (mm),2,17.68
Computer Vision,3D Multi-Person Pose Estimation,MuPoTS-3D,3DPCK,1,85.3
Computer Vision,3D Multi-Person Pose Estimation,MuPoTS-3D,3DPCK,2,75.8
Computer Vision,3D Multi-Person Pose Estimation,Shelf,PCP3D,1,98.2
Computer Vision,3D Multi-Person Pose Estimation,Shelf,PCP3D,2,97.6
Computer Vision,3D Multi-Person Pose Estimation,Campus,PCP3D,1,97.4
Computer Vision,3D Multi-Person Pose Estimation,Campus,PCP3D,2,96.79
Computer Vision,3D Absolute Human Pose Estimation,Total Capture,MPJPE,1,24.6
Computer Vision,3D Absolute Human Pose Estimation,Human3.6M,MRPE,1,88.1
Computer Vision,3D Absolute Human Pose Estimation,Human3.6M,MRPE,2,120.0
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,OOB Rate (10^−3) ,1,1.733
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Path Difference,1,0.581
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Path Length,1,0.573
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Player Distance ,1,0.423
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Step Change (10^−3),1,2.565
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,OOB Rate (10^−3) ,2,3.874
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Path Difference,2,0.571
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Path Length,2,0.702
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Player Distance ,2,0.417
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Basketball Players Movement,Step Change (10^−3),2,4.811
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Beijing Air Quality,MAE (PM2.5),1,11.56
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,Beijing Air Quality,MAE (PM2.5),2,12.12
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,UCI localization data,MAE (10% missing),1,0.219
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,UCI localization data,MAE (10% missing),2,0.248
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,MuJoCo,"MSE (10^2, 50% missing)",1,0.285
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,MuJoCo,"MSE (10^2, 50% missing)",2,0.447
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,PEMS-SF,L2 Loss (10^-4),1,3.54
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,PEMS-SF,L2 Loss (10^-4),2,4.51
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,KDD CUP Challenge 2018,MSE (10% missing),1,0.334
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,KDD CUP Challenge 2018,MSE (10% missing),2,0.355
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,PhysioNet Challenge 2012,MAE (10% of data as GT),1,0.281
"Computer Vision', 'Time Series",Multivariate Time Series Imputation,PhysioNet Challenge 2012,MAE (10% of data as GT),2,0.390
Computer Vision,No-Reference Image Quality Assessment,200k Short Texts for Humor Detection,14 gestures accuracy,1,kindness
Computer Vision,Aesthetics Quality Assessment,AVA,Accuracy,1,83.0
Computer Vision,Aesthetics Quality Assessment,AVA,Accuracy,2,82.5
Computer Vision,Low-Light Image Enhancement,LOL,Average PSNR,1,20.8665
Computer Vision,Low-Light Image Enhancement,LIME,User Study Score,1,3.8
Computer Vision,Low-Light Image Enhancement,VV,User Study Score,1,3.24
Computer Vision,Low-Light Image Enhancement,VV,User Study Score,2,3.17
Computer Vision,Low-Light Image Enhancement,MEF,User Study Score,1,4.13
Computer Vision,Low-Light Image Enhancement,MEF,User Study Score,2,3.75
Computer Vision,Low-Light Image Enhancement,AFLW (Zhang CVPR 2018 crops),14 gestures accuracy,1,1
Computer Vision,Low-Light Image Enhancement,3DMatch Benchmark,"mAP (@0.1, Through-wall)",1,224
Computer Vision,Low-Light Image Enhancement,NPE,User Study Score,1,3.81
Computer Vision,Low-Light Image Enhancement,DICM,User Study Score,1,3.52
Computer Vision,Low-Light Image Enhancement,DICM,User Study Score,2,3.50
Computer Vision,Image Relighting, VIDIT’20 validation set,LPIPS,1,0.2733
Computer Vision,Image Relighting, VIDIT’20 validation set,MPS,1,0.6956
Computer Vision,Image Relighting, VIDIT’20 validation set,PSNR,1,17.62
Computer Vision,Image Relighting, VIDIT’20 validation set,Runtime(s),1,0.53
Computer Vision,Image Relighting, VIDIT’20 validation set,SSIM,1,0.6645
Computer Vision,Image Relighting, VIDIT’20 validation set,LPIPS,2,0.440
Computer Vision,Image Relighting, VIDIT’20 validation set,MPS,2,0.578
Computer Vision,Image Relighting, VIDIT’20 validation set,PSNR,2,17.59
Computer Vision,Image Relighting, VIDIT’20 validation set,Runtime(s),2,0.5
Computer Vision,Image Relighting, VIDIT’20 validation set,SSIM,2,0.596
Computer Vision,Single Image Deraining,Test1200,PSNR,1,33.05
Computer Vision,Single Image Deraining,Test1200,SSIM,1,0.919
Computer Vision,Single Image Deraining,Test1200,PSNR,2,32.91
Computer Vision,Single Image Deraining,Test1200,SSIM,2,0.916
Computer Vision,Single Image Deraining,Test2800,PSNR,1,33.91
Computer Vision,Single Image Deraining,Test2800,SSIM,1,0.941
Computer Vision,Single Image Deraining,Test2800,PSNR,2,33.64
Computer Vision,Single Image Deraining,Test2800,SSIM,2,0.938
Computer Vision,Single Image Deraining,Rain100L,PSNR,1,37.28
Computer Vision,Single Image Deraining,Rain100L,SSIM,1,0.97
Computer Vision,Single Image Deraining,Rain100L,PSNR,2,36.40
Computer Vision,Single Image Deraining,Rain100L,SSIM,2,0.965
Computer Vision,Single Image Deraining,Test100,PSNR,1,30.29
Computer Vision,Single Image Deraining,Test100,SSIM,1,0.906
Computer Vision,Single Image Deraining,Test100,PSNR,2,30.27
Computer Vision,Single Image Deraining,Test100,SSIM,2,0.897
Computer Vision,Single Image Deraining,Rain100H,PSNR,1,30.65
Computer Vision,Single Image Deraining,Rain100H,SSIM,1,0.894
Computer Vision,Single Image Deraining,Rain100H,PSNR,2,30.41
Computer Vision,Single Image Deraining,Rain100H,SSIM,2,0.89
Computer Vision,Image Dehazing,RESIDE,PSNR,1,17.07
Computer Vision,Image Dehazing,I-Haze,PSNR,1,22.56
Computer Vision,Image Dehazing,I-Haze,SSIM,1,0.8994
Computer Vision,Image Dehazing,O-Haze,PSNR,1,24.27
Computer Vision,Image Dehazing,O-Haze,SSIM,1,0.8919
Computer Vision,Image Dehazing,O-Haze,PSNR,2,22.07
Computer Vision,Image Dehazing,O-Haze,SIMM,2,0.7459
Computer Vision,Image Dehazing,SOTS Indoor,PSNR,1,35.77
Computer Vision,Image Dehazing,SOTS Indoor,SSIM,1,0.9846
Computer Vision,Image Dehazing,SOTS Indoor,PSNR,2,30.23
Computer Vision,Image Dehazing,SOTS Indoor,SSIM,2,0.98
Computer Vision,Image Dehazing,Dense-Haze,PSNR,1,17.01
Computer Vision,Image Dehazing,Dense-Haze,SSIM,1,0.613
Computer Vision,Image Dehazing,SOTS Outdoor,PSNR,1,
Computer Vision,Image Dehazing,SOTS Outdoor,SSIM,1,
Computer Vision,Image Dehazing,SOTS Outdoor,PSNR,2,28.19
Computer Vision,Image Dehazing,SOTS Outdoor,SSIM,2,0.9638
Computer Vision,Single Image Dehazing,UIEB,L2 Norm,1,minimum
Natural Language Processing,Unsupervised Machine Translation,WMT2014 French-English,BLEU,1,39.2
Natural Language Processing,Unsupervised Machine Translation,WMT2014 French-English,BLEU,2,34.9
Natural Language Processing,Unsupervised Machine Translation,WMT2016 English--Romanian,BLEU,1,33.3
Natural Language Processing,Unsupervised Machine Translation,WMT2016 German-English,BLEU,1,40.6
Natural Language Processing,Unsupervised Machine Translation,WMT2016 German-English,BLEU,2,35.2
Natural Language Processing,Unsupervised Machine Translation,WMT2014 English-French,BLEU,1,37.5
Natural Language Processing,Unsupervised Machine Translation,WMT2014 English-French,BLEU,2,36.2
Natural Language Processing,Unsupervised Machine Translation,WMT2016 Romanian-English,BLEU,1,39.5
Natural Language Processing,Unsupervised Machine Translation,WMT2016 Romanian-English,BLEU,2,33.1
Natural Language Processing,Unsupervised Machine Translation,WMT2014 German-English,BLEU,1,27.0
Natural Language Processing,Unsupervised Machine Translation,WMT2014 German-English,BLEU,2,20.4
Natural Language Processing,Unsupervised Machine Translation,WMT2014 English-German,BLEU,1,22.5
Natural Language Processing,Unsupervised Machine Translation,WMT2014 English-German,BLEU,2,17.0
Natural Language Processing,Unsupervised Machine Translation,WMT2016 English-German,BLEU,1,29.7
Natural Language Processing,Unsupervised Machine Translation,WMT2016 English-German,BLEU,2,28.3
Natural Language Processing,Unsupervised Machine Translation,WMT2016 English-Romanian,BLEU,1,21
Natural Language Processing,Unsupervised Machine Translation,WMT2016 English-Romanian,BLEU,2,33.3
Natural Language Processing,Multimodal Machine Translation,Multi30K,BLEU (EN-DE),1,39.7
Natural Language Processing,Multimodal Machine Translation,Multi30K,BLEU (EN-FR),1,61.2
Natural Language Processing,Multimodal Machine Translation,Multi30K,Meteor (EN-DE),1,56.8
Natural Language Processing,Multimodal Machine Translation,Multi30K,Meteor (EN-FR),1,76.4
Natural Language Processing,Multimodal Machine Translation,Multi30K,BLEU (EN-DE),2,39.4
Natural Language Processing,Multimodal Machine Translation,Multi30K,Meteor (EN-DE),2,58.7
"Medical', 'Computer Vision",Lesion Segmentation,ISLES-2015,Dice Score,1,59
"Medical', 'Computer Vision",Lesion Segmentation,ISIC 2017,Mean IoU,1,0.765
"Medical', 'Computer Vision",Lesion Segmentation,ISIC 2018,Dice Score,1,0.8962
"Medical', 'Computer Vision",Lesion Segmentation,ISIC 2018,Dice Score,2,0.895
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS),Dice,1,0.3571
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS),IoU,1,0.254
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS),Precision,1,0.4769
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS),Recall,1,0.3335
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,Dice,1,0.5349
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,Precision,1,0.6331
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,Recall,1,0.5243
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,Dice,2,0.4867
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,IoU,2,0.3723
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,Precision,2,0.6000
"Medical', 'Computer Vision",Lesion Segmentation,Anatomical Tracings of Lesions After Stroke (ATLAS) ,Recall,2,0.4752
"Medical', 'Computer Vision",Lesion Segmentation,BUS 2017 Dataset B,Dice Score,1,0.804
"Medical', 'Computer Vision",Lesion Segmentation,BUS 2017 Dataset B,Dice Score,2,0.7341
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2019,Avg.,1,0.817
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2019,TC,1,0.817
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2019,Avg.,2,0.813
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2019,ET,2,0.737
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2019,TC,2,0.807
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2019,WT,2,0.894
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2018 val,Dice Score,1,91.59
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2015,Dice Score,1,87
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2015,Dice Score,2,85
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2013 leaderboard,Dice Score,1,0.84
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2013 leaderboard,Dice Score,2,0.84
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2014,Dice Score,1,0.8739
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2017 val,Dice Score,1,0.9071
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2017 val,Dice Score,2,0.9050
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2018,Dice Score,1,0.87049
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2018,Dice Score,2,0.8037
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2018,MSD,2,0.9
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS 2018,VS,2,93.08
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2013,Dice Score,1,92.76
"Medical', 'Computer Vision",Brain Tumor Segmentation,BRATS-2013,Dice Score,2,0.9258
"Medical', 'Computer Vision",Brain Segmentation,Brain MRI segmentation,Dice Scoe,1,0.861
"Medical', 'Computer Vision",Brain Segmentation,Brain MRI segmentation,Dice Score,1,0.8690000000000001
"Medical', 'Computer Vision",Brain Segmentation,Brain MRI segmentation,Dice Score,2,0.82
"Medical', 'Computer Vision",Cell Segmentation,PhC-U373,Mean IoU,1,0.9203
"Medical', 'Computer Vision",Cell Segmentation,DIC-HeLa,Mean IoU,1,0.7756
"Medical', 'Computer Vision",Retinal Vessel Segmentation,DRIVE,AUC,1,0.9887
"Medical', 'Computer Vision",Retinal Vessel Segmentation,DRIVE,Accuracy,1,0.9790
"Medical', 'Computer Vision",Retinal Vessel Segmentation,DRIVE,F1 score,1,0.8690
"Medical', 'Computer Vision",Retinal Vessel Segmentation,DRIVE,mIoU,1,0.9762
"Medical', 'Computer Vision",Retinal Vessel Segmentation,DRIVE,AUC,2,0.9886
"Medical', 'Computer Vision",Retinal Vessel Segmentation,DRIVE,F1 score,2,0.8316
"Medical', 'Computer Vision",Retinal Vessel Segmentation,CHASE_DB1,AUC,1,0.9920
"Medical', 'Computer Vision",Retinal Vessel Segmentation,CHASE_DB1,F1 score,1,0.8271
"Medical', 'Computer Vision",Retinal Vessel Segmentation,CHASE_DB1,AUC,2,0.9914
"Medical', 'Computer Vision",Retinal Vessel Segmentation,CHASE_DB1,F1 score,2,0.8957
"Medical', 'Computer Vision",Retinal Vessel Segmentation,CHASE_DB1,mIOU,2,0.9705
"Medical', 'Computer Vision",Retinal Vessel Segmentation,HRF,AUC,1,0.9838
"Medical', 'Computer Vision",Retinal Vessel Segmentation,HRF,F1 score,1,0.8151
"Medical', 'Computer Vision",Retinal Vessel Segmentation,STARE,AUC,1,0.9914
"Medical', 'Computer Vision",Retinal Vessel Segmentation,STARE,F1 score,1,0.8475
"Medical', 'Computer Vision",Retinal Vessel Segmentation,STARE,AUC,2,0.9898
"Medical', 'Computer Vision",Retinal Vessel Segmentation,STARE,F1 score,2,0.8373
"Medical', 'Computer Vision",3D Medical Imaging Segmentation,TCIA Pancreas-CT,Dice Score,1,81.3
"Medical', 'Computer Vision",3D Medical Imaging Segmentation,TCIA Pancreas-CT,Dice Score,2,76.8
"Medical', 'Computer Vision",Liver Segmentation,LiTS2017,Dice,1,94.23
"Medical', 'Computer Vision",Liver Segmentation,LiTS2017,IoU,1,89.46
"Medical', 'Computer Vision",Liver Segmentation,LiTS2017,Dice,2,92.27
"Medical', 'Computer Vision",Liver Segmentation,LiTS2017,IoU,2,85.6
"Medical', 'Computer Vision",Brain Image Segmentation,FIB-25 Whole Test,VOI,1,1.071
"Medical', 'Computer Vision",Brain Image Segmentation,SegEM,IED,1,4.839
"Medical', 'Computer Vision",Brain Image Segmentation,T1-weighted MRI,Dice Score,1,81.5
"Medical', 'Computer Vision",Brain Image Segmentation,FIB-25 Synaptic Sites,VOI,1,2.151
"Medical', 'Computer Vision",Brain Image Segmentation,Brain Tumor,IoU,1,91.21
"Medical', 'Computer Vision",Brain Image Segmentation,CREMI,CREMI Score,1,0.289
"Medical', 'Computer Vision",Brain Image Segmentation,CREMI,VOI,1,0.606
"Medical', 'Computer Vision",Lung Nodule Segmentation,LIDC-IDRI,Dice,1,75.86
"Medical', 'Computer Vision",Lung Nodule Segmentation,LIDC-IDRI,IoU,1,77.62
"Medical', 'Computer Vision",Lung Nodule Segmentation,LIDC-IDRI,IoU,2,77.24
"Medical', 'Computer Vision",Lung Nodule Segmentation,Lung Nodule ,Dice Score,1,0.994
"Medical', 'Computer Vision",Lung Nodule Segmentation,Montgomery County,Accuracy,1,0.9865
"Medical', 'Computer Vision",Lung Nodule Segmentation,Montgomery County,mIoU,1,0.942
"Medical', 'Computer Vision",Lung Nodule Segmentation,LUNA,AUC,1,0.9946
"Medical', 'Computer Vision",Lung Nodule Segmentation,LUNA,F1 score,1,0.9904
"Medical', 'Computer Vision",Lung Nodule Segmentation,LUNA,AUC,2,0.9849
"Medical', 'Computer Vision",Lung Nodule Segmentation,LUNA,F1 score,2,0.9690
"Medical', 'Computer Vision",Lung Nodule Segmentation,NIH,AVD,1,0.262
"Medical', 'Computer Vision",Lung Nodule Segmentation,NIH,Dice Score,1,0.962
"Medical', 'Computer Vision",Lung Nodule Segmentation,NIH,Precision,1,0.969
"Medical', 'Computer Vision",Lung Nodule Segmentation,NIH,Recall,1,0.956
"Medical', 'Computer Vision",Lung Nodule Segmentation,NIH,VS,1,0.985
"Medical', 'Computer Vision",Iris Segmentation,MICHE,F1,1,91.5
"Medical', 'Computer Vision",Iris Segmentation,MICHE,mIoU,1,85.07
"Medical', 'Computer Vision",Iris Segmentation,CASIA,F1,1,94.30
"Medical', 'Computer Vision",Iris Segmentation,CASIA,mIoU,1,89.4
"Medical', 'Computer Vision",Iris Segmentation,UBIRIS,F1,1,91.82
"Medical', 'Computer Vision",Iris Segmentation,UBIRIS,mIoU,1,85.39
"Medical', 'Computer Vision",Electron Microscopy Image Segmentation,EMOrganelles,Average IOU,1,0.7
"Medical', 'Computer Vision",Electron Microscopy Image Segmentation,3D Platelet EM,Average IOU,1,44.6
"Medical', 'Computer Vision",Electron Microscopy Image Segmentation,SNEMI3D,AUC,1,0.8953
"Medical', 'Computer Vision",Electron Microscopy Image Segmentation,SNEMI3D,AUC,2,0.8676
"Medical', 'Computer Vision",Nuclear Segmentation,Cell17,Dice,1,0.7088
"Medical', 'Computer Vision",Nuclear Segmentation,Cell17,F1-score,1,0.8216
"Medical', 'Computer Vision",Nuclear Segmentation,Cell17,Hausdorff,1,11.3141
"Medical', 'Computer Vision",Nuclear Segmentation,Cell17,Dice,2,0.707
"Medical', 'Computer Vision",Nuclear Segmentation,Cell17,F1-score,2,0.8004
"Medical', 'Computer Vision",Nuclear Segmentation,Cell17,Hausdorff,2,12.6723
"Medical', 'Computer Vision",Skin Cancer Segmentation,PH2,IoU,1,93.61
"Medical', 'Computer Vision",Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,AUC,1,0.9419
"Medical', 'Computer Vision",Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,F1 score,1,0.8920
"Medical', 'Computer Vision",Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,AUC,2,0.9396
"Medical', 'Computer Vision",Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,F1 score,2,0.8799
"Medical', 'Computer Vision",Volumetric Medical Image Segmentation,PROMISE 2012,Dice Score,1,0.869
"Medical', 'Computer Vision",Volumetric Medical Image Segmentation,PROMISE 2012,Dice Score,2,0.780
"Medical', 'Computer Vision",Infant Brain Mri Segmentation,iSEG 2017 Challenge,Dice Score,1,0.9243
Computer Vision,Image-to-Image Translation,Cityscapes Labels-to-Photo,Class IOU,1,0.18
Computer Vision,Image-to-Image Translation,Cityscapes Labels-to-Photo,Per-class Accuracy,1,25
Computer Vision,Image-to-Image Translation,Cityscapes Labels-to-Photo,Per-pixel Accuracy,1,71
Computer Vision,Image-to-Image Translation,Cityscapes Labels-to-Photo,Class IOU,2,
Computer Vision,Image-to-Image Translation,Cityscapes Labels-to-Photo,Per-class Accuracy,2,17
Computer Vision,Image-to-Image Translation,Cityscapes Labels-to-Photo,Per-pixel Accuracy,2,52
Computer Vision,Image-to-Image Translation,ADE20K Labels-to-Photos,Accuracy,1,85.5
Computer Vision,Image-to-Image Translation,ADE20K Labels-to-Photos,FID,1,31.9
Computer Vision,Image-to-Image Translation,ADE20K Labels-to-Photos,mIoU,1,49
Computer Vision,Image-to-Image Translation,ADE20K Labels-to-Photos,FID,2,28.3
Computer Vision,Image-to-Image Translation,ADE20K Labels-to-Photos,mIoU,2,48.8
Computer Vision,Image-to-Image Translation,ADE-Indoor Labels-to-Photo,FID,1,48.15
Computer Vision,Image-to-Image Translation,Cityscapes Photo-to-Labels,Class IOU,1,0.32
Computer Vision,Image-to-Image Translation,Cityscapes Photo-to-Labels,Per-class Accuracy,1,40
Computer Vision,Image-to-Image Translation,Cityscapes Photo-to-Labels,Per-pixel Accuracy,1,85
Computer Vision,Image-to-Image Translation,Cityscapes Photo-to-Labels,Class IOU,2,0.16
Computer Vision,Image-to-Image Translation,Cityscapes Photo-to-Labels,Per-class Accuracy,2,22
Computer Vision,Image-to-Image Translation,Cityscapes Photo-to-Labels,Per-pixel Accuracy,2,58
Computer Vision,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,mAP,1,38.8
Computer Vision,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,mAP,2,36.9
Computer Vision,Image-to-Image Translation,horse2zebra,Kernel Inception Distance,1,7.06
Computer Vision,Image-to-Image Translation,horse2zebra,Frechet Inception Distance,2,53.0
Computer Vision,Image-to-Image Translation,horse2zebra,Number of params,2,15.9M
Computer Vision,Image-to-Image Translation,anime-to-selfie,Kernel Inception Distance,1,10.23
Computer Vision,Image-to-Image Translation,anime-to-selfie,Kernel Inception Distance,2,11.52
Computer Vision,Image-to-Image Translation,portrait2photo,Kernel Inception Distance,1,1.69
Computer Vision,Image-to-Image Translation,SYNTHIA Fall-to-Winter,Per-pixel Accuracy,1,92.1
Computer Vision,Image-to-Image Translation,SYNTHIA Fall-to-Winter,fwIOU,1,85.7
Computer Vision,Image-to-Image Translation,SYNTHIA Fall-to-Winter,mIoU,1,63.3
Computer Vision,Image-to-Image Translation,SYNTHIA Fall-to-Winter,mIoU,2,59.6
Computer Vision,Image-to-Image Translation,dog2cat,Kernel Inception Distance,1,8.15
Computer Vision,Image-to-Image Translation,Aerial-to-Map,Class IOU,1,0.26
Computer Vision,Image-to-Image Translation,Aerial-to-Map,Per-class Accuracy,1,46
Computer Vision,Image-to-Image Translation,Aerial-to-Map,Per-pixel Accuracy,1,70
Computer Vision,Image-to-Image Translation,Aerial-to-Map,Class IOU,2,0.09
Computer Vision,Image-to-Image Translation,Aerial-to-Map,Per-class Accuracy,2,22
Computer Vision,Image-to-Image Translation,Aerial-to-Map,Per-pixel Accuracy,2,42
Computer Vision,Image-to-Image Translation,GTAV-to-Cityscapes Labels,mIoU,1,57.5
Computer Vision,Image-to-Image Translation,GTAV-to-Cityscapes Labels,mIoU,2,49.9
Computer Vision,Image-to-Image Translation,Zebra and Horses,Kernel Inception Distance,1,5.8
Computer Vision,Image-to-Image Translation,Object Transfiguration (sheep-to-giraffe),classification score,1,78.1
Computer Vision,Image-to-Image Translation,Object Transfiguration (sheep-to-giraffe),classification score,2,59.4
Computer Vision,Image-to-Image Translation,selfie2anime,DFID,1,35.6
Computer Vision,Image-to-Image Translation,selfie2anime,FID,1,34.4
Computer Vision,Image-to-Image Translation,selfie2anime,LPIPS,1,0.505
Computer Vision,Image-to-Image Translation,selfie2anime,DFID,2,56.2
Computer Vision,Image-to-Image Translation,selfie2anime,FID,2,38.1
Computer Vision,Image-to-Image Translation,selfie2anime,LPIPS,2,0.43
Computer Vision,Image-to-Image Translation,CelebA-HQ,FID,1,13.73
Computer Vision,Image-to-Image Translation,CelebA-HQ,LPIPS,1,0.428
Computer Vision,Image-to-Image Translation,CelebA-HQ,FID,2,14.3
Computer Vision,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,FID,1,48.6
Computer Vision,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,mIoU,1,40.4
Computer Vision,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,Accuracy,2,82.9
Computer Vision,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,FID,2,63.3
Computer Vision,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,mIoU,2,30.8
Computer Vision,Image-to-Image Translation,Apples and Oranges,Kernel Inception Distance,1,4.4
Computer Vision,Image-to-Image Translation,selfie-to-anime,Kernel Inception Distance,1,11.40
Computer Vision,Image-to-Image Translation,selfie-to-anime,Kernel Inception Distance,2,11.61
Computer Vision,Image-to-Image Translation,RaFD,Classification Error,1,2.12
Computer Vision,Image-to-Image Translation,RaFD,Classification Error,2,4.10
Computer Vision,Image-to-Image Translation,vangogh2photo,Kernel Inception Distance,1,5.61
Computer Vision,Image-to-Image Translation,vangogh2photo,Frechet Inception Distance,2,134.4
Computer Vision,Image-to-Image Translation,vangogh2photo,Number of Params,2,15.9M
Computer Vision,Image-to-Image Translation,Deep-Fashion,FID,1,14.4
Computer Vision,Image-to-Image Translation,photo2vangogh,Kernel Inception Distance,1,4.28
Computer Vision,Image-to-Image Translation,photo2vangogh,Frechet Inception Distance,2,151.4
Computer Vision,Image-to-Image Translation,photo2vangogh,Number of params,2,28.2M
Computer Vision,Image-to-Image Translation,zebra2horse,Kernel Inception Distance,1,7.47
Computer Vision,Image-to-Image Translation,zebra2horse,Frechet Inception Distance,2,110.5
Computer Vision,Image-to-Image Translation,zebra2horse,Number of params,2,28.2M
Computer Vision,Image-to-Image Translation,KITTI Object Tracking Evaluation 2012,Average PSNR,1,21.12
Computer Vision,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,FID,1,17.0
Computer Vision,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,mIoU,1,44.1
Computer Vision,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,Accuracy,2,71.5
Computer Vision,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,FID,2,19.1
Computer Vision,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,mIoU,2,42.1
Computer Vision,Image-to-Image Translation,AFHQ,FID,1,24.4
Computer Vision,Image-to-Image Translation,AFHQ,LPIPS,1,0.524
Computer Vision,Image-to-Image Translation,cat2dog,DFID,1,26.1
Computer Vision,Image-to-Image Translation,cat2dog,FID,1,26.9
Computer Vision,Image-to-Image Translation,cat2dog,DFID,2,53.6
Computer Vision,Image-to-Image Translation,cat2dog,FID,2,44.2
Computer Vision,Image-to-Image Translation,SYNTHIA-to-Cityscapes,mIoU (13 classes),1,62.0
Computer Vision,Image-to-Image Translation,SYNTHIA-to-Cityscapes,mIoU (13 classes),2,57.0
Computer Vision,Image-to-Image Translation,2017_test set,10 way 1~2 shot,1,457
Computer Vision,Image-to-Image Translation,photo2portrait,Kernel Inception Distance,1,1.79
Computer Vision,Image Inpainting,FFHQ 512 x 512,FID,1,3.7
Computer Vision,Image Inpainting,FFHQ 512 x 512,P-IDS,1,16.6
Computer Vision,Image Inpainting,FFHQ 512 x 512,U-IDS,1,29.4
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,LPIPS,1,0.19
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,PSNR,1,21.33
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,RMSE,1,24.28
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,SSIM,1,0.84
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,LPIPS,2,0.24
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,PSNR,2,19.67
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,RMSE,2,30.75
Computer Vision,Image Inpainting,FFHQ 1024 x 1024,SSIM,2,0.82
Computer Vision,Image Inpainting,Places2 val,free-form mask l1 err,1,
Computer Vision,Image Inpainting,Places2 val,free-form mask l2 err,1,1.6
Computer Vision,Image Inpainting,Places2 val,rect mask l1 error,1,8.6
Computer Vision,Image Inpainting,Places2 val,rect mask l2 err,1,2.0
Computer Vision,Image Inpainting,Places2 val,free-form mask l1 err,2,17.2
Computer Vision,Image Inpainting,Places2 val,free-form mask l2 err,2,4.7
Computer Vision,Image Inpainting,Places2 val,rect mask l1 error,2,8.6
Computer Vision,Image Inpainting,Places2 val,rect mask l2 err,2,2.1
Computer Vision,Image Inpainting,Paris StreetView,10-20% Mask PSNR,1,32.67
Computer Vision,Image Inpainting,Paris StreetView,20-30% Mask PSNR,1,30.32
Computer Vision,Image Inpainting,Paris StreetView,30-40% Mask PSNR,1,24.85
Computer Vision,Image Inpainting,Paris StreetView,40-50% Mask PSNR,1,23.10
Computer Vision,Image Inpainting,Paris StreetView,10-20% Mask PSNR,2,28.73
Computer Vision,Image Inpainting,Paris StreetView,20-30% Mask PSNR,2,26.16
Computer Vision,Image Inpainting,Paris StreetView,30-40% Mask PSNR,2,24.26
Computer Vision,Image Inpainting,Paris StreetView,40-50% Mask PSNR,2,22.62
Computer Vision,Image Inpainting,Apolloscape Inpainting,RMSE,1,9.633
Computer Vision,Image Inpainting,Apolloscape,MAE,1,6.135
Computer Vision,Image Inpainting,Apolloscape,PSNR,1,21.631
Computer Vision,Image Inpainting,Apolloscape,RMSE,1,9.633
Computer Vision,Image Inpainting,Apolloscape,SSIM,1,0.895
Computer Vision,Image Inpainting,StreetView,SSIM,1,0.79
Computer Vision,Image Inpainting,Places2,FID,1,7.9
Computer Vision,Image Inpainting,Places2,P-IDS,1,13.3
Computer Vision,Image Inpainting,Places2,U-IDS,1,27.4
Computer Vision,Image Inpainting,Places2,40-50% Mask PSNR,2,28.89
Computer Vision,Image Inpainting,Places2,L1-loss,2,2.23
Computer Vision,Image Inpainting,Places2,SSIM,2,92.21
Computer Vision,Image Inpainting,Places2,free-form mask l2 err,2,0.36
Computer Vision,Conditional Image Generation,COCO-Animals,FID,1,13.73
Computer Vision,Conditional Image Generation,COCO-Animals,IS,1,12.29
Computer Vision,Conditional Image Generation,COCO-Animals,FID,2,16.37
Computer Vision,Conditional Image Generation,COCO-Animals,IS,2,11.77
Computer Vision,Conditional Image Generation,ImageNet 128x128,FID,1,3.36
Computer Vision,Conditional Image Generation,ImageNet 128x128,Inception score,1,148.2
Computer Vision,Conditional Image Generation,ImageNet 128x128,FID,2,5.7
Computer Vision,Conditional Image Generation,ImageNet 128x128,Inception score,2,124.5
Computer Vision,Conditional Image Generation,CIFAR-100,FID,1,7.15
Computer Vision,Conditional Image Generation,CIFAR-100,Inception Score,1,9.74
Computer Vision,Conditional Image Generation,CIFAR-100,FID,2,7.22
Computer Vision,Conditional Image Generation,CIFAR-100,Inception Score,2,9.34
Computer Vision,Conditional Image Generation,ImageNet64x64,FID,1,9.07
Computer Vision,Conditional Image Generation,ImageNet64x64,Inception Score,1,37.10
Computer Vision,Conditional Image Generation,ImageNet64x64,FID,2,9.67
Computer Vision,Conditional Image Generation,ImageNet64x64,Inception Score,2,25.96
Computer Vision,Conditional Image Generation,CIFAR-10,FID,1,3.6
Computer Vision,Conditional Image Generation,CIFAR-10,Inception score,1,10.21
Computer Vision,Conditional Image Generation,CIFAR-10,FID,2,14.73
Computer Vision,Conditional Image Generation,CIFAR-10,Inception score,2,10.14
Computer Vision,Text-to-Image Generation,GeNeVA (i-CLEVR),F1-score,1,88.39
Computer Vision,Text-to-Image Generation,GeNeVA (i-CLEVR),rsim,1,74.02
Computer Vision,Text-to-Image Generation,GeNeVA (CoDraw),F1-score,1,58.83
Computer Vision,Text-to-Image Generation,GeNeVA (CoDraw),rsim,1,35.41
Computer Vision,Text-to-Image Generation,Oxford 102 Flowers,FID,1,48.68
Computer Vision,Text-to-Image Generation,Oxford 102 Flowers,Inception score,1,3.26
Computer Vision,Text-to-Image Generation,Oxford 102 Flowers,FID,2,55.28
Computer Vision,Text-to-Image Generation,Oxford 102 Flowers,Inception score,2,3.20
Computer Vision,Text-to-Image Generation,CUB,Inception score,1,4.86
Computer Vision,Text-to-Image Generation,CUB,FID,2,14.38
Computer Vision,Text-to-Image Generation,CUB,Inception score,2,4.77
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,Acc,1,20.4
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,FID,1,101.42
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,LPIPS,1,0.461
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,Real,1,21.0
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,Acc,2,18.4
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,FID,2,106.37
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,LPIPS,2,0.456
Computer Vision,Text-to-Image Generation,Multi-Modal-CelebA-HQ,Real,2,22.6
Computer Vision,Text-to-Image Generation,COCO,FID,1,20.79
Computer Vision,Text-to-Image Generation,COCO,Inception score,1,33.34
Computer Vision,Text-to-Image Generation,COCO,FID,2,23.93
Computer Vision,Text-to-Image Generation,COCO,Inception score,2,25.70
Computer Vision,Pose Transfer,Market-1501,DS,1,0.74
Computer Vision,Pose Transfer,Market-1501,IS,1,3.323
Computer Vision,Pose Transfer,Market-1501,PCKh,1,0.94
Computer Vision,Pose Transfer,Market-1501,SSIM,1,0.311
Computer Vision,Pose Transfer,Market-1501,mask-IS,1,3.773
Computer Vision,Pose Transfer,Market-1501,mask-SSIM,1,0.811
Computer Vision,Pose Transfer,Market-1501,IS,2,3.506
Computer Vision,Pose Transfer,Market-1501,PCKh,2,0.93
Computer Vision,Pose Transfer,Market-1501,SSIM,2,0.313
Computer Vision,Pose Transfer,Market-1501,mask-IS,2,3.872
Computer Vision,Pose Transfer,Market-1501,mask-SSIM,2,0.816
Computer Vision,Pose Transfer,Deep-Fashion,IS,1,3.476
Computer Vision,Pose Transfer,Deep-Fashion,PCKh,1,0.95
Computer Vision,Pose Transfer,Deep-Fashion,SSIM,1,0.778
Computer Vision,Pose Transfer,Deep-Fashion,IS,2,3.430
Computer Vision,Pose Transfer,Deep-Fashion,PCKh,2,0.97
Computer Vision,Pose Transfer,Deep-Fashion,SSIM,2,0.778
Computer Vision,Layout-to-Image Generation,Visual Genome 256x256,FID,1,36.4
Computer Vision,Layout-to-Image Generation,Visual Genome 256x256,Inception Score,1,11
Computer Vision,Layout-to-Image Generation,Visual Genome 256x256,LPIPS,1,0.51
Computer Vision,Layout-to-Image Generation,Visual Genome 256x256,FID,2,40.85
Computer Vision,Layout-to-Image Generation,Visual Genome 256x256,Inception Score,2,14.7
Computer Vision,Layout-to-Image Generation,COCO-Stuff 256x256,FID,1,41.65
Computer Vision,Layout-to-Image Generation,COCO-Stuff 256x256,Inception Score,1,17.8
Computer Vision,Layout-to-Image Generation,COCO-Stuff 256x256,FID,2,54.7
Computer Vision,Layout-to-Image Generation,COCO-Stuff 256x256,Inception Score,2,15.6
Computer Vision,Layout-to-Image Generation,COCO-Stuff 256x256,LPIPS,2,0.44
Computer Vision,Layout-to-Image Generation,Visual Genome 64x64,FID,1,20.27
Computer Vision,Layout-to-Image Generation,Visual Genome 64x64,Inception Score,1,9.3
Computer Vision,Layout-to-Image Generation,Visual Genome 64x64,FID,2,31.25
Computer Vision,Layout-to-Image Generation,Visual Genome 64x64,Inception Score,2,8.1
Computer Vision,Layout-to-Image Generation,COCO-Stuff 64x64,FID,1,29.57
Computer Vision,Layout-to-Image Generation,COCO-Stuff 64x64,Inception Score,1,10.8
Computer Vision,Layout-to-Image Generation,COCO-Stuff 64x64,FID,2,34.31
Computer Vision,Layout-to-Image Generation,COCO-Stuff 64x64,Inception Score,2,9.8
Computer Vision,Layout-to-Image Generation,Visual Genome 128x128,FID,1,28.26
Computer Vision,Layout-to-Image Generation,Visual Genome 128x128,Inception Score,1,12.3
Computer Vision,Layout-to-Image Generation,Visual Genome 128x128,SceneFID,1,9.63
Computer Vision,Layout-to-Image Generation,Visual Genome 128x128,FID,2,29.00
Computer Vision,Layout-to-Image Generation,Visual Genome 128x128,Inception Score,2,10.71
Computer Vision,Layout-to-Image Generation,COCO-Stuff 128x128,FID,1,24.76
Computer Vision,Layout-to-Image Generation,COCO-Stuff 128x128,Inception Score,1,14.21
Computer Vision,Layout-to-Image Generation,COCO-Stuff 128x128,FID,2,29.65
Computer Vision,Layout-to-Image Generation,COCO-Stuff 128x128,Inception Score,2,13.8
Computer Vision,Layout-to-Image Generation,COCO-Stuff 128x128,SceneFID,2,20.03
"Medical', 'Computer Vision",Retinal OCT Disease Classification,Srinivasan2014,Acc,1,100
"Medical', 'Computer Vision",Retinal OCT Disease Classification,Srinivasan2014,Acc,2,100
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Acc,1,99.8
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Sensitivity,1,99.8
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Acc,2,99.7
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Sensitivity,2,99.7
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (ABPA),1,0.687
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (Aspergillus),1,0.640
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (Diabetes),1,0.771
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (E. Coli),1,0.701
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (I. Obstruction),1,0.577
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (K. Pneumonia),1,0.718
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,I. Obstruction,1,0.577
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (ABPA),2,0.685
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (Aspergillus),2,0.641
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (Diabetes),2,0.764
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (E. Coli),2,0.697
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (I. Obstruction),2,0.578
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,AUC (K. Pneumonia),2,0.715
"Medical', 'Computer Vision",Disease Trajectory Forecasting,UK CF trust,I. Obstruction,2,0.578
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,MAP,1,55.9
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,Rank-1,1,72.4
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,Rank-10,1,87.7
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,Rank-5,1,84
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,MAP,2,40.4
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,Rank-1,2,63.3
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,Rank-10,2,80.4
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID,Rank-5,2,75.8
Computer Vision,Unsupervised Person Re-Identification,MSMT17->Market-1501,Rank-1,1,71.1
Computer Vision,Unsupervised Person Re-Identification,MSMT17->Market-1501,Rank-10,1,86.4
Computer Vision,Unsupervised Person Re-Identification,MSMT17->Market-1501,Rank-5,1,83.3
Computer Vision,Unsupervised Person Re-Identification,MSMT17->Market-1501,mAP,1,52.7
Computer Vision,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,Rank-1,1,78.0
Computer Vision,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,Rank-10,1,88.8
Computer Vision,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,Rank-5,1,92.5
Computer Vision,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,mAP,1,65.1
Computer Vision,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,Rank-1,2,76.2
Computer Vision,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,mAP,2,58.3
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,Rank-1,1,88.3
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,mAP,1,65.1
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,Rank-1,2,85.3
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,mAP,2,65.2
Computer Vision,Unsupervised Person Re-Identification,DukeMTMCreID, Rank-1,1,80.0
Computer Vision,Unsupervised Person Re-Identification,Market-1501->MSMT17,Top-1 (%),1,49.2
Computer Vision,Unsupervised Person Re-Identification,Market-1501->MSMT17,mAP,1,22.9
Computer Vision,Unsupervised Person Re-Identification,Market-1501->MSMT17,Rank-1,2,49.7
Computer Vision,Unsupervised Person Re-Identification,Market-1501->MSMT17,mAP,2,20.7
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,Rank-1,1,70.1
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,Rank-10,1,88.6
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,Rank-5,1,84.1
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,mAP,1,43.3
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,Rank-1,2,46.4
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,Rank-10,2,68.0
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,Rank-5,2,62.3
Computer Vision,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,mAP,2,26.2
Computer Vision,Unsupervised Person Re-Identification,Market-1501,MAP,1,71.5
Computer Vision,Unsupervised Person Re-Identification,Market-1501,Rank-1,1,87.5
Computer Vision,Unsupervised Person Re-Identification,Market-1501,Rank-10,1,96.8
Computer Vision,Unsupervised Person Re-Identification,Market-1501,Rank-5,1,95.2
Computer Vision,Unsupervised Person Re-Identification,Market-1501,MAP,2,43
Computer Vision,Unsupervised Person Re-Identification,Market-1501,Rank-1,2,75.1
Computer Vision,Unsupervised Person Re-Identification,Market-1501,Rank-10,2,91.6
Computer Vision,Unsupervised Person Re-Identification,Market-1501,Rank-5,2,87.6
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,Rank-1,1,56.5
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,mAP,1,24.4
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,Rank-1,2,43.6
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,Rank-10,2,61.8
Computer Vision,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,mAP,2,23.6
Computer Vision,Generalizable Person Re-identification,Market-1501->DukeMTMC-reID,Rank-1,1,48.8
Computer Vision,Generalizable Person Re-identification,Market-1501->DukeMTMC-reID,mAP,1,28.7
Computer Vision,Generalizable Person Re-identification,Market-1501->MSMT17,Rank-1,1,22.6
Computer Vision,Generalizable Person Re-identification,Market-1501->MSMT17,mAP,1,7.0
Computer Vision,Generalizable Person Re-identification,DukeMTMC-reID->Market-1501,Rank-1,1,58.6
Computer Vision,Generalizable Person Re-identification,DukeMTMC-reID->Market-1501,mAP,1,27.2
Computer Vision,Generalizable Person Re-identification,DukeMTMC-reID->MSMT17,Rank-1,1,29.0
Computer Vision,Generalizable Person Re-identification,DukeMTMC-reID->MSMT17,mAP,1,8.9
Computer Vision,Generalizable Person Re-identification,MSMT17->Market-1501,Rank-1,1,72.6
Computer Vision,Generalizable Person Re-identification,MSMT17->Market-1501,mAP,1,43.1
Computer Vision,Generalizable Person Re-identification,MSMT17->DukeMTMC-reID,Rank-1,1,69.4
Computer Vision,Generalizable Person Re-identification,MSMT17->DukeMTMC-reID,mAP,1,52.6
Computer Vision,Cross-Modal  Person Re-Identification,SYSU-MM01,mAP (All-search & Single-shot),1,57.51
Computer Vision,Cross-Modal  Person Re-Identification,SYSU-MM01,rank1,1,61.68
Computer Vision,Cross-Modal  Person Re-Identification,SYSU-MM01,mAP (All-search & Single-shot),2,55.13
Computer Vision,Cross-Modal  Person Re-Identification,SYSU-MM01,rank1,2,57.34
Computer Vision,Cross-Modal  Person Re-Identification,RegDB,mAP(V2T),1,83.28
Computer Vision,Cross-Modal  Person Re-Identification,RegDB,rank1(V2T),1,91.05
Computer Vision,Cross-Modal  Person Re-Identification,RegDB,mAP(V2T),2,73.78
Computer Vision,Cross-Modal  Person Re-Identification,RegDB,rank1(V2T),2,83.92
Computer Vision,3D Room Layouts From A Single RGB Panorama,Realtor360,3DIoU,1,77.20
Computer Vision,3D Room Layouts From A Single RGB Panorama,Realtor360,3DIoU,2,62.77
Computer Vision,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,3DIoU,1,79.79
Computer Vision,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,3DIoU,2,79.36
Computer Vision,3D Room Layouts From A Single RGB Panorama,PanoContext,3DIoU,1,82.17
Computer Vision,3D Room Layouts From A Single RGB Panorama,PanoContext,3DIoU,2,78.79
Computer Vision,Object Tracking,BIRDSAI - ICVGIP 2020,Animals,1,0.64
Computer Vision,Object Tracking,BIRDSAI - ICVGIP 2020,Humans,1,0.14
Computer Vision,Object Tracking,BIRDSAI - ICVGIP 2020,Animals,2,0.61
Computer Vision,Object Tracking,BIRDSAI - ICVGIP 2020,Humans,2,0.05
Computer Vision,Action Classification,AViD,Accuracy,1,53.8
Computer Vision,Action Classification,AViD,Accuracy,2,50.9
Computer Vision,Action Classification,Jester test,Accuracy,1,97.09
Computer Vision,Action Classification,Charades,MAP,1,66.3
Computer Vision,Action Classification,Charades,MAP,2,63.2
Computer Vision,Action Classification,ActivityNet-1.2,mAP,1,93.2
Computer Vision,Action Classification,ActivityNet-1.2,mAP,2,92.4
Computer Vision,Action Classification,Moments in Time,Top 1 Accuracy,1,41.1
Computer Vision,Action Classification,Moments in Time,Top 5 Accuracy,1,67.7
Computer Vision,Action Classification,Moments in Time,Top 1 Accuracy,2,40.2
Computer Vision,Action Classification,Kinetics-400,Vid acc@1,1,84.9
Computer Vision,Action Classification,Kinetics-400,Vid acc@5,1,96.7
Computer Vision,Action Classification,Kinetics-400,Vid acc@1,2,84.8
Computer Vision,Action Classification,Kinetics-400,Vid acc@5,2,95.8
Computer Vision,Action Classification,YouCook2,Object Top 5 Accuracy,1,33.7
Computer Vision,Action Classification,YouCook2,Object Top-1 Accuracy,1,13.1
Computer Vision,Action Classification,YouCook2,Verb Top-1 Accuracy,1,3.2
Computer Vision,Action Classification,YouCook2,Verb Top-5 Accuracy,1,43.3
Computer Vision,Action Classification,Toyota Smarthome dataset,CS,1,71.0
Computer Vision,Action Classification,Toyota Smarthome dataset,CV2,1,58.1
Computer Vision,Action Classification,Toyota Smarthome dataset,CS,2,63.6
Computer Vision,Action Classification,MiniKinetics,Top-1 Accuracy,1,73.5
Computer Vision,Action Classification,Kinetics-600,Top-1 Accuracy,1,86.1
Computer Vision,Action Classification,Kinetics-600,Top-5 Accuracy,1,97.3
Computer Vision,Action Classification,Kinetics-600,Top-1 Accuracy,2,85.8
Computer Vision,Action Classification,Kinetics-600,Top-5 Accuracy,2,96.5
Computer Vision,Action Classification,THUMOS'14,mAP,1,86.9
Computer Vision,Action Classification,Kinetics-700,Top-1 Accuracy,1,72.3
Computer Vision,Action Classification,Kinetics-700,Top-1 Accuracy,2,71.7
Computer Vision,Action Classification,THUMOS’14,mAP,1,86.9
Computer Vision,Action Classification,THUMOS’14,mAP,2,85.6
Computer Vision,Video Object Segmentation,DAVIS 2016,F-Score,1,84.7
Computer Vision,Video Object Segmentation,DAVIS 2016,Jaccard (Mean),1,84.3
Computer Vision,Video Object Segmentation,DAVIS 2016,F-Score,2,81.8
Computer Vision,Video Object Segmentation,DAVIS 2016,Jaccard (Mean),2,83.4
Computer Vision,Video Object Segmentation,DAVIS-2017,J&F,1,62.2
Computer Vision,Video Object Segmentation,DAVIS-2017,mIoU,1,59
Computer Vision,Video Object Segmentation,FBMS,F-Score,1,82.3
Computer Vision,Video Prediction,KTH,LPIPS,1,0.139
Computer Vision,Video Prediction,KTH,PSNR,1,28.37
Computer Vision,Video Prediction,Moving MNIST,MAE,1,70.3
Computer Vision,Video Prediction,Moving MNIST,MSE,1,24.4
Computer Vision,Video Prediction,Moving MNIST,SSIM,1,0.947
Computer Vision,Video Prediction,Moving MNIST,MSE,2,48.4
Computer Vision,Video Prediction,Moving MNIST,SSIM,2,0.891
Computer Vision,Video Prediction,CMU Mocap-1,Test Error,1,15.99
Computer Vision,Video Prediction,CMU Mocap-1,Test Error,2,93.07
Computer Vision,Video Prediction,CMU Mocap-2,Test Error,1,4.03
Computer Vision,Video Prediction,CMU Mocap-2,Test Error,2,5.98
Computer Vision,Video Prediction,Colored dSprites,MSE,1,4.5
Computer Vision,Video Prediction,Human3.6M,MAE,1,1620
Computer Vision,Video Prediction,Human3.6M,MSE,1,369
Computer Vision,Video Prediction,Human3.6M,SSIM,1,0.901
Computer Vision,Video Prediction,Human3.6M,MAE,2,1782.8
Computer Vision,Video Prediction,Human3.6M,MSE,2,429.9
Computer Vision,Video Prediction,Human3.6M,SSIM,2,0.790
Computer Vision,Video Prediction,Sprites,MSE,1,61.6
Computer Vision,Video Prediction,"Kinetics-600 12 frames, 64x64",FVD score,1,82.45
Computer Vision,Video Prediction,YouTube-8M,Average PSNR,1,37.15
Computer Vision,Video Classification,Multimodal PISA,Accuracy (%),1,73.95
Computer Vision,Video Classification,Charades,mAP,1,38.2
Computer Vision,Video Classification,Home Action Genome,Accuracy (%),1,24.7
Computer Vision,Video Classification,Kinetics,Top-1,1,77.6
Computer Vision,Video Classification,Something-Something V2,Top-5 Accuracy,1,91
Computer Vision,Video Classification,Something-Something V1,Top-5 Accuracy,1,84
Computer Vision,Video Classification,YouTube-8M,Hit@1,1,87.7
Computer Vision,Video Classification,YouTube-8M,Global Average Precision,2,81.1
Computer Vision,Video Classification,YouTube-8M,Hit@1,2,86.8
Computer Vision,Video Classification,YouTube-8M,mAP,2,41.4
Computer Vision,Video Generation,"Kinetics-600 48 frames, 64x64",FID,1,12.92
Computer Vision,Video Generation,"Kinetics-600 48 frames, 64x64",Inception Score,1,219.05
Computer Vision,Video Generation,"Kinetics-600 12 frames, 64x64",FID,1,0.91
Computer Vision,Video Generation,"Kinetics-600 12 frames, 64x64",Inception Score,1,129.9
Computer Vision,Video Generation,BAIR Robot Pushing,FVD score,1,94
Computer Vision,Video Generation,BAIR Robot Pushing,FVD score,2,103.3
Computer Vision,Video Generation,TrailerFaces,FID,1,404.1
Computer Vision,Video Generation,"UCF-101 16 frames, Unconditional, Single GPU",Inception Score,1,22.91
Computer Vision,Video Generation,"UCF-101 16 frames, Unconditional, Single GPU",Inception Score,2,21.45
Computer Vision,Video Generation,"Kinetics-600 12 frames, 128x128",FID,1,2.16
Computer Vision,Video Generation,"UCF-101 16 frames, 64x64, Unconditional",Inception Score,1,15.20
Computer Vision,Video Generation,"UCF-101 16 frames, 64x64, Unconditional",Inception Score,2,13.62
Computer Vision,Video Generation,"UCF-101 16 frames, 128x128, Unconditional",Inception Score,1,28.87
Computer Vision,Video Generation,"UCF-101 16 frames, 128x128, Unconditional",Inception Score,2,27.38
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video Mean Rank,1,14.6
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video Median Rank,1,2
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video R@1,1,45.6
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video R@10,1,81.7
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video R@5,1,72.6
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text Mean Rank,1,10.2
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text Median Rank,1,2
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text R@1,1,43.5
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text R@10,1,82.1
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text R@5,1,72.3
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video Mean Rank,2,15.3
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video Median Rank,2,2
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video R@1,2,44.5
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video R@10,2,81.6
Computer Vision,Video Retrieval,MSR-VTT-1kA,text-to-video R@5,2,71.4
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text Median Rank,2,2
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text R@1,2,42.7
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text R@10,2,80.6
Computer Vision,Video Retrieval,MSR-VTT-1kA,video-to-text R@5,2,70.9
Computer Vision,Video Retrieval,TVR,R@1,1,4.34
Computer Vision,Video Retrieval,TVR,R@10,1,13.97
Computer Vision,Video Retrieval,TVR,R@100,1,21.78
Computer Vision,Video Retrieval,TVR,R@1,2,2.70
Computer Vision,Video Retrieval,TVR,R@10,2,8.93
Computer Vision,Video Retrieval,TVR,R@100,2,15.34
Computer Vision,Video Retrieval,YouCook2,text-to-video Median Rank,1,4
Computer Vision,Video Retrieval,YouCook2,text-to-video R@1,1,28.9
Computer Vision,Video Retrieval,YouCook2,text-to-video R@10,1,70.0
Computer Vision,Video Retrieval,YouCook2,text-to-video R@5,1,57.6
Computer Vision,Video Retrieval,YouCook2,text-to-video Median Rank,2,9
Computer Vision,Video Retrieval,YouCook2,text-to-video R@1,2,16.7
Computer Vision,Video Retrieval,YouCook2,text-to-video R@10,2,52.3
Computer Vision,Video Retrieval,LSMDC,text-to-video Mean Rank,1,58.0
Computer Vision,Video Retrieval,LSMDC,text-to-video Median Rank,1,11.0
Computer Vision,Video Retrieval,LSMDC,text-to-video R@1,1,21.6
Computer Vision,Video Retrieval,LSMDC,text-to-video R@10,1,49.8
Computer Vision,Video Retrieval,LSMDC,text-to-video R@5,1,41.8
Computer Vision,Video Retrieval,LSMDC,video-to-text Median Rank,1,11
Computer Vision,Video Retrieval,LSMDC,video-to-text R@1,1,20.9
Computer Vision,Video Retrieval,LSMDC,video-to-text R@10,1,49.1
Computer Vision,Video Retrieval,LSMDC,video-to-text R@5,1,40.7
Computer Vision,Video Retrieval,LSMDC,text-to-video Mean Rank,2,58.0
Computer Vision,Video Retrieval,LSMDC,text-to-video Median Rank,2,12.3
Computer Vision,Video Retrieval,LSMDC,text-to-video R@1,2,18.8
Computer Vision,Video Retrieval,LSMDC,text-to-video R@10,2,47.9
Computer Vision,Video Retrieval,LSMDC,text-to-video R@5,2,38.5
Computer Vision,Video Retrieval,DiDeMo,text-to-video Mean Rank,1,17.5
Computer Vision,Video Retrieval,DiDeMo,text-to-video Median Rank,1,2.0
Computer Vision,Video Retrieval,DiDeMo,text-to-video R@1,1,43.4
Computer Vision,Video Retrieval,DiDeMo,text-to-video R@10,1,80.6
Computer Vision,Video Retrieval,DiDeMo,text-to-video R@5,1,70.2
Computer Vision,Video Retrieval,DiDeMo,text-to-video Median Rank,2,3
Computer Vision,Video Retrieval,DiDeMo,text-to-video R@1,2,31.0
Computer Vision,Video Retrieval,DiDeMo,text-to-video R@10,2,72.4
Computer Vision,Video Retrieval,DiDeMo,text-to-video R@5,2,59.8
Computer Vision,Video Retrieval,MSVD,text-to-video Mean Rank,1,9.6
Computer Vision,Video Retrieval,MSVD,text-to-video Median Rank,1,2
Computer Vision,Video Retrieval,MSVD,text-to-video R@1,1,47
Computer Vision,Video Retrieval,MSVD,text-to-video R@10,1,85.9
Computer Vision,Video Retrieval,MSVD,text-to-video R@5,1,76.8
Computer Vision,Video Retrieval,MSVD,video-to-text Mean Rank,1,4.3
Computer Vision,Video Retrieval,MSVD,video-to-text Median Rank,1,1
Computer Vision,Video Retrieval,MSVD,video-to-text R@1,1,58.7
Computer Vision,Video Retrieval,MSVD,video-to-text R@10,1,91.6
Computer Vision,Video Retrieval,MSVD,video-to-text R@5,1,85.6
Computer Vision,Video Retrieval,MSVD,text-to-video Mean Rank,2,10.0
Computer Vision,Video Retrieval,MSVD,text-to-video Median Rank,2,2
Computer Vision,Video Retrieval,MSVD,text-to-video R@1,2,46.2
Computer Vision,Video Retrieval,MSVD,text-to-video R@10,2,84.6
Computer Vision,Video Retrieval,MSVD,text-to-video R@5,2,76.1
Computer Vision,Video Retrieval,MSVD,video-to-text Median Rank,2,1
Computer Vision,Video Retrieval,MSVD,video-to-text R@1,2,62.0
Computer Vision,Video Retrieval,MSVD,video-to-text R@10,2,92.6
Computer Vision,Video Retrieval,MSVD,video-to-text R@5,2,87.3
Computer Vision,Video Retrieval,ActivityNet,text-to-video Mean Rank,1,7.5
Computer Vision,Video Retrieval,ActivityNet,text-to-video Median Rank,1,2.0
Computer Vision,Video Retrieval,ActivityNet,text-to-video R@1,1,40.5
Computer Vision,Video Retrieval,ActivityNet,text-to-video R@5,1,72.4
Computer Vision,Video Retrieval,ActivityNet,text-to-video R@50,1,98.2
Computer Vision,Video Retrieval,ActivityNet,text-to-video Mean Rank,2,16
Computer Vision,Video Retrieval,ActivityNet,text-to-video Median Rank,2,3.3
Computer Vision,Video Retrieval,ActivityNet,text-to-video R@1,2,28.7
Computer Vision,Video Retrieval,ActivityNet,text-to-video R@5,2,61.4
Computer Vision,Video Retrieval,ActivityNet,text-to-video R@50,2,94.5
Computer Vision,Video Retrieval,VATEX,text-to-video Mean Rank,1,3.6
Computer Vision,Video Retrieval,VATEX,text-to-video Median Rank,1,1
Computer Vision,Video Retrieval,VATEX,text-to-video R@1,1,57.3
Computer Vision,Video Retrieval,VATEX,text-to-video R@10,1,95.5
Computer Vision,Video Retrieval,VATEX,text-to-video R@5,1,90
Computer Vision,Video Retrieval,VATEX,video-to-text Mean Rank,1,1.5
Computer Vision,Video Retrieval,VATEX,video-to-text Median Rank,1,1
Computer Vision,Video Retrieval,VATEX,video-to-text R@1,1,76
Computer Vision,Video Retrieval,VATEX,video-to-text R@10,1,99.9
Computer Vision,Video Retrieval,VATEX,video-to-text R@5,1,97.7
Computer Vision,Video Retrieval,MSR-VTT,text-to-video Mean Rank,1,45.5
Computer Vision,Video Retrieval,MSR-VTT,text-to-video Median Rank,1,4
Computer Vision,Video Retrieval,MSR-VTT,text-to-video R@1,1,29.8
Computer Vision,Video Retrieval,MSR-VTT,text-to-video R@10,1,66.2
Computer Vision,Video Retrieval,MSR-VTT,text-to-video R@5,1,55.5
Computer Vision,Video Retrieval,MSR-VTT,video-to-text Mean Rank,1,5.3
Computer Vision,Video Retrieval,MSR-VTT,video-to-text Median Rank,1,1
Computer Vision,Video Retrieval,MSR-VTT,video-to-text R@1,1,54.6
Computer Vision,Video Retrieval,MSR-VTT,video-to-text R@10,1,90.8
Computer Vision,Video Retrieval,MSR-VTT,video-to-text R@5,1,82.1
Computer Vision,Video Retrieval,MSR-VTT,text-to-video Mean Rank,2,52.8
Computer Vision,Video Retrieval,MSR-VTT,text-to-video Median Rank,2,6
Computer Vision,Video Retrieval,MSR-VTT,text-to-video R@1,2,23.1
Computer Vision,Video Retrieval,MSR-VTT,text-to-video R@10,2,61.8
Computer Vision,Video Retrieval,MSR-VTT,text-to-video R@5,2,49.8
Computer Vision,Video Super-Resolution,SPMCS - 4x upscaling,PSNR,1,29.84
Computer Vision,Video Super-Resolution,SPMCS - 4x upscaling,SSIM,1,0.8690
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,PSNR,1,27.43
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,SSIM,1,0.835
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,PSNR,2,27.31
Computer Vision,Video Super-Resolution,Vid4 - 4x upscaling,SSIM,2,0.832
Computer Vision,Video Super-Resolution,Xiph HD - 4x upscaling,Average PSNR,1,31.67
Computer Vision,Video Super-Resolution,Xiph HD - 4x upscaling,Average PSNR,2,31.47
Computer Vision,Video Super-Resolution,TbD-3D,PSNR,1,26.23
Computer Vision,Video Super-Resolution,TbD-3D,SSIM,1,0.699
Computer Vision,Video Super-Resolution,TbD-3D,TIoU,1,0.879
Computer Vision,Video Super-Resolution,TbD-3D,PSNR,2,23.13
Computer Vision,Video Super-Resolution,TbD-3D,SSIM,2,0.651
Computer Vision,Video Super-Resolution,TbD-3D,TIoU,2,0.598
Computer Vision,Video Super-Resolution,UDM10 - 4x upscaling,PSNR,1,38.97
Computer Vision,Video Super-Resolution,UDM10 - 4x upscaling,SSIM,1,0.9534
Computer Vision,Video Super-Resolution,Vimeo90k,PSNR,1,40.17
Computer Vision,Video Super-Resolution,Ultra Video Group HD - 4x upscaling,Average PSNR,1,37.91
Computer Vision,Video Super-Resolution,Ultra Video Group HD - 4x upscaling,Average PSNR,2,37.52
Computer Vision,Video Super-Resolution,Falling Objects,PSNR,1,26.83
Computer Vision,Video Super-Resolution,Falling Objects,SSIM,1,0.753
Computer Vision,Video Super-Resolution,Falling Objects,TIoU,1,0.684
Computer Vision,Video Super-Resolution,Falling Objects,PSNR,2,23.42
Computer Vision,Video Super-Resolution,Falling Objects,SSIM,2,0.671
Computer Vision,Video Super-Resolution,Falling Objects,TIoU,2,0.539
Computer Vision,Video Super-Resolution,TbD,PSNR,1,25.21
Computer Vision,Video Super-Resolution,TbD,SSIM,1,0.674
Computer Vision,Video Super-Resolution,TbD,TIoU,1,0.542
Computer Vision,Video Super-Resolution,TbD,PSNR,2,23.22
Computer Vision,Video Super-Resolution,TbD,SSIM,2,0.605
Computer Vision,Video Super-Resolution,TbD,TIoU,2,0.542
Computer Vision,Video Frame Interpolation,X4K1000FPS,PSNR,1,30.12
Computer Vision,Video Frame Interpolation,X4K1000FPS,SSIM,1,0.870
Computer Vision,Video Frame Interpolation,X4K1000FPS,tOF,1,2.15
Computer Vision,Video Frame Interpolation,X4K1000FPS,PSNR,2,28.86
Computer Vision,Video Frame Interpolation,X4K1000FPS,SSIM,2,0.858
Computer Vision,Video Frame Interpolation,X4K1000FPS,tOF,2,2.67
Computer Vision,Video Frame Interpolation,Vimeo90k,PSNR,1,36.10
Computer Vision,Video Frame Interpolation,Vimeo90k,SSIM,1,0.970
Computer Vision,Video Frame Interpolation,Vimeo90k,PSNR,2,36.10
Computer Vision,Video Frame Interpolation,UCF101,PSNR,1,35.39
Computer Vision,Video Frame Interpolation,UCF101,SSIM,1,0.952
Computer Vision,Video Frame Interpolation,UCF101,LPIPS,2,0.015
Computer Vision,Video Frame Interpolation,UCF101,PSNR,2,35.21
Computer Vision,Video Frame Interpolation,Vid4 - 4x upscaling,PSNR,1,26.31
Computer Vision,Video Frame Interpolation,Vid4 - 4x upscaling,Parameters,1,11100000
Computer Vision,Video Frame Interpolation,Vid4 - 4x upscaling,SSIM,1,0.7976
Computer Vision,Video Frame Interpolation,Vid4 - 4x upscaling,runtime (s),1,0.0606
Computer Vision,Video Frame Interpolation,Middlebury,Interpolation Error,1,4.22
Computer Vision,Video Frame Interpolation,Middlebury,PSNR,1,38.42
Computer Vision,Video Frame Interpolation,Middlebury,SSIM,1,0.971
Computer Vision,Video Frame Interpolation,Middlebury,Interpolation Error,2,4.48
Computer Vision,Video Summarization,SumMe,F1-score (Augmented),1,50.7
Computer Vision,Video Summarization,SumMe,F1-score (Canonical),1,50.2
Computer Vision,Video Summarization,SumMe,F1-score (Augmented),2,51.09
Computer Vision,Video Summarization,SumMe,F1-score (Canonical),2,49.71
Computer Vision,Video Summarization,TvSum,F1-score (Augmented),1,63.9
Computer Vision,Video Summarization,TvSum,F1-score (Canonical),1,62.1
Computer Vision,Video Summarization,TvSum,F1-score (Augmented),2,62.37
Computer Vision,Video Summarization,TvSum,F1-score (Canonical),2,61.42
Computer Vision,Video Denoising,DAVIS sigma50,PSNR,1,31.85
Computer Vision,Video Denoising,DAVIS sigma50,PSNR,2,31.83
Computer Vision,Video Denoising,DAVIS sigma40,PSNR,1,32.86
Computer Vision,Video Denoising,DAVIS sigma40,PSNR,2,32.8
Computer Vision,Video Denoising,Set8 sigma10,PSNR,1,36.43
Computer Vision,Video Denoising,Set8 sigma10,PSNR,2,36.08
Computer Vision,Video Denoising,Set8 sigma20,PSNR,1,33.49
Computer Vision,Video Denoising,Set8 sigma20,PSNR,2,33.37
Computer Vision,Video Denoising,Set8 sigma30,PSNR,1,31.79
Computer Vision,Video Denoising,Set8 sigma30,PSNR,2,31.6
Computer Vision,Video Denoising,DAVIS sigma10,PSNR,1,38.97
Computer Vision,Video Denoising,DAVIS sigma10,PSNR,2,38.13
Computer Vision,Video Denoising,Set8 sigma40,PSNR,1,30.55
Computer Vision,Video Denoising,Set8 sigma40,PSNR,2,30.37
Computer Vision,Video Denoising,DAVIS sigma20,PSNR,1,35.86
Computer Vision,Video Denoising,DAVIS sigma20,PSNR,2,35.7
Computer Vision,Video Denoising,Set8 sigma50,PSNR,1,29.56
Computer Vision,Video Denoising,Set8 sigma50,PSNR,2,29.42
Computer Vision,Video Denoising,DAVIS sigma30,PSNR,1,34.08
Computer Vision,Video Denoising,DAVIS sigma30,PSNR,2,34.06
Computer Vision,Anomaly Detection In Surveillance Videos,ShanghaiTech Weakly Supervised,AUC-ROC,1,97.21
Computer Vision,Anomaly Detection In Surveillance Videos,ShanghaiTech Weakly Supervised,AUC-ROC,2,94.83
Computer Vision,Anomaly Detection In Surveillance Videos,UCF-Crime,Decidability,1,
Computer Vision,Anomaly Detection In Surveillance Videos,UCF-Crime,EER,1,
Computer Vision,Anomaly Detection In Surveillance Videos,UCF-Crime,ROC AUC,1,84.03
Computer Vision,Anomaly Detection In Surveillance Videos,UCF-Crime,ROC AUC,2,82.30
Computer Vision,Anomaly Detection In Surveillance Videos,XD-Violence,AP,1,77.81
Computer Vision,Anomaly Detection In Surveillance Videos,XD-Violence,AP,2,75.41
Computer Vision,Video-to-Video Synthesis,YouTube Dancing,FID,1,80.44
Computer Vision,Video-to-Video Synthesis,Street Scene,FID,1,144.24
Computer Vision,Action Spotting,SoccerNet-v2,Average-mAP,1,40.7
Computer Vision,Action Spotting,SoccerNet-v2,Average-mAP,2,39.9
Computer Vision,Action Spotting,SoccerNet,Average-mAP,1,75.1
Computer Vision,Action Spotting,SoccerNet,Average-mAP,2,63.3
Computer Vision,Activity Recognition In Videos,DogCentric,Accuracy,1,81.4
Computer Vision,Activity Recognition In Videos,DogCentric,Accuracy,2,76.6
Computer Vision,Video Deinterlacing,MSU Deinterlacer Benchmark,FPS on CPU,1,1.3
Computer Vision,Video Deinterlacing,MSU Deinterlacer Benchmark,PSNR,1,40.708
Computer Vision,Video Deinterlacing,MSU Deinterlacer Benchmark,SSIM,1,0.983
Computer Vision,Video Deinterlacing,MSU Deinterlacer Benchmark,FPS on CPU,2,50.3
Computer Vision,Video Deinterlacing,MSU Deinterlacer Benchmark,PSNR,2,39.916
Computer Vision,Video Deinterlacing,MSU Deinterlacer Benchmark,SSIM,2,0.977
Computer Vision,Video Story QA,MovieQA,Accuracy,1,42.53
Computer Vision,Video Story QA,MovieQA,Accuracy,2,36.25
Computer Vision,Action Recognition,ActionNet-VE,F-measure (%),1,90.27
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Action@1,1,47.7
Computer Vision,Action Recognition,EPIC-KITCHENS-100,GFLOPs,1,117x1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Noun@1,1,57.3
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Verb@1,1,72.2
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Action@1,2,44.5
Computer Vision,Action Recognition,EPIC-KITCHENS-100,GFLOPs,2,74.9x1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Noun@1,2,55.1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Verb@1,2,69.1
Computer Vision,Action Recognition,AVA v2.2,mAP,1,31.0
Computer Vision,Action Recognition,AVA v2.2,mAP,2,28.7
Computer Vision,Action Recognition,EPIC-KITCHENS-55,Top-1 Accuracy,1,34.2
Computer Vision,Action Recognition,Something-Something V2,GFLOPs,1,320.6
Computer Vision,Action Recognition,Something-Something V2,Parameters,1,89M
Computer Vision,Action Recognition,Something-Something V2,Top-1 Accuracy,1,69.6
Computer Vision,Action Recognition,Something-Something V2,Top-5 Accuracy,1,92.7
Computer Vision,Action Recognition,Something-Something V2,Top-1 Accuracy,2,69.02
Computer Vision,Action Recognition,Something-Something V2,Top-5 Accuracy,2,92.70
Computer Vision,Action Recognition,HMDB-51,Average accuracy of 3 splits,1,84.36
Computer Vision,Action Recognition,HMDB-51,Average accuracy of 3 splits,2,83.8
Computer Vision,Action Recognition,UCF 101,Average accuracy of 3 splits,1,85.10
Computer Vision,Action Recognition,SSBD,Accuracy,1,95.7
Computer Vision,Action Recognition,IRD,Accuracy,1,80.11
Computer Vision,Action Recognition,IRD,Accuracy,2,74.03
Computer Vision,Action Recognition,UCF101,3-fold Accuracy,1,98.64
Computer Vision,Action Recognition,UCF101,3-fold Accuracy,2,98.6
Computer Vision,Action Recognition,Volleyball,Accuracy,1,91.3
Computer Vision,Action Recognition,Volleyball,Accuracy,2,82.6
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CS),1,97.0
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CS),2,95.66
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CV),2,98.79
Computer Vision,Action Recognition,THUMOS’14,mAP@0.3,1,56.0
Computer Vision,Action Recognition,THUMOS’14,mAP@0.4,1,47.4
Computer Vision,Action Recognition,THUMOS’14,mAP@0.5,1,38.8
Computer Vision,Action Recognition,THUMOS’14,mAP@0.3,2,53.9
Computer Vision,Action Recognition,THUMOS’14,mAP@0.4,2,46.8
Computer Vision,Action Recognition,THUMOS’14,mAP@0.5,2,37.4
Computer Vision,Action Recognition,ActivityNet,mAP,1,84.4
Computer Vision,Action Recognition,ActivityNet,mAP,2,53.8
Computer Vision,Action Recognition,Jester,Val,1,97.4
Computer Vision,Action Recognition,Jester,Val,2,96.70
Computer Vision,Action Recognition,Autism,Accuracy,1,75.1
Computer Vision,Action Recognition,MTL-AQA,Armstand Accuracy,1,99.72
Computer Vision,Action Recognition,MTL-AQA,No. of Somersaults Accuracy,1,96.88
Computer Vision,Action Recognition,MTL-AQA,No. of Twists Accuracy,1,93.20
Computer Vision,Action Recognition,MTL-AQA,Position Accuracy,1,96.32
Computer Vision,Action Recognition,MTL-AQA,Rotation Type Accuracy,1,97.45
Computer Vision,Action Recognition,EgoGesture,Top-1 Accuracy,1,94.3
Computer Vision,Action Recognition,EgoGesture,Top-5 Accuracy,1,99.2
Computer Vision,Action Recognition,Sports-1M,Video hit@1 ,1,75.5
Computer Vision,Action Recognition,Sports-1M,Video hit@5,1,92.8
Computer Vision,Action Recognition,Sports-1M,Video hit@1 ,2,74.9
Computer Vision,Action Recognition,Sports-1M,Video hit@5,2,92.6
Computer Vision,Action Recognition,Something-Something V1,Top 1 Accuracy,1,57.0
Computer Vision,Action Recognition,Something-Something V1,Top 5 Accuracy,1,83.7
Computer Vision,Action Recognition,Something-Something V1,Top 1 Accuracy,2,56.8
Computer Vision,Action Recognition,Something-Something V1,Top 5 Accuracy,2,84.1
Computer Vision,Action Recognition,UTD-MHAD,Accuracy,1,92.5
Computer Vision,Action Recognition,HACS,Top 1 Accuracy,1,84.33
Computer Vision,Action Recognition,HACS,Top 5 Accuracy,1,96.85
Computer Vision,Action Recognition,HACS,Top 1 Accuracy,2,83.77
Computer Vision,Action Recognition,HACS,Top 5 Accuracy,2,96.56
Computer Vision,Action Recognition,VIRAT Ground 2.0,Average Accuracy,1,66.45
Computer Vision,Action Recognition,MECCANO,Top-1 Accuracy,1,42.85
Computer Vision,Action Recognition,Diving-48,Accuracy,1,85.5
Computer Vision,Action Recognition,Diving-48,Accuracy,2,81
Computer Vision,Action Recognition,AVA v2.1,mAP (Val),1,28.3
Computer Vision,Action Recognition,AVA v2.1,mAP (Val),2,27.7
Computer Vision,Action Recognition,Win-Fail Action Understanding,2-Class Accuracy,1,75.74
Computer Vision,Action Recognition,miniSports,Accuracy,1,74.9
Computer Vision,Action Recognition,miniSports,Accuracy,2,69.9
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,95.3
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,90.7
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,92.5
Computer Vision,Action Recognition,HAA500,Top-1 (%),1,64.4
Computer Vision,Action Recognition,HAA500,Top-1 (%),2,50.53
Computer Vision,Action Recognition,ICVL-4,Accuracy,1,91.86
Computer Vision,Action Recognition,ICVL-4,Accuracy,2,80.23
Computer Vision,Weakly Supervised Action Localization,THUMOS 2014,mAP@0.1:0.5,1,53.2
Computer Vision,Weakly Supervised Action Localization,THUMOS 2014,mAP@0.1:0.7,1,42.6
Computer Vision,Weakly Supervised Action Localization,THUMOS 2014,mAP@0.5,1,34.6
Computer Vision,Weakly Supervised Action Localization,THUMOS 2014,mAP@0.1:0.5,2,51.6
Computer Vision,Weakly Supervised Action Localization,THUMOS 2014,mAP@0.1:0.7,2,41.9
Computer Vision,Weakly Supervised Action Localization,THUMOS 2014,mAP@0.5,2,33.7
Computer Vision,Weakly Supervised Action Localization,THUMOS’14,mAP@0.5,1,35.9
Computer Vision,Weakly Supervised Action Localization,THUMOS’14,mAP@0.5,2,34.6
Computer Vision,Weakly Supervised Action Localization,THUMOS14,avg-mAP (0.1-0.5),1,53.2
Computer Vision,Weakly Supervised Action Localization,THUMOS14,avg-mAP (0.1-0.9),1,33.6
Computer Vision,Weakly Supervised Action Localization,THUMOS14,avg-mAP (0.3-0.7),1,33.4
Computer Vision,Weakly Supervised Action Localization,THUMOS14,avg-mAP (0.1-0.5),2,51.6
Computer Vision,Weakly Supervised Action Localization,THUMOS14,avg-mAP (0.1-0.9),2,33.0
Computer Vision,Weakly Supervised Action Localization,THUMOS14,avg-mAP (0.3-0.7),2,32.9
Computer Vision,Weakly Supervised Action Localization,ActivityNet-1.2,Mean mAP,1,26.1
Computer Vision,Weakly Supervised Action Localization,ActivityNet-1.2,mAP@0.5,1,42.7
Computer Vision,Weakly Supervised Action Localization,ActivityNet-1.2,Mean mAP,2,26
Computer Vision,Weakly Supervised Action Localization,ActivityNet-1.2,mAP@0.5,2,42.3
Computer Vision,Weakly Supervised Action Localization,ActivityNet-1.3,mAP@0.5,1,40.1
Computer Vision,Weakly Supervised Action Localization,ActivityNet-1.3,mAP@0.5,2,37
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.1,1,68.9
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.2,1,62.7
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.3,1,55.0
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.4,1,44.6
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.5,1,34.6
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.6,1,21.8
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.7,1,10.8
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.8,1,3.6
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.9,1,0.6
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP@AVG(0.1:0.9),1,33.6
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.1,2,61.2
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.2,2,56.1
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.3,2,48.1
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.4,2,39.0
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.5,2,30.1
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.6,2,19.2
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.7,2,10.6
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.8,2,4.8
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP IOU@0.9,2,1.0
Computer Vision,Weakly-supervised Temporal Action Localization,THUMOS’14,mAP@AVG(0.1:0.9),2,30.0
Computer Vision,Temporal Action Proposal Generation,THUMOS' 14,AR@100,1,46.06
Computer Vision,Temporal Action Proposal Generation,THUMOS' 14,AR@1000,1,64.52
Computer Vision,Temporal Action Proposal Generation,THUMOS' 14,AR@200,1,53.21
Computer Vision,Temporal Action Proposal Generation,THUMOS' 14,AR@50,1,37.46
Computer Vision,Temporal Action Proposal Generation,THUMOS' 14,AR@500,1,60.64
Computer Vision,Temporal Action Proposal Generation,ActivityNet-1.3,AR@100,1,76.63
Computer Vision,Temporal Action Proposal Generation,ActivityNet-1.3,AUC (val),1,69.04
Computer Vision,Temporal Action Proposal Generation,ActivityNet-1.3,AR@100,2,76.52
Computer Vision,Temporal Action Proposal Generation,ActivityNet-1.3,AUC (val),2,68.26
Computer Vision,Temporal Action Proposal Generation,ActivityNet Captions,Average F1,1,60.27
Computer Vision,Temporal Action Proposal Generation,ActivityNet Captions,Average Precision,1,48.23
Computer Vision,Temporal Action Proposal Generation,ActivityNet Captions,Average Recall,1,80.31
Computer Vision,Activity Recognition In Videos,DogCentric,Accuracy,1,81.4
Computer Vision,Activity Recognition In Videos,DogCentric,Accuracy,2,76.6
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,MNIST,AUC-ROC,1,97.80
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,	 Fashion-MNIST,AUC-ROC,1,93.11
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,CIFAR-10,AUC-ROC,1,73.76
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,KolektorSDD2,Segmentation AUROC,1,0.981
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,20NEWS,AUC (outlier ratio = 0.5),1,0.831
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,Caltech-101,AUC (outlier ratio = 0.5),1,0.772
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,ECG5000,AUC,1,0.9836
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,Reuters-21578,AUC (outlier ratio = 0.5),1,0.849
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,KolektorSDD,Segmentation AUROC,1,0.960
"Computer Vision', 'Miscellaneous', 'Methodology",Unsupervised Anomaly Detection,Fashion-MNIST,AUC (outlier ratio = 0.5),1,0.833
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,ShanghaiTech Weakly Supervised,AUC-ROC,1,97.21
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,ShanghaiTech Weakly Supervised,AUC-ROC,2,94.83
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,UCF-Crime,Decidability,1,
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,UCF-Crime,EER,1,
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,UCF-Crime,ROC AUC,1,84.03
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,UCF-Crime,ROC AUC,2,82.30
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,XD-Violence,AP,1,77.81
"Computer Vision', 'Miscellaneous', 'Methodology",Anomaly Detection In Surveillance Videos,XD-Violence,AP,2,75.41
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UBI-Fights,AUC,1,0.906
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UBI-Fights,Decidability,1,1.386
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UBI-Fights,EER,1,0.160
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UBI-Fights,AUC,2,0.892
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UBI-Fights,Decidability,2,0.804
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UBI-Fights,EER,2,0.186
"Computer Vision', 'Miscellaneous', 'Methodology",Abnormal Event Detection In Video,UCSD,AUC,1,97.4
Natural Language Processing,Machine Reading Comprehension,ReClor,Accuracy,1,56.0
Natural Language Processing,Machine Reading Comprehension,ReClor,Accuracy (easy),1,75.7
Natural Language Processing,Machine Reading Comprehension,ReClor,Accuracy (hard),1,40.5
Natural Language Processing,Machine Reading Comprehension,ReClor,Accuracy,2,55.6
Natural Language Processing,Machine Reading Comprehension,ReClor,Accuracy (easy),2,75.5
Natural Language Processing,Machine Reading Comprehension,ReClor,Accuracy (hard),2,40.0
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB 200 50-way (0-shot),Accuracy,1,54.6
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB 200 50-way (0-shot),Accuracy,2,50.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,Caltech-256 5-way (1-shot),Accuracy,1,74.7
"Computer Vision', 'Methodology",Few-Shot Image Classification,Caltech-256 5-way (1-shot),Accuracy,2,73.2
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 1-shot,Top 1 Accuracy,1,68.66
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 1-shot,Top 1 Accuracy,2,63.38
"Computer Vision', 'Methodology",Few-Shot Image Classification,AWA - 0-Shot,Accuracy,1,72.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 5-way",Accuracy,1,99.92
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 5-way",Accuracy,2,99.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,AWA2 - 0-Shot,Accuracy,1,69.3
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200-2011 5-way (1-shot),Accuracy,1,67.33
"Computer Vision', 'Methodology",Few-Shot Image Classification,mini-ImageNet - 100-Way,Accuracy,1,39.14
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 5-shot,Top 1 Accuracy,1,82.78
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 5-shot,Top 1 Accuracy,2,78.21
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 10-way (5-shot),Accuracy,1,85.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 10-way (5-shot),Accuracy,2,83.1
"Computer Vision', 'Methodology",Few-Shot Image Classification,OMNIGLOT-EMNIST 5-way (1-shot),Accuracy,1,75.40
"Computer Vision', 'Methodology",Few-Shot Image Classification,iNaturalist (227-way multi-shot),Accuracy,1,74.97
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 10-way (1-shot),Accuracy,1,68.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 10-way (1-shot),Accuracy,2,63.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 5-way (10-shot),Accuracy,1,90.03
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 5-way (10-shot),Accuracy,2,81.57
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Dogs 5-way (5-shot),Accuracy,1,75.59
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Dogs 5-way (5-shot),Accuracy,2,70.29
"Computer Vision', 'Methodology",Few-Shot Image Classification,SUN - 0-Shot,Accuracy,1,62.7
"Computer Vision', 'Methodology",Few-Shot Image Classification,SUN - 0-Shot,Accuracy,2,60.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,aPY - 0-Shot,Accuracy,1,42.2
"Computer Vision', 'Methodology",Few-Shot Image Classification,Oxford 102 Flower,ACCURACY,1,75.33
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR100 5-way (1-shot),Accuracy,1,89.6
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR100 5-way (1-shot),Accuracy,2,66.7
"Computer Vision', 'Methodology",Few-Shot Image Classification,FC100 5-way (1-shot),Accuracy,1,51.35
"Computer Vision', 'Methodology",Few-Shot Image Classification,FC100 5-way (1-shot),Accuracy,2,50.57
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 1000 way",Accuracy,1,68.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,OMNIGLOT-EMNIST 5-way (5-shot),Accuracy,1,90.3
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR-FS 5-way (1-shot),Accuracy,1,87.79
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR-FS 5-way (1-shot),Accuracy,2,87.73
"Computer Vision', 'Methodology",Few-Shot Image Classification,miniImagenet → CUB (5-way 1-shot),Accuracy,1,55.46
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 5-way (1-shot),Accuracy,1,82.99
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 5-way (1-shot),Accuracy,2,82.92
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 20-way",Accuracy,1,99.63
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 20-way",Accuracy,2,99.11
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB 200 5-way 5-shot,Accuracy,1,96.28
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB 200 5-way 5-shot,Accuracy,2,94.09
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 5-way (5-shot),Accuracy,1,91.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 5-way (5-shot),Accuracy,2,90.98
"Computer Vision', 'Methodology",Few-Shot Image Classification,FC100 5-way (10-shot),Accuracy,1,63.4
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 20-way",Accuracy,1,99.65
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 20-way",Accuracy,2,99.63
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR-FS - 1-Shot Learning,Accuracy,1,81.87
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Dogs 5-way (1-shot),Accuracy,1,59.05
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Dogs 5-way (1-shot),Accuracy,2,55.63
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 1000 way",Accuracy,1,78.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 5-way",Accuracy,1,99.97
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 5-way",Accuracy,2,99.92
"Computer Vision', 'Methodology",Few-Shot Image Classification,Meta-Dataset,Accuracy,1,72.15
"Computer Vision', 'Methodology",Few-Shot Image Classification,Meta-Dataset,Accuracy,2,70.72
"Computer Vision', 'Methodology",Few-Shot Image Classification,Fewshot-CIFAR100 - 1-Shot Learning,Accuracy,1,50.57
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 20-way (5-shot),Accuracy,1,59.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 20-way (5-shot),Accuracy,2,47.31
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 10-way (5-shot),Accuracy,1,80.6
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 10-way (5-shot),Accuracy,2,78.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet (1-shot),Top-5 Accuracy,1,58.2
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet (1-shot),Top-5 Accuracy,2,59.2
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (1-shot),Accuracy,1,62.49
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (1-shot),Accuracy,2,49.44
"Computer Vision', 'Methodology",Few-Shot Image Classification,Flowers-102 - 0-Shot,AP50,1,59.6
"Computer Vision', 'Methodology",Few-Shot Image Classification,Flowers-102 - 0-Shot,Accuracy,1,65.6
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200-2011 5-way (5-shot),Accuracy,1,83.92
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 5-way (5-shot),Accuracy,1,90.44
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 5-way (5-shot),Accuracy,2,89.8
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB 200 5-way 1-shot,Accuracy,1,94.73
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB 200 5-way 1-shot,Accuracy,2,91.68
"Computer Vision', 'Methodology",Few-Shot Image Classification,miniImagenet → CUB (5-way 5-shot),Accuracy,1,66.33
"Computer Vision', 'Methodology",Few-Shot Image Classification,AWA1 - 0-Shot,Accuracy,1,70.8
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Cars 5-way (1-shot),Accuracy,1,73.15
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Cars 5-way (1-shot),Accuracy,2,72.43
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Cars 5-way (5-shot),Accuracy,1,91.89
"Computer Vision', 'Methodology",Few-Shot Image Classification,Stanford Cars 5-way (5-shot),Accuracy,2,91.05
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 10-way (1-shot),Accuracy,1,65.1
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 10-way (1-shot),Accuracy,2,57.1
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 423 way",Accuracy,1,88
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (5-shot),Accuracy,1,76.51
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (5-shot),Accuracy,2,68.33
"Computer Vision', 'Methodology",Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 423 way",Accuracy,1,73.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR-FS - 5-Shot Learning,Accuracy,1,89.12
"Computer Vision', 'Methodology",Few-Shot Image Classification,Meta-Dataset Rank,Mean Rank,1,2.85
"Computer Vision', 'Methodology",Few-Shot Image Classification,Meta-Dataset Rank,Mean Rank,2,3.05
"Computer Vision', 'Methodology",Few-Shot Image Classification,FC100 5-way (5-shot),Accuracy,1,67.66
"Computer Vision', 'Methodology",Few-Shot Image Classification,FC100 5-way (5-shot),Accuracy,2,67.17
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200 - 0-Shot Learning,Accuracy,1,56.9
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200 - 0-Shot Learning,Accuracy,2,
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet - 1-Shot Learning,Accuracy,1,82.92
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet - 1-Shot Learning,Accuracy,2,78.55
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 5-way (1-shot),Accuracy,1,85.41
"Computer Vision', 'Methodology",Few-Shot Image Classification,Tiered ImageNet 5-way (1-shot),Accuracy,2,84.01
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet to CUB - 5 shot learning,Accuracy,1,71
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-ImageNet to CUB - 5 shot learning,Accuracy,2,69.30
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 0-Shot,Accuracy,1,1.5
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 0-Shot,Accuracy,2,1.4
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR-FS 5-way (5-shot),Accuracy,1,91.09
"Computer Vision', 'Methodology",Few-Shot Image Classification,CIFAR-FS 5-way (5-shot),Accuracy,2,90.73
"Computer Vision', 'Methodology",Few-Shot Image Classification,Fewshot-CIFAR100 - 5-Shot Learning,Accuracy,1,61.58
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 20-way (1-shot),Accuracy,1,39.3
"Computer Vision', 'Methodology",Few-Shot Image Classification,Mini-Imagenet 20-way (1-shot),Accuracy,2,32.07
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 10-shot,Top 1 Accuracy,1,84.29
"Computer Vision', 'Methodology",Few-Shot Image Classification,ImageNet - 10-shot,Top 1 Accuracy,2,80.33
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200-2011 - 0-Shot,AP50,1,48.7
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200-2011 - 0-Shot,Top-1 Accuracy,1,56.8
"Computer Vision', 'Methodology",Few-Shot Image Classification,CUB-200-2011 - 0-Shot,Top-1 Accuracy,2,54.7
"Computer Vision', 'Methodology",One-Shot Learning,MNIST,Accuracy,1,97.5
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,PASCAL-5i (5-Shot),Mean IoU,1,70.4
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,PASCAL-5i (5-Shot),Mean IoU,2,66.6
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i (1-shot),Mean IoU,1,41.2
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i (1-shot),Mean IoU,2,40.3
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,FSS-1000 (5-shot),Mean IoU,1,88.5
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,FSS-1000 (1-shot),Mean IoU,1,86.5
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,PASCAL-5i (10-Shot),Mean IoU,1,70.6
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,PASCAL-5i (10-Shot),Mean IoU,2,68.1
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i (5-shot),Mean IoU,1,49.5
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i (5-shot),Mean IoU,2,45.6
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,Pascal5i,meanIOU,1,62.2
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,Pascal5i,meanIOU,2,60.6
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,FSS-1000,Mean IoU,1,86.5
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,FSS-1000,Mean IoU,2,83.36
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i -> Pascal VOC (1-shot),Mean IoU,1,63.1
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i -> Pascal VOC (1-shot),Mean IoU,2,61.1
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i (10-shot),Mean IoU,1,48.7
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i (10-shot),Mean IoU,2,44.1
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,PASCAL-5i (1-Shot),Mean IoU,1,66.2
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,PASCAL-5i (1-Shot),Mean IoU,2,64.3
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i -> Pascal VOC (5-shot),Mean IoU,1,67.7
"Computer Vision', 'Methodology",Few-Shot Semantic Segmentation,COCO-20i -> Pascal VOC (5-shot),Mean IoU,2,63.4
"Computer Vision', 'Methodology",Cross-Domain Few-Shot,miniImagenet,Accuracy (%),1,73.78
"Computer Vision', 'Methodology",Temporal Action Localization,MEXaction2,mAP,1,7.4
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS'14,mAP IOU@0.5,1,57.18
"Computer Vision', 'Methodology",Temporal Action Localization,CrossTask,Recall,1,33.6
"Computer Vision', 'Methodology",Temporal Action Localization,CrossTask,Recall,2,31.6
"Computer Vision', 'Methodology",Temporal Action Localization,UCF101-24,Frame-mAP,1,87.2
"Computer Vision', 'Methodology",Temporal Action Localization,UCF101-24,Video-mAP 0.5,1,48.8
"Computer Vision', 'Methodology",Temporal Action Localization,UCF101-24,Frame-mAP,2,76.3
"Computer Vision', 'Methodology",Temporal Action Localization,UCF101-24,Video-mAP 0.5,2,59.9
"Computer Vision', 'Methodology",Temporal Action Localization,J-HMDB-21,Frame-mAP,1,74.4
"Computer Vision', 'Methodology",Temporal Action Localization,J-HMDB-21,Video-mAP 0.2,1,87.8
"Computer Vision', 'Methodology",Temporal Action Localization,J-HMDB-21,Video-mAP 0.5,1,85.7
"Computer Vision', 'Methodology",Temporal Action Localization,J-HMDB-21,Video-mAP 0.75,1,58.1
"Computer Vision', 'Methodology",Temporal Action Localization,J-HMDB-21,Frame-mAP,2,73.3
"Computer Vision', 'Methodology",Temporal Action Localization,J-HMDB-21,Video-mAP 0.5,2,78.6
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.1,1,60.5
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.3,1,48.4
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.5,1,35.2
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.7,1,16.3
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.3,1,70.1
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.4,1,64.9
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.5,1,57.1
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.6,1,45.4
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.7,1,28.8
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.3,2,68.9
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.4,2,64.0
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.5,2,56.9
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.6,2,46.3
"Computer Vision', 'Methodology",Temporal Action Localization,THUMOS’14,mAP IOU@0.7,2,31.0
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP,1,36.82
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.5,1,54.34
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.75,1,37.76
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.95,1,8.93
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP,2,37.56
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.5,2,54.33
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.75,2,39.13
"Computer Vision', 'Methodology",Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.95,2,8.41
"Computer Vision', 'Methodology",Generalized Zero-Shot Learning,AWA2,Harmonic mean,1,66.6
"Computer Vision', 'Methodology",Generalized Zero-Shot Learning,Oxford 102 Flower,Harmonic mean,1,71.7
"Computer Vision', 'Methodology",Generalized Zero-Shot Learning,SUN Attribute,Harmonic mean,1,43
"Computer Vision', 'Methodology",Generalized Zero-Shot Learning,SUN Attribute,Harmonic mean,2,41.3
"Computer Vision', 'Methodology",Generalized Zero-Shot Learning,CUB-200-2011,Harmonic mean,1,58.1
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,MIT-States,Top-1 accuracy %,1,19.9
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,MIT-States,Top-2 accuracy %,1,28.2
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,MIT-States,Top-3 accuracy %,1,33.8
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",H-Mean,1,16.1
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Seen accuracy,1,24.4
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Test AUC top 1,1,3.0
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Test AUC top 2,1,7.6
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Test AUC top 3,1,12.3
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Unseen accuracy,1,25.2
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Val AUC top 1,1,4.3
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Val AUC top 2,1,9.8
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,"MIT-States, generalized split",Val AUC top 3,1,14.8
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,UT-Zappos,Top-1 accuracy %,1,52.1
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,UT-Zappos,Top-2 accuracy %,1,67.8
"Computer Vision', 'Methodology",Compositional Zero-Shot Learning,UT-Zappos,Top-3 accuracy %,1,76.0
"Computer Vision', 'Methodology",Multi-label zero-shot learning,NUS-WIDE,mAP,1,25.9
"Computer Vision', 'Methodology",Multi-label zero-shot learning,NUS-WIDE,mAP,2,25.7
Methodology,Multi-Task Learning,Cifar100 (20 tasks),Average Accuracy,1,95.98
Methodology,Multi-Task Learning,Cifar10 (5 tasks),Average Accuracy,1,98.28
Methodology,Multi-Task Learning,OMNIGLOT,Average Accuracy,1,93.52
Methodology,Multi-Task Learning,OMNIGLOT,Average Accuracy,2,92.19
Methodology,Multi-Task Learning,Coarse-CIFAR100,Average Accuracy,1,85.59
Methodology,Multi-Task Learning,CelebA,Error,1,8.25
Methodology,Multi-Task Learning,Hendrycks Test,Accuracy (%),1,48.9
Methodology,Multi-Task Learning,Hendrycks Test,Accuracy (%),2,43.9
Methodology,Multi-Task Learning,Cityscapes test,mIoU,1,66.63
Natural Language Processing,Open-Domain Question Answering,SearchQA,EM,1,68.0
Natural Language Processing,Open-Domain Question Answering,SearchQA,EM,2,66.0
Natural Language Processing,Open-Domain Question Answering,SQuAD1.1 dev,EM,1,59.3
Natural Language Processing,Open-Domain Question Answering,SQuAD1.1 dev,EM,2,50.2
Natural Language Processing,Open-Domain Question Answering,Natural Questions,Exact Match,1,55.9
Natural Language Processing,Open-Domain Question Answering,Natural Questions,Exact Match,2,41.6
Natural Language Processing,Open-Domain Question Answering,SQuAD1.1,EM,1,70.0
Natural Language Processing,Open-Domain Question Answering,SQuAD1.1,EM,2,66.2
Natural Language Processing,Open-Domain Question Answering,TQA,Exact Match,1,56.8
Natural Language Processing,Open-Domain Question Answering,DuReader,EM,1,64.2
Natural Language Processing,Open-Domain Question Answering,DuReader,EM,2,61.3
Natural Language Processing,Open-Domain Question Answering,Quasar,EM (Quasar-T),1,42.3
Natural Language Processing,Open-Domain Question Answering,Quasar,F1 (Quasar-T),1,49.6
Natural Language Processing,Open-Domain Question Answering,Quasar,EM (Quasar-T),2,42.2
Natural Language Processing,Open-Domain Question Answering,Quasar,F1 (Quasar-T),2,49.3
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,EM,1,44.39
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,F1,1,52.35
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,KILT-EM,1,32.69
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,KILT-F1,1,37.91
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,R-Prec,1,59.49
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,Recall@5,1,67.06
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,EM,2,38.64
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,F1,2,47.09
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,KILT-EM,2,31.99
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,KILT-F1,2,37.58
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,R-Prec,2,60.66
Natural Language Processing,Open-Domain Question Answering,KILT: Natural Questions,Recall@5,2,46.79
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,EM,1,31.77
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,F1,1,41.56
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,KILT-EM,1,9.53
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,KILT-F1,1,11.27
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,R-Prec,1,42.92
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,Recall@5,1,28.39
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,EM,2,26.97
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,F1,2,36.03
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,KILT-EM,2,3.21
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,KILT-F1,2,4.1
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,R-Prec,2,30.59
Natural Language Processing,Open-Domain Question Answering,KILT: HotpotQA,Recall@5,2,12.59
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,EM,1,59.6
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,F1,1,66.53
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,KILT-EM,1,42.36
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,KILT-F1,1,46.19
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,R-Prec,1,61.49
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,Recall@5,1,68.33
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,EM,2,71.27
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,F1,2,75.88
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,KILT-EM,2,38.13
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,KILT-F1,2,40.15
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,R-Prec,2,48.68
Natural Language Processing,Open-Domain Question Answering,KILT: TriviaQA,Recall@5,2,57.13
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,F1,1,27.13
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,KILT-F1,1,3.0
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,KILT-RL,1,2.62
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,R-Prec,1,10.83
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,ROUGE-L,1,24.53
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,Recall@5,1,27.25
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,F1,2,22.88
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,KILT-F1,2,2.34
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,KILT-RL,2,2.36
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,R-Prec,2,10.67
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,ROUGE-L,2,23.19
Natural Language Processing,Open-Domain Question Answering,KILT: ELI5,Recall@5,2,24.56
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v2, Ranking)",1 in 10 R@1,1,0.652
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v2, Ranking)",1 in 10 R@2,1,0.815
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v2, Ranking)",1 in 10 R@5,1,0.966
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v2, Ranking)",1 in 2 R@1,1,0.915
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v1, Ranking)",1 in 10 R@1,1,0.684
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v1, Ranking)",1 in 10 R@2,1,0.822
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v1, Ranking)",1 in 10 R@5,1,0.960
Natural Language Processing,Answer Selection,"Ubuntu Dialogue (v1, Ranking)",1 in 2 R@1,1,0.916
Natural Language Processing,Community Question Answering,CrowdSource QA,MSE,1,0.046
Natural Language Processing,Knowledge Base Question Answering,ComplexWebQuestions,Accuracy,1,70.4
Natural Language Processing,Knowledge Base Question Answering,ComplexWebQuestions,Accuracy,2,53.9
Natural Language Processing,Knowledge Base Question Answering,WebQSP-WD,Avg F1,1,0.2588
Natural Language Processing,Generative Question Answering,CoQA,F1-Score,1,84.5
Natural Language Processing,Generative Question Answering,CoQA,F1-Score,2,82.5
Natural Language Processing,Cross-Lingual Question Answering,MLQA,EM,1,54.9
Natural Language Processing,Cross-Lingual Question Answering,MLQA,F1,1,71.6
Natural Language Processing,Cross-Lingual Question Answering,MLQA,EM,2,37.3
Natural Language Processing,Cross-Lingual Question Answering,MLQA,F1,2,53.1
Natural Language Processing,Cross-Lingual Question Answering,XQuAD,EM,1,63.6
Natural Language Processing,Cross-Lingual Question Answering,XQuAD,F1,1,79.7
Natural Language Processing,Cross-Lingual Question Answering,XQuAD,EM,2,46.9
Natural Language Processing,Cross-Lingual Question Answering,XQuAD,F1,2,63.8
Natural Language Processing,Cross-Lingual Question Answering,TyDiQA-GoldP,EM,1,60.0
Natural Language Processing,Cross-Lingual Question Answering,TyDiQA-GoldP,F1,1,75.3
Natural Language Processing,Cross-Lingual Question Answering,TyDiQA-GoldP,EM,2,42.8
Natural Language Processing,Cross-Lingual Question Answering,TyDiQA-GoldP,F1,2,58.1
Natural Language Processing,Logical Reasoning Question Answering,ReClor,Accuracy,1,56.0
Natural Language Processing,Logical Reasoning Question Answering,ReClor,Accuracy (easy),1,75.7
Natural Language Processing,Logical Reasoning Question Answering,ReClor,Accuracy (hard),1,40.5
Natural Language Processing,Logical Reasoning Question Answering,ReClor,Accuracy,2,55.6
Natural Language Processing,Logical Reasoning Question Answering,ReClor,Accuracy (easy),2,75.5
Natural Language Processing,Logical Reasoning Question Answering,ReClor,Accuracy (hard),2,40.0
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,EM(QE-PE),1,64.29
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,EM(QE-PH),1,44.71
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,EM(QH-PE),1,41.01
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,EM(QH-PH),1,45.63
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,F1 (QE-PE),1,76.51
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,F1 (QE-PH),1,57.31
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,F1(QH-PE),1,51.04
Natural Language Processing,Multilingual Machine Comprehension in English Hindi,Extended XQuAD,F1(QH-PH),1,59.80
Natural Language Processing,Question Quality Assessment,CrowdSource QA,MSE,1,0.046
"Computer Vision', 'Natural Language Processing",Machine Reading Comprehension,ReClor,Accuracy,1,56.0
"Computer Vision', 'Natural Language Processing",Machine Reading Comprehension,ReClor,Accuracy (easy),1,75.7
"Computer Vision', 'Natural Language Processing",Machine Reading Comprehension,ReClor,Accuracy (hard),1,40.5
"Computer Vision', 'Natural Language Processing",Machine Reading Comprehension,ReClor,Accuracy,2,55.6
"Computer Vision', 'Natural Language Processing",Machine Reading Comprehension,ReClor,Accuracy (easy),2,75.5
"Computer Vision', 'Natural Language Processing",Machine Reading Comprehension,ReClor,Accuracy (hard),2,40.0
Computer Vision,Facial Inpainting,FFHQ, SSIM,1,0.8985
Computer Vision,Facial Inpainting,FFHQ,LPIPS,1,0.0457
Computer Vision,Facial Inpainting,FFHQ,PSNR,1,26.49
Computer Vision,Facial Inpainting,VggFace2,PSNR,1,27.81
Computer Vision,Facial Inpainting,WebFace,PSNR,1,27.22
Computer Vision,Image Outpainting,Places365-Standard,L1,1,0.0791
Computer Vision,Image Outpainting,Places365-Standard,MSE,1,0.023
Computer Vision,Image Outpainting,Places365-Standard,Adversarial,2,0.0941
Computer Vision,Image Outpainting,Places365-Standard,L1,2,0.08
Computer Vision,Image Outpainting,Places365-Standard,MSE,2,0.7814
Computer Vision,Cloud Removal,SEN12MS-CR,MAE,1,0.029
Computer Vision,Cloud Removal,SEN12MS-CR,PSNR,1,28.7
Computer Vision,Cloud Removal,SEN12MS-CR,RMSE,1,0.036
Computer Vision,Cloud Removal,SEN12MS-CR,SAM,1,8.15
Computer Vision,Cloud Removal,SEN12MS-CR,SSIM,1,0.875
Computer Vision,3D Multi-Object Tracking,KITTI,MOTA,1,84.24
Computer Vision,3D Multi-Object Tracking,KITTI,MOTP,1,85.73
Computer Vision,3D Multi-Object Tracking,KITTI,MOTA,2,83.34
Computer Vision,3D Multi-Object Tracking,KITTI,MOTP,2,85.23
Computer Vision,3D Multi-Object Tracking,nuScenes,amota,1,0.7
Computer Vision,3D Multi-Object Tracking,nuScenes,amota,2,0.68
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,1,86.9
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,2,86.7
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,1,99.50
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,2,98.5
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,1,93.99
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,2,93.5
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,1,99.02
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,2,98.60
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,1,58.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,1,78.1
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,1,85.9
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,1,89.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,1,92.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,2,45.2
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,2,69.6
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,2,80.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,2,87.5
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,2,91.4
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,89.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),1,88.3
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,89.2
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,88.2
Computer Vision,Skeleton Based Action Recognition,HDM05,Accuracy,1,89.80
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,1,96.0
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,2,92.91
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,1,81.4
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,2,73.8
Computer Vision,Skeleton Based Action Recognition,MSRC-12,Accuracy,1,99.08
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,1,47.7
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,2,38.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,1,60.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,2,58.1
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),1,57
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),1,75
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),1,76
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),1,29
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),1,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),2,53
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),2,43
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),2,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),2,25
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),2,56
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,1,99.1
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,2,98.4
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),1,89.64
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),1,91.78
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),1,89.56
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),2,91.12
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),2,91.76
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),2,91.26
Computer Vision,Skeleton Based Action Recognition,TCG-dataset,Acc,1,87.24
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,1,91.9
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Speed  (FPS),1,2200
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,93.57
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,2,91.43
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),1,94.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),1,97.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),2,91.0
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),2,96.5
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Accuracy,1,78.0
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,1,77.2
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,2,67.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),1,92.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),1,94.4
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),2,92.6
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),2,94.2
Computer Vision,Skeleton Based Action Recognition,Skeletics-152,Accuracy (Cross-Subject),1,57.01
Computer Vision,Skeleton Based Action Recognition,Skeleton-Mimetics,Accuracy (%),1,57.37
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,1,88.51
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,2,86.1
Computer Vision,Skeleton Based Action Recognition,MSR ActionPairs,Accuracy,1,98.02
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,1,91.1
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,2,89.3
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:1 Accuracy,1,95.93
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:3 Accuracy,1,92.9
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,3:1 Accuracy,1,96.76
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,Cross-person Accuracy,1,88.70
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,1,37.98
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,2,36.97
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),1,90.4
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (pose),1,67.9
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),2,86.1
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,1,97.5
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,2,93.4
Computer Vision,One-Shot 3D Action Recognition,NTU RGB+D 120,Accuracy,1,49.6
Computer Vision,One-Shot 3D Action Recognition,NTU RGB+D 120,Accuracy,2,46.5
Time Series,Multivariate Time Series Forecasting,MuJoCo,"MSE (10^-2, 50% missing)",1,1.258
Time Series,Multivariate Time Series Forecasting,MuJoCo,"MSE (10^-2, 50% missing)",2,1.377
Time Series,Multivariate Time Series Forecasting,Helpdesk,Accuracy,1,0.7123
Time Series,Multivariate Time Series Forecasting,MIMIC-III,MSE,1,0.48
Time Series,Multivariate Time Series Forecasting,MIMIC-III,NegLL,1,0.83
Time Series,Multivariate Time Series Forecasting,MIMIC-III,MSE,2,0.62
Time Series,Multivariate Time Series Forecasting,MIMIC-III,NegLL,2,1.02
Time Series,Multivariate Time Series Forecasting,USHCN-Daily,MSE,1,0.43
Time Series,Multivariate Time Series Forecasting,USHCN-Daily,MSE,2,0.53
Time Series,Multivariate Time Series Forecasting,BPI challenge '12,Accuracy,1,0.7600
Time Series,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,MSE stdev,1,0.050
Time Series,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,mse (10^-3),1,2.208
Time Series,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,MSE stdev,2,0.029
Time Series,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,mse (10^-3),2,2.231
Time Series,Univariate Time Series Forecasting,Solar-Power,RRSE,1,0.4643
Time Series,Univariate Time Series Forecasting,Electricity,RRSE,1,0.0745
Time Series,Univariate Time Series Forecasting,Electricity,RRSE,2,0.0823
Time Series,Probabilistic Time Series Forecasting,Internet Traffic dataset (A5M),CRPS,1,6.84e7
Time Series,Probabilistic Time Series Forecasting,Internet Traffic dataset (A5M),KLD,1,2.84e11
Time Series,Probabilistic Time Series Forecasting,Lorenz dataset,CRPS,1,1.511
Time Series,Probabilistic Time Series Forecasting,Lorenz dataset,KLD,1,1.67e2
Time Series,Probabilistic Time Series Forecasting,Mackey-Glass dataset,CRPS,1,1.91e4
Time Series,Probabilistic Time Series Forecasting,Mackey-Glass dataset,KLD,1,3.18e3
Computer Vision,Scene Understanding,ADE20K val,Mean IoU,1,46.3
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),OMQ,1,0.44
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_fp_quality,1,0.28
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_label,1,1.0
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_pairwise,1,0.68
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_spatial,1,0.51
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),OMQ,2,0.37
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_fp_quality,2,0.09
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_label,2,0.97
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_pairwise,2,0.74
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (passive actuation & ground-truth localisation),avg_spatial,2,0.59
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (active actuation & ground-truth localisation),OMQ,1,0.35
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (active actuation & ground-truth localisation),avg_fp_quality,1,0.43
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (active actuation & ground-truth localisation),avg_label,1,1.0
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (active actuation & ground-truth localisation),avg_pairwise,1,0.64
Computer Vision,Scene Understanding,Semantic Scene Understanding Challenge (active actuation & ground-truth localisation),avg_spatial,1,0.46
Computer Vision,Scene Text Recognition,ICDAR2013,Accuracy,1,95.5
Computer Vision,Scene Text Recognition,ICDAR2013,Accuracy,2,94.7
Computer Vision,Scene Text Recognition,ICDAR 2003,Accuracy,1,96.7
Computer Vision,Scene Text Recognition,ICDAR 2003,Accuracy,2,95.0
Computer Vision,Scene Text Recognition,SVT,Accuracy,1,91.8
Computer Vision,Scene Text Recognition,SVT,Accuracy,2,91.5
Computer Vision,Scene Text Recognition,ICDAR2015,Accuracy,1,82.2
Computer Vision,Scene Text Recognition,ICDAR2015,Accuracy,2,81.6
Computer Vision,Scene Recognition,SUN-RGBD,Accuracy (%),1,60.7
Computer Vision,Scene Recognition,YUP++,Accuracy (%),1,84.44
Computer Vision,Scene Recognition,ScanNet,Average Recall,1,54.28
Computer Vision,Scene Graph Generation,3R-Scan,Top-5 Accuracy,1,0.87
Computer Vision,Scene Graph Generation,3R-Scan,Top-5 Accuracy,2,0.66
Computer Vision,Scene Graph Generation,VRD,Recall@50,1,18.32
Computer Vision,Scene Graph Generation,VRD,Recall@50,2,18.16
Computer Vision,Scene Graph Generation,Visual Genome,Recall@50,1,31.93
Computer Vision,Scene Graph Generation,Visual Genome,mean Recall @20,1,6.9
Computer Vision,Scene Graph Generation,Visual Genome,Recall@50,2,31.74
Computer Vision,Scene Graph Generation,Visual Genome,mean Recall @20,2,7.1
Computer Vision,Face Parsing,iBugMask,Average F1,1,86.466666667
Natural Language Processing,Dialogue Generation,Amazon-5,1 in 10 R@2,1,5
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Activity),F1,1,11.43
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Activity),Precision,1,16.84
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Activity),Recall,1,9.72
Natural Language Processing,Dialogue Generation,Reddit (multi-ref),interest (human),1,2.53
Natural Language Processing,Dialogue Generation,Reddit (multi-ref),relevance (human),1,2.72
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Entity),F1,1,3.72
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Entity),Precision,1,4.91
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Entity),Recall,1,3.36
Natural Language Processing,Dialogue Generation,Twitter Dialogue (Noun),F1,1,4.63
Natural Language Processing,Dialogue Generation,Twitter Dialogue (Noun),Precision,1,4.82
Natural Language Processing,Dialogue Generation,Twitter Dialogue (Noun),Recall,1,5.22
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Tense),Accuracy,1,29.01
Natural Language Processing,Dialogue Generation,Ubuntu Dialogue (Cmd),Accuracy,1,95.04
Natural Language Processing,Dialogue Generation,Persona-Chat,Avg F1,1,19.77
Natural Language Processing,Dialogue Generation,Persona-Chat,Avg F1,2,19.09
Natural Language Processing,Dialogue Generation,Twitter Dialogue (Tense),Accuracy,1,34.48
Natural Language Processing,Data-to-Text Generation,WebNLG,BLEU,1,0.6607
Natural Language Processing,Data-to-Text Generation,WebNLG,BLEU,2,0.647
Natural Language Processing,Data-to-Text Generation,MULTIWOZ 2.1,BLEU,1,35.1
Natural Language Processing,Data-to-Text Generation,MULTIWOZ 2.1,BLEU,2,34.96
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Content Selection),Precision,1,40.9
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Content Selection),Recall,1,49.5
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Content Selection),Precision,2,40.8
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Content Selection),Recall,2,54.9
Natural Language Processing,Data-to-Text Generation,RotoWire (Relation Generation),Precision,1,97.6
Natural Language Processing,Data-to-Text Generation,RotoWire (Relation Generation),count,1,42.1
Natural Language Processing,Data-to-Text Generation,RotoWire (Relation Generation),Precision,2,89.46
Natural Language Processing,Data-to-Text Generation,RotoWire (Relation Generation),count,2,21.17
Natural Language Processing,Data-to-Text Generation,ViGGO,BLEU,1,53.6
Natural Language Processing,Data-to-Text Generation,ViGGO,BLEU,2,52.1
Natural Language Processing,Data-to-Text Generation,ToTTo,BLEU,1,49.5
Natural Language Processing,Data-to-Text Generation,ToTTo,PARENT,1,58.4
Natural Language Processing,Data-to-Text Generation,ToTTo,BLEU,2,44
Natural Language Processing,Data-to-Text Generation,ToTTo,PARENT,2,52.6
Natural Language Processing,Data-to-Text Generation,MLB Dataset,BLEU,1,12.62
Natural Language Processing,Data-to-Text Generation,MLB Dataset,BLEU,2,11.50
Natural Language Processing,Data-to-Text Generation,RotoWire (Content Ordering),BLEU,1,17.50
Natural Language Processing,Data-to-Text Generation,RotoWire (Content Ordering),DLD,1,18.90
Natural Language Processing,Data-to-Text Generation,RotoWire (Content Ordering),BLEU,2,16.50
Natural Language Processing,Data-to-Text Generation,RotoWire (Content Ordering),DLD,2,18.58
Natural Language Processing,Data-to-Text Generation,WebNLG Full,BLEU,1,60.56
Natural Language Processing,Data-to-Text Generation,WebNLG Full,BLEU,2,57.1
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Content Ordering),DLD,1,21.8
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Content Ordering),DLD,2,20.7
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,BLEU score,1,26.35
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,CIDER,1,2.60
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,METEOR,1,25.81
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,NIST,1,5.24
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,BLEU score,2,21.96
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,CIDER,2,2.18
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,METEOR,2,23.32
Natural Language Processing,Data-to-Text Generation,Czech Restaurant NLG,NIST,2,4.77
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Relation Generation),Precision,1,94.4
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Relation Generation),count,1,30.8
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Relation Generation),Precision,2,81.1
Natural Language Processing,Data-to-Text Generation,MLB Dataset (Relation Generation),count,2,23.8
Natural Language Processing,Data-to-Text Generation,RotoWire,BLEU,1,17.50
Natural Language Processing,Data-to-Text Generation,RotoWire,BLEU,2,16.50
Natural Language Processing,Data-to-Text Generation,SR11Deep,BLEU,1,80.49
Natural Language Processing,Data-to-Text Generation,SR11Deep,BLEU,2,0.666
Natural Language Processing,Data-to-Text Generation,WebNLG ru,METEOR,1,0.613
Natural Language Processing,Data-to-Text Generation,WebNLG ru,METEOR,2,0.180
Natural Language Processing,Data-to-Text Generation,Rotowire (Content Selection),Precision,1,39.47
Natural Language Processing,Data-to-Text Generation,Rotowire (Content Selection),Recall,1,51.64
Natural Language Processing,Data-to-Text Generation,Rotowire (Content Selection),Precision,2,34.18
Natural Language Processing,Data-to-Text Generation,Rotowire (Content Selection),Recall,2,51.22
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,BLEU,1,68.60
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,CIDEr,1,2.37
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,METEOR,1,45.25
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,NIST,1,8.73
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,ROUGE-L,1,70.82
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,BLEU,2,67.05
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,CIDEr,2,2.2355
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,METEOR,2,44.49
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,NIST,2,8.5150
Natural Language Processing,Data-to-Text Generation,E2E NLG Challenge,ROUGE-L,2,68.94
Natural Language Processing,Data-to-Text Generation,WebNLG en,METEOR,1,0.462
Natural Language Processing,Data-to-Text Generation,WebNLG en,METEOR,2,0.287
Natural Language Processing,Data-to-Text Generation,Cleaned E2E NLG Challenge,METEOR,1,0.394
Natural Language Processing,Data-to-Text Generation,Cleaned E2E NLG Challenge,METEOR,2,0.391
Natural Language Processing,Multi-Document Summarization,DUC 2004,ROUGE-1,1,38.23
Natural Language Processing,Multi-Document Summarization,review,1-of-100 Accuracy,1,100
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-1,1,43.57
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-2,1,14.03
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-SU4,1,17.37
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-1,2,43.47
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-2,2,14.89
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-SU4,2,17.41
Natural Language Processing,Text Style Transfer,Yelp Review Dataset (Small),"G-Score (BLEU, Accuracy)",1,74.56
Natural Language Processing,Text Style Transfer,Yelp Review Dataset (Small),"G-Score (BLEU, Accuracy)",2,66.25
Natural Language Processing,Text Style Transfer,Yelp Review Dataset (Large),"G-Score (BLEU, Accuracy)",1,59.17
Natural Language Processing,Text Style Transfer,Yelp Review Dataset (Large),BLEU,2,30
Natural Language Processing,Paraphrase Generation,quora,BLEU-1,1,45.7
Natural Language Processing,Paraphrase Generation,quora,BLEU-1,2,22.9
Natural Language Processing,Paraphrase Generation,Paralex,iBLEU,1,14.84
Natural Language Processing,Paraphrase Generation,Quora Question Pairs,iBLEU,1,5.84
Natural Language Processing,Table-to-Text Generation,Wikipedia Person and Animal Dataset,BLEU,1,23.2
Natural Language Processing,Table-to-Text Generation,Wikipedia Person and Animal Dataset,METEOR,1,42.0
Natural Language Processing,Table-to-Text Generation,Wikipedia Person and Animal Dataset,ROUGE,1,23.4
Natural Language Processing,Table-to-Text Generation,WikiBio,BLEU,1,44.89
Natural Language Processing,Table-to-Text Generation,WikiBio,ROUGE,1,41.21
Natural Language Processing,Table-to-Text Generation,WikiBio,BLEU,2,44.71
Natural Language Processing,Table-to-Text Generation,WikiBio,ROUGE,2,41.65
Natural Language Processing,Distractor Generation,RACE,BLEU-1,1,39.81
Natural Language Processing,Distractor Generation,RACE,BLEU-2,1,24.81
Natural Language Processing,Distractor Generation,RACE,BLEU-3,1,17.66
Natural Language Processing,Distractor Generation,RACE,BLEU-4,1,13.56
Natural Language Processing,Distractor Generation,RACE,ROUGE-L,1,34.01
Natural Language Processing,Paper generation,ACL Title and Abstract Dataset,METEOR,1,14.0
Natural Language Processing,Paper generation,ACL Title and Abstract Dataset,ROUGE-L,1,20.3
Natural Language Processing,Concept-To-Text Generation,COCO Captions,BLEU-2,1,2
Natural Language Processing,Fact-based Text Editing,RotoEdit,ADD,1,41.5
Natural Language Processing,Fact-based Text Editing,RotoEdit,BLEU,1,84.43
Natural Language Processing,Fact-based Text Editing,RotoEdit,DELETE,1,84.24
Natural Language Processing,Fact-based Text Editing,RotoEdit,Exact Match,1,2.65
Natural Language Processing,Fact-based Text Editing,RotoEdit,F1,1,63.39
Natural Language Processing,Fact-based Text Editing,RotoEdit,KEEP,1,98.41
Natural Language Processing,Fact-based Text Editing,RotoEdit,Precision,1,78.84
Natural Language Processing,Fact-based Text Editing,RotoEdit,Recall,1,52.3
Natural Language Processing,Fact-based Text Editing,RotoEdit,SARI,1,74.72
Natural Language Processing,Fact-based Text Editing,WebEdit,ADD,1,47.69
Natural Language Processing,Fact-based Text Editing,WebEdit,BLEU,1,75.68
Natural Language Processing,Fact-based Text Editing,WebEdit,DELETE,1,0.7707
Natural Language Processing,Fact-based Text Editing,WebEdit,Exact Match,1,24.8
Natural Language Processing,Fact-based Text Editing,WebEdit,F1,1,93.17
Natural Language Processing,Fact-based Text Editing,WebEdit,KEEP,1,0.9184
Natural Language Processing,Fact-based Text Editing,WebEdit,Precision,1,96.88
Natural Language Processing,Fact-based Text Editing,WebEdit,Recall,1,89.74
Natural Language Processing,Fact-based Text Editing,WebEdit,SARI,1,72.2
Natural Language Processing,Fact-based Text Editing,WebEdit,ADD,2,43.82
Natural Language Processing,Fact-based Text Editing,WebEdit,BLEU,2,71.03
Natural Language Processing,Fact-based Text Editing,WebEdit,DELETE,2,0.7548
Natural Language Processing,Fact-based Text Editing,WebEdit,Exact Match,2,20.96
Natural Language Processing,Fact-based Text Editing,WebEdit,F1,2,92.51
Natural Language Processing,Fact-based Text Editing,WebEdit,KEEP,2,0.8949
Natural Language Processing,Fact-based Text Editing,WebEdit,Precision,2,98.06
Natural Language Processing,Fact-based Text Editing,WebEdit,Recall,2,87.56
Natural Language Processing,Fact-based Text Editing,WebEdit,SARI,2,69.59
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Php,Smoothed BLEU-4,1,26.23
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Php,Smoothed BLEU-4,2,21.32
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Go,Smoothed BLEU-4,1,26.79
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Go,Smoothed BLEU-4,2,26.66
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Ruby,Smoothed BLEU-4,1,15.26
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Ruby,Smoothed BLEU-4,2,8.46
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet,Smoothed BLEU-4,1,15.99
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet,Smoothed BLEU-4,2,15.55
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Java,Smoothed BLEU-4,1,21.87
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Java,Smoothed BLEU-4,2,14.56
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - JavaScript,Smoothed BLEU-4,1,25.61
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - JavaScript,Smoothed BLEU-4,2,18.98
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Python,Smoothed BLEU-4,1,20.39
"Computer Code', 'Natural Language Processing",Code Documentation Generation,CodeSearchNet - Python,Smoothed BLEU-4,2,15.48
Computer Vision,Action Recognition,ActionNet-VE,F-measure (%),1,90.27
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Action@1,1,47.7
Computer Vision,Action Recognition,EPIC-KITCHENS-100,GFLOPs,1,117x1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Noun@1,1,57.3
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Verb@1,1,72.2
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Action@1,2,44.5
Computer Vision,Action Recognition,EPIC-KITCHENS-100,GFLOPs,2,74.9x1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Noun@1,2,55.1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Verb@1,2,69.1
Computer Vision,Action Recognition,AVA v2.2,mAP,1,31.0
Computer Vision,Action Recognition,AVA v2.2,mAP,2,28.7
Computer Vision,Action Recognition,EPIC-KITCHENS-55,Top-1 Accuracy,1,34.2
Computer Vision,Action Recognition,Something-Something V2,GFLOPs,1,320.6
Computer Vision,Action Recognition,Something-Something V2,Parameters,1,89M
Computer Vision,Action Recognition,Something-Something V2,Top-1 Accuracy,1,69.6
Computer Vision,Action Recognition,Something-Something V2,Top-5 Accuracy,1,92.7
Computer Vision,Action Recognition,Something-Something V2,Top-1 Accuracy,2,69.02
Computer Vision,Action Recognition,Something-Something V2,Top-5 Accuracy,2,92.70
Computer Vision,Action Recognition,HMDB-51,Average accuracy of 3 splits,1,84.36
Computer Vision,Action Recognition,HMDB-51,Average accuracy of 3 splits,2,83.8
Computer Vision,Action Recognition,UCF 101,Average accuracy of 3 splits,1,85.10
Computer Vision,Action Recognition,SSBD,Accuracy,1,95.7
Computer Vision,Action Recognition,IRD,Accuracy,1,80.11
Computer Vision,Action Recognition,IRD,Accuracy,2,74.03
Computer Vision,Action Recognition,UCF101,3-fold Accuracy,1,98.64
Computer Vision,Action Recognition,UCF101,3-fold Accuracy,2,98.6
Computer Vision,Action Recognition,Volleyball,Accuracy,1,91.3
Computer Vision,Action Recognition,Volleyball,Accuracy,2,82.6
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CS),1,97.0
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CS),2,95.66
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CV),2,98.79
Computer Vision,Action Recognition,THUMOS’14,mAP@0.3,1,56.0
Computer Vision,Action Recognition,THUMOS’14,mAP@0.4,1,47.4
Computer Vision,Action Recognition,THUMOS’14,mAP@0.5,1,38.8
Computer Vision,Action Recognition,THUMOS’14,mAP@0.3,2,53.9
Computer Vision,Action Recognition,THUMOS’14,mAP@0.4,2,46.8
Computer Vision,Action Recognition,THUMOS’14,mAP@0.5,2,37.4
Computer Vision,Action Recognition,ActivityNet,mAP,1,84.4
Computer Vision,Action Recognition,ActivityNet,mAP,2,53.8
Computer Vision,Action Recognition,Jester,Val,1,97.4
Computer Vision,Action Recognition,Jester,Val,2,96.70
Computer Vision,Action Recognition,Autism,Accuracy,1,75.1
Computer Vision,Action Recognition,MTL-AQA,Armstand Accuracy,1,99.72
Computer Vision,Action Recognition,MTL-AQA,No. of Somersaults Accuracy,1,96.88
Computer Vision,Action Recognition,MTL-AQA,No. of Twists Accuracy,1,93.20
Computer Vision,Action Recognition,MTL-AQA,Position Accuracy,1,96.32
Computer Vision,Action Recognition,MTL-AQA,Rotation Type Accuracy,1,97.45
Computer Vision,Action Recognition,EgoGesture,Top-1 Accuracy,1,94.3
Computer Vision,Action Recognition,EgoGesture,Top-5 Accuracy,1,99.2
Computer Vision,Action Recognition,Sports-1M,Video hit@1 ,1,75.5
Computer Vision,Action Recognition,Sports-1M,Video hit@5,1,92.8
Computer Vision,Action Recognition,Sports-1M,Video hit@1 ,2,74.9
Computer Vision,Action Recognition,Sports-1M,Video hit@5,2,92.6
Computer Vision,Action Recognition,Something-Something V1,Top 1 Accuracy,1,57.0
Computer Vision,Action Recognition,Something-Something V1,Top 5 Accuracy,1,83.7
Computer Vision,Action Recognition,Something-Something V1,Top 1 Accuracy,2,56.8
Computer Vision,Action Recognition,Something-Something V1,Top 5 Accuracy,2,84.1
Computer Vision,Action Recognition,UTD-MHAD,Accuracy,1,92.5
Computer Vision,Action Recognition,HACS,Top 1 Accuracy,1,84.33
Computer Vision,Action Recognition,HACS,Top 5 Accuracy,1,96.85
Computer Vision,Action Recognition,HACS,Top 1 Accuracy,2,83.77
Computer Vision,Action Recognition,HACS,Top 5 Accuracy,2,96.56
Computer Vision,Action Recognition,VIRAT Ground 2.0,Average Accuracy,1,66.45
Computer Vision,Action Recognition,MECCANO,Top-1 Accuracy,1,42.85
Computer Vision,Action Recognition,Diving-48,Accuracy,1,85.5
Computer Vision,Action Recognition,Diving-48,Accuracy,2,81
Computer Vision,Action Recognition,AVA v2.1,mAP (Val),1,28.3
Computer Vision,Action Recognition,AVA v2.1,mAP (Val),2,27.7
Computer Vision,Action Recognition,Win-Fail Action Understanding,2-Class Accuracy,1,75.74
Computer Vision,Action Recognition,miniSports,Accuracy,1,74.9
Computer Vision,Action Recognition,miniSports,Accuracy,2,69.9
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,95.3
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,90.7
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,92.5
Computer Vision,Action Recognition,HAA500,Top-1 (%),1,64.4
Computer Vision,Action Recognition,HAA500,Top-1 (%),2,50.53
Computer Vision,Action Recognition,ICVL-4,Accuracy,1,91.86
Computer Vision,Action Recognition,ICVL-4,Accuracy,2,80.23
Computer Vision,Egocentric Activity Recognition,EGTEA,Average Accuracy,1,69.58
Computer Vision,Egocentric Activity Recognition,EGTEA,Mean class accuracy,1,62.84
Computer Vision,Egocentric Activity Recognition,EGTEA,Average Accuracy,2,62.7
Computer Vision,Egocentric Activity Recognition,EGTEA,Mean class accuracy,2,
Computer Vision,Egocentric Activity Recognition,EPIC-KITCHENS-55,Actions Top-1 (S1),1,34.8
Computer Vision,Egocentric Activity Recognition,EPIC-KITCHENS-55,Actions Top-1 (S2),1,19.06
Computer Vision,Egocentric Activity Recognition,EPIC-KITCHENS-55,Actions Top-1 (S1),2,33.06
Computer Vision,Egocentric Activity Recognition,EPIC-KITCHENS-55,Actions Top-1 (S2),2,19.49
Computer Vision,Multimodal Activity Recognition,Nurse Care Activity Recognition Challenge,Accuracy,1,80.2
Computer Vision,Multimodal Activity Recognition,Nurse Care Activity Recognition Challenge,Accuracy,2,64.6
Computer Vision,Multimodal Activity Recognition,Nurse Care Activity Recognition Challenge,Train F-measure,2,52.9
Computer Vision,Multimodal Activity Recognition,UTD-MHAD,Accuracy (CS),1,95.12
Computer Vision,Multimodal Activity Recognition,UTD-MHAD,Accuracy (CS),2,94.5
Computer Vision,Multimodal Activity Recognition,Moments in Time Dataset,Top-1 (%),1,34.27
Computer Vision,Multimodal Activity Recognition,Moments in Time Dataset,Top-5 (%),1,62.71
Computer Vision,Multimodal Activity Recognition,Moments in Time Dataset,Top-1 (%),2,31.16
Computer Vision,Multimodal Activity Recognition,Moments in Time Dataset,Top-5 (%),2,57.67
Computer Vision,Multimodal Activity Recognition,UCSD-MIT Human Motion,F1-score,1,81.52
Computer Vision,Multimodal Activity Recognition,LboroHAR,Accuracy,1,97.90
Computer Vision,Multimodal Activity Recognition,LboroHAR,Accuracy,2,95.00
Computer Vision,Multimodal Activity Recognition,MSR Daily Activity3D dataset,Accuracy,1,97.5
Computer Vision,Multimodal Activity Recognition,MSR Daily Activity3D dataset,Accuracy,2,95.0
Computer Vision,Multimodal Activity Recognition,EV-Action,Accuracy,1,80.1
Computer Vision,Multimodal Activity Recognition,EV-Action,Accuracy,2,79.6
Computer Vision,Multimodal Activity Recognition, CMU Multi-Modal Activity (CMU-MMAC),Accuracy,1,86.64
Computer Vision,Multimodal Activity Recognition,UT-Kinect,Accuracy (CS),1,97.56
Computer Vision,Group Activity Recognition,Collective Activity,Accuracy,1,91
Computer Vision,Group Activity Recognition,Collective Activity,Accuracy,2,83.75
Computer Vision,Group Activity Recognition,Volleyball,Accuracy,1,92.6
Computer Vision,Group Activity Recognition,Volleyball,Accuracy,2,91.0
Computer Vision,Human action generation,NTU RGB+D,MMD,1,0.285
Computer Vision,Human action generation,NTU RGB+D,MMD,2,0.338
Computer Vision,Human action generation,Human3.6M,MMD,1,0.134
Computer Vision,Human action generation,Human3.6M,MMD,2,0.195
Computer Vision,Recognizing And Localizing Human Actions,HAR,1:1 Accuracy,1,90.37
Knowledge Base,Knowledge Graph Completion,MovieLens 1M,Hits@10,1,48.9
Knowledge Base,Knowledge Graph Completion,MovieLens 1M,Mean Rank,1,527
Knowledge Base,Knowledge Graph Completion,DBbook2014,Hits@10,1,60.75
Knowledge Base,Knowledge Graph Completion,DBbook2014,Mean Rank,1,499
Knowledge Base,Knowledge Graph Completion,FB15k-237,Hits@10,1,62.6
Knowledge Base,Knowledge Graph Completion,FB15k-237,Hits@3,1,54
Knowledge Base,Knowledge Graph Completion,FB15k-237,Hits@10,2,54.2
Knowledge Base,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,Ambiguous dataset,1,97.9
Knowledge Base,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,Base Dataset,1,94.8
Knowledge Base,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,ReVerb45k,1,98.3
Computer Vision,Story Visualization,Pororo,FID,1,67.7
Computer Vision,Story Visualization,Pororo,FSD,1,71.51
Computer Vision,Story Visualization,Pororo,FID,2,77.67
Computer Vision,Story Visualization,Pororo,FSD,2,111.09
Computer Vision,Crowd Counting,ShanghaiTech B,MAE,1,6.3
Computer Vision,Crowd Counting,ShanghaiTech B,MAE,2,6.32
Computer Vision,Crowd Counting,Venice,MAE,1,20.5
Computer Vision,Crowd Counting,Venice,MAE,2,23.5
Computer Vision,Crowd Counting,WorldExpo’10,Average MAE,1,7.2
Computer Vision,Crowd Counting,WorldExpo’10,Average MAE,2,7.32
Computer Vision,Crowd Counting,UCF CC 50,MAE,1,162.33
Computer Vision,Crowd Counting,UCF CC 50,MAE,2,212.2
Computer Vision,Crowd Counting,ShanghaiTech A,MAE,1,57.55
Computer Vision,Crowd Counting,ShanghaiTech A,MSE,1,94.48
Computer Vision,Crowd Counting,ShanghaiTech A,MAE,2,57.6
Computer Vision,Crowd Counting,UCF-QNRF,MAE,1,85.6
Computer Vision,Crowd Counting,UCF-QNRF,MAE,2,85.6
"Robots', 'Computer Vision",Face Anti-Spoofing,CASIA-MFSD,EER,1,4.92
"Robots', 'Computer Vision",Face Anti-Spoofing,CASIA-MFSD,EER,2,2.22
"Robots', 'Computer Vision",Face Anti-Spoofing,CASIA-MFSD,HTER,2,1.67
"Robots', 'Computer Vision",Face Anti-Spoofing,Replay-Attack,EER,1,2.14
"Robots', 'Computer Vision",Face Anti-Spoofing,Replay-Attack,EER,2,0.40
"Robots', 'Computer Vision",Face Anti-Spoofing,Replay-Attack,HTER,2,2.90
"Robots', 'Computer Vision",Face Anti-Spoofing,MSU-MFSD,Equal Error Rate,1,7.5
"Robots', 'Computer Vision",Face Anti-Spoofing,MSU-MFSD,Equal Error Rate,2,10.8
"Robots', 'Computer Vision",Face Anti-Spoofing,MLFP,HTER,1,3.4
"Robots', 'Computer Vision",Face Anti-Spoofing,Replay Mobile,HTER,1,0
Computer Vision,Pulmonary Artery–Vein Classification,SunYs,Accuracy (median),1,0.778
Computer Vision,Pulmonary Artery–Vein Classification,SunYs,Accuracy (median),2,0.764
Computer Vision,Pulmonary Artery–Vein Classification,LUMC,Accuracy (median),1,0.738
Computer Vision,Pulmonary Artery–Vein Classification,LUMC,Accuracy (median),2,0.723
Natural Language Processing,Chinese Word Segmentation,PKU,F1,1,96.7
Natural Language Processing,Chinese Word Segmentation,PKU,Precision,1,97.1
Natural Language Processing,Chinese Word Segmentation,PKU,Recall,1,96.4
Natural Language Processing,Chinese Word Segmentation,CITYU,F1,1,97.9
Natural Language Processing,Chinese Word Segmentation,CITYU,Precision,1,97.9
Natural Language Processing,Chinese Word Segmentation,CITYU,Recall,1,98
Natural Language Processing,Chinese Word Segmentation,AS,F1,1,96.7
Natural Language Processing,Chinese Word Segmentation,AS,Precision,1,96.6
Natural Language Processing,Chinese Word Segmentation,AS,Recall,1,96.8
Natural Language Processing,Chinese Word Segmentation,MSRA,F1,1,97.4
Natural Language Processing,Chinese Word Segmentation,MSR,F1,1,98.35
Natural Language Processing,Chinese Word Segmentation,MSR,F1,2,98.3
Natural Language Processing,Chinese Word Segmentation,MSR,Precision,2,98.2
Natural Language Processing,Chinese Word Segmentation,MSR,Recall,2,98.3
Natural Language Processing,Word Sense Induction,SemEval 2010 WSI,AVG,1,53.6
Natural Language Processing,Word Sense Induction,SemEval 2010 WSI,F-Score,1,71.3
Natural Language Processing,Word Sense Induction,SemEval 2010 WSI,V-Measure,1,40.4
Natural Language Processing,Word Sense Induction,SemEval 2010 WSI,AVG,2,24.59
Natural Language Processing,Word Sense Induction,SemEval 2010 WSI,F-Score,2,61.7
Natural Language Processing,Word Sense Induction,SemEval 2010 WSI,V-Measure,2,9.8
Natural Language Processing,Word Sense Induction,SemEval 2013,AVG,1,37.0
Natural Language Processing,Word Sense Induction,SemEval 2013,F-BC,1,64.0
Natural Language Processing,Word Sense Induction,SemEval 2013,F_NMI,1,21.4
Natural Language Processing,Word Sense Induction,SemEval 2013,AVG,2,22.16
Natural Language Processing,Word Sense Induction,SemEval 2013,F-BC,2,61.7
Natural Language Processing,Word Sense Induction,SemEval 2013,F_NMI,2,7.96
Medical,Sleep Stage Detection,MASS SS3,Accuracy,1,89.1
Medical,Sleep Stage Detection,MASS SS3,Accuracy,2,88.8
Medical,Sleep Stage Detection,DODH,Accuracy,1,89.9
Medical,Sleep Stage Detection,DODH,Kappa,1,84.6
Medical,Sleep Stage Detection,DODH,Accuracy,2,89.6
Medical,Sleep Stage Detection,DODH,Kappa,2,84.3
Medical,Sleep Stage Detection,MASS SS2,Accuracy,1,84.5
Medical,Sleep Stage Detection,MASS SS2,Accuracy,2,78.6
Medical,Sleep Stage Detection,Sleep-EDF,Accuracy,1,84.0
Medical,Sleep Stage Detection,Sleep-EDF,Accuracy,2,82
Medical,Sleep Stage Detection,Sleep-EDF,Cohen's kappa,2,0.76
Medical,Sleep Stage Detection,Sleep-EDF,Macro-F1,2,76.9
Medical,Sleep Stage Detection,DODO,Accuracy,1,88.7
Medical,Sleep Stage Detection,DODO,Kappa,1,82.3
Medical,Sleep Stage Detection,DODO,Accuracy,2,87.5
Medical,Sleep Stage Detection,DODO,Kappa,2,80.4
Medical,Spindle Detection,Wisconsin Sleep Cohort (WSC),F1-score (@IoU = 0.3),1,0.46
Medical,Spindle Detection,Stanford Sleep Cohort (SSC),F1-score (@IoU = 0.3),1,0.48
Medical,Spindle Detection,MASS SS2,F1-score (@IoU = 0.2),1,0.812
Medical,Spindle Detection,MASS SS2,F1-score (@IoU = 0.3),1,0.812
Medical,Spindle Detection,MASS SS2,F1-score (@IoU = 0.2),2,0.809
Medical,Spindle Detection,MASS SS2,F1-score (@IoU = 0.3),2,0.809
Medical,K-complex detection,MASS SS2,F1-score (@IoU = 0.2),1,0.828
Medical,K-complex detection,MASS SS2,F1-score (@IoU = 0.3),1,0.827
Medical,K-complex detection,MASS SS2,F1-score (@IoU = 0.2),2,0.826
Medical,K-complex detection,MASS SS2,F1-score (@IoU = 0.3),2,0.825
Medical,Sleep apnea detection,Dreem_NCT03657329,Accuracy,1,81
Medical,Sleep apnea detection,Dreem_NCT03657329,F1-score (@IoU = 0.3),1,0.57
Medical,Sleep apnea detection,Dreem_NCT03657329,Mean AHI Error,1,4.69
Medical,Multimodal Sleep Stage Detection,Sleep-EDF-ST,Accuracy,1,79.6
Medical,Multimodal Sleep Stage Detection,Surrey-PSG,Accuracy,1,79.9
Medical,Multimodal Sleep Stage Detection,Surrey-cEEGGrid,Accuracy,1,81.5
Medical,Multimodal Sleep Stage Detection,Sleep-EDF-SC,Accuracy,1,82.2
Medical,Sleep Arousal Detection,You Snooze You Win - The PhysioNet Computing in Cardiology Challenge 2018,AUPRC,1,0.550
Medical,Sleep Arousal Detection,You Snooze You Win - The PhysioNet Computing in Cardiology Challenge 2018,AUROC,1,0.927
Medical,Sleep Arousal Detection,MESA,F1-score (@IoU = 0.3),1,0.71
Medical,Sleep Arousal Detection,MESA,F1-score (@IoU = 0.3),2,0.61
Speech,Spoken language identification,YouTube News dataset (Crackling Noise),Accuracy ,1,0.93
Speech,Spoken language identification,YouTube News dataset (Crackling Noise),F1 Score,1,0.93
Speech,Spoken language identification,YouTube News dataset (Crackling Noise),Accuracy ,2,0.82
Speech,Spoken language identification,YouTube News dataset (Crackling Noise),F1 Score,2,0.83
Speech,Spoken language identification,VOXLINGUA107,0..5sec,1,12.3
Speech,Spoken language identification,VOXLINGUA107,5..20sec,1,6.1
Speech,Spoken language identification,VOXLINGUA107,Average,1,7.1
Speech,Spoken language identification,VOXLINGUA107,0..5sec,2,13.4
Speech,Spoken language identification,VOXLINGUA107,5..20sec,2,6.6
Speech,Spoken language identification,VOXLINGUA107,Average,2,7.6
Speech,Spoken language identification,VoxForge Commonwealth,Accuracy (%),1,95.4
Speech,Spoken language identification,VoxForge Commonwealth,Accuracy (%),2,95.0
Speech,Spoken language identification,YouTube News dataset (White Noise),Accuracy ,1,0.91
Speech,Spoken language identification,YouTube News dataset (White Noise),F1 Score,1,0.91
Speech,Spoken language identification,YouTube News dataset (White Noise),Accuracy ,2,0.63
Speech,Spoken language identification,YouTube News dataset (White Noise),F1 Score,2,0.63
Speech,Spoken language identification,YouTube News dataset (No Noise),Accuracy ,1,0.96
Speech,Spoken language identification,YouTube News dataset (No Noise),F1 Score,1,0.96
Speech,Spoken language identification,YouTube News dataset (No Noise),Accuracy ,2,0.91
Speech,Spoken language identification,YouTube News dataset (No Noise),F1 Score,2,0.91
Speech,Spoken language identification,VoxForge European,Accuracy (%),1,96.3
Speech,Spoken language identification,VoxForge European,Accuracy (%),2,96.0
Speech,Spoken language identification,LRE07,10 sec,1,2.61
Speech,Spoken language identification,LRE07,3 sec,1,8.25
Speech,Spoken language identification,LRE07,30 sec,1,1.16
Speech,Spoken language identification,LRE07,Average,1,4.00
Speech,Spoken language identification,LRE07,10 sec,2,2.49
Speech,Spoken language identification,LRE07,3 sec,2,8.59
Speech,Spoken language identification,LRE07,30 sec,2,1.09
Speech,Spoken language identification,LRE07,Average,2,4.06
Speech,Spoken language identification,KALAKA-3,EC,1,0.022
Speech,Spoken language identification,KALAKA-3,EO,1,0.058
Speech,Spoken language identification,KALAKA-3,PC,1,0.041
Speech,Spoken language identification,KALAKA-3,PO,1,0.056
Speech,Spoken language identification,KALAKA-3,EC,2,0.033
Speech,Spoken language identification,KALAKA-3,EO,2,0.059
Speech,Spoken language identification,KALAKA-3,PC,2,0.055
Speech,Spoken language identification,KALAKA-3,PO,2,0.083
Speech,Spoken language identification,Untranscribed mixed-speech dataset,ACC,1,45.2
Speech,Spoken language identification,Untranscribed mixed-speech dataset,PRC,1,44.8
Speech,Spoken language identification,Untranscribed mixed-speech dataset,RCL,1,45.4
Speech,Spoken language identification,Untranscribed mixed-speech dataset,ACC,2,40.4
Speech,Spoken language identification,Untranscribed mixed-speech dataset,PRC,2,40.2
Speech,Spoken language identification,Untranscribed mixed-speech dataset,RCL,2,41.3
Speech,Spoken language identification,YouTube News dataset (Background Music),Accuracy ,1,0.89
Speech,Spoken language identification,YouTube News dataset (Background Music),F1 Score,1,0.89
Speech,Spoken language identification,YouTube News dataset (Background Music),Accuracy ,2,0.70
Speech,Spoken language identification,YouTube News dataset (Background Music),F1 Score,2,0.70
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,Accuracy,1,85.2
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,Accuracy,2,74.3
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-French,Accuracy,1,84.7
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-French,Accuracy,2,67.7
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI,Accuracy,1,83.7
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI,Accuracy,2,71.3
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,Accuracy,1,84.2
Natural Language Processing,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,Accuracy,2,70.5
Medical,ALS Detection,ALS EMG (University of Copenhagen),Accuracy,1,96.69
Medical,EMG Signal Prediction,Grand Challenge Competition - in Vivo Knee Loads," RMSE (SE, Gluteus Medius)",1,0.22
Medical,Medial knee JRF Prediction,Grand Challenge Competition - in Vivo Knee Loads, RMSE (Subject-exposed),1,186
Medical,Medial knee JRF Prediction,Grand Challenge Competition - in Vivo Knee Loads,RMSE (Subject-naïve),1,216
Medical,Medial knee JRF Prediction,Grand Challenge Competition - in Vivo Knee Loads, RMSE (Subject-exposed),2,212
Medical,Medial knee JRF Prediction,Grand Challenge Competition - in Vivo Knee Loads,RMSE (Subject-naïve),2,247
Medical,Muscle Force Prediction,Grand Challenge Competition - in Vivo Knee Loads," RMSE (SE, Gluteus Maximus)",1,91
Medical,Muscle Force Prediction,Grand Challenge Competition - in Vivo Knee Loads," RMSE (SE, Gluteus Medius)",1,196
Medical,Muscle Force Prediction,Grand Challenge Competition - in Vivo Knee Loads," RMSE (SE, Hamstrings)",1,140
Medical,Muscle Force Prediction,Grand Challenge Competition - in Vivo Knee Loads," RMSE (SE, Quadriceps)",1,194
Natural Language Processing,Cross-Document Language Modeling,MultiNews test,Perplexity,1,1.76
Natural Language Processing,Cross-Document Language Modeling,MultiNews test,Perplexity,2,1.93
Natural Language Processing,Cross-Document Language Modeling,MultiNews val,Perplexity,1,1.69
Natural Language Processing,Cross-Document Language Modeling,MultiNews val,Perplexity,2,1.88
"Medical', 'Computer Vision",Retinal OCT Disease Classification,Srinivasan2014,Acc,1,100
"Medical', 'Computer Vision",Retinal OCT Disease Classification,Srinivasan2014,Acc,2,100
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Acc,1,99.8
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Sensitivity,1,99.8
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Acc,2,99.7
"Medical', 'Computer Vision",Retinal OCT Disease Classification,OCT2017,Sensitivity,2,99.7
Medical,Predicting Patient Outcomes,eICU Collaborative Research Database,Kappa,1,0.58
Medical,Atrial Fibrillation Detection,PhysioNet Challenge 2017,F1,1,0.8843
Medical,Atrial Fibrillation Detection,PhysioNet Challenge 2017,PR-AUC,1,0.9584
Medical,Atrial Fibrillation Detection,PhysioNet Challenge 2017,ROC-AUC,1,0.9550
Medical,Atrial Fibrillation Detection,PhysioNet Challenge 2017,F1,2,0.8342
Medical,Atrial Fibrillation Detection,PhysioNet Challenge 2017,PR-AUC,2,0.9436
Medical,Atrial Fibrillation Detection,PhysioNet Challenge 2017,ROC-AUC,2,0.9488
Medical,Atrial Fibrillation Detection,MIT-BIH AF,Accuracy,1,99.40
Medical,Atrial Fibrillation Detection,MIT-BIH AF,Accuracy,2,99.16
Miscellaneous,Malware Detection,Android Malware Dataset,Accuracy,1,99.03
Miscellaneous,Malware Detection,Android Malware Dataset,Accuracy,2,98.16
Computer Vision,Co-Salient Object Detection,CoSal2015,Average MAE,1,0.071
Computer Vision,Co-Salient Object Detection,CoSal2015,S-Measure,1,0.844
Computer Vision,Co-Salient Object Detection,CoSal2015,max E-Measure,1,0.887
Computer Vision,Co-Salient Object Detection,CoSal2015,max F-Measure,1,0.844
Computer Vision,Co-Salient Object Detection,CoSal2015,Average MAE,2,0.077
Computer Vision,Co-Salient Object Detection,CoSal2015,S-Measure,2,0.836
Computer Vision,Co-Salient Object Detection,CoSal2015,max E-Measure,2,0.882
Computer Vision,Co-Salient Object Detection,CoSal2015,max F-Measure,2,0.832
Computer Vision,Co-Salient Object Detection,CoCA,Mean F-measure,1,0.504
Computer Vision,Co-Salient Object Detection,CoCA,S-Measure,1,0.658
Computer Vision,Co-Salient Object Detection,CoCA,max F-Measure,1,0.513
Computer Vision,Co-Salient Object Detection,CoCA,mean E-Measure,1,0.701
Computer Vision,Co-Salient Object Detection,CoCA,Mean F-measure,2,0.390
Computer Vision,Co-Salient Object Detection,CoCA,S-Measure,2,0.627
Computer Vision,Co-Salient Object Detection,CoCA,max F-Measure,2,0.499
Computer Vision,Co-Salient Object Detection,CoCA,mean E-Measure,2,0.606
Computer Vision,Co-Salient Object Detection,iCoSeg,Average MAE,1,0.060
Computer Vision,Co-Salient Object Detection,iCoSeg,S-Measure,1,0.875
Computer Vision,Co-Salient Object Detection,iCoSeg,max E-Measure,1,0.912
Computer Vision,Co-Salient Object Detection,iCoSeg,max F-Measure,1,0.876
Computer Vision,Co-Salient Object Detection,CoSOD3k,Average MAE,1,0.092
Computer Vision,Co-Salient Object Detection,CoSOD3k,S-Measure,1,0.762
Computer Vision,Co-Salient Object Detection,CoSOD3k,max E-Measure,1,0.825
Computer Vision,Co-Salient Object Detection,CoSOD3k,max F-Measure,1,0.736
Computer Vision,Co-Salient Object Detection,CoSOD3k,Average MAE,2,0.119
Computer Vision,Co-Salient Object Detection,CoSOD3k,S-Measure,2,0.7619
Computer Vision,Co-Salient Object Detection,CoSOD3k,max E-Measure,2,0.793
Computer Vision,Co-Salient Object Detection,CoSOD3k,max F-Measure,2,0.702
Computer Vision,Video Saliency Detection,UCFSports,CC,1,0.673
Computer Vision,Video Saliency Detection,DHF1K,AUC-J,1,0.908
Computer Vision,Video Saliency Detection,DHF1K,CC,1,0.51
Computer Vision,Video Saliency Detection,DHF1K,NSS,1,2.87
Computer Vision,Video Saliency Detection,DHF1K,s-AUC,1,0.728
Computer Vision,Video Saliency Detection,DHF1K,NSS,2,2.667
Computer Vision,Video Saliency Detection,Hollywood2,CC,1,0.693
Computer Vision,Video Saliency Detection,DIEM,CC,1,0.632
Natural Language Processing,Hate Speech Detection,OffensEval 2019,Macro F1,1,0.805
Natural Language Processing,Hate Speech Detection,OffensEval 2019,Macro F1,2,0.803
Natural Language Processing,Hate Speech Detection,HatEval,Macro F1,1,0.494
Natural Language Processing,Hate Speech Detection,HatEval,Macro F1,2,0.48
Natural Language Processing,Hate Speech Detection,Hate Speech and Offensive Language,Accuracy,1,0.956
Natural Language Processing,Hate Speech Detection,"Waseem et al., 2018",AAA,1,50.94
Natural Language Processing,Hate Speech Detection,"Waseem et al., 2018",F1 (micro),1,84.42
Natural Language Processing,Hate Speech Detection,"Waseem et al., 2018",AAA,2,46.51
Natural Language Processing,Hate Speech Detection,"Waseem et al., 2018",F1 (micro),2,82.18
Natural Language Processing,Hate Speech Detection,HateXplain,AUROC,1,0.851
Natural Language Processing,Hate Speech Detection,HateXplain,Accuracy,1,0.698
Natural Language Processing,Hate Speech Detection,HateXplain,Macro F1,1,0.687
Natural Language Processing,Hate Speech Detection,HateXplain,AUROC,2,0.851
Natural Language Processing,Hate Speech Detection,HateXplain,Macro F1,2,0.687
Natural Language Processing,Hate Speech Detection,ToLD-Br,F1-score,1,0.75
Natural Language Processing,Hate Speech Detection,ToLD-Br,F1-score,2,0.74
Natural Language Processing,Hate Speech Detection,Ethos MultiLabel,Hamming Loss,1,0.2948
Natural Language Processing,Hate Speech Detection,Ethos MultiLabel,Hamming Loss,2,0.1606
Natural Language Processing,Hate Speech Detection,Ethos Binary,Classification Accuracy,1,0.7734
Natural Language Processing,Hate Speech Detection,Ethos Binary,F1-score,1,0.768
Natural Language Processing,Hate Speech Detection,Ethos Binary,Precision,1,77.76
Natural Language Processing,Hate Speech Detection,Ethos Binary,Classification Accuracy,2,0.7664
Natural Language Processing,Hate Speech Detection,Ethos Binary,F1-score,2,0.7883
Natural Language Processing,Hate Speech Detection,Ethos Binary,Precision,2,79.17
Natural Language Processing,Hate Speech Detection,Automatic Misogynistic Identification,Accuracy,1,0.832
Natural Language Processing,Hate Speech Detection,Automatic Misogynistic Identification,Accuracy,2,0.704
Natural Language Processing,Hate Speech Detection,Hostility Detection Dataset in Hindi,F1 score,1,0.5725
Natural Language Processing,Hate Speech Detection,AbusEval,Macro F1,1,0.742
Natural Language Processing,Hate Speech Detection,AbusEval,Macro F1,2,0.724
Miscellaneous,Network Intrusion Detection,NB15-Backdoor,AUC,1,0.969
Miscellaneous,Network Intrusion Detection,NB15-Backdoor,Average Precision,1,0.883
Miscellaneous,Network Intrusion Detection,UNSW-NB15,Accuracy,1,99.6
Miscellaneous,Network Intrusion Detection,UNSW-NB15,Precision,1,99.5
Miscellaneous,Network Intrusion Detection,UNSW-NB15,Recall,1,99.75
Miscellaneous,Network Intrusion Detection,UNSW-NB15,Accuracy,2,99.5
Miscellaneous,Network Intrusion Detection,UNSW-NB15,Precision,2,99.5
Miscellaneous,Network Intrusion Detection,UNSW-NB15,Recall,2,99.55
Miscellaneous,Network Intrusion Detection,KDD ,Accuracy,1,93
Natural Language Processing,Negation Scope Resolution,*sem 2012 Shared Task: Sherlock Dataset,F1,1,92.36
Natural Language Processing,Negation Scope Resolution,*sem 2012 Shared Task: Sherlock Dataset,F1,2,91.59
Natural Language Processing,Negation Scope Resolution,BioScope : Abstracts,F1,1,95.74
Natural Language Processing,Negation Scope Resolution,BioScope : Abstracts,F1,2,95.68
Natural Language Processing,Negation Scope Resolution,SFU Review Corpus,F1,1,91.25
Natural Language Processing,Negation Scope Resolution,SFU Review Corpus,F1,2,90.95
Natural Language Processing,Negation Scope Resolution,BioScope : Full Papers,F1,1,94.4
Natural Language Processing,Negation Scope Resolution,BioScope : Full Papers,F1,2,91.24
Natural Language Processing,Stance Detection (US Election 2020 - Biden),Twitter Stance Election 2020,Average F1,1,0.7577
Natural Language Processing,Stance Detection (US Election 2020 - Trump),Twitter Stance Election 2020,Average F1,1,0.7877
"Robots', 'Miscellaneous",Grasp Contact Prediction,ContactPose,AUC,1,84.74
"Robots', 'Miscellaneous",Grasp Contact Prediction,ContactDB,Error rate,1,8.72
"Robots', 'Miscellaneous",Grasp Contact Prediction,ContactDB,Error rate,2,17.27
Natural Language Processing,Event Extraction,Infectious Diseases 2011 (ID),F1,1,61.62
Natural Language Processing,Event Extraction,GENIA 2013,F1,1,56.72
Natural Language Processing,Event Extraction,Cancer Genetics 2013 (CG),F1,1,61.74
Natural Language Processing,Event Extraction,GENIA,F1,1,63.96
Natural Language Processing,Event Extraction,GENIA,F1,2,60.06
Natural Language Processing,Event Extraction,Multi-Level Event Extraction (MLEE),F1,1,61.87
Natural Language Processing,Event Extraction,Epigenetics and Post-translational Modifications 2011 (EPI),F1,1,65.57
Natural Language Processing,Event Extraction,Pathway Curation 2013 (PC),F1,1,57.72
Natural Language Processing,Event Extraction,Infectious Diseases 2011 (ID),F1,1,61.62
Natural Language Processing,Event Extraction,GENIA 2013,F1,1,56.72
Natural Language Processing,Event Extraction,Cancer Genetics 2013 (CG),F1,1,61.74
Natural Language Processing,Event Extraction,GENIA,F1,1,63.96
Natural Language Processing,Event Extraction,GENIA,F1,2,60.06
Natural Language Processing,Event Extraction,Multi-Level Event Extraction (MLEE),F1,1,61.87
Natural Language Processing,Event Extraction,Epigenetics and Post-translational Modifications 2011 (EPI),F1,1,65.57
Natural Language Processing,Event Extraction,Pathway Curation 2013 (PC),F1,1,57.72
Natural Language Processing,Joint Entity and Relation Extraction,NYT,F1,1,92.5
Natural Language Processing,Joint Entity and Relation Extraction,ACE 2005,Relation F1,1,62.2
Natural Language Processing,Joint Entity and Relation Extraction,SciERC,Relation F1,1,50.84
Natural Language Processing,Joint Entity and Relation Extraction,SciERC,Entity F1,2,67.50
Natural Language Processing,Joint Entity and Relation Extraction,SciERC,Relation F1,2,48.40
Natural Language Processing,Joint Entity and Relation Extraction,WebNLG,F1,1,93.4
Natural Language Processing,Joint Entity and Relation Extraction,DocRED,Relation F1,1,40.38
Natural Language Processing,Temporal Information Extraction,TimeBank,F1 score,1,0.511
Natural Language Processing,Temporal Information Extraction,TimeBank,F1 score,2,0.507
Natural Language Processing,Temporal Information Extraction,TempEval-3,Temporal awareness,1,67.2
Natural Language Processing,Temporal Information Extraction,TempEval-3,Temporal awareness,2,30.98
Natural Language Processing,Low Resource Named Entity Recognition,CONLL 2003 German,F1 score,1,65.24
Natural Language Processing,Low Resource Named Entity Recognition,Conll 2003 Spanish,F1 score,1,75.93
Natural Language Processing,Low Resource Named Entity Recognition,CONLL 2003 Dutch,F1 score,1,74.61
Natural Language Processing,Drug–drug Interaction Extraction,DDI extraction 2013 corpus,F1,1,0.8408
Natural Language Processing,Drug–drug Interaction Extraction,DDI extraction 2013 corpus,Micro F1,1,84.08
Natural Language Processing,Drug–drug Interaction Extraction,DDI extraction 2013 corpus,F1,2,0.8367
Natural Language Processing,Drug–drug Interaction Extraction,DDI extraction 2013 corpus,Micro F1,2,83.67
Computer Vision,Tumor Segmentation,BUS 2017 Dataset B,Dice Score,1,0.7341
Computer Vision,3D Semantic Segmentation,PartNet,mIOU,1,58.2
Computer Vision,3D Semantic Segmentation,PartNet,mIOU,2,53.8
Computer Vision,3D Semantic Segmentation,SemanticKITTI,mIoU,1,70.8
Computer Vision,3D Semantic Segmentation,SemanticKITTI,mIoU,2,68.9
Computer Vision,3D Semantic Segmentation,nuScenes,mIoU,1,78.3
Computer Vision,3D Semantic Segmentation,RELLIS-3D Dataset,Mean IoU (class),1,40.2
Computer Vision,3D Semantic Segmentation,RELLIS-3D Dataset,Mean IoU (class),2,18.64
Computer Vision,3D Semantic Segmentation,3D Platelet EM,Mean IoU (test),1,0.446
Computer Vision,3D Semantic Segmentation,S3DIS,mAcc,1,87.12
Computer Vision,3D Semantic Segmentation,S3DIS,mIoU,2,58.98
Computer Vision,Panoptic Segmentation,Cityscapes val,AP,1,46.8
Computer Vision,Panoptic Segmentation,Cityscapes val,PQ,1,69.6
Computer Vision,Panoptic Segmentation,Cityscapes val,mIoU,1,85.3
Computer Vision,Panoptic Segmentation,Cityscapes val,AP,2,
Computer Vision,Panoptic Segmentation,Cityscapes val,PQ,2,68.5
Computer Vision,Panoptic Segmentation,Cityscapes val,mIoU,2,84.6
Computer Vision,Panoptic Segmentation,KITTI Panoptic Segmentation,PQ,1,43.7
Computer Vision,Panoptic Segmentation,KITTI Panoptic Segmentation,PQ,2,42.2
Computer Vision,Panoptic Segmentation,Indian Driving Dataset,PQ,1,51.1
Computer Vision,Panoptic Segmentation,Indian Driving Dataset,PQ,2,48.5
Computer Vision,Panoptic Segmentation,Cityscapes test,PQ,1,68.5
Computer Vision,Panoptic Segmentation,Cityscapes test,PQ,2,67.1
Computer Vision,Panoptic Segmentation,Mapillary val,PQ,1,44.8
Computer Vision,Panoptic Segmentation,Mapillary val,PQst,1,51.9
Computer Vision,Panoptic Segmentation,Mapillary val,PQth,1,39.3
Computer Vision,Panoptic Segmentation,Mapillary val,mIoU,1,60.0
Computer Vision,Panoptic Segmentation,Mapillary val,PQ,2,41.1
Computer Vision,Panoptic Segmentation,Mapillary val,PQst,2,51.3
Computer Vision,Panoptic Segmentation,Mapillary val,PQth,2,33.4
Computer Vision,Panoptic Segmentation,Mapillary val,mIoU,2,58.4
Computer Vision,Panoptic Segmentation,COCO minival,PQ,1,44.3
Computer Vision,Panoptic Segmentation,COCO minival,PQst,1,35.6
Computer Vision,Panoptic Segmentation,COCO minival,PQth,1,50
Computer Vision,Panoptic Segmentation,COCO minival,RQ,1,53
Computer Vision,Panoptic Segmentation,COCO minival,RQst,1,43.5
Computer Vision,Panoptic Segmentation,COCO minival,RQth,1,59.3
Computer Vision,Panoptic Segmentation,COCO minival,SQ,1,80.7
Computer Vision,Panoptic Segmentation,COCO minival,SQst,1,76.7
Computer Vision,Panoptic Segmentation,COCO minival,SQth,1,83.4
Computer Vision,Panoptic Segmentation,COCO panoptic,PQ,1,52.7
Computer Vision,Panoptic Segmentation,COCO panoptic,PQst,1,44.0
Computer Vision,Panoptic Segmentation,COCO panoptic,PQth,1,58.5
Computer Vision,Panoptic Segmentation,COCO panoptic,RQ,1,63.5
Computer Vision,Panoptic Segmentation,COCO panoptic,SQ,1,81.8
Computer Vision,Panoptic Segmentation,COCO panoptic,PQ,2,51.1
Computer Vision,Panoptic Segmentation,COCO panoptic,PQst,2,42.2
Computer Vision,Panoptic Segmentation,COCO panoptic,PQth,2,57.0
Computer Vision,Panoptic Segmentation,COCO test-dev,PQ,1,52.1
Computer Vision,Panoptic Segmentation,COCO test-dev,PQst,1,42.8
Computer Vision,Panoptic Segmentation,COCO test-dev,PQth,1,58.2
Computer Vision,Panoptic Segmentation,COCO test-dev,PQ,2,51.5
Computer Vision,Panoptic Segmentation,COCO test-dev,PQst,2,39.2
Computer Vision,Panoptic Segmentation,COCO test-dev,PQth,2,59.6
Computer Vision,Panoptic Segmentation,ScanNetV2,PQ,1,31.5
Computer Vision,Panoptic Segmentation,ScanNetV2,RQ,1,42.2
Computer Vision,Panoptic Segmentation,ScanNetV2,SQ,1,72.9
Computer Vision,Panoptic Segmentation,SemanticKITTI,PQ,1,0.559
Computer Vision,Panoptic Segmentation,SemanticKITTI,PQ_dagger,1,0.625
Computer Vision,Panoptic Segmentation,SemanticKITTI,PQst,1,0.565
Computer Vision,Panoptic Segmentation,SemanticKITTI,PQth,1,0.551
Computer Vision,Panoptic Segmentation,SemanticKITTI,RQ,1,0.667
Computer Vision,Panoptic Segmentation,SemanticKITTI,RQst,1,0.695
Computer Vision,Panoptic Segmentation,SemanticKITTI,RQth,1,0.628
Computer Vision,Panoptic Segmentation,SemanticKITTI,SQ,1,0.823
Computer Vision,Panoptic Segmentation,SemanticKITTI,SQst,1,0.787
Computer Vision,Panoptic Segmentation,SemanticKITTI,SQth,1,0.872
Computer Vision,Panoptic Segmentation,SemanticKITTI,mIoU,1,0.616
Computer Vision,Real-Time Semantic Segmentation,CamVid,Frame (fps),1,94(2080Ti)
Computer Vision,Real-Time Semantic Segmentation,CamVid,Time (ms),1,10.6
Computer Vision,Real-Time Semantic Segmentation,CamVid,mIoU,1,79.9
Computer Vision,Real-Time Semantic Segmentation,CamVid,Frame (fps),2,16.6
Computer Vision,Real-Time Semantic Segmentation,CamVid,Time (ms),2,60.2
Computer Vision,Real-Time Semantic Segmentation,CamVid,mIoU,2,79.1
Computer Vision,Real-Time Semantic Segmentation,Cityscapes test,Frame (fps),1,108.8(2080Ti)
Computer Vision,Real-Time Semantic Segmentation,Cityscapes test,Time (ms),1,9.2
Computer Vision,Real-Time Semantic Segmentation,Cityscapes test,mIoU,1,77.4
Computer Vision,Real-Time Semantic Segmentation,Cityscapes test,Frame (fps),2,97.0(1080Ti)
Computer Vision,Real-Time Semantic Segmentation,Cityscapes test,mIoU,2,76.8
Computer Vision,Real-Time Semantic Segmentation,Cityscapes val,mIoU,1,68.48
Computer Vision,Real-Time Semantic Segmentation,Cityscapes val,mIoU,2,67.8
Computer Vision,Real-Time Semantic Segmentation,NYU Depth v2,Speed(ms/f),1,36
Computer Vision,Real-Time Semantic Segmentation,NYU Depth v2,mIoU,1,44.4
Computer Vision,Real-Time Semantic Segmentation,NYU Depth v2,Speed(ms/f),2,27
Computer Vision,Real-Time Semantic Segmentation,NYU Depth v2,mIoU,2,43.6
Computer Vision,Real-Time Semantic Segmentation,COCO-Stuff,Frame (fps),1,42.5(1080Ti)
Computer Vision,Real-Time Semantic Segmentation,COCO-Stuff,mIoU,1,28.7
Computer Vision,Real-Time Semantic Segmentation,COCO-Stuff,Frame (fps),2,87.9(1080Ti)
Computer Vision,Real-Time Semantic Segmentation,COCO-Stuff,mIoU,2,25.2
Computer Vision,Scene Segmentation,ScanNet,Average Accuracy,1,75.0
Computer Vision,Scene Segmentation,ScanNet,Average Accuracy,2,60.2
Computer Vision,Scene Segmentation,SUN-RGBD,Mean IoU,1,33.48
Computer Vision,Scene Segmentation,SUN-RGBD,Mean IoU,2,32.08
Computer Vision,Scene Segmentation,NYU Depth v2,Mean IoU,1,32.3
Computer Vision,Weakly-Supervised Semantic Segmentation,COCO 2014 val,mIoU,1,35.7
Computer Vision,Weakly-Supervised Semantic Segmentation,COCO 2014 val,mIoU,2,33.6
Computer Vision,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 test,Mean IoU,1,72.2
Computer Vision,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 test,Mean IoU,2,71.8
Computer Vision,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 val,Mean IoU,1,71.9
Computer Vision,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 val,Mean IoU,2,71.0
Computer Vision,3D Part Segmentation,ShapeNet-Part,Class Average IoU,1,87.7
Computer Vision,3D Part Segmentation,ShapeNet-Part,Instance Average IoU,1,86.6
Computer Vision,3D Part Segmentation,ShapeNet-Part,Class Average IoU,2,85.1
Computer Vision,3D Part Segmentation,ShapeNet-Part,Instance Average IoU,2,86.4
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 1% labeled,Validation mIoU,1,63.60
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 1% labeled,Validation mIoU,2,63.16
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 50%,Validation mIoU,1,78.2
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 50%,Validation mIoU,2,76.5
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 500 labels,Validation mIoU,1,65.4
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 1464 labels,Validation mIoU,1,74.85
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 1464 labels,Validation mIoU,2,73.7
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 50% labeled,Validation mIoU,1,80.21
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 50% labeled,Validation mIoU,2,78.7
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,Validation mIoU,1,72.14
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,Validation mIoU,2,67.9
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,Validation mIoU,1,77.62
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,Validation mIoU,2,74.1
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 1000 labels,Validation mIoU,1,68.1
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL Context 25% labeled,Validation mIoU,1,41.7
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL Context 25% labeled,Validation mIoU,2,37.8
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 2% labeled,Validation mIoU,1,53.51
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 2% labeled,Validation mIoU,2,52.14
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,Validation mIoU,1,79.21
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,Validation mIoU,2,77.8
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 25% labeled,Validation mIoU,1,77.8
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL VOC 2012 25% labeled,Validation mIoU,2,77.68
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 100 samples labeled,Validation mIoU,1,64.9
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 100 samples labeled,Validation mIoU,2,60.28
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL Context 12.5% labeled,Validation mIoU,1,40.3
Computer Vision,Semi-Supervised Semantic Segmentation,PASCAL Context 12.5% labeled,Validation mIoU,2,35.3
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,Validation mIoU,1,73.66
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,Validation mIoU,2,70.0
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,Validation mIoU,1,76.44
Computer Vision,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,Validation mIoU,2,76.4
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 5% labeled,Validation mIoU,1,59.98
Computer Vision,Semi-Supervised Semantic Segmentation,Cityscapes 5% labeled,Validation mIoU,2,58.77
Computer Vision,One-Shot Segmentation,Cluttered Omniglot,IoU [256 distractors],1,43.7
Computer Vision,One-Shot Segmentation,Cluttered Omniglot,IoU [32 distractors],1,65.6
Computer Vision,One-Shot Segmentation,Cluttered Omniglot,IoU [4 distractors],1,95.8
Computer Vision,One-Shot Segmentation,Cluttered Omniglot,IoU [256 distractors],2,38.4
Computer Vision,One-Shot Segmentation,Cluttered Omniglot,IoU [32 distractors],2,62.4
Computer Vision,One-Shot Segmentation,Cluttered Omniglot,IoU [4 distractors],2,97.1
Computer Vision,Unsupervised Semantic Segmentation,COCO-Stuff-15,Accuracy,1,27.7
Computer Vision,Unsupervised Semantic Segmentation,Potsdam,Accuracy,1,65.1
Computer Vision,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,Prior,1,Saliency
Computer Vision,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,mIoU,1,63.9
Computer Vision,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,mIoU (KMeans),1,44.2
Computer Vision,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,Prior,2,
Computer Vision,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,mIoU,2,58.4
Computer Vision,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,mIoU (KMeans),2,35.0
Computer Vision,Unsupervised Semantic Segmentation,Potsdam-3,Accuracy,1,45.4
Computer Vision,Unsupervised Semantic Segmentation,COCO-Stuff-3,Accuracy,1,72.3
Computer Vision,4D Spatio Temporal Semantic Segmentation,4,4,1,7
Computer Vision,Polyp Segmentation,Kvasir-SEG,DSC,1,0.8133
Computer Vision,Polyp Segmentation,Kvasir-SEG,mIoU,1,0.7927
Computer Vision,Polyp Segmentation,Kvasir-SEG,DSC,2,0.7877
Computer Vision,Weakly-Supervised Object Localization,Tiny ImageNet,Top-1 Localization Accuracy,1,43.34
Computer Vision,Weakly-Supervised Object Localization,Tiny ImageNet,Top-1 Localization Accuracy,2,40.55
Computer Vision,Weakly-Supervised Object Localization, CUB-200-2011,Top-1 Error Rate,1,34.8
Computer Vision,Weakly-Supervised Object Localization, CUB-200-2011,Top-1 Localization Accuracy,1,65.22
Computer Vision,Weakly-Supervised Object Localization, CUB-200-2011,Top-1 Error Rate,2,37.71
Computer Vision,Weakly-Supervised Object Localization,ILSVRC 2015,Top-1 Error Rate,1,51.40
Computer Vision,Weakly-Supervised Object Localization,ILSVRC 2015,Top-1 Error Rate,2,67.19
Computer Vision,Weakly-Supervised Object Localization,ILSVRC 2016,Top-5 Error,1,40.00
Computer Vision,Weakly-Supervised Object Localization,ILSVRC 2016,Top-5 Error,2,42.58
Computer Vision,Image-Based Localization,cvusa,Recall@10,1,74.58
Computer Vision,Image-Based Localization,cvusa,recall@1,1,43.91
Computer Vision,Image-Based Localization,cvusa,recall@5,1,66.38
Computer Vision,Image-Based Localization,cvusa,recall@top1%,1,91.78
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Speech Emotion Recognition,IEMOCAP,F1,1,
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Speech Emotion Recognition,IEMOCAP,UA,1,0.805
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Speech Emotion Recognition,IEMOCAP,WA,1,0.74
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Speech Emotion Recognition,IEMOCAP,F1,2,0.718
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Speech Emotion Recognition,IEMOCAP,UA,2,0.701
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,EmoryNLP,Weighted Macro-F1,1,38.11
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,EmoryNLP,Weighted Macro-F1,2,36.75
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,EmotionPush,Unweighted Accuracy,1,63.03
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,EmotionPush,Weighted Accuracy,1,86.92
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,DailyDialog,Micro-F1,1,63.12
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,DailyDialog,Micro-F1,2,60.14
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,MELD,Weighted-F1,1,68.23
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,MELD,Weighted-F1,2,65.21
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,IEMOCAP,Weighted-F1,1,68.03
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,IEMOCAP,Weighted-F1,2,67.1
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Arousal),1,0.161
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Expectancy),1,0.168
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Power),1,7.68
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Valence),1,0.157
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Arousal),2,0.16
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Expectancy),2,0.16
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Power),2,7.70
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,SEMAINE,MAE (Valence),2,0.16
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,EC,Micro-F1,1,0.7765
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Conversation,EC,Micro-F1,2,0.7731
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Multimodal Emotion Recognition,IEMOCAP,F1,1,0.768
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Multimodal Emotion Recognition,IEMOCAP,UA,1,0.765
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Multimodal Emotion Recognition,IEMOCAP,F1,2,0.760
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Multimodal Emotion Recognition,IEMOCAP,UA,2,0.761
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Multimodal Emotion Recognition,Expressive hands and faces dataset (EHF).,v2v error,1,52.9
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion-Cause Pair Extraction,ECPE,F1,1,73.6
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion-Cause Pair Extraction,ECPE,F1,2,68.89
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion-Cause Pair Extraction,ECPE-FanSplit,F1,1,69.15
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion-Cause Pair Extraction,ECPE-FanSplit,F1,2,67.99
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Cause Extraction,ECE,F1,1,76.77
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Cause Extraction,ECE,F1,2,72.42
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Context,EMOTIC,mAP,1,35.48
"Computer Vision', 'Natural Language Processing', 'Speech', 'Miscellaneous",Emotion Recognition in Context,EMOTIC,mAP,2,32.03
Computer Vision,Temporal Action Localization,MEXaction2,mAP,1,7.4
Computer Vision,Temporal Action Localization,THUMOS'14,mAP IOU@0.5,1,57.18
Computer Vision,Temporal Action Localization,CrossTask,Recall,1,33.6
Computer Vision,Temporal Action Localization,CrossTask,Recall,2,31.6
Computer Vision,Temporal Action Localization,UCF101-24,Frame-mAP,1,87.2
Computer Vision,Temporal Action Localization,UCF101-24,Video-mAP 0.5,1,48.8
Computer Vision,Temporal Action Localization,UCF101-24,Frame-mAP,2,76.3
Computer Vision,Temporal Action Localization,UCF101-24,Video-mAP 0.5,2,59.9
Computer Vision,Temporal Action Localization,J-HMDB-21,Frame-mAP,1,74.4
Computer Vision,Temporal Action Localization,J-HMDB-21,Video-mAP 0.2,1,87.8
Computer Vision,Temporal Action Localization,J-HMDB-21,Video-mAP 0.5,1,85.7
Computer Vision,Temporal Action Localization,J-HMDB-21,Video-mAP 0.75,1,58.1
Computer Vision,Temporal Action Localization,J-HMDB-21,Frame-mAP,2,73.3
Computer Vision,Temporal Action Localization,J-HMDB-21,Video-mAP 0.5,2,78.6
Computer Vision,Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.1,1,60.5
Computer Vision,Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.3,1,48.4
Computer Vision,Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.5,1,35.2
Computer Vision,Temporal Action Localization,ActivityNet-1.2,mAP IOU@0.7,1,16.3
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.3,1,70.1
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.4,1,64.9
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.5,1,57.1
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.6,1,45.4
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.7,1,28.8
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.3,2,68.9
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.4,2,64.0
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.5,2,56.9
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.6,2,46.3
Computer Vision,Temporal Action Localization,THUMOS’14,mAP IOU@0.7,2,31.0
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP,1,36.82
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.5,1,54.34
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.75,1,37.76
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.95,1,8.93
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP,2,37.56
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.5,2,54.33
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.75,2,39.13
Computer Vision,Temporal Action Localization,ActivityNet-1.3,mAP IOU@0.95,2,8.41
Computer Vision,Action Segmentation,50 Salads,Acc,1,84.5
Computer Vision,Action Segmentation,50 Salads,Edit,1,79.3
Computer Vision,Action Segmentation,50 Salads,F1@10%,1,84.9
Computer Vision,Action Segmentation,50 Salads,F1@25%,1,83.5
Computer Vision,Action Segmentation,50 Salads,F1@50%,1,77.3
Computer Vision,Action Segmentation,50 Salads,Acc,2,84.4
Computer Vision,Action Segmentation,50 Salads,Edit,2,74.3
Computer Vision,Action Segmentation,50 Salads,F1@10%,2,82.3
Computer Vision,Action Segmentation,50 Salads,F1@25%,2,81.3
Computer Vision,Action Segmentation,50 Salads,F1@50%,2,74
Computer Vision,Action Segmentation,Breakfast,Acc,1,76.0
Computer Vision,Action Segmentation,Breakfast,Edit,1,69.6
Computer Vision,Action Segmentation,Breakfast,F1@10%,1,72.2
Computer Vision,Action Segmentation,Breakfast,F1@25%,1,68.7
Computer Vision,Action Segmentation,Breakfast,F1@50%,1,57.6
Computer Vision,Action Segmentation,Breakfast,Acc,2,71.0
Computer Vision,Action Segmentation,Breakfast,Edit,2,73.6
Computer Vision,Action Segmentation,Breakfast,F1@10%,2,74.2
Computer Vision,Action Segmentation,Breakfast,F1@25%,2,68.6
Computer Vision,Action Segmentation,Breakfast,F1@50%,2,56.5
Computer Vision,Action Segmentation,GTEA,Acc,1,77.3
Computer Vision,Action Segmentation,GTEA,Edit,1,83.7
Computer Vision,Action Segmentation,GTEA,F1@10%,1,89.4
Computer Vision,Action Segmentation,GTEA,F1@25%,1,87.8
Computer Vision,Action Segmentation,GTEA,F1@50%,1,79.8
Computer Vision,Action Segmentation,GTEA,Acc,2,79.8
Computer Vision,Action Segmentation,GTEA,Edit,2,86.2
Computer Vision,Action Segmentation,GTEA,F1@10%,2,90.0
Computer Vision,Action Segmentation,GTEA,F1@25%,2,89.1
Computer Vision,Action Segmentation,GTEA,F1@50%,2,78.0
Computer Vision,Hand Pose Estimation,HANDS 2019,Average 3D Error,1,13.66
Computer Vision,Hand Pose Estimation,HANDS 2019,Average 3D Error,2,13.76
Computer Vision,Hand Pose Estimation,MSRA Hands,Average 3D Error,1,7.15
Computer Vision,Hand Pose Estimation,MSRA Hands,Average 3D Error,2,7.2
Computer Vision,Hand Pose Estimation,Custom FINNgers,1:1 Accuracy,1,98
Computer Vision,Hand Pose Estimation,NYU Hands,Average 3D Error,1,7.48
Computer Vision,Hand Pose Estimation,NYU Hands,Average 3D Error,2,
Computer Vision,Hand Pose Estimation,HANDS 2017,Average 3D Error,1,7.48
Computer Vision,Hand Pose Estimation,HANDS 2017,Average 3D Error,2,8.57
Computer Vision,Hand Pose Estimation,ICVL Hands,Average 3D Error,1,5.98
Computer Vision,Hand Pose Estimation,ICVL Hands,Average 3D Error,2,6.152
Computer Vision,Hand Pose Estimation,K2HPD,PDJ@5mm,1,76.3
Computer Vision,Hand Gesture Recognition,MGB,Accuracy,1,98.04
Computer Vision,Hand Gesture Recognition,EgoGesture,Accuracy,1,94.03
Computer Vision,Hand Gesture Recognition,EgoGesture,Accuracy,2,93.87
Computer Vision,Hand Gesture Recognition,BUAA,Accuracy,1,99.25
Computer Vision,Hand Gesture Recognition,Cambridge,Accuracy,1,98.23
Computer Vision,Hand Gesture Recognition,Cambridge,Accuracy,2,93
Computer Vision,Hand Gesture Recognition,SHREC 2017,14 gestures accuracy,1,95.9
Computer Vision,Hand Gesture Recognition,SHREC 2017,28 gestures accuracy,1,94.7
Computer Vision,Hand Gesture Recognition,SHREC 2017,14 gestures accuracy,2,94.4
Computer Vision,Hand Gesture Recognition,SHREC 2017,28 gestures accuracy,2,90.7
Computer Vision,Hand Gesture Recognition,Jester test,Top 1 Accuracy,1,96.6
Computer Vision,Hand Gesture Recognition,Jester test,Top 1 Accuracy,2,94.78
Computer Vision,Hand Gesture Recognition,NVGesture,Accuracy,1,87.9
Computer Vision,Hand Gesture Recognition,NVGesture,Accuracy,2,86.93
Computer Vision,Hand Gesture Recognition,ChaLearn val,Accuracy,1,57.4
Computer Vision,Hand Gesture Recognition,ChaLearn val,Accuracy,2,39.23
Computer Vision,Hand Gesture Recognition,DHG-28,Accuracy,1,88
Computer Vision,Hand Gesture Recognition,Jester val,Top 1 Accuracy,1,96.33
Computer Vision,Hand Gesture Recognition,Jester val,Top 5 Accuracy,1,99.86
Computer Vision,Hand Gesture Recognition,ChaLean test,Accuracy,1,56.7
Computer Vision,Hand Gesture Recognition,DHG-14,Accuracy,1,91.9
Computer Vision,Hand Gesture Recognition,Northwestern University,Accuracy,1,96.89
Computer Vision,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,95.9
Computer Vision,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,94.6
Computer Vision,Hand Gesture Recognition,VIVA Hand Gestures Dataset,Accuracy,1,86.08
Computer Vision,Hand Gesture Recognition,VIVA Hand Gestures Dataset,Accuracy,2,83.1
Computer Vision,Hand Gesture Recognition,SmartWatch,Accuracy,1,97.4
Computer Vision,Hand-Gesture Recognition,InAirGestures,Accuracy (%),1,99.94
Computer Vision,Gesture-to-Gesture Translation,Senz3D,AMT,1,22.6
Computer Vision,Gesture-to-Gesture Translation,Senz3D,IS,1,3.4107
Computer Vision,Gesture-to-Gesture Translation,Senz3D,MSE,1,169.9219
Computer Vision,Gesture-to-Gesture Translation,Senz3D,PSNR,1,27.9749
Computer Vision,Gesture-to-Gesture Translation,Senz3D,AMT,2,6.9
Computer Vision,Gesture-to-Gesture Translation,Senz3D,IS,2,3.3874
Computer Vision,Gesture-to-Gesture Translation,Senz3D,PSNR,2,26.9451
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,AMT,1,26.1
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,IS,1,2.5532
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,MSE,1,105.7286
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,PSNR,1,32.6091
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,AMT,2,2.6
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,IS,2,2.4919
Computer Vision,Gesture-to-Gesture Translation,NTU Hand Digit,PSNR,2,28.0185
Natural Language Processing,Predicate Detection,CoNLL 2005,F1,1,98.4
Natural Language Processing,Predicate Detection,CoNLL 2005,F1,2,96.4
Natural Language Processing,Predicate Detection,CoNLL 2012,F1,1,97.2
Natural Language Processing,Semantic Role Labeling (predicted predicates),CoNLL 2012,F1,1,83.38
Natural Language Processing,Semantic Role Labeling (predicted predicates),CoNLL 2012,F1,2,82.9
Natural Language Processing,Semantic Role Labeling (predicted predicates),CoNLL 2005,F1,1,86.90
Natural Language Processing,Semantic Role Labeling (predicted predicates),CoNLL 2005,F1,2,86.0
Natural Language Processing,Paraphrase Identification,TURL,AP,1,76.8
Natural Language Processing,Paraphrase Identification,MRPC,Accuracy,1,89.2
Natural Language Processing,Paraphrase Identification,WikiHop,Accuracy,1,90.7
Natural Language Processing,Paraphrase Identification,Quora Question Pairs,F1,1,89.2
Natural Language Processing,Paraphrase Identification,Quora Question Pairs,Accuracy,2,91.4
Natural Language Processing,Paraphrase Identification,Quora Question Pairs,F1,2,88.5
Natural Language Processing,Paraphrase Identification,PIT,AP,1,69.2
Natural Language Processing,Paraphrase Identification,2017_test set,10 fold Cross validation,1,50
Natural Language Processing,Paraphrase Identification,MSRP,Accuracy,1,80.41
Natural Language Processing,Paraphrase Identification,MSRP,F1,1,85.96
Natural Language Processing,Paraphrase Identification,MSRP,Accuracy,2,72.75
Natural Language Processing,Paraphrase Identification,MSRP,F1,2,81.48
Natural Language Processing,AMR Parsing,LDC2014T12:,F1 Full,1,0.70
Natural Language Processing,AMR Parsing,LDC2014T12:,F1 Newswire,1,0.75
Natural Language Processing,AMR Parsing,LDC2014T12:,F1 Full,2,0.68
Natural Language Processing,AMR Parsing,LDC2014T12:,F1 Newswire,2,0.73
Natural Language Processing,AMR Parsing,LDC2017T10,Smatch,1,84.3
Natural Language Processing,AMR Parsing,LDC2017T10,Smatch,2,81.4
Natural Language Processing,AMR Parsing,LDC2014T12,F1 Full,1,68.4
Natural Language Processing,AMR Parsing,LDC2014T12,F1 Newswire,1,73.3
Natural Language Processing,AMR Parsing,LDC2014T12,F1 Full,2,66
Natural Language Processing,AMR Parsing,LDC2014T12,F1 Newswire,2,71
Natural Language Processing,AMR Parsing,LDC2015E86,Smatch,1,73.7
Natural Language Processing,AMR Parsing,LDC2015E86,Smatch,2,70.7
Natural Language Processing,AMR Parsing,LDC2020T02,Smatch,1,83.0
Natural Language Processing,AMR Parsing,LDC2020T02,Smatch,2,83.0
Natural Language Processing,Semantic Dependency Parsing,DM,In-domain,1,95.6
Natural Language Processing,Semantic Dependency Parsing,DM,Out-of-domain,1,92.6
Natural Language Processing,Semantic Dependency Parsing,DM,In-domain,2,94.4
Natural Language Processing,Semantic Dependency Parsing,DM,Out-of-domain,2,91.0
Natural Language Processing,Semantic Dependency Parsing,PAS,In-domain,1,95.8
Natural Language Processing,Semantic Dependency Parsing,PAS,Out-of-domain,1,94.6
Natural Language Processing,Semantic Dependency Parsing,PAS,In-domain,2,95.1
Natural Language Processing,Semantic Dependency Parsing,PAS,Out-of-domain,2,93.4
Natural Language Processing,Semantic Dependency Parsing,PSD,In-domain,1,83.8
Natural Language Processing,Semantic Dependency Parsing,PSD,Out-of-domain,1,83.4
Natural Language Processing,Semantic Dependency Parsing,PSD,In-domain,2,82.6
Natural Language Processing,Semantic Dependency Parsing,PSD,Out-of-domain,2,82.0
Natural Language Processing,UCCA Parsing,SemEval 2019 Task 1,English-20K (open) F1,1,76.7
Natural Language Processing,UCCA Parsing,SemEval 2019 Task 1,English-Wiki (open) F1,1,80.5
Natural Language Processing,UCCA Parsing,SemEval 2019 Task 1,English-Wiki (open) F1,2,76.6
Natural Language Processing,UCCA Parsing,CoNLL 2019,Full MRP F1,1,81.7
Natural Language Processing,UCCA Parsing,CoNLL 2019,Full UCCA F1,1,66.7
Natural Language Processing,UCCA Parsing,CoNLL 2019,LPP MRP F1,1,82.6
Natural Language Processing,UCCA Parsing,CoNLL 2019,LPP UCCA F1,1,64.4
Natural Language Processing,UCCA Parsing,CoNLL 2019,Full MRP F1,2,77.7
Natural Language Processing,UCCA Parsing,CoNLL 2019,Full UCCA F1,2,57.4
Natural Language Processing,UCCA Parsing,CoNLL 2019,LPP MRP F1,2,82.2
Natural Language Processing,UCCA Parsing,CoNLL 2019,LPP UCCA F1,2,65.9
Natural Language Processing,DRS Parsing,PMB-2.2.0,F1,1,88.3
Natural Language Processing,DRS Parsing,PMB-2.2.0,F1,2,87.1
Natural Language Processing,DRS Parsing,PMB-3.0.0,F1,1,89.3
Natural Language Processing,DRS Parsing,PMB-3.0.0,F1,2,87.7
Natural Language Processing,Unsupervised semantic parsing,VG graph-text,F1,1,21.7
Natural Language Processing,Unsupervised semantic parsing,WebNLG v2.1,F1,1,39.1
Natural Language Processing,Grammatical Error Detection,CoNLL-2014 A2,F0.5,1,63.1
Natural Language Processing,Grammatical Error Detection,CoNLL-2014 A2,F0.5,2,45.1
Natural Language Processing,Grammatical Error Detection,FCE,F0.5,1,72.2
Natural Language Processing,Grammatical Error Detection,FCE,F0.5,2,52.07
Natural Language Processing,Grammatical Error Detection,JFLEG,F0.5,1,52.52
Natural Language Processing,Grammatical Error Detection,CoNLL-2014 A1,F0.5,1,54.3
Natural Language Processing,Grammatical Error Detection,CoNLL-2014 A1,F0.5,2,36.1
Natural Language Processing,Dependency Grammar Induction,WSJ10,UAS,1,79.9
Natural Language Processing,Dependency Grammar Induction,WSJ10,UAS,2,75.6
Natural Language Processing,Dependency Grammar Induction,WSJ,UAS,1,67.5
Natural Language Processing,Cross-lingual zero-shot dependency parsing,Universal Dependency Treebank,LAS,1,77.3
Natural Language Processing,Cross-lingual zero-shot dependency parsing,Universal Dependency Treebank,UAS,1,84.2
Natural Language Processing,Cross-lingual zero-shot dependency parsing,Universal Dependency Treebank,LAS,2,70.5
Natural Language Processing,Unsupervised Dependency Parsing,Penn Treebank,UAS,1,66.2
Natural Language Processing,Unsupervised Dependency Parsing,Penn Treebank,UAS,2,64.4
Audio,Environmental Sound Classification,ESC-50,Accuracy,1,97.15
Audio,Environmental Sound Classification,UrbanSound8k,Accuracy (10-fold),1,79
Audio,Environmental Sound Classification,UrbanSound8k,Accuracy (10-fold),2,73
Computer Vision,3D Human Pose Estimation,MPI-INF-3DHP,3DPCK,1,95.1
Computer Vision,3D Human Pose Estimation,MPI-INF-3DHP,AUC,1,62.2
Computer Vision,3D Human Pose Estimation,MPI-INF-3DHP,MJPE,1,60.1
Computer Vision,3D Human Pose Estimation,MPI-INF-3DHP,3DPCK,2,94.8
Computer Vision,3D Human Pose Estimation,MPI-INF-3DHP,AUC,2,61.4
Computer Vision,3D Human Pose Estimation,MPI-INF-3DHP,MJPE,2,61.6
Computer Vision,3D Human Pose Estimation,Surreal,MPJPE,1,37.1
Computer Vision,3D Human Pose Estimation,Surreal,PCK3D,1,97.3
Computer Vision,3D Human Pose Estimation,Surreal,MPJPE,2,49.1
Computer Vision,3D Human Pose Estimation,3DPW,MPJPE,1,79.1
Computer Vision,3D Human Pose Estimation,3DPW,MPVPE,1,94.2
Computer Vision,3D Human Pose Estimation,3DPW,PA-MPJPE,1,46.4
Computer Vision,3D Human Pose Estimation,3DPW,MPJPE,2,76.7
Computer Vision,3D Human Pose Estimation,3DPW,MPVPE,2,93.4
Computer Vision,3D Human Pose Estimation,3DPW,PA-MPJPE,2,47.3
Computer Vision,3D Human Pose Estimation,Total Capture,Average MPJPE (mm),1,24.6
Computer Vision,3D Human Pose Estimation,Total Capture,Average MPJPE (mm),2,28.9
Computer Vision,3D Human Pose Estimation,CHALL H80K,MPJPE,1,55.3
Computer Vision,3D Human Pose Estimation,Human3.6M,Average MPJPE (mm),1,18.7
Computer Vision,3D Human Pose Estimation,Human3.6M,Multi-View or Monocular,1,MultiView
Computer Vision,3D Human Pose Estimation,Human3.6M,Using 2D ground-truth joints,1,No
Computer Vision,3D Human Pose Estimation,Human3.6M,Average MPJPE (mm),2,19.0
Computer Vision,3D Human Pose Estimation,Human3.6M,Multi-View or Monocular,2,MultiView
Computer Vision,3D Human Pose Estimation,Human3.6M,Using 2D ground-truth joints,2,No
Computer Vision,3D Human Pose Estimation,HumanEva-I,Mean Reconstruction Error (mm),1,12.2
Computer Vision,3D Human Pose Estimation,HumanEva-I,Mean Reconstruction Error (mm),2,13.5
Computer Vision,3D Human Pose Estimation,3D Poses in the Wild Challenge,MPJAE,1,19.69
Computer Vision,3D Human Pose Estimation,3D Poses in the Wild Challenge,MPJPE,1,83.15
Computer Vision,3D Human Pose Estimation,3D Poses in the Wild Challenge,MPJAE,2,20.80
Computer Vision,3D Human Pose Estimation,3D Poses in the Wild Challenge,MPJPE,2,81.76
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,MPJPE (CA),1,57.8
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,MPJPE (CS),1,67.3
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,PCK3D (CA),1,95.5
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,PCK3D (CS),1,93.9
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,MPJPE (CA),2,81.1
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,MPJPE (CS),2,91.0
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,PCK3D (CA),2,88.1
Computer Vision,3D Human Pose Estimation,Geometric Pose Affordance ,PCK3D (CS),2,85.7
Computer Vision,Keypoint Detection, Pascal3D+,Mean PCK,1,82.5
Computer Vision,Keypoint Detection, Pascal3D+,Mean PCK,2,78.6
Computer Vision,Keypoint Detection,COCO test-dev,AP50,1,92.7
Computer Vision,Keypoint Detection,COCO test-dev,AP75,1,84.5
Computer Vision,Keypoint Detection,COCO test-dev,APL,1,83.1
Computer Vision,Keypoint Detection,COCO test-dev,APM,1,73.4
Computer Vision,Keypoint Detection,COCO test-dev,AR,1,82.0
Computer Vision,Keypoint Detection,COCO test-dev,AP50,2,92.4
Computer Vision,Keypoint Detection,COCO test-dev,AP75,2,84.0
Computer Vision,Keypoint Detection,COCO test-dev,APL,2,82.7
Computer Vision,Keypoint Detection,COCO test-dev,APM,2,73.0
Computer Vision,Keypoint Detection,COCO test-dev,AR,2,81.5
Computer Vision,Keypoint Detection,COCO test-dev,AR50,2,95.8
Computer Vision,Keypoint Detection,COCO test-dev,AR75,2,88.2
Computer Vision,Keypoint Detection,COCO test-dev,ARL,2,87.2
Computer Vision,Keypoint Detection,COCO test-dev,ARM,2,77.4
Computer Vision,Keypoint Detection,COCO,Test AP,1,79.5
Computer Vision,Keypoint Detection,COCO,Test AP,2,78.9
Computer Vision,Keypoint Detection,COCO test-challenge,AP,1,76.4
Computer Vision,Keypoint Detection,COCO test-challenge,AP50,1,92.9
Computer Vision,Keypoint Detection,COCO test-challenge,AP75,1,82.6
Computer Vision,Keypoint Detection,COCO test-challenge,APL,1,88.6
Computer Vision,Keypoint Detection,COCO test-challenge,AR,1,82.2
Computer Vision,Keypoint Detection,COCO test-challenge,AR50,1,96
Computer Vision,Keypoint Detection,COCO test-challenge,AR75,1,87.7
Computer Vision,Keypoint Detection,COCO test-challenge,ARL,1,83.2
Computer Vision,Keypoint Detection,COCO test-challenge,ARM,1,77.5
Computer Vision,Keypoint Detection,COCO test-challenge,AP,2,74.5
Computer Vision,Keypoint Detection,COCO test-challenge,AP50,2,90.9
Computer Vision,Keypoint Detection,COCO test-challenge,AP75,2,80.8
Computer Vision,Keypoint Detection,COCO test-challenge,APL,2,87.5
Computer Vision,Keypoint Detection,COCO test-challenge,AR,2,80.5
Computer Vision,Keypoint Detection,COCO test-challenge,AR50,2,95.1
Computer Vision,Keypoint Detection,COCO test-challenge,AR75,2,86.3
Computer Vision,Keypoint Detection,COCO test-challenge,ARL,2,82.9
Computer Vision,Keypoint Detection,COCO test-challenge,ARM,2,75.3
Computer Vision,Keypoint Detection,MPII Multi-Person,mAP@0.5,1,82.1
Computer Vision,Keypoint Detection,MPII Multi-Person,mAP@0.5,2,80.4
Computer Vision,Keypoint Detection,ApolloCar3D,A3DP,1,20.21
Computer Vision,3D Pose Estimation,Human3.6M,Average MPJPE (mm),1,18.7
Computer Vision,3D Pose Estimation,Human3.6M,Average MPJPE (mm),2,44.8
Computer Vision,3D Pose Estimation,CMU Panoptic,Average MPJPE (mm),1,7.3
Computer Vision,3D Pose Estimation,CarFusion,3DPCK,1,93.2
Computer Vision,3D Pose Estimation,K2HPD,FPS,1,93.78
Computer Vision,3D Pose Estimation,ApolloCar3D,A3DP,1,20.21
Computer Vision,Multi-Person Pose Estimation,CrowdPose,mAP @0.5:0.95,1,71.3
Computer Vision,Multi-Person Pose Estimation,CrowdPose,AP Easy,2,87.4
Computer Vision,Multi-Person Pose Estimation,CrowdPose,AP Hard,2,75.8
Computer Vision,Multi-Person Pose Estimation,CrowdPose,AP Medium,2,72.6
Computer Vision,Multi-Person Pose Estimation,CrowdPose,FPS,2,
Computer Vision,Multi-Person Pose Estimation,CrowdPose,mAP @0.5:0.95,2,67.6
Computer Vision,Multi-Person Pose Estimation,COCO,AP,1,0.774
Computer Vision,Multi-Person Pose Estimation,COCO,AP,2,0.764
Computer Vision,Multi-Person Pose Estimation,COCO,Validation AP,2,79.5
Computer Vision,Multi-Person Pose Estimation,PoseTrack2017,Mean mAP,1,77.94
Computer Vision,Multi-Person Pose Estimation,PoseTrack2017,Mean mAP,2,77.9
Computer Vision,Multi-Person Pose Estimation,PoseTrack2018,MAP,1,73.8
Computer Vision,Multi-Person Pose Estimation,PoseTrack2018,Mean mAP,2,78
Computer Vision,Multi-Person Pose Estimation,COCO minival,AP,1,79.1
Computer Vision,Multi-Person Pose Estimation,COCO minival,AP,2,77.8
Computer Vision,Multi-Person Pose Estimation,Multi-Person PoseTrack,Mean mAP,1,38.2
Computer Vision,Multi-Person Pose Estimation,WAF,AOP,1,88.10
Computer Vision,Multi-Person Pose Estimation,WAF,AOP,2,86.5
Computer Vision,Multi-Person Pose Estimation,COCO test-dev,AP,1,78.7
Computer Vision,Multi-Person Pose Estimation,COCO test-dev,AP,2,76.2
Computer Vision,Multi-Person Pose Estimation,MPII Multi-Person,AP,1,82.1
Computer Vision,Multi-Person Pose Estimation,MPII Multi-Person,AP,2,80.4
Computer Vision,Hand Pose Estimation,HANDS 2019,Average 3D Error,1,13.66
Computer Vision,Hand Pose Estimation,HANDS 2019,Average 3D Error,2,13.76
Computer Vision,Hand Pose Estimation,MSRA Hands,Average 3D Error,1,7.15
Computer Vision,Hand Pose Estimation,MSRA Hands,Average 3D Error,2,7.2
Computer Vision,Hand Pose Estimation,Custom FINNgers,1:1 Accuracy,1,98
Computer Vision,Hand Pose Estimation,NYU Hands,Average 3D Error,1,7.48
Computer Vision,Hand Pose Estimation,NYU Hands,Average 3D Error,2,
Computer Vision,Hand Pose Estimation,HANDS 2017,Average 3D Error,1,7.48
Computer Vision,Hand Pose Estimation,HANDS 2017,Average 3D Error,2,8.57
Computer Vision,Hand Pose Estimation,ICVL Hands,Average 3D Error,1,5.98
Computer Vision,Hand Pose Estimation,ICVL Hands,Average 3D Error,2,6.152
Computer Vision,Hand Pose Estimation,K2HPD,PDJ@5mm,1,76.3
Computer Vision,6D Pose Estimation,ApolloCar3D,A3DP,1,20.21
Computer Vision,6D Pose Estimation,YCB-Video,ADDS AUC,1,96.1
Computer Vision,6D Pose Estimation,YCB-Video,ADDS AUC,2,93.3
Computer Vision,6D Pose Estimation,LineMOD,Accuracy (ADD),1,99.4
Computer Vision,6D Pose Estimation,LineMOD,Accuracy (ADD),2,97.8
Computer Vision,6D Pose Estimation,NOCS-REAL275,5°5 cm,1,33.3
Computer Vision,6D Pose Estimation,NOCS-REAL275,IOU25,1,94.2
Computer Vision,6D Pose Estimation,NOCS-REAL275,Rerr,1,16.0
Computer Vision,6D Pose Estimation,NOCS-REAL275,Terr,1,3.5
Computer Vision,6D Pose Estimation using RGB,LineMOD,Accuracy (ADD),1,97.35
Computer Vision,6D Pose Estimation using RGB,LineMOD,Mean ADD,1,97.35
Computer Vision,6D Pose Estimation using RGB,LineMOD,Accuracy (ADD),2,96.1
Computer Vision,6D Pose Estimation using RGB,LineMOD,Mean ADD,2,96.1
Computer Vision,6D Pose Estimation using RGB,YCB-Video,Mean ADD,1,70.1
Computer Vision,6D Pose Estimation using RGB,YCB-Video,Mean ADI,1,84.2
Computer Vision,6D Pose Estimation using RGB,YCB-Video,Accuracy (ADD),2,21.3
Computer Vision,6D Pose Estimation using RGB,YCB-Video,Mean ADD,2,53.7
Computer Vision,6D Pose Estimation using RGB,YCB-Video,Mean ADD-S,2,75.9
Computer Vision,6D Pose Estimation using RGB,Occlusion LineMOD,Mean ADD,1,55.5
Computer Vision,6D Pose Estimation using RGB,Occlusion LineMOD,Mean ADD,2,51.6
Computer Vision,6D Pose Estimation using RGB,OCCLUSION,MAP,1,0.48
Computer Vision,6D Pose Estimation using RGB,OCCLUSION,MAP,2,0.38
Computer Vision,6D Pose Estimation using RGB,ApolloCar3D,A3DP,1,20.21
Computer Vision,6D Pose Estimation using RGB,T-LESS,Recall (VSD),1,29.5
Computer Vision,6D Pose Estimation using RGB,T-LESS,Mean Recall,2,36.8
Computer Vision,Head Pose Estimation,Pointing'04,MAE,1,4.64
Computer Vision,Head Pose Estimation,BJUT-3D,MAE,1,0.09
Computer Vision,Head Pose Estimation,AFLW,MAE,1,4.06
Computer Vision,Head Pose Estimation,AFLW,MAE,2,5.09
Computer Vision,Head Pose Estimation,BIWI,MAE (trained with other data),1,3.48
Computer Vision,Head Pose Estimation,BIWI,MAE (trained with other data),2,3.66
Computer Vision,Head Pose Estimation,AFLW2000,MAE,1,3.83
Computer Vision,Head Pose Estimation,AFLW2000,MAE,2,3.913
Computer Vision,Head Pose Estimation,AFLW2000,MAE_t,2,0.099
Computer Vision,Vehicle Pose Estimation,CarFusion,PCK,1,88.8
Computer Vision,Vehicle Pose Estimation,ApolloCar3D,A3DP,1,20.21
Computer Vision,Vehicle Pose Estimation,KITTI,Average Orientation Similarity,1,89.43
Computer Vision,Vehicle Pose Estimation,KITTI Cars Hard,Average Orientation Similarity,1,80.96
Computer Vision,Vehicle Pose Estimation,KITTI Cars Hard,Average Orientation Similarity,2,80.39
Computer Vision,6D Pose Estimation using RGBD,Tejani,IoU-2D,1,0.988
Computer Vision,6D Pose Estimation using RGBD,Tejani,IoU-3D,1,0.963
Computer Vision,6D Pose Estimation using RGBD,Tejani,VSS-2D,1,0.724
Computer Vision,6D Pose Estimation using RGBD,Tejani,VSS-3D,1,0.854
Computer Vision,6D Pose Estimation using RGBD,LineMOD,Mean ADD,1,99.4
Computer Vision,6D Pose Estimation using RGBD,LineMOD,Mean ADD,2,97.8
Computer Vision,6D Pose Estimation using RGBD,REAL275,"mAP 10, 10cm",1,26.7
Computer Vision,6D Pose Estimation using RGBD,REAL275,"mAP 10, 5cm",1,26.7
Computer Vision,6D Pose Estimation using RGBD,REAL275,mAP 3DIou@25,1,84.9
Computer Vision,6D Pose Estimation using RGBD,REAL275,mAP 3DIou@50,1,80.5
Computer Vision,6D Pose Estimation using RGBD,REAL275,"mAP 5, 5cm",1,9.5
Computer Vision,6D Pose Estimation using RGBD,YCB-Video,Mean ADD,1,93.3
Computer Vision,6D Pose Estimation using RGBD,YCB-Video,Mean ADD-S,1,93.3
Computer Vision,6D Pose Estimation using RGBD,YCB-Video,Mean ADD,2,80.6
Computer Vision,6D Pose Estimation using RGBD,YCB-Video,Mean ADI,2,92.4
Computer Vision,6D Pose Estimation using RGBD,T-LESS,Mean Recall,1,72.76
Computer Vision,6D Pose Estimation using RGBD,CAMERA25,"mAP 10, 10cm",1,62.2
Computer Vision,6D Pose Estimation using RGBD,CAMERA25,"mAP 10, 5cm",1,61.7
Computer Vision,6D Pose Estimation using RGBD,CAMERA25,mAP 3DIou@25,1,91.4
Computer Vision,6D Pose Estimation using RGBD,CAMERA25,mAP 3DIou@50,1,85.3
Computer Vision,6D Pose Estimation using RGBD,CAMERA25,"mAP 5, 5cm",1,38.8
Computer Vision,Animal Pose Estimation,Horse-10,PCK@0.3,1,88.4
Computer Vision,Animal Pose Estimation,Horse-10,PCK@0.3,2,84.3
Computer Vision,Human Pose Forecasting,Human3.6M,"MAR, walking, 1,000ms",1,0.67
Computer Vision,Human Pose Forecasting,Human3.6M,"MAR, walking, 400ms",1,0.56
Computer Vision,Human Pose Forecasting,Human3.6M,"MAR, walking, 1,000ms",2,0.69
Computer Vision,Human Pose Forecasting,Human3.6M,"MAR, walking, 400ms",2,0.59
Computer Vision,RF-based Pose Estimation, RF-MMD,"mAP (@0.1, Through-wall)",1,86.5
Computer Vision,RF-based Pose Estimation, RF-MMD,"mAP (@0.1, Visible)",1,90.1
Computer Vision,RF-based Pose Estimation, RF-MMD,"mAP (@0.1, Through-wall)",2,78.5
Computer Vision,RF-based Pose Estimation, RF-MMD,"mAP (@0.1, Visible)",2,825
Computer Vision,Activeness Detection,COCO test-dev,Accuracy (%),1,76.67
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2015 Task 12,Restaurant (Acc),1,81.7
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 1+2,F1,1,70.71
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 1+2,F1,2,68.06
Natural Language Processing,Aspect-Based Sentiment Analysis,MAMS,Acc,1,84.52
Natural Language Processing,Aspect-Based Sentiment Analysis,MAMS,Macro-F1,1,83.74
Natural Language Processing,Aspect-Based Sentiment Analysis,MAMS,Acc,2,84.52
Natural Language Processing,Aspect-Based Sentiment Analysis,Sentihood,Aspect,1,87.9
Natural Language Processing,Aspect-Based Sentiment Analysis,Sentihood,Sentiment,1,93.3
Natural Language Processing,Aspect-Based Sentiment Analysis,Sentihood,Aspect,2,86.4
Natural Language Processing,Aspect-Based Sentiment Analysis,Sentihood,Sentiment,2,93.6
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 1,Laptop (F1),1,84.26
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 1,Restaurant (F1),1,77.97
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 1,Laptop (F1),2,81.59
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 1,Restaurant (F1),2,74.37
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Laptop,F1,1,68.06
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Laptop,F1,2,63.4
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,Accuracy (3-way),1,89.9
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,Accuracy (4-way),1,85.9
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,Binary Accuracy,1,95.6
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval-2016 Task 5 Subtask 1,Restaurant (Acc),1,88.70
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval-2016 Task 5 Subtask 1,Restaurant (Acc),2,88.0
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,Laptop (Acc),1,82.29
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,Mean Acc (Restaurant + Laptop),1,86.24
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,Restaurant (Acc),1,90.18
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,Laptop (Acc),2,83.78
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,Mean Acc (Restaurant + Laptop),2,85.58
Natural Language Processing,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,Restaurant (Acc),2,87.37
Natural Language Processing,Aspect-Based Sentiment Analysis, SemEval 2015 Task 12,Restaurant (Acc),1,80.6
Natural Language Processing,Multimodal Sentiment Analysis,MOSI,Accuracy,1,83.91
Natural Language Processing,Multimodal Sentiment Analysis,MOSI,F1 score,1,81.17
Natural Language Processing,Multimodal Sentiment Analysis,MOSI,Accuracy,2,83
Natural Language Processing,Multimodal Sentiment Analysis,MOSI,F1 score,2,82.8
Natural Language Processing,Multimodal Sentiment Analysis,CMU-MOSEI,Accuracy,1,82.40
Natural Language Processing,Multimodal Sentiment Analysis,CMU-MOSEI,Accuracy,2,82.10
Natural Language Processing,Multimodal Sentiment Analysis,CMU-MOSEI,MAE,2,0.59
Natural Language Processing,Multimodal Sentiment Analysis,B-T4SA,Accuracy,1,95.19
Natural Language Processing,Multimodal Sentiment Analysis,B-T4SA,Accuracy,2,95.16
Natural Language Processing,Aspect Sentiment Triplet Extraction,SemEval,F1,1,72.46
Natural Language Processing,Aspect Sentiment Triplet Extraction,SemEval,F1,2,70.32
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Avg F1,1,69.18
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Laptop 2014 (F1),1,67.37
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Restaurant 2014 (F1),1,73.56
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Restaurant 2015 (F1),1,66.61
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Avg F1,2,68.99
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Laptop 2014 (F1),2,65.94
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Restaurant 2014 (F1),2,75.95
Natural Language Processing,Aspect Term Extraction and Sentiment Classification,SemEval,Restaurant 2015 (F1),2,65.08
Natural Language Processing,Fine-Grained Opinion Analysis,MPQA,Holder Binary F1,1,84.91
Natural Language Processing,Fine-Grained Opinion Analysis,MPQA,Target Binary F1,1,73.29
Natural Language Processing,Fine-Grained Opinion Analysis,MPQA,Holder Binary F1,2,83.80
Natural Language Processing,Fine-Grained Opinion Analysis,MPQA,Target Binary F1,2,72.06
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,1,86.9
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,2,86.7
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,1,99.50
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,2,98.5
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,1,93.99
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,2,93.5
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,1,99.02
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,2,98.60
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,1,58.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,1,78.1
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,1,85.9
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,1,89.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,1,92.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,2,45.2
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,2,69.6
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,2,80.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,2,87.5
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,2,91.4
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,89.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),1,88.3
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,89.2
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,88.2
Computer Vision,Skeleton Based Action Recognition,HDM05,Accuracy,1,89.80
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,1,96.0
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,2,92.91
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,1,81.4
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,2,73.8
Computer Vision,Skeleton Based Action Recognition,MSRC-12,Accuracy,1,99.08
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,1,47.7
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,2,38.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,1,60.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,2,58.1
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),1,57
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),1,75
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),1,76
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),1,29
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),1,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),2,53
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),2,43
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),2,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),2,25
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),2,56
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,1,99.1
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,2,98.4
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),1,89.64
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),1,91.78
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),1,89.56
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),2,91.12
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),2,91.76
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),2,91.26
Computer Vision,Skeleton Based Action Recognition,TCG-dataset,Acc,1,87.24
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,1,91.9
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Speed  (FPS),1,2200
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,93.57
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,2,91.43
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),1,94.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),1,97.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),2,91.0
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),2,96.5
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Accuracy,1,78.0
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,1,77.2
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,2,67.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),1,92.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),1,94.4
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),2,92.6
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),2,94.2
Computer Vision,Skeleton Based Action Recognition,Skeletics-152,Accuracy (Cross-Subject),1,57.01
Computer Vision,Skeleton Based Action Recognition,Skeleton-Mimetics,Accuracy (%),1,57.37
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,1,88.51
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,2,86.1
Computer Vision,Skeleton Based Action Recognition,MSR ActionPairs,Accuracy,1,98.02
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,1,91.1
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,2,89.3
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:1 Accuracy,1,95.93
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:3 Accuracy,1,92.9
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,3:1 Accuracy,1,96.76
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,Cross-person Accuracy,1,88.70
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,1,37.98
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,2,36.97
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),1,90.4
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (pose),1,67.9
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),2,86.1
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,1,97.5
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,2,93.4
Natural Language Processing,Native Language Identification,italki NLI,Average F1,1,0.5807
Natural Language Processing,Native Language Identification,italki NLI,Average F1,2,0.5035
Natural Language Processing,Chinese Named Entity Recognition,Resume NER,F1,1,96.79
Natural Language Processing,Chinese Named Entity Recognition,Resume NER,F1,2,96.62
Natural Language Processing,Chinese Named Entity Recognition,MSRA,F1,1,96.72
Natural Language Processing,Chinese Named Entity Recognition,MSRA,F1,2,96.09
Natural Language Processing,Chinese Named Entity Recognition,Weibo NER,F1,1,71.25
Natural Language Processing,Chinese Named Entity Recognition,Weibo NER,F1,2,69.8
Natural Language Processing,Chinese Named Entity Recognition,MSRA Dev,F1,1,96.3
Natural Language Processing,Chinese Named Entity Recognition,MSRA Dev,F1,2,95.2
Natural Language Processing,Chinese Named Entity Recognition,OntoNotes 4,F1,1,84.47
Natural Language Processing,Chinese Named Entity Recognition,OntoNotes 4,F1,2,82.11
Natural Language Processing,Chinese Named Entity Recognition,SighanNER,F1,1,
Natural Language Processing,Nested Named Entity Recognition,NNE,Micro F1,1,94.68
Natural Language Processing,Nested Named Entity Recognition,ACE 2004,F1,1,87.41
Natural Language Processing,Nested Named Entity Recognition,ACE 2004,F1,2,86.84
Natural Language Processing,Nested Named Entity Recognition,ACE 2005,F1,1,86.67
Natural Language Processing,Nested Named Entity Recognition,ACE 2005,F1,2,85.4
Natural Language Processing,Nested Named Entity Recognition,GENIA,F1,1,83.75
Natural Language Processing,Nested Named Entity Recognition,GENIA,F1,2,80.54
Natural Language Processing,Medical Named Entity Recognition,ShARe/CLEF eHealth corpus,F1,1,0.8371
Natural Language Processing,Medical Named Entity Recognition,ShARe/CLEF eHealth corpus,F1,2,0.792
Natural Language Processing,Cross-Domain Named Entity Recognition,CoNLL04,F1,1,70.04
Natural Language Processing,Named Entity Recognition In Vietnamese,VLSP-2016,F1,1,94.43
Natural Language Processing,Few-shot NER,Few-NERD (INTRA),10 way 1~2 shot,1,12.48
Natural Language Processing,Few-shot NER,Few-NERD (INTRA),10 way 5~10 shot,1,21.52
Natural Language Processing,Few-shot NER,Few-NERD (INTRA),5 way 1~2 shot,1,16.73
Natural Language Processing,Few-shot NER,Few-NERD (INTRA),5 way 5~10 shot,1,28.21
Natural Language Processing,Few-shot NER,Few-NERD (INTER),10 way 1~2 shot,1,25.51
Natural Language Processing,Few-shot NER,Few-NERD (INTER),10 way 5~10 shot,1,36.04
Natural Language Processing,Few-shot NER,Few-NERD (INTER),5 way 1~2 shot,1,31.84
Natural Language Processing,Few-shot NER,Few-NERD (INTER),5 way 5~10 shot,1,41.86
Natural Language Processing,Scientific Concept Extraction,STM-corpus,Exact Span F1,1,65.5
Natural Language Processing,Scientific Concept Extraction,STM-corpus,Exact Span F1,2,66.4
"Medical', 'Methodology",Mortality Prediction,MIMIC-III,F1 score,1,0.97
"Medical', 'Methodology",Mortality Prediction,MIMIC-III,Precision,1,0.97
"Medical', 'Methodology",Mortality Prediction,MIMIC-III,Recall,1,0.97
"Medical', 'Methodology",Mortality Prediction,MIMIC-III,F1 score,2,0.96
"Medical', 'Methodology",Mortality Prediction,MIMIC-III,Precision,2,0.95
"Medical', 'Methodology",Mortality Prediction,MIMIC-III,Recall,2,0.96
"Medical', 'Methodology",Mortality Prediction,Clinical Admission Notes from MIMIC-III,AUROC,1,84.04
"Medical', 'Methodology",Mortality Prediction,Clinical Admission Notes from MIMIC-III,AUROC,2,82.55
"Medical', 'Methodology",Arrhythmia Detection,MIT-BIH AR,Accuracy (Inter-Patient),1,99.53
"Medical', 'Methodology",Arrhythmia Detection,MIT-BIH AR,Accuracy (Intra-Patient),1,99.92
"Medical', 'Methodology",Arrhythmia Detection,MIT-BIH AR,Accuracy (Inter-Patient),2,99.47
"Medical', 'Methodology",Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,Accuracy (TEST-DB),1,79
"Medical', 'Methodology",Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,Accuracy (TRAIN-DB),1,72.0
"Medical', 'Methodology",Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,Accuracy (TEST-DB),2,79
"Medical', 'Methodology",Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,Accuracy (TRAIN-DB),2,62.4
"Medical', 'Methodology",Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",F1 (Sequence),1,0.807
"Medical', 'Methodology",Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",F1 (Set),1,0.837
"Medical', 'Methodology",Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",F1 (Sequence),2,0.753
"Medical', 'Methodology",Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",F1 (Set),2,0.780
"Medical', 'Methodology",Arrhythmia Detection,The China Physiological Signal Challenge 2018,F1 (Hidden Test Set),1,0.837
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (1dAVb),1,0.893
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (AF),1,0.857
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (LBBB),1,0.984
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (RBBB),1,0.932
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (SB),1,0.882
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (ST),1,0.933
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (1dAVb),2,0.776
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (AF),2,0.769
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (LBBB),2,0.947
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (RBBB),2,0.917
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (SB),2,0.882
"Medical', 'Methodology",ECG Classification,Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG),F1 (ST),2,0.896
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,Accuracy(stratified10-fold),1,020±002
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,F1(stratified10-fold),1,035±001
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,F2(stratified10-fold),1,040±001
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,G2(stratified10-fold),1,019±001
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,PhysioNet/CinC Challenge Score(stratified10-fold),1,037±003
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,Accuracy(stratified10-fold),2,013±002
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,F1(stratified10-fold),2,028±001
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,F2(stratified10-fold),2,036±002
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,G2(stratified10-fold),2,015±001
"Medical', 'Methodology",ECG Classification,PhysioNet Challenge 2020,PhysioNet/CinC Challenge Score(stratified10-fold),2,036±001
"Medical', 'Methodology",Heartbeat Classification,MIT-BIH+BIDMC,Accuracy,1,0.978
"Medical', 'Methodology",Heartbeat Classification,MIT-BIH AR,PPV (VEB),1,95.7
"Medical', 'Methodology",Heartbeat Classification,MIT-BIH AR,Sensitivity (VEB),1,92.7
"Medical', 'Methodology",Heartbeat Classification,MIT-BIH AR,PPV (VEB),2,90.9
"Medical', 'Methodology",Heartbeat Classification,MIT-BIH AR,Sensitivity (VEB),2,93.9
"Medical', 'Methodology",Heartbeat Classification,AHA,Accuracy (VEB+),1,98.6
"Medical', 'Methodology",Heartbeat Classification,AHA,PPV (VEB+),1,94.9
"Medical', 'Methodology",Heartbeat Classification,AHA,Sensitivity (VEB+),1,90.4
"Medical', 'Methodology",Heartbeat Classification,AHA,Specificity (VEB+),1,99.5
"Medical', 'Methodology",Myocardial infarction detection,PTB,Accuracy (%),1,99.43
"Medical', 'Methodology",Myocardial infarction detection,"PTB dataset, ECG lead II",Accuracy,1,99.43
"Medical', 'Methodology",Myocardial infarction detection,"PTB dataset, ECG lead II",Accuracy,2,95.9
"Medical', 'Methodology",QRS Complex Detection,QT,Accuracy,1,97.42
"Medical', 'Methodology",QRS Complex Detection,QT,Accuracy,2,96.6
"Medical', 'Methodology",QRS Complex Detection,MIT-BIH AR,Accuracy,1,99.60
"Medical', 'Methodology",QRS Complex Detection,MIT-BIH AR,Accuracy,2,99.22
"Medical', 'Methodology",QRS Complex Detection,INCART,Accuracy,1,97.85
"Medical', 'Methodology",QRS Complex Detection,INCART,Accuracy,2,91.65
"Medical', 'Methodology",ECG Denoising,UnoViS_auto2012,MSE,1,0.167
"Medical', 'Methodology",Congestive Heart Failure detection,CHF database,Accuracy,1,98.49
"Medical', 'Methodology",Congestive Heart Failure detection,CHF database,Precision,1,98.05
"Medical', 'Methodology",Congestive Heart Failure detection,CHF database,Sensitivity,1,98.3
"Medical', 'Methodology",Congestive Heart Failure detection,MIT-BIH+BIDMC,Accuracy,1,97.9
Natural Language Processing,Extracting COVID-19 Events from Twitter,W-NUT 2020 Shared Task-3,F1,1,0.66
"Miscellaneous', 'Computer Vision",Change detection for remote sensing images,CDD Dataset (season-varying),F1-Score,1,0.962
"Miscellaneous', 'Computer Vision",Change detection for remote sensing images,CDD Dataset (season-varying),F1-Score,2,0.953
"Miscellaneous', 'Computer Vision",Building change detection for remote sensing images,LEVIR-CD,F1,1,91.79
"Miscellaneous', 'Computer Vision",Building change detection for remote sensing images,LEVIR-CD,F1,2,87.3
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,1,86.9
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,2,86.7
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,1,99.50
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,2,98.5
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,1,93.99
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,2,93.5
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,1,99.02
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,2,98.60
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,1,58.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,1,78.1
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,1,85.9
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,1,89.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,1,92.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,2,45.2
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,2,69.6
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,2,80.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,2,87.5
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,2,91.4
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,89.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),1,88.3
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,89.2
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,88.2
Computer Vision,Skeleton Based Action Recognition,HDM05,Accuracy,1,89.80
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,1,96.0
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,2,92.91
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,1,81.4
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,2,73.8
Computer Vision,Skeleton Based Action Recognition,MSRC-12,Accuracy,1,99.08
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,1,47.7
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,2,38.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,1,60.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,2,58.1
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),1,57
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),1,75
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),1,76
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),1,29
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),1,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),2,53
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),2,43
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),2,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),2,25
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),2,56
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,1,99.1
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,2,98.4
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),1,89.64
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),1,91.78
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),1,89.56
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),2,91.12
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),2,91.76
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),2,91.26
Computer Vision,Skeleton Based Action Recognition,TCG-dataset,Acc,1,87.24
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,1,91.9
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Speed  (FPS),1,2200
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,93.57
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,2,91.43
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),1,94.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),1,97.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),2,91.0
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),2,96.5
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Accuracy,1,78.0
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,1,77.2
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,2,67.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),1,92.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),1,94.4
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),2,92.6
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),2,94.2
Computer Vision,Skeleton Based Action Recognition,Skeletics-152,Accuracy (Cross-Subject),1,57.01
Computer Vision,Skeleton Based Action Recognition,Skeleton-Mimetics,Accuracy (%),1,57.37
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,1,88.51
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,2,86.1
Computer Vision,Skeleton Based Action Recognition,MSR ActionPairs,Accuracy,1,98.02
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,1,91.1
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,2,89.3
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:1 Accuracy,1,95.93
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:3 Accuracy,1,92.9
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,3:1 Accuracy,1,96.76
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,Cross-person Accuracy,1,88.70
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,1,37.98
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,2,36.97
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),1,90.4
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (pose),1,67.9
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),2,86.1
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,1,97.5
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,2,93.4
Computer Vision,Audio-Visual Active Speaker Detection,AVA-ActiveSpeaker,validation mean average precision,1,93.6
Computer Vision,Audio-Visual Active Speaker Detection,AVA-ActiveSpeaker,validation mean average precision,2,93.5
Natural Language Processing,Hope Speech Detection,HopeEDI,Weighted Average F1-score,1,0.93
Natural Language Processing,Hope Speech Detection,HopeEDI,Weighted Average F1-score,2,0.90
Computer Vision,Curved Text Detection,SCUT-CTW1500,F-Measure,1,86.3
Computer Vision,Curved Text Detection,SCUT-CTW1500,F-Measure,2,75.6
Computer Vision,Multi-Oriented Scene Text Detection,ICDAR2015,F-Measure,1,82.4
"Computer Vision', 'Playing Games",Steering Control,BDD100K,Accuracy,1,85.03
"Computer Vision', 'Playing Games",Steering Control,Udacity,MAE,1,1.6236
"Computer Vision', 'Playing Games",Steering Control,Comma.ai,MAE,1,0.7048
Computer Vision,Relational Captioning,relational captioning dataset,Image-Level Recall,1,45.96
Computer Vision,Relational Captioning,relational captioning dataset,Image-Level Recall,2,34.27
Computer Vision,Dense Video Captioning,YouCook2,ROUGE-L,1,39.03
Computer Vision,Dense Video Captioning,ActivityNet Captions,METEOR,1,9.71
Computer Vision,Dense Video Captioning,ActivityNet Captions,BLEU-3,2,4.16
Computer Vision,Dense Video Captioning,ActivityNet Captions,BLEU-4,2,2.02
Computer Vision,Dense Video Captioning,ActivityNet Captions,METEOR,2,8.75
"Robots', 'Computer Vision",PointGoal Navigation,Gibson PointGoal Navigation,spl,1,0.917
"Robots', 'Computer Vision",PointGoal Navigation,Gibson PointGoal Navigation,spl,2,0.79
Computer Vision,Visual Object Tracking,UAV123,AUC,1,0.679
Computer Vision,Visual Object Tracking,UAV123,Precision,1,0.873
Computer Vision,Visual Object Tracking,UAV123,AUC,2,0.672
Computer Vision,Visual Object Tracking,VOT2017,Expected Average Overlap (EAO),1,0.397
Computer Vision,Visual Object Tracking,VOT2017,Expected Average Overlap (EAO),2,0.30
Computer Vision,Visual Object Tracking,YouTube-VOS,F-Measure (Seen),1,60.5
Computer Vision,Visual Object Tracking,YouTube-VOS,F-Measure (Unseen),1,60.7
Computer Vision,Visual Object Tracking,YouTube-VOS,O (Average of Measures),1,58.8
Computer Vision,Visual Object Tracking,YouTube-VOS,F-Measure (Seen),2,62.7
Computer Vision,Visual Object Tracking,YouTube-VOS,F-Measure (Unseen),2,51.4
Computer Vision,Visual Object Tracking,YouTube-VOS,Jaccard (Seen),2,60.1
Computer Vision,Visual Object Tracking,YouTube-VOS,Jaccard (Unseen),2,46.6
Computer Vision,Visual Object Tracking,YouTube-VOS,O (Average of Measures),2,55.2
Computer Vision,Visual Object Tracking,OTB-2013,AUC,1,0.68
Computer Vision,Visual Object Tracking,OTB-2013,AUC,2,0.677
Computer Vision,Visual Object Tracking,TrackingNet,Accuracy,1,82.0
Computer Vision,Visual Object Tracking,TrackingNet,Normalized Precision,1,86.9
Computer Vision,Visual Object Tracking,TrackingNet,Precision,1,79.1
Computer Vision,Visual Object Tracking,TrackingNet,Accuracy,2,81.2
Computer Vision,Visual Object Tracking,TrackingNet,Normalized Precision,2,85.4
Computer Vision,Visual Object Tracking,TrackingNet,Precision,2,80.0
Computer Vision,Visual Object Tracking,GOT-10k,Average Overlap,1,68.8
Computer Vision,Visual Object Tracking,GOT-10k,Success Rate 0.5,1,78.1
Computer Vision,Visual Object Tracking,GOT-10k,Average Overlap,2,64.9
Computer Vision,Visual Object Tracking,GOT-10k,Success Rate 0.5,2,72.8
Computer Vision,Visual Object Tracking,VOT2019,Expected Average Overlap (EAO),1,0.327
Computer Vision,Visual Object Tracking,VOT2019,Expected Average Overlap (EAO),2,0.309
Computer Vision,Visual Object Tracking,LaSOT,AUC,1,67.1
Computer Vision,Visual Object Tracking,LaSOT,AUC,2,64.9
Computer Vision,Visual Object Tracking,VOT2018,Expected Average Overlap (EAO),1,0.467
Computer Vision,Visual Object Tracking,OTB-100,AUC,1,0.707
Computer Vision,Visual Object Tracking,NeedForSpeed,AUC,1,0.65
Computer Vision,Visual Object Tracking,OTB-50,AUC,1,0.61
Computer Vision,Visual Object Tracking,OTB-50,AUC,2,0.610
Computer Vision,Visual Object Tracking,TempleColor128,AUC,1,0.62
Computer Vision,Visual Object Tracking,TempleColor128,Precision,1,0.84
Computer Vision,Visual Object Tracking,VOT2016,Expected Average Overlap (EAO),1,0.466
Computer Vision,Visual Object Tracking,VOT2016,Expected Average Overlap (EAO),2,0.3903
Computer Vision,Visual Object Tracking,VOT2017/18,Expected Average Overlap (EAO),1,0.446
Computer Vision,Visual Object Tracking,VOT2017/18,Expected Average Overlap (EAO),2,0.4160
Computer Vision,Visual Object Tracking,OTB-2015,AUC,1,0.701
Computer Vision,Visual Object Tracking,OTB-2015,Precision,1,0.931
Computer Vision,Visual Object Tracking,OTB-2015,AUC,2,0.70
Computer Vision,Visual Object Tracking,OTB-2015,Precision,2,0.91
Computer Vision,Multi-Object Tracking,MOTS20,sMOTSA,1,70.4
Computer Vision,Multi-Object Tracking,MOTS20,sMOTSA,2,54.9
Computer Vision,Multi-Object Tracking,MOT15,MOTA,1,66.5
Computer Vision,Multi-Object Tracking,TAO,Track mAP,1,27.461
Computer Vision,Multi-Object Tracking,MOT16,IDF1,1,76.8
Computer Vision,Multi-Object Tracking,MOT16,MOTA,1,76.7
Computer Vision,Multi-Object Tracking,MOT16,MOTA,2,74.9
Computer Vision,Multi-Object Tracking,MOT17,IDF1,1,75.1
Computer Vision,Multi-Object Tracking,MOT17,MOTA,1,76.7
Computer Vision,Multi-Object Tracking,MOT17,IDF1,2,72.3
Computer Vision,Multi-Object Tracking,MOT17,MOTA,2,73.7
Computer Vision,Multi-Object Tracking,MOT20,IDF1,1,75.2
Computer Vision,Multi-Object Tracking,MOT20,MOTA,1,77.5
Computer Vision,Multi-Object Tracking,MOT20,MOTA,2,67.1
Computer Vision,Multi-Object Tracking,2D MOT 2015,MOTA,1,60.7
Computer Vision,Multi-Object Tracking,2D MOT 2015,IDF1,2,60.0
Computer Vision,Multi-Object Tracking,2D MOT 2015,MOTA,2,52.5
Computer Vision,Multi-Object Tracking,2DMOT15,MOTA,1,60.6
Computer Vision,Multi-Object Tracking,2DMOT15,IDF1,2,66
Computer Vision,Multi-Object Tracking,2DMOT15,MOTA,2,57
Computer Vision,Multiple Object Tracking,BDD100K val,mIDF1,1,50.8
Computer Vision,Multiple Object Tracking,BDD100K val,mMOTA,1,36.6
Computer Vision,Multiple Object Tracking,BDD100K,mIDF1,1,52.3
Computer Vision,Multiple Object Tracking,BDD100K,mMOTA,1,35.5
Computer Vision,Multiple Object Tracking,Waymo Open Dataset,MOTA/L1,1,51.18
Computer Vision,Multiple Object Tracking,KITTI Tracking test,MOTA,1,90.03
Computer Vision,Multiple Object Tracking,KITTI Tracking test,MOTA,2,89.44
Computer Vision,Online Multi-Object Tracking,MOT17,MOTA,1,53.5
Computer Vision,Online Multi-Object Tracking,MOT17,MOTA,2,49.9
Computer Vision,Online Multi-Object Tracking,MOT16,MOTA,1,67.7
Computer Vision,Online Multi-Object Tracking,MOT16,MOTA,2,54.4
Computer Vision,Online Multi-Object Tracking,MOT15,MOTA,1,30.7
Computer Vision,Online Multi-Object Tracking,2D MOT 2015,MOTA,1,44.1
Computer Vision,Sketch-Based Image Retrieval,Handbags,R@1,1,51.2
Computer Vision,Sketch-Based Image Retrieval,Handbags,R@10,1,85.7
Computer Vision,Sketch-Based Image Retrieval,Handbags,R@1,2,49.4
Computer Vision,Sketch-Based Image Retrieval,Handbags,R@10,2,82.7
Computer Vision,Sketch-Based Image Retrieval,Chairs,R@1,1,85.6
Computer Vision,Sketch-Based Image Retrieval,Chairs,R@10,1,97.9
Computer Vision,Sketch-Based Image Retrieval,Chairs,R@1,2,81.4
Computer Vision,Sketch-Based Image Retrieval,Chairs,R@10,2,95.9
Computer Vision,Sketch-Based Image Retrieval,Shoes,R@1,1,54.8
Computer Vision,Sketch-Based Image Retrieval,Shoes,R@10,1,92.2
Computer Vision,Content-Based Image Retrieval,INRIA Holidays Dataset,MAP,1,90.94
Computer Vision,Text-Image Retrieval,Flickr30k,QPS,1,451.4
Computer Vision,Text-Image Retrieval,Flickr30k,recall@1,1,57.4
Computer Vision,Text-Image Retrieval,Flickr30k,recall@10,1,88.1
Computer Vision,Text-Image Retrieval,Flickr30k,recall@5,1,82.0
Computer Vision,Text-Image Retrieval,COCO,Recall@10,1,99.8
Computer Vision,Text-Image Retrieval,COCO (image as query),Recall@10,1,98.3
Computer Vision,Text-Image Retrieval,COCO (image as query),Recall@10,2,97.2
Computer Vision,Text-Image Retrieval,WIT,R@1,1,0.346
Computer Vision,Text-Image Retrieval,WIT,R@5,1,0.642
Computer Vision,Text-Image Retrieval,WIT,R@1,2,0.048
Computer Vision,Text-Image Retrieval,WIT,R@5,2,0.122
Computer Vision,Text-Image Retrieval,MSCOCO-1k,QPS,1,451.4
Computer Vision,Text-Image Retrieval,MSCOCO-1k,recall@1,1,68.2
Computer Vision,Text-Image Retrieval,MSCOCO-1k,recall@10,1,96.3
Computer Vision,Text-Image Retrieval,MSCOCO-1k,recall@5,1,91.8
Natural Language Processing,Document Ranking,ClueWeb09-B,ERR@20,1,20.28
Natural Language Processing,Document Ranking,ClueWeb09-B,nDCG@20,1,31.10
Natural Language Processing,Short Text Clustering,Searchsnippets,Acc,1,85.2
Natural Language Processing,Short Text Clustering,Searchsnippets,Acc,2,77.1
Natural Language Processing,Short Text Clustering,Biomedical,Acc,1,46.2
Natural Language Processing,Short Text Clustering,Biomedical,Acc,2,43.62
Natural Language Processing,Short Text Clustering,Stackoverflow,Acc,1,75.5
Natural Language Processing,Short Text Clustering,Stackoverflow,Acc,2,51.14
Natural Language Processing,Short Text Clustering,GoogleNews-TS,Acc,1,89.8
Natural Language Processing,Short Text Clustering,AG News,Acc,1,88.2
Natural Language Processing,Short Text Clustering,GoogleNews-T,Acc,1,75.8
Natural Language Processing,Short Text Clustering,Tweet,Acc,1,78.2
Natural Language Processing,Short Text Clustering,GoogleNews-S,Acc,1,83.1
Computer Vision,Point Cloud Completion,ShapeNet,Chamfer Distance,1,8.828
Computer Vision,Point Cloud Completion,ShapeNet,F-Score@1%,1,0.708
Computer Vision,Point Cloud Completion,ShapeNet,Chamfer Distance,2,9.636
Computer Vision,Point Cloud Completion,ShapeNet,F-Score@1%,2,0.695
Computer Vision,Point Cloud Completion,Completion3D,Chamfer Distance,1,10.64
Computer Vision,Point Cloud Completion,Completion3D,Chamfer Distance,2,14.25
"Computer Code', 'Reasoning",Program Repair,DeepFix,Average Success Rate,1,71.7
"Computer Code', 'Reasoning",Program Repair,DeepFix,Average Success Rate,2,68.2
"Computer Code', 'Reasoning",Program Repair,GitHub-Python,Accuracy (%),1,90.5
"Computer Code', 'Reasoning",Program Repair,GitHub-Python,Accuracy (%),2,62.0
"Computer Code', 'Reasoning",Type prediction,Py150,MRR,1,98.7
"Computer Code', 'Reasoning",Type prediction,DeepTyper,Accuracy@5,1,84.60
"Computer Code', 'Reasoning",Value prediction,Py150,MRR,1,73.6
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,1,86.9
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,2,86.7
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,1,99.50
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,2,98.5
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,1,93.99
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,2,93.5
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,1,99.02
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,2,98.60
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,1,58.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,1,78.1
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,1,85.9
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,1,89.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,1,92.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,2,45.2
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,2,69.6
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,2,80.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,2,87.5
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,2,91.4
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,89.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),1,88.3
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,89.2
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,88.2
Computer Vision,Skeleton Based Action Recognition,HDM05,Accuracy,1,89.80
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,1,96.0
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,2,92.91
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,1,81.4
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,2,73.8
Computer Vision,Skeleton Based Action Recognition,MSRC-12,Accuracy,1,99.08
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,1,47.7
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,2,38.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,1,60.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,2,58.1
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),1,57
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),1,75
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),1,76
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),1,29
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),1,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),2,53
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),2,43
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),2,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),2,25
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),2,56
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,1,99.1
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,2,98.4
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),1,89.64
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),1,91.78
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),1,89.56
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),2,91.12
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),2,91.76
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),2,91.26
Computer Vision,Skeleton Based Action Recognition,TCG-dataset,Acc,1,87.24
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,1,91.9
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Speed  (FPS),1,2200
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,93.57
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,2,91.43
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),1,94.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),1,97.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),2,91.0
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),2,96.5
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Accuracy,1,78.0
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,1,77.2
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,2,67.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),1,92.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),1,94.4
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),2,92.6
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),2,94.2
Computer Vision,Skeleton Based Action Recognition,Skeletics-152,Accuracy (Cross-Subject),1,57.01
Computer Vision,Skeleton Based Action Recognition,Skeleton-Mimetics,Accuracy (%),1,57.37
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,1,88.51
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,2,86.1
Computer Vision,Skeleton Based Action Recognition,MSR ActionPairs,Accuracy,1,98.02
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,1,91.1
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,2,89.3
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:1 Accuracy,1,95.93
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:3 Accuracy,1,92.9
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,3:1 Accuracy,1,96.76
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,Cross-person Accuracy,1,88.70
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,1,37.98
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,2,36.97
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),1,90.4
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (pose),1,67.9
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),2,86.1
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,1,97.5
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,2,93.4
Computer Vision,Hand Gesture Recognition,MGB,Accuracy,1,98.04
Computer Vision,Hand Gesture Recognition,EgoGesture,Accuracy,1,94.03
Computer Vision,Hand Gesture Recognition,EgoGesture,Accuracy,2,93.87
Computer Vision,Hand Gesture Recognition,BUAA,Accuracy,1,99.25
Computer Vision,Hand Gesture Recognition,Cambridge,Accuracy,1,98.23
Computer Vision,Hand Gesture Recognition,Cambridge,Accuracy,2,93
Computer Vision,Hand Gesture Recognition,SHREC 2017,14 gestures accuracy,1,95.9
Computer Vision,Hand Gesture Recognition,SHREC 2017,28 gestures accuracy,1,94.7
Computer Vision,Hand Gesture Recognition,SHREC 2017,14 gestures accuracy,2,94.4
Computer Vision,Hand Gesture Recognition,SHREC 2017,28 gestures accuracy,2,90.7
Computer Vision,Hand Gesture Recognition,Jester test,Top 1 Accuracy,1,96.6
Computer Vision,Hand Gesture Recognition,Jester test,Top 1 Accuracy,2,94.78
Computer Vision,Hand Gesture Recognition,NVGesture,Accuracy,1,87.9
Computer Vision,Hand Gesture Recognition,NVGesture,Accuracy,2,86.93
Computer Vision,Hand Gesture Recognition,ChaLearn val,Accuracy,1,57.4
Computer Vision,Hand Gesture Recognition,ChaLearn val,Accuracy,2,39.23
Computer Vision,Hand Gesture Recognition,DHG-28,Accuracy,1,88
Computer Vision,Hand Gesture Recognition,Jester val,Top 1 Accuracy,1,96.33
Computer Vision,Hand Gesture Recognition,Jester val,Top 5 Accuracy,1,99.86
Computer Vision,Hand Gesture Recognition,ChaLean test,Accuracy,1,56.7
Computer Vision,Hand Gesture Recognition,DHG-14,Accuracy,1,91.9
Computer Vision,Hand Gesture Recognition,Northwestern University,Accuracy,1,96.89
Computer Vision,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,95.9
Computer Vision,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,94.6
Computer Vision,Hand Gesture Recognition,VIVA Hand Gestures Dataset,Accuracy,1,86.08
Computer Vision,Hand Gesture Recognition,VIVA Hand Gestures Dataset,Accuracy,2,83.1
Computer Vision,Hand Gesture Recognition,SmartWatch,Accuracy,1,97.4
Computer Vision,Hand-Gesture Recognition,InAirGestures,Accuracy (%),1,99.94
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Image-to-text R@1,1,95.3
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Image-to-text R@10,1,100
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Image-to-text R@5,1,99.8
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Text-to-image R@1,1,84.9
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Text-to-image R@10,1,98.6
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Text-to-image R@5,1,97.4
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Image-to-text R@1,2,83.5
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Image-to-text R@10,2,98.6
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Image-to-text R@5,2,96.7
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Text-to-image R@1,2,64.4
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Text-to-image R@10,2,93.8
Miscellaneous,Cross-Modal Retrieval,Flickr30k,Text-to-image R@5,2,88.7
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Image-to-text R@1,1,77
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Image-to-text R@10,1,96.9
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Image-to-text R@5,1,93.5
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Text-to-image R@1,1,59.9
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Text-to-image R@10,1,89.8
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Text-to-image R@5,1,83.3
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Image-to-text R@1,2,73.5
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Image-to-text R@10,2,96.0
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Image-to-text R@5,2,92.2
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Text-to-image R@1,2,57.5
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Text-to-image R@10,2,89.8
Miscellaneous,Cross-Modal Retrieval,COCO 2014,Text-to-image R@5,2,82.8
Natural Language Processing,Cross-Lingual Transfer,XCOPA,Accuracy,1,76.05
Natural Language Processing,Cross-Lingual Transfer,XCOPA,Accuracy,2,60.94
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot German-to-French,Accuracy,1,75.45
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,Accuracy,1,93.32
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,Accuracy,2,82.48
Natural Language Processing,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,Accuracy,1,84.4
Natural Language Processing,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,Accuracy,2,79.2
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,Accuracy,1,76.02
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,Accuracy,2,69.43
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Japanese,Accuracy,1,69.57
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Japanese,Accuracy,2,67.63
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,Accuracy,1,96.95
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,Accuracy,2,91.62
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,Accuracy,1,96.05
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,Accuracy,2,89.42
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,Accuracy,1,89.7
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,Accuracy,2,67.83
Natural Language Processing,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,Accuracy,1,92.7
Natural Language Processing,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,Accuracy,2,88.1
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,Accuracy,1,96.8
Natural Language Processing,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,Accuracy,2,79.1
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Grayscale),PSNR,1,38.43
Computer Vision,JPEG Artifact Correction,Live1 (Quality 10 Grayscale),PSNR,1,29.71
Computer Vision,JPEG Artifact Correction,Live1 (Quality 10 Grayscale),PSNR-B,1,29.66
Computer Vision,JPEG Artifact Correction,Live1 (Quality 10 Grayscale),SSIM,1,0.838
Computer Vision,JPEG Artifact Correction,Live1 (Quality 10 Grayscale),PSNR,2,29.7
Computer Vision,JPEG Artifact Correction,Live1 (Quality 10 Grayscale),SSIM,2,0.8252
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 40 Grayscale),PSNR,1,34.54
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 40 Grayscale),SSIM,1,0.9304
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 40 Grayscale),PSNR,2,34.45
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 30 Color),PSNR,1,31.21
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 30 Color),PSNR-B,1,30.71
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 30 Color),SSIM,1,0.908
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 20 Grayscale),PSNR,1,31.79
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 20 Grayscale),PSNR-B,1,30.96
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 20 Grayscale),SSIM,1,0.894
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 30 Grayscale),PSNR,1,33.54
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 30 Grayscale),SSIM,1,0.9156
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 30 Grayscale),PSNR,2,33.45
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 30 Grayscale),PSNR,1,33.12
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 30 Grayscale),PSNR-B,1,32.42
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 30 Grayscale),SSIM,1,0.907
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 10 Color),PSNR,1,27.69
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 10 Color),PSNR-B,1,27.36
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 10 Color),SSIM,1,0.810
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Color),PSNR,1,32.11
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Color),PSNR-B,1,32.47
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Color),SSIM,1,0.815
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Color),PSNR,2,31.71
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Color),PSNR-B,2,32.02
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Color),SSIM,2,0.809
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Color),PSNR,1,30.04
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Color),PSNR-B,1,30.01
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Color),SSIM,1,0.882
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Color),PSNR,2,29.92
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Color),PSNR-B,2,29.51
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Color),SSIM,2,0.882
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Grayscale),PSNR,1,37.12
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Grayscale),PSNR-B,1,36.88
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Grayscale),SSIM,1,0.924
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Grayscale),PSNR,2,36.56
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Grayscale),PSNR-B,2,36.44
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Grayscale),SSIM,2,0.902
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Color),PSNR,1,35.20
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Color),PSNR-B,1,35.67
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Color),SSIM,1,0.860
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Color),PSNR,2,34.11
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Color),PSNR-B,2,34.69
Computer Vision,JPEG Artifact Correction,ICB (Quality 30 Color),SSIM,2,0.845
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Color),PSNR,1,34.23
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Color),PSNR-B,1,34.67
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Color),SSIM,1,0.845
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Color),PSNR,2,33.99
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Color),PSNR-B,2,34.37
Computer Vision,JPEG Artifact Correction,ICB (Quality 20 Color),SSIM,2,0.838
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 20 Grayscale),PSNR,1,32.19
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 20 Grayscale),SSIM,1,0.8704
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 20 Grayscale),PSNR,2,32.16
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 40 Grayscale),PSNR,1,34.29
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 40 Grayscale),SSIM,1,0.9063
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 40 Grayscale),PSNR,2,34.27
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Grayscale),PSNR,1,34.73
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Grayscale),PSNR-B,1,34.58
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Grayscale),SSIM,1,0.896
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Grayscale),PSNR,2,34.18
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Grayscale),PSNR-B,2,34.15
Computer Vision,JPEG Artifact Correction,ICB (Quality 10 Grayscale),SSIM,2,0.874
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 30 Color),PSNR,1,31.15
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 30 Color),PSNR-B,1,30.37
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 30 Color),SSIM,1,0.903
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 30 Grayscale),PSNR,1,33.46
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 30 Grayscale),SSIM,1,0.8932
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 30 Grayscale),PSNR,2,33.43
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 10 Color),PSNR,1,27.65
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 10 Color),PSNR-B,1,27.40
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 10 Color),SSIM,1,0.819
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 10 Color),PSNR,2,27.63
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 10 Color),PSNR-B,2,27.63
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 10 Color),SSIM,2,0.816
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 10 Grayscale),PSNR,1,30.03
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 10 Grayscale),SSIM,1,0.8194
Computer Vision,JPEG Artifact Correction,Classic5 (Quality 10 Grayscale),PSNR,2,30.01
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Grayscale),PSNR,1,32.1
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Grayscale),SSIM,1,0.8886
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Grayscale),PSNR,2,32.09
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Grayscale),PSNR-B,2,32.00
Computer Vision,JPEG Artifact Correction,LIVE1 (Quality 20 Grayscale),SSIM,2,0.9006
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 10 Grayscale),PSNR,1,29.54
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 10 Grayscale),PSNR-B,1,29.04
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 10 Grayscale),SSIM,1,0.833
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 20 Color),PSNR,1,29.89
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 20 Color),PSNR-B,1,29.29
Computer Vision,JPEG Artifact Correction,BSDS500 (Quality 20 Color),SSIM,1,0.876
Computer Vision,MRI Reconstruction,IXI Dataset,DSSIM,1,1.44e03
Computer Vision,MRI Reconstruction,IXI Dataset,MSE,1,3.44e05
Computer Vision,MRI Reconstruction,fastMRI Knee 8x,PSNR,1,37
Computer Vision,MRI Reconstruction,fastMRI Knee 8x,SSIM,1,0.890
Computer Vision,MRI Reconstruction,fastMRI Knee 8x,PSNR,2,37.2
Computer Vision,MRI Reconstruction,fastMRI Knee 8x,SSIM,2,0.8893
Computer Vision,MRI Reconstruction,fastMRI Knee 4x,PSNR,1,40
Computer Vision,MRI Reconstruction,fastMRI Knee 4x,SSIM,1,0.930
Computer Vision,MRI Reconstruction,fastMRI Knee 4x,PSNR,2,40.2
Computer Vision,MRI Reconstruction,fastMRI Knee 4x,SSIM,2,0.9287
Computer Vision,MRI Reconstruction,fastMRI Brain 4x,PSNR,1,41
Computer Vision,MRI Reconstruction,fastMRI Brain 4x,SSIM,1,0.959
Computer Vision,MRI Reconstruction,fastMRI Brain 4x,PSNR,2,41.3
Computer Vision,MRI Reconstruction,fastMRI Brain 4x,SSIM,2,0.9581
Computer Vision,MRI Reconstruction,fastMRI Brain 8x,PSNR,1,38
Computer Vision,MRI Reconstruction,fastMRI Brain 8x,SSIM,1,0.943
Computer Vision,MRI Reconstruction,fastMRI Brain 8x,PSNR,2,38.1
Computer Vision,MRI Reconstruction,fastMRI Brain 8x,SSIM,2,0.9408
Computer Vision,Multi-view Subspace Clustering,ARL Polarimetric Thermal Face Dataset,Accuracy,1,0.988
Computer Vision,Multi-view Subspace Clustering,ORL,Accuracy,1,0.870
Computer Vision,Multi-view Subspace Clustering,ORL,Accuracy,2,0.833
"Miscellaneous', 'Methodology",Neural Network Compression,ImageNet,All,1,0.1
"Miscellaneous', 'Methodology",Neural Network Compression,CIFAR-10,Size (MB),1,1.9
"Miscellaneous', 'Methodology",Neural Network Compression,CIFAR-10,Size (MB),2,2.9
Computer Vision,3D Object Reconstruction,ShapeNet,3DIoU,1,64.64
Computer Vision,3D Object Reconstruction,Data3D−R2N2,3DIoU,1,0.67
Computer Vision,3D Object Reconstruction,Data3D−R2N2,3DIoU,2,0.661
Computer Vision,Multiview Gait Recognition,OU-MVLP,Accuracy (Cross-View),1,88.7
Computer Vision,Multiview Gait Recognition,OU-MVLP,Accuracy (Cross-View),2,87.1
Computer Vision,Multiview Gait Recognition,CASIA-B,"Accuracy (Cross-View, Avg)",1,88.8
Computer Vision,Multiview Gait Recognition,CASIA-B,BG#1-2,1,91.5
Computer Vision,Multiview Gait Recognition,CASIA-B,CL#1-2,1,78.7
Computer Vision,Multiview Gait Recognition,CASIA-B,NM#5-6 ,1,96.2
Computer Vision,Multiview Gait Recognition,CASIA-B,"Accuracy (Cross-View, Avg)",2,84.2
Computer Vision,Multiview Gait Recognition,CASIA-B,BG#1-2,2,87.2
Computer Vision,Multiview Gait Recognition,CASIA-B,CL#1-2,2,70.4
Computer Vision,Multiview Gait Recognition,CASIA-B,NM#5-6 ,2,95.0
Computer Vision,Image Denoising,SIDD,PSNR (sRGB),1,39.99
Computer Vision,Image Denoising,SIDD,SSIM (sRGB),1,0.958
Computer Vision,Image Denoising,SIDD,PSNR (sRGB),2,39.77
Computer Vision,Image Denoising,SIDD,SSIM (sRGB),2,0.970
Computer Vision,Image Denoising,"ultracold fermions Technion system, pixelfly",ODRMSE,1,0.0711
Computer Vision,Image Denoising,FMD,PSNR,1,810dB
Computer Vision,Image Denoising,FFHQ 64x64 - 4x upscaling,LPIPS,1,0.24
Computer Vision,Image Denoising,DND,PSNR (sRGB),1,39.96
Computer Vision,Image Denoising,DND,SSIM (sRGB),1,0.956
Computer Vision,Image Denoising,DND,PSNR (sRGB),2,39.88
Computer Vision,Image Denoising,DND,SSIM (sRGB),2,0.956
Computer Vision,Image Denoising,FFHQ,LPIPS,1,0.24
Computer Vision,Color Image Denoising,CBSD68 sigma55,PSNR,1,25.95
Computer Vision,Color Image Denoising,CBSD68 sigma15,PSNR,1,34.1
Computer Vision,Color Image Denoising,CBSD68 sigma15,PSNR,2,33.87
Computer Vision,Color Image Denoising,CellNet,PSNR,1,34.4
Computer Vision,Color Image Denoising,BSD68 sigma25,PSNR,1,31.37
Computer Vision,Color Image Denoising,BSD68 sigma25,PSNR,2,31.18
Computer Vision,Color Image Denoising,Urban100 sigma50,PSNR,1,29.38
Computer Vision,Color Image Denoising,CBSD68 sigma40,PSNR,1,28.01
Computer Vision,Color Image Denoising,Urban100 sigma10,PSNR,1,36.75
Computer Vision,Color Image Denoising,Kodak24 sigma10,PSNR,1,37.33
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,PSNR (Raw),1,48.88
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,PSNR (sRGB),1,40.35
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,SSIM (Raw),1,0.9821
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,SSIM (sRGB),1,0.9641
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,PSNR (Raw),2,48.5
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,PSNR (sRGB),2,39.4
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,SSIM (Raw),2,0.9806
Computer Vision,Color Image Denoising,Darmstadt Noise Dataset,SSIM (sRGB),2,0.9528
Computer Vision,Color Image Denoising,Kodak25 sigma35,PSNR,1,30.57
Computer Vision,Color Image Denoising,CBSD68 sigma30,PSNR,1,29.71
Computer Vision,Color Image Denoising,CBSD68 sigma75,PSNR,1,26.35
Computer Vision,Color Image Denoising,CBSD68 sigma75,PSNR,2,26.24
Computer Vision,Color Image Denoising,BSD68 sigma10,PSNR,1,36.49
Computer Vision,Color Image Denoising,BSD68 sigma30,PSNR,1,30.7
Computer Vision,Color Image Denoising,McMaster sigma50,PSNR,1,29.18
Computer Vision,Color Image Denoising,CBSD68 sigma10,PSNR,1,35.98
Computer Vision,Color Image Denoising,CBSD68 sigma10,PSNR,2,35.92
Computer Vision,Color Image Denoising,McMaster sigma75,PSNR,1,27.33
Computer Vision,Color Image Denoising,Urban100 sigma30,PSNR,1,31.78
Computer Vision,Color Image Denoising,Hanzi,PSNR,1,13.9
Computer Vision,Color Image Denoising,NTIRE 2019 Real Image Denoising Challenge (sRGB),PSNR,1,39.931743
Computer Vision,Color Image Denoising,NTIRE 2019 Real Image Denoising Challenge (sRGB),SSIM,1,0.973589
Computer Vision,Color Image Denoising,CBSD68 sigma70,PSNR,1,24.18
Computer Vision,Color Image Denoising,CBSD68 sigma35,PSNR,1,29.58
Computer Vision,Color Image Denoising,CBSD68 sigma35,PSNR,2,29.34
Computer Vision,Color Image Denoising,Kodak24 sigma50,PSNR,1,29.7
Computer Vision,Color Image Denoising,McMaster sigma35,PSNR,1,30.81
Computer Vision,Color Image Denoising,Kodak24 sigma30,PSNR,1,31.98
Computer Vision,Color Image Denoising,Kodak24 sigma30,PSNR,2,31.95
Computer Vision,Color Image Denoising,BSD68 sigma15,PSNR,1,34.01
Computer Vision,Color Image Denoising,BSD68 sigma15,PSNR,2,33.86
Computer Vision,Color Image Denoising,CBSD68 sigma45,PSNR,1,27.28
Computer Vision,Color Image Denoising,CBSD68 sigma5,PSNR,1,40.05
Computer Vision,Color Image Denoising,CBSD68 sigma5,PSNR,2,39.73
Computer Vision,Color Image Denoising,McMaster sigma25,PSNR,1,32.35
Computer Vision,Color Image Denoising,BSD68 sigma35,PSNR,1,29.5
Computer Vision,Color Image Denoising,Kodak24 sigma70,PSNR,1,28.24
Computer Vision,Color Image Denoising,McMaster sigma15,PSNR,1,34.66
Computer Vision,Color Image Denoising,Urban100 sigma70,PSNR,1,27.74
Computer Vision,Color Image Denoising,BSD68 sigma70,PSNR,1,26.88
Computer Vision,Color Image Denoising,Kodak25 sigma75,PSNR,1,27.27
Computer Vision,Color Image Denoising,Kodak25 sigma25,PSNR,1,32.13
Computer Vision,Color Image Denoising,CBSD68 sigma65,PSNR,1,24.75
Computer Vision,Color Image Denoising,CBSD68 sigma50,PSNR,1,28.34
Computer Vision,Color Image Denoising,CBSD68 sigma50,PSNR,2,28.14
Computer Vision,Color Image Denoising,Kodak25 sigma50,PSNR,1,28.98
Computer Vision,Color Image Denoising,BSD68 sigma5,PSNR,1,40.36
Computer Vision,Color Image Denoising,ImageNet,PSNR,1,22
Computer Vision,Color Image Denoising,CBSD68 sigma25,PSNR,1,31.21
Computer Vision,Color Image Denoising,CBSD68 sigma25,PSNR,2,30.99
Computer Vision,Color Image Denoising,BSD68 sigma75,PSNR,1,26.32
Computer Vision,Color Image Denoising,Kodak25 sigma15,PSNR,1,34.63
Computer Vision,Color Image Denoising,CBSD68 sigma20,PSNR,1,32.02
Computer Vision,Color Image Denoising,CBSD68 sigma60,PSNR,1,25.34
Computer Vision,Salt-And-Pepper Noise Removal,BSD300 Noise Level 70%,PSNR,1,32.4
Computer Vision,Salt-And-Pepper Noise Removal,BSD300 Noise Level 70%,PSNR,2,31.42
Computer Vision,Salt-And-Pepper Noise Removal,BSD300 Noise Level 30%,PSNR,1,40.90
Computer Vision,Salt-And-Pepper Noise Removal,BSD300 Noise Level 30%,PSNR,2,39.83
Computer Vision,Salt-And-Pepper Noise Removal,Kodak24 Noise Level 30%,PSNR,1,36.39
Computer Vision,Salt-And-Pepper Noise Removal,Kodak24 Noise Level 30%,PSNR,2,34.95
Computer Vision,Salt-And-Pepper Noise Removal,BSD300 Noise Level 50%,PSNR,1,37.28
Computer Vision,Salt-And-Pepper Noise Removal,BSD300 Noise Level 50%,PSNR,2,35.92
Computer Vision,Salt-And-Pepper Noise Removal,Kodak24 Noise Level 70%,PSNR,1,31.56
Computer Vision,Salt-And-Pepper Noise Removal,Kodak24 Noise Level 70%,PSNR,2,30.49
Computer Vision,Salt-And-Pepper Noise Removal,Kodak24 Noise Level 50%,PSNR,1,34.35
Computer Vision,Salt-And-Pepper Noise Removal,Kodak24 Noise Level 50%,PSNR,2,32.27
Computer Vision,Grayscale Image Denoising,Kodak24 sigma10,PSNR,1,35.19
Computer Vision,Grayscale Image Denoising,BSD68 sigma15,PSNR,1,31.88
Computer Vision,Grayscale Image Denoising,BSD68 sigma15,PSNR,2,31.86
Computer Vision,Grayscale Image Denoising,BSD68 sigma10,PSNR,1,34.01
Computer Vision,Grayscale Image Denoising,BSD68 sigma10,PSNR,2,33.47
Computer Vision,Grayscale Image Denoising,Kodak24 sigma30,PSNR,1,30.02
Computer Vision,Grayscale Image Denoising,BSD68 sigma20,PSNR,1,29.88
Computer Vision,Grayscale Image Denoising,BSD68 sigma75,PSNR,1,24.79
Computer Vision,Grayscale Image Denoising,BSD68 sigma75,PSNR,2,22.67
Computer Vision,Grayscale Image Denoising,Set12 sigma25,PSNR,1,30.79
Computer Vision,Grayscale Image Denoising,Set12 sigma25,PSNR,2,30.78
Computer Vision,Grayscale Image Denoising,BSD68 sigma55,PSNR,1,24.55
Computer Vision,Grayscale Image Denoising,Kodak24 sigma70,PSNR,1,26.57
Computer Vision,Grayscale Image Denoising,Urban100 sigma70,PSNR,1,25.71
Computer Vision,Grayscale Image Denoising,Urban100 sigma70,PSNR,2,25.15
Computer Vision,Grayscale Image Denoising,BSD200 sigma50,PSNR,1,32.48
Computer Vision,Grayscale Image Denoising,BSD200 sigma50,PSNR,2,25.97
Computer Vision,Grayscale Image Denoising,BSD200 sigma10,PSNR,1,36.36
Computer Vision,Grayscale Image Denoising,BSD200 sigma10,PSNR,2,33.63
Computer Vision,Grayscale Image Denoising,BSD200 sigma10,SSIM,2,0.9319
Computer Vision,Grayscale Image Denoising,BSD68 sigma60,PSNR,1,24.05
Computer Vision,Grayscale Image Denoising,Urban100 sigma15,PSNR,1,33.47
Computer Vision,Grayscale Image Denoising,Urban100 sigma15,PSNR,2,33.45
Computer Vision,Grayscale Image Denoising,Set12 sigma70,PSNR,1,25.9
Computer Vision,Grayscale Image Denoising,BSD68 sigma45,PSNR,1,25.67
Computer Vision,Grayscale Image Denoising,BSD200 sigma30,PSNR,1,33.57
Computer Vision,Grayscale Image Denoising,BSD200 sigma30,PSNR,2,28.2
Computer Vision,Grayscale Image Denoising,Clip300 sigma60,PSNR,1,25.51
Computer Vision,Grayscale Image Denoising,BSD68 sigma50,PSNR,1,26.53
Computer Vision,Grayscale Image Denoising,BSD68 sigma50,PSNR,2,26.47
Computer Vision,Grayscale Image Denoising,Urban100 sigma50,PSNR,1,27.49
Computer Vision,Grayscale Image Denoising,Urban100 sigma50,PSNR,2,27.47
Computer Vision,Grayscale Image Denoising,Set12 sigma50,PSNR,1,27.74
Computer Vision,Grayscale Image Denoising,Set12 sigma50,PSNR,2,27.64
Computer Vision,Grayscale Image Denoising,BSD68 sigma30,PSNR,1,28.58
Computer Vision,Grayscale Image Denoising,BSD68 sigma30,PSNR,2,27.82
Computer Vision,Grayscale Image Denoising,Kodak24 sigma50,PSNR,1,27.88
Computer Vision,Grayscale Image Denoising,BSD68 sigma5,PSNR,1,37.25
Computer Vision,Grayscale Image Denoising,BSD68 sigma40,PSNR,1,26.31
Computer Vision,Grayscale Image Denoising,Set12 sigma30,PSNR,1,30.8
Computer Vision,Grayscale Image Denoising,Set12 sigma30,PSNR,2,30.43
Computer Vision,Grayscale Image Denoising,Urban100 sigma10,PSNR,1,35.45
Computer Vision,Grayscale Image Denoising,Clip300 sigma15,PSNR,1,31.68
Computer Vision,Grayscale Image Denoising,Clip300 sigma35,PSNR,1,27.75
Computer Vision,Grayscale Image Denoising,Set12 sigma15,PSNR,1,33.16
Computer Vision,Grayscale Image Denoising,Set12 sigma15,PSNR,2,33.15
Computer Vision,Grayscale Image Denoising,BSD68 sigma65,PSNR,1,23.56
Computer Vision,Grayscale Image Denoising,Urban100 sigma25,PSNR,1,30.95
Computer Vision,Grayscale Image Denoising,Urban100 sigma25,PSNR,2,30.94
Computer Vision,Grayscale Image Denoising,BSD68 sigma70,PSNR,1,25.14
Computer Vision,Grayscale Image Denoising,BSD68 sigma70,PSNR,2,25.12
Computer Vision,Grayscale Image Denoising,Urban100 sigma30,PSNR,1,30.08
Computer Vision,Grayscale Image Denoising,Clip300 sigma25,PSNR,1,29.25
Computer Vision,Grayscale Image Denoising,BSD68 sigma25,PSNR,1,29.41
Computer Vision,Grayscale Image Denoising,BSD68 sigma25,PSNR,2,29.41
Computer Vision,Grayscale Image Denoising,BSD200 sigma70,PSNR,1,31.17
Computer Vision,Grayscale Image Denoising,BSD200 sigma70,PSNR,2,24.62
Computer Vision,Grayscale Image Denoising,BSD68 sigma35,PSNR,1,27.73
Computer Vision,Grayscale Image Denoising,BSD68 sigma35,PSNR,2,27.03
Computer Vision,Grayscale Image Denoising,Clip300 sigma50,PSNR,1,26.25
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Overall Accuracy,1,95.36
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Average Accuracy,2,88.44
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Kappa,2,0.8555
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Overall Accuracy,2,86.61
Computer Vision,Hyperspectral Image Classification,Kennedy Space Center,Overall Accuracy,1,99.34
Computer Vision,Hyperspectral Image Classification,Salinas Scene,Overall Accuracy,1,100
Computer Vision,Hyperspectral Image Classification,Salinas Scene,Overall Accuracy,2,100
Computer Vision,Hyperspectral Image Classification,Salinas,AA@200,1,99.91
Computer Vision,Hyperspectral Image Classification,Salinas,Kappa@200,1,0.9991
Computer Vision,Hyperspectral Image Classification,Salinas,OA@200,1,99.92
Computer Vision,Hyperspectral Image Classification,Indian Pines,Overall Accuracy,1,99.86
Computer Vision,Hyperspectral Image Classification,Indian Pines,Overall Accuracy,2,99.81
Computer Vision,Hyperspectral Image Classification,Pavia University,Overall Accuracy,1,99.99
Computer Vision,Hyperspectral Image Classification,Pavia University,Kappa@1%,2,0.9996
Computer Vision,Hyperspectral Image Classification,Pavia University,Overall Accuracy,2,99.97
Computer Vision,Classification Of Hyperspectral Images,Pavia University,Accuracy,1,99.43
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,1,86.9
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,2,86.7
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,1,99.50
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,2,98.5
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,1,93.99
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,2,93.5
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,1,99.02
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,2,98.60
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,1,58.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,1,78.1
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,1,85.9
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,1,89.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,1,92.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,2,45.2
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,2,69.6
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,2,80.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,2,87.5
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,2,91.4
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,89.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),1,88.3
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,89.2
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,88.2
Computer Vision,Skeleton Based Action Recognition,HDM05,Accuracy,1,89.80
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,1,96.0
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,2,92.91
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,1,81.4
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,2,73.8
Computer Vision,Skeleton Based Action Recognition,MSRC-12,Accuracy,1,99.08
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,1,47.7
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,2,38.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,1,60.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,2,58.1
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),1,57
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),1,75
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),1,76
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),1,29
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),1,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),2,53
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),2,43
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),2,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),2,25
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),2,56
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,1,99.1
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,2,98.4
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),1,89.64
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),1,91.78
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),1,89.56
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),2,91.12
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),2,91.76
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),2,91.26
Computer Vision,Skeleton Based Action Recognition,TCG-dataset,Acc,1,87.24
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,1,91.9
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Speed  (FPS),1,2200
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,93.57
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,2,91.43
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),1,94.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),1,97.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),2,91.0
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),2,96.5
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Accuracy,1,78.0
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,1,77.2
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,2,67.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),1,92.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),1,94.4
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),2,92.6
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),2,94.2
Computer Vision,Skeleton Based Action Recognition,Skeletics-152,Accuracy (Cross-Subject),1,57.01
Computer Vision,Skeleton Based Action Recognition,Skeleton-Mimetics,Accuracy (%),1,57.37
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,1,88.51
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,2,86.1
Computer Vision,Skeleton Based Action Recognition,MSR ActionPairs,Accuracy,1,98.02
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,1,91.1
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,2,89.3
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:1 Accuracy,1,95.93
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:3 Accuracy,1,92.9
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,3:1 Accuracy,1,96.76
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,Cross-person Accuracy,1,88.70
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,1,37.98
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,2,36.97
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),1,90.4
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (pose),1,67.9
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),2,86.1
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,1,97.5
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,2,93.4
Computer Vision,3D Semantic Segmentation,PartNet,mIOU,1,58.2
Computer Vision,3D Semantic Segmentation,PartNet,mIOU,2,53.8
Computer Vision,3D Semantic Segmentation,SemanticKITTI,mIoU,1,70.8
Computer Vision,3D Semantic Segmentation,SemanticKITTI,mIoU,2,68.9
Computer Vision,3D Semantic Segmentation,nuScenes,mIoU,1,78.3
Computer Vision,3D Semantic Segmentation,RELLIS-3D Dataset,Mean IoU (class),1,40.2
Computer Vision,3D Semantic Segmentation,RELLIS-3D Dataset,Mean IoU (class),2,18.64
Computer Vision,3D Semantic Segmentation,3D Platelet EM,Mean IoU (test),1,0.446
Computer Vision,3D Semantic Segmentation,S3DIS,mAcc,1,87.12
Computer Vision,3D Semantic Segmentation,S3DIS,mIoU,2,58.98
Computer Vision,Zero Shot Skeletal Action Recognition,NTU RGB+D 120,Accuracy (10 unseen classes),1,62.69
Computer Vision,Zero Shot Skeletal Action Recognition,NTU RGB+D 120,Accuracy (24 unseen classes),1,38.70
Computer Vision,Zero Shot Skeletal Action Recognition,NTU RGB+D,Accuracy (12 unseen classes),1,33.30
Computer Vision,Zero Shot Skeletal Action Recognition,NTU RGB+D,Accuracy (5 unseen classes),1,75.81
Computer Vision,Generalized Zero Shot skeletal action recognition,NTU RGB+D,Harmonic Mean (12 unseen classes),1,36.33
Computer Vision,Generalized Zero Shot skeletal action recognition,NTU RGB+D,Harmonic Mean (5 unseen classes),1,59.02
Computer Vision,Generalized Zero Shot skeletal action recognition,NTU RGB+D 120,Harmonic Mean (10 unseen classes),1,54.94
Computer Vision,Generalized Zero Shot skeletal action recognition,NTU RGB+D 120,Harmonic Mean (24 unseen classes),1,41.04
Natural Language Processing,Sentence Compression,Google Dataset,CR,1,0.407
Natural Language Processing,Sentence Compression,Google Dataset,F1,1,0.855
Natural Language Processing,Sentence Compression,Google Dataset,CR,2,0.39
Natural Language Processing,Sentence Compression,Google Dataset,F1,2,0.851
Natural Language Processing,Sentence Embeddings For Biomedical Texts,MedSTS,Pearson Correlation,1,0.767
Natural Language Processing,Sentence Embeddings For Biomedical Texts,MedSTS,Pearson Correlation,2,0.759
Natural Language Processing,Sentence Embeddings For Biomedical Texts,BIOSSES,Pearson Correlation,1,0.817
Natural Language Processing,Sentence Embeddings For Biomedical Texts,BIOSSES,Pearson Correlation,2,0.795
Natural Language Processing,Constituency Grammar Induction,PTB,Mean F1 (WSJ),1,60.4
Natural Language Processing,Constituency Grammar Induction,PTB,Max F1 (WSJ),2,61.4
Natural Language Processing,Constituency Grammar Induction,PTB,Mean F1 (WSJ),2,57.7
Graphs,Knowledge Graph Embedding,FB15k,MRR,1,0.815
Graphs,Clustering Ensemble,pathbased,Purity,1,0.98
Graphs,Clustering Ensemble,ionosphere,Purity,1,0.83
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - EUB,AUC,1,0.8494
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - EUB,CC,1,0.7442
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - EUB,NSS,1,1.8831
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 10-shot ,AUC,1,0.8276
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 10-shot ,CC,1,0.6605
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 10-shot ,NSS,1,1.6439
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 1-shot,AUC,1,0.8051
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 1-shot,CC,1,0.6121
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 1-shot,NSS,1,1.5077
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 1-shot,AUC,2,0.7983
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 1-shot,CC,2,0.5817
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 1-shot,NSS,2,1.4272
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 5-shot ,AUC,1,0.8200
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 5-shot ,CC,1,0.6468
Computer Vision,Few-Shot Transfer Learning for Saliency Prediction,SALICON->WebpageSaliency - 5-shot ,NSS,1,1.6085
"Computer Code', 'Natural Language Processing",Method name prediction,CodeSearchNet,F1,1,17.24
Computer Vision,Unsupervised Video Summarization,TvSum,F1-score,1,60.6
Computer Vision,Unsupervised Video Summarization,TvSum,F1-score,2,58.8
Computer Vision,Unsupervised Video Summarization,SumMe,F1-score,1,51.3
Computer Vision,Unsupervised Video Summarization,SumMe,F1-score,2,50.8
Computer Vision,Supervised Video Summarization,TvSum,F1-score (Canonical),1,67.5
Computer Vision,Supervised Video Summarization,TvSum,F1-score (Canonical),2,63.9
Computer Vision,Supervised Video Summarization,SumMe,F1-score (Augmented),1,50.7
Computer Vision,Supervised Video Summarization,SumMe,F1-score (Canonical),1,50.2
Computer Vision,Supervised Video Summarization,SumMe,F1-score (Augmented),2,48.7
Computer Vision,Supervised Video Summarization,SumMe,F1-score (Canonical),2,48.6
Natural Language Processing,Abstractive Text Summarization,MLSUM de,METEOR,1,0.437
Natural Language Processing,Abstractive Text Summarization,MLSUM es,METEOR,1,0.210
Natural Language Processing,Abstractive Text Summarization,CNN / Daily Mail,ROUGE-1,1,44.51
Natural Language Processing,Abstractive Text Summarization,CNN / Daily Mail,ROUGE-2,1,21.58
Natural Language Processing,Abstractive Text Summarization,CNN / Daily Mail,ROUGE-L,1,41.24
Natural Language Processing,Abstractive Text Summarization,CNN / Daily Mail,ROUGE-1,2,44.45
Natural Language Processing,Abstractive Text Summarization,CNN / Daily Mail,ROUGE-2,2,21.25
Natural Language Processing,Abstractive Text Summarization,CNN / Daily Mail,ROUGE-L,2,41.4
Natural Language Processing,Abstractive Text Summarization,WikiHow,Content F1,1,29.8
Natural Language Processing,Abstractive Text Summarization,WikiHow,ROUGE-1,1,35.91
Natural Language Processing,Abstractive Text Summarization,WikiHow,ROUGE-2,1,13.9
Natural Language Processing,Abstractive Text Summarization,WikiHow,ROUGE-L,1,34.82
Natural Language Processing,Abstractive Text Summarization,AESLC,ROUGE-1,1,37.68
Natural Language Processing,Abstractive Text Summarization,AESLC,ROUGE-2,1,21.25
Natural Language Processing,Abstractive Text Summarization,AESLC,ROUGE-L,1,36.51
Natural Language Processing,Abstractive Text Summarization,AESLC,ROUGE-1,2,23.67
Natural Language Processing,Abstractive Text Summarization,AESLC,ROUGE-2,2,10.29
Natural Language Processing,Abstractive Text Summarization,AESLC,ROUGE-L,2,
Natural Language Processing,Document Summarization,BBC XSum,ROUGE-1,1,47.12
Natural Language Processing,Document Summarization,BBC XSum,ROUGE-2,1,24.05
Natural Language Processing,Document Summarization,BBC XSum,ROUGE-L,1,38.8
Natural Language Processing,Document Summarization,CNN / Daily Mail,ROUGE-1,1,44.48
Natural Language Processing,Document Summarization,CNN / Daily Mail,ROUGE-2,1,21.31
Natural Language Processing,Document Summarization,CNN / Daily Mail,ROUGE-L,1,41.52
Natural Language Processing,Document Summarization,CNN / Daily Mail,ROUGE-1,2,44.41
Natural Language Processing,Document Summarization,CNN / Daily Mail,ROUGE-2,2,20.86
Natural Language Processing,Document Summarization,CNN / Daily Mail,ROUGE-L,2,40.55
Natural Language Processing,Multi-Document Summarization,DUC 2004,ROUGE-1,1,38.23
Natural Language Processing,Multi-Document Summarization,review,1-of-100 Accuracy,1,100
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-1,1,43.57
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-2,1,14.03
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-SU4,1,17.37
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-1,2,43.47
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-2,2,14.89
Natural Language Processing,Multi-Document Summarization,Multi-News,ROUGE-SU4,2,17.41
Natural Language Processing,Extractive Text Summarization,DUC 2004 Task 1,ROUGE-1,1,26.55
Natural Language Processing,Extractive Text Summarization,DUC 2004 Task 1,ROUGE-2,1,7.06
Natural Language Processing,Extractive Text Summarization,DUC 2004 Task 1,ROUGE-L,1,22.05
Natural Language Processing,Extractive Text Summarization,DUC 2004 Task 1,ROUGE-1,2,26.55
Natural Language Processing,Extractive Text Summarization,DUC 2004 Task 1,ROUGE-2,2,7.06
Natural Language Processing,Extractive Text Summarization,DebateSum,ROUGE-L,1,57.21
Natural Language Processing,Extractive Text Summarization,DebateSum,ROUGE-L,2,53.23
Natural Language Processing,Extractive Text Summarization,CNN / Daily Mail,ROUGE-1,1,44.68
Natural Language Processing,Extractive Text Summarization,CNN / Daily Mail,ROUGE-2,1,21.30
Natural Language Processing,Extractive Text Summarization,CNN / Daily Mail,ROUGE-L,1,40.75
Natural Language Processing,Extractive Text Summarization,CNN / Daily Mail,ROUGE-1,2,44.41
Natural Language Processing,Extractive Text Summarization,CNN / Daily Mail,ROUGE-2,2,20.86
Natural Language Processing,Extractive Text Summarization,CNN / Daily Mail,ROUGE-L,2,40.55
Natural Language Processing,Sentence Compression,Google Dataset,CR,1,0.407
Natural Language Processing,Sentence Compression,Google Dataset,F1,1,0.855
Natural Language Processing,Sentence Compression,Google Dataset,CR,2,0.39
Natural Language Processing,Sentence Compression,Google Dataset,F1,2,0.851
Natural Language Processing,Scientific Document Summarization,CL-SciSumm,ROUGE-2,1,33.88
Natural Language Processing,Query-Based Extractive Summarization,Debatepedia,ROUGE-1,1,53.09
Natural Language Processing,Query-Based Extractive Summarization,Debatepedia,ROUGE-1,2,41.26
Playing Games,Montezuma's Revenge,Atari 2600 Montezuma's Revenge,Average Return (NoOp),1,1668
Playing Games,Montezuma's Revenge,Atari 2600 Montezuma's Revenge,Average Return (NoOp),2,900
Playing Games,Atari Games,Atari 2600 Atlantis,Score,1,3084781.7
Playing Games,Atari Games,Atari 2600 Atlantis,Score,2,2193605.67
Playing Games,Atari Games,Atari 2600 Asterix,Score,1,999153.3
Playing Games,Atari Games,Atari 2600 Asterix,Score,2,998425.00
Playing Games,Atari Games,Atari 2600 Space Invaders,Score,1,74335.30
Playing Games,Atari Games,Atari 2600 Space Invaders,Score,2,54681
Playing Games,Atari Games,Atari 2600 Tennis,Score,1,23.9
Playing Games,Atari Games,Atari 2600 Tennis,Score,2,23.84
Playing Games,Atari Games,Atari 2600 Yars Revenge,Score,1,998532.37
Playing Games,Atari Games,Atari 2600 Yars Revenge,Score,2,995048.4
Playing Games,Atari Games,Atari 2600 Up and Down,Score,1,715545.61
Playing Games,Atari Games,Atari 2600 Up and Down,Score,2,653662
Playing Games,Atari Games,Atari 2600 Zaxxon,Score,1,725853.90
Playing Games,Atari Games,Atari 2600 Zaxxon,Score,2,249808.9
Playing Games,Atari Games,Atari 2600 Defender,Score,1,993010
Playing Games,Atari Games,Atari 2600 Defender,Score,2,839642.95
Playing Games,Atari Games,Atari 2600 Tutankham,Score,1,2354.91
Playing Games,Atari Games,Atari 2600 Tutankham,Score,2,491.48
Playing Games,Atari Games,Atari 2600 Star Gunner,Score,1,839573.53
Playing Games,Atari Games,Atari 2600 Star Gunner,Score,2,717344.0
Playing Games,Atari Games,Atari 2600 James Bond,Score,1,135784.96
Playing Games,Atari Games,Atari 2600 James Bond,Score,2,87291.7
Playing Games,Atari Games,Atari 2600 Freeway,Score,1,34.0
Playing Games,Atari Games,Atari 2600 Freeway,Score,2,34
Playing Games,Atari Games,Atari 2600 Ice Hockey,Score,1,79.3
Playing Games,Atari Games,Atari 2600 Ice Hockey,Score,2,67.04
Playing Games,Atari Games,Atari 2600 River Raid,Score,1,323417.18
Playing Games,Atari Games,Atari 2600 River Raid,Score,2,171673.78
Playing Games,Atari Games,Atari 2600 Kung-Fu Master,Score,1,233413.3
Playing Games,Atari Games,Atari 2600 Kung-Fu Master,Score,2,206845.82
Playing Games,Atari Games,Atari 2600 Seaquest,Score,1,999997.63
Playing Games,Atari Games,Atari 2600 Seaquest,Score,2,999996.7
Playing Games,Atari Games,Atari 2600 Chopper Command,Score,1,999900
Playing Games,Atari Games,Atari 2600 Chopper Command,Score,2,991039.70
Playing Games,Atari Games,Atari 2600 Krull,Score,1,269358.27
Playing Games,Atari Games,Atari 2600 Krull,Score,2,251997.31
Playing Games,Atari Games,Atari 2600 Phoenix,Score,1,955137.84
Playing Games,Atari Games,Atari 2600 Phoenix,Score,2,908264.15
Playing Games,Atari Games,Atari 2600 Alien,Score,1,741812.63
Playing Games,Atari Games,Atari 2600 Alien,Score,2,297638.17
Playing Games,Atari Games,Atari 2600 Name This Game,Score,1,157177.85
Playing Games,Atari Games,Atari 2600 Name This Game,Score,2,101197.71
Playing Games,Atari Games,Atari 2600 Berzerk,Score,1,197376
Playing Games,Atari Games,Atari 2600 Berzerk,Score,2,85932.60
Playing Games,Atari Games,Atari 2600 Double Dunk,Score,1,24
Playing Games,Atari Games,Atari 2600 Double Dunk,Score,2,23.94
Playing Games,Atari Games,Atari 2600 Video Pinball,Score,1,999383.2
Playing Games,Atari Games,Atari 2600 Video Pinball,Score,2,992340.74
Playing Games,Atari Games,Atari 2600 Wizard of Wor,Score,1,197126.00
Playing Games,Atari Games,Atari 2600 Wizard of Wor,Score,2,157306.41
Playing Games,Atari Games,Atari 2600 Demon Attack,Score,1,230324
Playing Games,Atari Games,Atari 2600 Demon Attack,Score,2,143964.26
Playing Games,Atari Games,Atari 2600 Pitfall!,Score,1,107363
Playing Games,Atari Games,Atari 2600 Pitfall!,Score,2,18756.01
Playing Games,Atari Games,Atari 2600 Robotank,Score,1,131.13
Playing Games,Atari Games,Atari 2600 Robotank,Score,2,127.32
Playing Games,Atari Games,Atari 2600 Breakout,Score,1,864.00
Playing Games,Atari Games,Atari 2600 Breakout,Score,2,855
Playing Games,Atari Games,Atari 2600 Assault,Score,1,143972.03
Playing Games,Atari Games,Atari 2600 Assault,Score,2,108197.0
Playing Games,Atari Games,Atari 2600 Pong,Score,1,106.1
Playing Games,Atari Games,Atari 2600 Pong,Score,2,21.0
Playing Games,Atari Games,Atari 2600 Road Runner,Score,1,613411.80
Playing Games,Atari Games,Atari 2600 Road Runner,Score,2,599246.7
Playing Games,Atari Games,Atari 2600 Elevator Action,Score,1,29100
Playing Games,Atari Games,Atari 2600 Elevator Action,Score,2,27088.89
Playing Games,Atari Games,Atari 2600 Carnival,Score,1,5132.0
Playing Games,Atari Games,Atari 2600 Battle Zone,Score,1,934134.88
Playing Games,Atari Games,Atari 2600 Battle Zone,Score,2,848623.00
Playing Games,Atari Games,Atari 2600 Pooyan,Score,1,17763.4
Playing Games,Atari Games,Atari 2600 Pooyan,Score,2,4801.27
Playing Games,Atari Games,Atari 2600 Boxing,Score,1,100.00
Playing Games,Atari Games,Atari 2600 Boxing,Score,2,100
Playing Games,Atari Games,Atari 2600 HERO,Score,1,114736.26
Playing Games,Atari Games,Atari 2600 HERO,Score,2,49244.11
Playing Games,Atari Games,Atari 2600 Skiing,Score,1,0
Playing Games,Atari Games,Atari 2600 Skiing,Score,2,0
Playing Games,Atari Games,Atari-57,Medium Human-Normalized Score,1,2041.1
Playing Games,Atari Games,Atari-57,Medium Human-Normalized Score,2,1920.6
Playing Games,Atari Games,Atari 2600 Beam Rider,Score,1,454993.53
Playing Games,Atari Games,Atari 2600 Beam Rider,Score,2,333077.44
Playing Games,Atari Games,Atari 2600 Enduro,Score,1,3454.0
Playing Games,Atari Games,Atari 2600 Enduro,Score,2,2382.44
Playing Games,Atari Games,Atari 2600 Gopher,Score,1,130345.58
Playing Games,Atari Games,Atari 2600 Gopher,Score,2,124776.3
Playing Games,Atari Games,Atari 2600 Gravitar,Score,1,19213.96
Playing Games,Atari Games,Atari 2600 Gravitar,Score,2,15680.7
Playing Games,Atari Games,Atari 2600 Amidar,Score,1,29660.08
Playing Games,Atari Games,Atari 2600 Amidar,Score,2,29321.4
Playing Games,Atari Games,Atari 2600 Asteroids,Score,1,678558.64
Playing Games,Atari Games,Atari 2600 Asteroids,Score,2,476412
Playing Games,Atari Games,Atari 2600 Solaris,Score,1,44199.93
Playing Games,Atari Games,Atari 2600 Solaris,Score,2,19671
Playing Games,Atari Games,Atari 2600 Ms. Pacman,Score,1,243401.10
Playing Games,Atari Games,Atari 2600 Ms. Pacman,Score,2,70659.76
Playing Games,Atari Games,Atari 2600 Crazy Climber,Score,1,565909.85
Playing Games,Atari Games,Atari 2600 Crazy Climber,Score,2,458315.40
Playing Games,Atari Games,Atari 2600 Frostbite,Score,1,631378.53
Playing Games,Atari Games,Atari 2600 Frostbite,Score,2,541280.88
Playing Games,Atari Games,Atari 2600 Centipede,Score,1,1422628
Playing Games,Atari Games,Atari 2600 Centipede,Score,2,1159049.27
Playing Games,Atari Games,Atari 2600 Bank Heist,Score,1,27219.8
Playing Games,Atari Games,Atari 2600 Bank Heist,Score,2,24235.9
Playing Games,Atari Games,Atari 2600 Q*Bert,Score,1,580328.14
Playing Games,Atari Games,Atari 2600 Q*Bert,Score,2,572510
Playing Games,Atari Games,Atari 2600 Kangaroo,Score,1,24034.16
Playing Games,Atari Games,Atari 2600 Kangaroo,Score,2,16763.60
Playing Games,Atari Games,Atari 2600 Bowling,Score,1,260.13
Playing Games,Atari Games,Atari 2600 Bowling,Score,2,260
Playing Games,Atari Games,Atari 2600 Montezuma's Revenge,Score,1,43791
Playing Games,Atari Games,Atari 2600 Montezuma's Revenge,Score,2,43763
Playing Games,Atari Games,Atari 2600 Venture,Score,1,2623.71
Playing Games,Atari Games,Atari 2600 Venture,Score,2,2281
Playing Games,Atari Games,Atari 2600 Private Eye,Score,1,95756
Playing Games,Atari Games,Atari 2600 Private Eye,Score,2,79716.46
Playing Games,Atari Games,Atari 2600 Fishing Derby,Score,1,91.16
Playing Games,Atari Games,Atari 2600 Fishing Derby,Score,2,86.97
Playing Games,Atari Games,Atari 2600 Time Pilot,Score,1,476763.90
Playing Games,Atari Games,Atari 2600 Time Pilot,Score,2,445377.3
Playing Games,Atari Games,Atari 2600 Journey Escape,Score,1,7683.3
Playing Games,Atari Games,Atari 2600 Surround,Score,1,10
Playing Games,Atari Games,Atari 2600 Surround,Score,2,9.99
Playing Games,Starcraft II,CollectMineralShards,Max Score,1,137
Playing Games,Starcraft II,MoveToBeacon,Max Score,1,35
Playing Games,SNES Games,Mortal Kombat,Score,1,169300
Playing Games,SNES Games,Mortal Kombat,Score,2,83733
Playing Games,SNES Games,Gradius III,Score,1,16929
Playing Games,SNES Games,Gradius III,Score,2,12343
Playing Games,SNES Games,Super Mario,Score,1,20030
Playing Games,SNES Games,Super Mario,Score,2,16946
Playing Games,SNES Games,Wolfenstein,Score,1,100
Playing Games,SNES Games,Wolfenstein,Score,2,83
Playing Games,SNES Games,F-Zero,Score,1,5161
Playing Games,SNES Games,F-Zero,Score,2,3636
Methodology,Graph Embedding,Barabasi-Albert,Entropy Difference,1,0.0001261
Methodology,Graph Representation Learning,COMA,Error (mm),1,0.474
Computer Vision,Unconstrained Lip-synchronization,LRW,FID,1,2.475
Computer Vision,Unconstrained Lip-synchronization,LRW,LSE-C,1,7.263
Computer Vision,Unconstrained Lip-synchronization,LRW,LSE-D,1,6.774
Computer Vision,Unconstrained Lip-synchronization,LRW,FID,2,3.189
Computer Vision,Unconstrained Lip-synchronization,LRW,LSE-C,2,7.49
Computer Vision,Unconstrained Lip-synchronization,LRW,LSE-D,2,6.512
Computer Vision,Unconstrained Lip-synchronization,LRS2,FID,1,4.446
Computer Vision,Unconstrained Lip-synchronization,LRS2,LSE-D,1,6.469
Computer Vision,Unconstrained Lip-synchronization,LRS2,FID,2,4.887
Computer Vision,Unconstrained Lip-synchronization,LRS2,LSE-C,2,7.789
Computer Vision,Unconstrained Lip-synchronization,LRS2,LSE-D,2,6.386
Computer Vision,Unconstrained Lip-synchronization,LRS3,FID,1,4.35
Computer Vision,Unconstrained Lip-synchronization,LRS3,LSE-C,1,7.574
Computer Vision,Unconstrained Lip-synchronization,LRS3,LSE-D,1,6.986
Computer Vision,Unconstrained Lip-synchronization,LRS3,FID,2,4.844
Computer Vision,Unconstrained Lip-synchronization,LRS3,LSE-C,2,7.887
Computer Vision,Unconstrained Lip-synchronization,LRS3,LSE-D,2,6.652
Miscellaneous,Session-Based Recommendations,Diginetica,Hit@20,1,56.25
Miscellaneous,Session-Based Recommendations,Diginetica,MRR@20,1,19.86
Miscellaneous,Session-Based Recommendations,Diginetica,Hit@20,2,56.58
Miscellaneous,Session-Based Recommendations,Diginetica,MRR@20,2,19.48
Miscellaneous,Session-Based Recommendations,Last.FM,HR@20,1,28.82
Miscellaneous,Session-Based Recommendations,Last.FM,MRR@20,1,11.33
Miscellaneous,Session-Based Recommendations,Last.FM,HR@20,2,24.76
Miscellaneous,Session-Based Recommendations,Last.FM,MRR@20,2,9.02
Miscellaneous,Session-Based Recommendations,yoochoose1,MRR@20,1,31.16
Miscellaneous,Session-Based Recommendations,yoochoose1,Precision@20,1,74.3
Miscellaneous,Session-Based Recommendations,yoochoose1,MRR@20,2,31.04
Miscellaneous,Session-Based Recommendations,yoochoose1,Precision@20,2,73.0
Miscellaneous,Session-Based Recommendations,yoochoose1/64,HR@20,1,70.74
Miscellaneous,Session-Based Recommendations,yoochoose1/64,MRR@20,1,32.87
Miscellaneous,Session-Based Recommendations,yoochoose1/64,HR@20,2,72.08
Miscellaneous,Session-Based Recommendations,yoochoose1/64,MRR@20,2,31.78
Miscellaneous,Session-Based Recommendations,yoochoose1/4,HR@20,1,72.90
Miscellaneous,Session-Based Recommendations,yoochoose1/4,MRR@20,1,32.04
Miscellaneous,Session-Based Recommendations,yoochoose1/4,HR@20,2,71.36
Miscellaneous,Session-Based Recommendations,yoochoose1/4,MRR@20,2,31.89
Miscellaneous,Session-Based Recommendations,Retailrocket,Hit@20,1,0.5073
Miscellaneous,Session-Based Recommendations,Retailrocket,MRR@20,1,0.3664
Miscellaneous,Session-Based Recommendations,Retailrocket,Hit@20,2,0.4704
Miscellaneous,Session-Based Recommendations,Retailrocket,MRR@20,2,0.3524
Miscellaneous,Session-Based Recommendations,Gowalla,HR@20,1,55.33
Miscellaneous,Session-Based Recommendations,Gowalla,MRR@20,1,26.67
Miscellaneous,Session-Based Recommendations,Gowalla,HR@20,2,50.32
Miscellaneous,Session-Based Recommendations,Gowalla,MRR@20,2,24.25
"Computer Vision', 'Graphs",3D Hand Pose Estimation,FreiHAND,PA-MPJPE,1,6.8
"Computer Vision', 'Graphs",3D Hand Pose Estimation,FreiHAND,PA-MPVPE,1,6.7
"Computer Vision', 'Graphs",3D Hand Pose Estimation,FreiHAND,PA-MPJPE,2,7.4
"Computer Vision', 'Graphs",3D Hand Pose Estimation,FreiHAND,PA-MPVPE,2,7.6
Computer Vision,Incomplete multi-view clustering,n-MNIST,NMI,1,75.23
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,1,86.9
Computer Vision,Skeleton Based Action Recognition,SYSU 3D,Accuracy,2,86.7
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,1,99.50
Computer Vision,Skeleton Based Action Recognition,UT-Kinect,Accuracy,2,98.5
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,1,93.99
Computer Vision,Skeleton Based Action Recognition,N-UCLA,Accuracy,2,93.5
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,1,99.02
Computer Vision,Skeleton Based Action Recognition,SBU,Accuracy,2,98.60
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,1,58.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,1,78.1
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,1,85.9
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,1,89.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,1,92.4
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.1,2,45.2
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.2,2,69.6
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.3,2,80.8
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.4,2,87.5
Computer Vision,Skeleton Based Action Recognition,JHMDB Pose Tracking,PCK@0.5,2,91.4
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,89.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),1,88.3
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,89.2
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,88.2
Computer Vision,Skeleton Based Action Recognition,HDM05,Accuracy,1,89.80
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,1,96.0
Computer Vision,Skeleton Based Action Recognition,Gaming 3D (G3D),Accuracy,2,92.91
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,1,81.4
Computer Vision,Skeleton Based Action Recognition,UWA3D,Accuracy,2,73.8
Computer Vision,Skeleton Based Action Recognition,MSRC-12,Accuracy,1,99.08
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,1,47.7
Computer Vision,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,Accuracy,2,38.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,1,60.6
Computer Vision,Skeleton Based Action Recognition,J-HMBD Early Action,10%,2,58.1
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),1,57
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),1,75
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),1,76
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),1,29
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),1,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV I),2,53
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (AV II),2,43
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CS),2,71
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV I),2,25
Computer Vision,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,Accuracy (CV II),2,56
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,1,99.1
Computer Vision,Skeleton Based Action Recognition,Florence 3D,Accuracy,2,98.4
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),1,89.64
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),1,91.78
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),1,89.56
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers + Face joints),2,91.12
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body + Fingers joints),2,91.76
Computer Vision,Skeleton Based Action Recognition,NTU60-X,Accuracy (Body joints),2,91.26
Computer Vision,Skeleton Based Action Recognition,TCG-dataset,Acc,1,87.24
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,1,91.9
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Accuracy,1,94.6
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,Speed  (FPS),1,2200
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,93.57
Computer Vision,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,28 gestures accuracy,2,91.43
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),1,94.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),1,97.1
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CS),2,91.0
Computer Vision,Skeleton Based Action Recognition,NTU RGB+D,Accuracy (CV),2,96.5
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Accuracy,1,78.0
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,1,77.2
Computer Vision,Skeleton Based Action Recognition,JHMDB (2D poses only),Average accuracy of 3 splits,2,67.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),1,92.9
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),1,94.4
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CS),2,92.6
Computer Vision,Skeleton Based Action Recognition,PKU-MMD,mAP@0.50 (CV),2,94.2
Computer Vision,Skeleton Based Action Recognition,Skeletics-152,Accuracy (Cross-Subject),1,57.01
Computer Vision,Skeleton Based Action Recognition,Skeleton-Mimetics,Accuracy (%),1,57.37
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,1,88.51
Computer Vision,Skeleton Based Action Recognition,MSR Action3D,Accuracy,2,86.1
Computer Vision,Skeleton Based Action Recognition,MSR ActionPairs,Accuracy,1,98.02
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,1,91.1
Computer Vision,Skeleton Based Action Recognition,CAD-120,Accuracy,2,89.3
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:1 Accuracy,1,95.93
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,1:3 Accuracy,1,92.9
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,3:1 Accuracy,1,96.76
Computer Vision,Skeleton Based Action Recognition,First-Person Hand Action Benchmark,Cross-person Accuracy,1,88.70
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,1,37.98
Computer Vision,Skeleton Based Action Recognition,UAV-Human,Average Accuracy,2,36.97
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),1,90.4
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (pose),1,67.9
Computer Vision,Skeleton Based Action Recognition,J-HMDB,Accuracy (RGB+pose),2,86.1
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,1,97.5
Computer Vision,Skeleton Based Action Recognition,UPenn Action,Accuracy,2,93.4
Natural Language Processing,Reader-Aware Summarization,RASG,ROUGE-1,1,30.33
Computer Vision,Action Recognition,ActionNet-VE,F-measure (%),1,90.27
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Action@1,1,47.7
Computer Vision,Action Recognition,EPIC-KITCHENS-100,GFLOPs,1,117x1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Noun@1,1,57.3
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Verb@1,1,72.2
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Action@1,2,44.5
Computer Vision,Action Recognition,EPIC-KITCHENS-100,GFLOPs,2,74.9x1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Noun@1,2,55.1
Computer Vision,Action Recognition,EPIC-KITCHENS-100,Verb@1,2,69.1
Computer Vision,Action Recognition,AVA v2.2,mAP,1,31.0
Computer Vision,Action Recognition,AVA v2.2,mAP,2,28.7
Computer Vision,Action Recognition,EPIC-KITCHENS-55,Top-1 Accuracy,1,34.2
Computer Vision,Action Recognition,Something-Something V2,GFLOPs,1,320.6
Computer Vision,Action Recognition,Something-Something V2,Parameters,1,89M
Computer Vision,Action Recognition,Something-Something V2,Top-1 Accuracy,1,69.6
Computer Vision,Action Recognition,Something-Something V2,Top-5 Accuracy,1,92.7
Computer Vision,Action Recognition,Something-Something V2,Top-1 Accuracy,2,69.02
Computer Vision,Action Recognition,Something-Something V2,Top-5 Accuracy,2,92.70
Computer Vision,Action Recognition,HMDB-51,Average accuracy of 3 splits,1,84.36
Computer Vision,Action Recognition,HMDB-51,Average accuracy of 3 splits,2,83.8
Computer Vision,Action Recognition,UCF 101,Average accuracy of 3 splits,1,85.10
Computer Vision,Action Recognition,SSBD,Accuracy,1,95.7
Computer Vision,Action Recognition,IRD,Accuracy,1,80.11
Computer Vision,Action Recognition,IRD,Accuracy,2,74.03
Computer Vision,Action Recognition,UCF101,3-fold Accuracy,1,98.64
Computer Vision,Action Recognition,UCF101,3-fold Accuracy,2,98.6
Computer Vision,Action Recognition,Volleyball,Accuracy,1,91.3
Computer Vision,Action Recognition,Volleyball,Accuracy,2,82.6
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CS),1,97.0
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CS),2,95.66
Computer Vision,Action Recognition,NTU RGB+D,Accuracy (CV),2,98.79
Computer Vision,Action Recognition,THUMOS’14,mAP@0.3,1,56.0
Computer Vision,Action Recognition,THUMOS’14,mAP@0.4,1,47.4
Computer Vision,Action Recognition,THUMOS’14,mAP@0.5,1,38.8
Computer Vision,Action Recognition,THUMOS’14,mAP@0.3,2,53.9
Computer Vision,Action Recognition,THUMOS’14,mAP@0.4,2,46.8
Computer Vision,Action Recognition,THUMOS’14,mAP@0.5,2,37.4
Computer Vision,Action Recognition,ActivityNet,mAP,1,84.4
Computer Vision,Action Recognition,ActivityNet,mAP,2,53.8
Computer Vision,Action Recognition,Jester,Val,1,97.4
Computer Vision,Action Recognition,Jester,Val,2,96.70
Computer Vision,Action Recognition,Autism,Accuracy,1,75.1
Computer Vision,Action Recognition,MTL-AQA,Armstand Accuracy,1,99.72
Computer Vision,Action Recognition,MTL-AQA,No. of Somersaults Accuracy,1,96.88
Computer Vision,Action Recognition,MTL-AQA,No. of Twists Accuracy,1,93.20
Computer Vision,Action Recognition,MTL-AQA,Position Accuracy,1,96.32
Computer Vision,Action Recognition,MTL-AQA,Rotation Type Accuracy,1,97.45
Computer Vision,Action Recognition,EgoGesture,Top-1 Accuracy,1,94.3
Computer Vision,Action Recognition,EgoGesture,Top-5 Accuracy,1,99.2
Computer Vision,Action Recognition,Sports-1M,Video hit@1 ,1,75.5
Computer Vision,Action Recognition,Sports-1M,Video hit@5,1,92.8
Computer Vision,Action Recognition,Sports-1M,Video hit@1 ,2,74.9
Computer Vision,Action Recognition,Sports-1M,Video hit@5,2,92.6
Computer Vision,Action Recognition,Something-Something V1,Top 1 Accuracy,1,57.0
Computer Vision,Action Recognition,Something-Something V1,Top 5 Accuracy,1,83.7
Computer Vision,Action Recognition,Something-Something V1,Top 1 Accuracy,2,56.8
Computer Vision,Action Recognition,Something-Something V1,Top 5 Accuracy,2,84.1
Computer Vision,Action Recognition,UTD-MHAD,Accuracy,1,92.5
Computer Vision,Action Recognition,HACS,Top 1 Accuracy,1,84.33
Computer Vision,Action Recognition,HACS,Top 5 Accuracy,1,96.85
Computer Vision,Action Recognition,HACS,Top 1 Accuracy,2,83.77
Computer Vision,Action Recognition,HACS,Top 5 Accuracy,2,96.56
Computer Vision,Action Recognition,VIRAT Ground 2.0,Average Accuracy,1,66.45
Computer Vision,Action Recognition,MECCANO,Top-1 Accuracy,1,42.85
Computer Vision,Action Recognition,Diving-48,Accuracy,1,85.5
Computer Vision,Action Recognition,Diving-48,Accuracy,2,81
Computer Vision,Action Recognition,AVA v2.1,mAP (Val),1,28.3
Computer Vision,Action Recognition,AVA v2.1,mAP (Val),2,27.7
Computer Vision,Action Recognition,Win-Fail Action Understanding,2-Class Accuracy,1,75.74
Computer Vision,Action Recognition,miniSports,Accuracy,1,74.9
Computer Vision,Action Recognition,miniSports,Accuracy,2,69.9
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),1,95.3
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Setup),2,90.7
Computer Vision,Action Recognition,NTU RGB+D 120,Accuracy (Cross-Subject),2,92.5
Computer Vision,Action Recognition,HAA500,Top-1 (%),1,64.4
Computer Vision,Action Recognition,HAA500,Top-1 (%),2,50.53
Computer Vision,Action Recognition,ICVL-4,Accuracy,1,91.86
Computer Vision,Action Recognition,ICVL-4,Accuracy,2,80.23
Computer Vision,Talking Face Generation,LRW,LMD,1,0.60
Computer Vision,Talking Face Generation,LRW,SSIM,1,0.96
Computer Vision,Talking Head Generation,100 sleep nights of 8 caregivers,10%,1,12
Computer Vision,Talking Head Generation,VoxCeleb2 - 8-shot learning,FID,1,24.9
Computer Vision,Talking Head Generation,VoxCeleb2 - 8-shot learning,FID,2,42.2
Computer Vision,Talking Head Generation,VoxCeleb1 - 1-shot learning,FID,1,43.0
Computer Vision,Talking Head Generation,VoxCeleb1 - 1-shot learning,FID,2,45.8
Computer Vision,Talking Head Generation,VoxCeleb1 - 32-shot learning,FID,1,29.5
Computer Vision,Talking Head Generation,VoxCeleb1 - 32-shot learning,FID,2,56.5
Computer Vision,Talking Head Generation,VoxCeleb1 - 8-shot learning,FID,1,38.0
Computer Vision,Talking Head Generation,VoxCeleb1 - 8-shot learning,FID,2,51.5
Computer Vision,Talking Head Generation,VoxCeleb2 - 32-shot learning,FID,1,30.6
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,CSIM,1,0.653
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,LPIPS,1,0.358
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,Normalized Pose Error,1,43.3
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,SSIM,1,0.508
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,inference time (ms),1,4
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,CSIM,2,0.638
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,LPIPS,2,0.311
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,Normalized Pose Error,2,47.8
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,SSIM,2,0.553
Computer Vision,Talking Head Generation,VoxCeleb2 - 1-shot learning,inference time (ms),2,13
Computer Vision,3D Object Detection,SUN-RGBD,mAP@0.25,1,63.4
Computer Vision,3D Object Detection,SUN-RGBD,mAP@0.25,2,63.0
Computer Vision,3D Object Detection,SUN-RGBD,mAP@0.5,2,45.2
Computer Vision,3D Object Detection,KITTI Pedestrians Moderate val,AP,1,58.33
Computer Vision,3D Object Detection,KITTI Pedestrian Moderate val,AP,1,64.71
Computer Vision,3D Object Detection,KITTI Pedestrian Moderate val,AP,2,61.32
Computer Vision,3D Object Detection,KITTI Pedestrians Easy,AP,1,56.92
Computer Vision,3D Object Detection,KITTI Pedestrians Easy,AP,2,55.21
Computer Vision,3D Object Detection,KITTI Cars Easy val,AP,1,95.45
Computer Vision,3D Object Detection,KITTI Cars Easy val,AP,2,92.57
Computer Vision,3D Object Detection,NYU Depth v2,MAP,1,41.3
Computer Vision,3D Object Detection,KITTI Cyclist Easy val,AP,1,81.4
Computer Vision,3D Object Detection,KITTI Cyclist Easy val,AP,2,77.15
Computer Vision,3D Object Detection,KITTI Cyclists Moderate,AP,1,66.13
Computer Vision,3D Object Detection,KITTI Cyclists Moderate,AP,2,64.68
Computer Vision,3D Object Detection,KITTI Cyclist Moderate val,AP,1,59.97
Computer Vision,3D Object Detection,KITTI Cyclist Moderate val,AP,2,56.49
Computer Vision,3D Object Detection,ScanNetV2,mAP@0.25,1,69.1
Computer Vision,3D Object Detection,ScanNetV2,mAP@0.5,1,52.8
Computer Vision,3D Object Detection,ScanNetV2,mAP@0.25,2,66.1
Computer Vision,3D Object Detection,ScanNetV2,mAP@0.5,2,50.9
Computer Vision,3D Object Detection,KITTI Cars Moderate val,AP,1,86.83
Computer Vision,3D Object Detection,KITTI Cars Moderate val,AP,2,84.83
Computer Vision,3D Object Detection,KITTI Cyclists Moderate val,AP,1,73.46
Computer Vision,3D Object Detection,KITTI Cyclists Hard,AP,1,57.65
Computer Vision,3D Object Detection,KITTI Cyclists Hard,AP,2,57.64
Computer Vision,3D Object Detection,KITTI Cyclists Easy,AP,1,79.58
Computer Vision,3D Object Detection,KITTI Cyclists Easy,AP,2,79.22
Computer Vision,3D Object Detection,waymo pedestrian,APH/L2,1,71.52
Computer Vision,3D Object Detection,waymo pedestrian,APH/L2,2,70.16
Computer Vision,3D Object Detection,nuScenes-F,AP,1,43
Computer Vision,3D Object Detection,nuScenes-F,AP50,1,64.9
Computer Vision,3D Object Detection,nuScenes-F,AP75,1,48.5
Computer Vision,3D Object Detection,nuScenes-F,AR,1,48.6
Computer Vision,3D Object Detection,nuScenes-F,ARI,1,58.2
Computer Vision,3D Object Detection,nuScenes-F,ARm,1,41.2
Computer Vision,3D Object Detection,nuScenes-F,ARs,1,4
Computer Vision,3D Object Detection,nuScenes-FB,AP,1,35.5
Computer Vision,3D Object Detection,nuScenes-FB,AP50,1,59
Computer Vision,3D Object Detection,nuScenes-FB,AP75,1,37
Computer Vision,3D Object Detection,nuScenes-FB,AR,1,42.1
Computer Vision,3D Object Detection,nuScenes-FB,ARI,1,51.4
Computer Vision,3D Object Detection,nuScenes-FB,ARm,1,39.1
Computer Vision,3D Object Detection,nuScenes-FB,ARs,1,21.1
Computer Vision,3D Object Detection,KITTI Cars Moderate,AP,1,82.54
Computer Vision,3D Object Detection,KITTI Cars Moderate,AP,2,81.88
Computer Vision,3D Object Detection,SUN-RGBD val,mAP@0.25,1,63.0
Computer Vision,3D Object Detection,SUN-RGBD val,mAP@0.5,1,45.2
Computer Vision,3D Object Detection,SUN-RGBD val,mAP@0.25,2,61.6
Computer Vision,3D Object Detection,KITTI Cars Easy,AP,1,91.67
Computer Vision,3D Object Detection,KITTI Cars Easy,AP,2,91.49
Computer Vision,3D Object Detection,KITTI Pedestrians Hard,AP,1,44.56
Computer Vision,3D Object Detection,KITTI Pedestrians Hard,AP,2,42.39
Computer Vision,3D Object Detection,waymo all_ns,APH/L2,1,71.93
Computer Vision,3D Object Detection,waymo all_ns,APH/L2,2,71.52
Computer Vision,3D Object Detection,KITTI Cars Hard val,AP,1,82.69
Computer Vision,3D Object Detection,KITTI Cars Hard val,AP,2,82.23
Computer Vision,3D Object Detection,KITTI Pedestrian Easy val,AP,1,73.2
Computer Vision,3D Object Detection,KITTI Pedestrian Easy val,AP,2,70.00
Computer Vision,3D Object Detection,KITTI Cyclist Hard val,AP,1,56.24
Computer Vision,3D Object Detection,KITTI Cyclist Hard val,AP,2,53.37
Computer Vision,3D Object Detection,KITTI Cars Hard,AP,1,77.15
Computer Vision,3D Object Detection,KITTI Cars Hard,AP,2,77.15
Computer Vision,3D Object Detection,KITTI Pedestrian Hard val,AP,1,56.78
Computer Vision,3D Object Detection,KITTI Pedestrian Hard val,AP,2,53.59
Computer Vision,3D Object Detection,KITTI Pedestrians Moderate,AP,1,47.71
Computer Vision,3D Object Detection,KITTI Pedestrians Moderate,AP,2,44.81
Computer Vision,3D Object Detection,waymo cyclist,APH/L2,1,71.28
Computer Vision,3D Object Detection,waymo cyclist,APH/L2,2,71.16
Computer Vision,3D Object Detection,waymo vehicle,APH/L2,1,73.23
Computer Vision,3D Object Detection,Argoverse,AVG-CDS,1,0.41
Computer Vision,3D Object Detection,Argoverse,AVG-CDS,2,0.35
Computer Vision,3D Object Detection,nuScenes,NDS,1,0.75
Computer Vision,3D Object Detection,nuScenes,mAAE,1,0.13
Computer Vision,3D Object Detection,nuScenes,mAOE,1,0.32
Computer Vision,3D Object Detection,nuScenes,mAP,1,0.72
Computer Vision,3D Object Detection,nuScenes,mASE,1,0.23
Computer Vision,3D Object Detection,nuScenes,mATE,1,0.24
Computer Vision,3D Object Detection,nuScenes,mAVE,1,0.21
Computer Vision,3D Object Detection,nuScenes,NDS,2,0.72
Computer Vision,3D Object Detection,nuScenes,mAAE,2,0.13
Computer Vision,3D Object Detection,nuScenes,mAOE,2,0.35
Computer Vision,3D Object Detection,nuScenes,mAP,2,0.68
Computer Vision,3D Object Detection,nuScenes,mASE,2,0.23
Computer Vision,3D Object Detection,nuScenes,mATE,2,0.25
Computer Vision,3D Object Detection,nuScenes,mAVE,2,0.26
Computer Vision,RGB Salient Object Detection,UCF,Balanced Error Rate,1,7.21
Computer Vision,RGB Salient Object Detection,UCF,Balanced Error Rate,2,7.69
Computer Vision,RGB Salient Object Detection,SOC,Average MAE,1,0.089
Computer Vision,RGB Salient Object Detection,SOC,S-Measure,1,0.849
Computer Vision,RGB Salient Object Detection,SOC,mean E-Measure,1,0.872
Computer Vision,RGB Salient Object Detection,SOC,Average MAE,2,0.091
Computer Vision,RGB Salient Object Detection,SOC,S-Measure,2,0.842
Computer Vision,RGB Salient Object Detection,SOC,mean E-Measure,2,0.868
Computer Vision,RGB Salient Object Detection,DUTS-TE,F-measure,1,0.912
Computer Vision,RGB Salient Object Detection,DUTS-TE,MAE,1,0.029
Computer Vision,RGB Salient Object Detection,DUTS-TE,F-measure,2,0.895
Computer Vision,RGB Salient Object Detection,DUTS-TE,MAE,2,0.033
Computer Vision,RGB Salient Object Detection,HKU-IS,MAE,1,0.026
Computer Vision,RGB Salient Object Detection,HKU-IS,S-Measure,1,0.921
Computer Vision,RGB Salient Object Detection,HKU-IS,MAE,2,0.027
Computer Vision,RGB Salient Object Detection,HKU-IS,S-Measure,2,0.917
Computer Vision,RGB Salient Object Detection,DUTS-test,F-measure,1,80.5
Computer Vision,RGB Salient Object Detection,DUTS-test,MAE,1,0.043
Computer Vision,RGB Salient Object Detection,DUTS-test,MAE,2,0.034
Computer Vision,RGB Salient Object Detection,DUTS-test,mean F-Measure,2,0.773
Computer Vision,RGB Salient Object Detection,SOD,F-measure,1,0.882
Computer Vision,RGB Salient Object Detection,SOD,MAE,1,0.102
Computer Vision,RGB Salient Object Detection,SOD,MAE,2,0.108
Computer Vision,RGB Salient Object Detection,ISTD,Balanced Error Rate,1,6.76
Computer Vision,RGB Salient Object Detection,ISTD,Balanced Error Rate,2,7.10
Computer Vision,RGB Salient Object Detection,ECSSD,MAE,1,0.035
Computer Vision,RGB Salient Object Detection,ECSSD,S-Measure,1,0.921
Computer Vision,RGB Salient Object Detection,ECSSD,F-measure,2,0.917
Computer Vision,RGB Salient Object Detection,ECSSD,MAE,2,0.037
Computer Vision,RGB Salient Object Detection,PASCAL-S,F-measure,1,0.88
Computer Vision,RGB Salient Object Detection,PASCAL-S,MAE,1,0.065
Computer Vision,RGB Salient Object Detection,PASCAL-S,F-measure,2,0.824
Computer Vision,RGB Salient Object Detection,PASCAL-S,MAE,2,0.072
Computer Vision,RGB Salient Object Detection,DUT-OMRON,MAE,1,0.050
Computer Vision,RGB Salient Object Detection,DUT-OMRON,S-Measure,1,0.843
Computer Vision,RGB Salient Object Detection,DUT-OMRON,MAE,2,0.051
Computer Vision,RGB Salient Object Detection,DUT-OMRON,S-Measure,2,0.839
Computer Vision,RGB Salient Object Detection,SBU,Balanced Error Rate,1,4.19
Computer Vision,RGB Salient Object Detection,SBU,Balanced Error Rate,2,5.59
Computer Vision,Real-Time Object Detection,PASCAL VOC 2007,FPS,1,46.0
Computer Vision,Real-Time Object Detection,PASCAL VOC 2007,MAP,1,63.4
Computer Vision,Real-Time Object Detection,PASCAL VOC 2007,FPS,2,24
Computer Vision,Real-Time Object Detection,PASCAL VOC 2007,MAP,2,79.1
Computer Vision,Real-Time Object Detection,COCO,FPS,1,30
Computer Vision,Real-Time Object Detection,COCO,MAP,1,55.4
Computer Vision,Real-Time Object Detection,COCO,FPS,2,16
Computer Vision,Real-Time Object Detection,COCO,MAP,2,55.4
Computer Vision,Real-Time Object Detection,COCO,inference time (ms),2,63
Computer Vision,Real-Time Object Detection,COCO minival,APbb75,1,45.2
Computer Vision,Real-Time Object Detection,COCO minival,MAP,2,37.6
Computer Vision,RGB-D Salient Object Detection,SIP,Average MAE,1,0.044
Computer Vision,RGB-D Salient Object Detection,SIP,S-Measure,1,89.6
Computer Vision,RGB-D Salient Object Detection,SIP,max E-Measure,1,93.3
Computer Vision,RGB-D Salient Object Detection,SIP,max F-Measure,1,90.1
Computer Vision,RGB-D Salient Object Detection,SIP,Average MAE,2,0.046
Computer Vision,RGB-D Salient Object Detection,SIP,S-Measure,2,89.2
Computer Vision,RGB-D Salient Object Detection,SIP,max E-Measure,2,94.9
Computer Vision,RGB-D Salient Object Detection,SIP,max F-Measure,2,90.0
Computer Vision,RGB-D Salient Object Detection,NJU2K,Average MAE,1,0.035
Computer Vision,RGB-D Salient Object Detection,NJU2K,S-Measure,1,92.1
Computer Vision,RGB-D Salient Object Detection,NJU2K,max E-Measure,1,94.9
Computer Vision,RGB-D Salient Object Detection,NJU2K,max F-Measure,1,92.0
Computer Vision,RGB-D Salient Object Detection,NJU2K,Average MAE,2,0.036
Computer Vision,RGB-D Salient Object Detection,NJU2K,S-Measure,2,92.1
Computer Vision,RGB-D Salient Object Detection,NJU2K,max E-Measure,2,95.4
Computer Vision,RGB-D Salient Object Detection,NJU2K,max F-Measure,2,92.4
Computer Vision,RGB-D Salient Object Detection,DES,Average MAE,1,0.018
Computer Vision,RGB-D Salient Object Detection,DES,S-Measure,1,94.3
Computer Vision,RGB-D Salient Object Detection,DES,max E-Measure,1,97.9
Computer Vision,RGB-D Salient Object Detection,DES,max F-Measure,1,94.0
Computer Vision,RGB-D Salient Object Detection,DES,Average MAE,2,0.016
Computer Vision,RGB-D Salient Object Detection,DES,S-Measure,2,94.0
Computer Vision,RGB-D Salient Object Detection,SSD,Average MAE,1,0.042
Computer Vision,RGB-D Salient Object Detection,SSD,S-Measure,1,88.5
Computer Vision,RGB-D Salient Object Detection,SSD,max F-Measure,1,88.1
Computer Vision,RGB-D Salient Object Detection,SSD,Average MAE,2,0.044
Computer Vision,RGB-D Salient Object Detection,SSD,S-Measure,2,88.2
Computer Vision,RGB-D Salient Object Detection,SSD,max E-Measure,2,91.9
Computer Vision,RGB-D Salient Object Detection,SSD,max F-Measure,2,85.9
Computer Vision,RGB-D Salient Object Detection,STERE,Average MAE,1,0.038
Computer Vision,RGB-D Salient Object Detection,STERE,S-Measure,1,91.5
Computer Vision,RGB-D Salient Object Detection,STERE,max E-Measure,1,94.9
Computer Vision,RGB-D Salient Object Detection,STERE,max F-Measure,1,91.1
Computer Vision,RGB-D Salient Object Detection,STERE,Average MAE,2,0.039
Computer Vision,RGB-D Salient Object Detection,STERE,S-Measure,2,91.1
Computer Vision,RGB-D Salient Object Detection,STERE,max E-Measure,2,94.9
Computer Vision,RGB-D Salient Object Detection,STERE,max F-Measure,2,90.7
Computer Vision,RGB-D Salient Object Detection,NJUD,S-Measure,1,0.922
Computer Vision,RGB-D Salient Object Detection,LFSD,Average MAE,1,0.065
Computer Vision,RGB-D Salient Object Detection,LFSD,S-Measure,1,86.8
Computer Vision,RGB-D Salient Object Detection,LFSD,Average MAE,2,0.07
Computer Vision,RGB-D Salient Object Detection,LFSD,S-Measure,2,86.7
Computer Vision,RGB-D Salient Object Detection,LFSD,max E-Measure,2,90.6
Computer Vision,RGB-D Salient Object Detection,LFSD,max F-Measure,2,87.4
Computer Vision,RGB-D Salient Object Detection,NLPR,Average MAE,1,0.023
Computer Vision,RGB-D Salient Object Detection,NLPR,S-Measure,1,93.4
Computer Vision,RGB-D Salient Object Detection,NLPR,max E-Measure,1,96.5
Computer Vision,RGB-D Salient Object Detection,NLPR,max F-Measure,1,92.3
Computer Vision,RGB-D Salient Object Detection,NLPR,Average MAE,2,0.023
Computer Vision,RGB-D Salient Object Detection,NLPR,S-Measure,2,93.0
Computer Vision,RGB-D Salient Object Detection,NLPR,max E-Measure,2,96.1
Computer Vision,RGB-D Salient Object Detection,NLPR,max F-Measure,2,91.8
Computer Vision,Video Object Detection,DAVIS 2017,J&F,1,71.4
Computer Vision,Video Object Detection,ImageNet VID,MAP ,1,85.5
Computer Vision,Video Object Detection,ImageNet VID,MAP ,2,85.4
Computer Vision,2D Object Detection,xView,mAP,1,0.1456
Computer Vision,2D Object Detection,DOTA,mAP,1,71.78
Computer Vision,Weakly Supervised Object Detection,Clipart1k,MAP,1,38.4
Computer Vision,Weakly Supervised Object Detection,Clipart1k,MAP,2,41.1
Computer Vision,Weakly Supervised Object Detection,Watercolor2k,MAP,1,55.5
Computer Vision,Weakly Supervised Object Detection,Watercolor2k,MAP,2,54.3
Computer Vision,Weakly Supervised Object Detection,Cityscapes-to-Foggy Cityscapes,mAP,1,40.5
Computer Vision,Weakly Supervised Object Detection,Cityscapes-to-Foggy Cityscapes,mAP,2,39.8
Computer Vision,Weakly Supervised Object Detection,PASCAL VOC 2007,MAP,1,58.1
Computer Vision,Weakly Supervised Object Detection,PASCAL VOC 2007,MAP,2,56.8
Computer Vision,Weakly Supervised Object Detection,PASCAL VOC 2012 test,MAP,1,53.6
Computer Vision,Weakly Supervised Object Detection,PASCAL VOC 2012 test,MAP,2,52.1
Computer Vision,Weakly Supervised Object Detection,PeopleArt,MAP,1,58.3
Computer Vision,Weakly Supervised Object Detection,PeopleArt,MAP,2,55.4
Computer Vision,Weakly Supervised Object Detection,COCO,MAP,1,56.6
Computer Vision,Weakly Supervised Object Detection,COCO,MAP,2,55.3
Computer Vision,Weakly Supervised Object Detection,Comic2k,MAP,1,27
Computer Vision,Weakly Supervised Object Detection,Comic2k,MAP,2,37.2
Computer Vision,Weakly Supervised Object Detection,ImageNet,MAP,1,19.6
Computer Vision,Weakly Supervised Object Detection,ImageNet,MAP,2,16.3
Computer Vision,Weakly Supervised Object Detection,COCO test-dev,AP50,1,24.8
Computer Vision,Weakly Supervised Object Detection,COCO test-dev,AP50,2,13.6
Computer Vision,Weakly Supervised Object Detection,IconArt,MAP,1,15.1
Computer Vision,Weakly Supervised Object Detection,IconArt,MAP,2,13.2
Computer Vision,Weakly Supervised Object Detection,HICO-DET,MAP,1,5.39
Computer Vision,Weakly Supervised Object Detection,HICO-DET,MAP,2,3.62
Computer Vision,Weakly Supervised Object Detection,Charades,MAP,1,10.03
Computer Vision,Weakly Supervised Object Detection,Charades,MAP,2,2.83
Computer Vision,Weakly Supervised Object Detection,MSCOCO,mAP,1,13.9
Computer Vision,Weakly Supervised Object Detection,MSCOCO,mAP@50,1,27.8
Computer Vision,Weakly Supervised Object Detection,CASPAPaintings,Mean mAP,1,16.2
Computer Vision,Few-Shot Object Detection,MS-COCO (10-shot),AP,1,17.8
Computer Vision,Few-Shot Object Detection,MS-COCO (10-shot),AP,2,16.7
Computer Vision,Few-Shot Object Detection,MS-COCO (30-shot),AP,1,22.9
Computer Vision,Few-Shot Object Detection,MS-COCO (30-shot),AP,2,21.3
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,AP,1,37.72
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,AP50,1,52.58
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,AP75,1,40.64
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,APc,1,38.23
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,APf,1,42.8
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,APr,1,25.18
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,AP,2,35.84
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,AP50,2,49.3
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,AP75,2,38.4
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,APc,2,34.49
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,APf,2,42.69
Computer Vision,Few-Shot Object Detection,LVIS v1.0 test-dev,APr,2,24.05
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,AP,1,27.26
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,AP50,1,41.58
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,AP75,1,28.99
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,APc,1,26.13
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,APf,1,31.95
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,APr,1,19.47
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,AP,2,25.8
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,AP50,2,39.76
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,AP75,2,27.53
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,APc,2,25.51
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,APf,2,31.39
Computer Vision,Few-Shot Object Detection,LVIS v1.0 val,APr,2,13.82
Computer Vision,Small Object Detection,Bee4Exp Honeybee Detection,Average F1,1,0.86
Computer Vision,Object Proposal Generation,"PASCAL VOC 2012, 60 proposals per image",Average Recall,1,0.814
Computer Vision,Object Proposal Generation,"PASCAL VOC 2012, 60 proposals per image",Average Recall,2,0.667
Computer Vision,Object Detection In Aerial Images,DOTA,mAP,1,68.16
Computer Vision,Dense Object Detection,SKU-110K,AP,1,0.587
Computer Vision,Dense Object Detection,SKU-110K,AP75,1,0.673
Computer Vision,Dense Object Detection,SKU-110K,AP,2,0.492
Computer Vision,Dense Object Detection,SKU-110K,AP75,2,0.556
Computer Vision,Head Detection,Rebar Head,F1,1,98.83
Computer Vision,Robust Object Detection,Cityscapes test,mPC [AP],1,17.2
Computer Vision,Robust Object Detection,Cityscapes test,rPC [%],1,47.4
Computer Vision,Robust Object Detection,Cityscapes test,mPC [AP],2,12.2
Computer Vision,Robust Object Detection,Cityscapes test,rPC [%],2,33.4
Computer Vision,Robust Object Detection,COCO,mPC [AP],1,20.4
Computer Vision,Robust Object Detection,COCO,rPC [%],1,58.9
Computer Vision,Robust Object Detection,COCO,mPC [AP],2,18.2
Computer Vision,Robust Object Detection,COCO,rPC [%],2,50.2
Computer Vision,Robust Object Detection,PASCAL VOC 2007,mPC [AP50],1,56.2
Computer Vision,Robust Object Detection,PASCAL VOC 2007,rPC [%],1,69.9
Computer Vision,Robust Object Detection,PASCAL VOC 2007,mPC [AP50],2,48.6
Computer Vision,Robust Object Detection,PASCAL VOC 2007,rPC [%],2,60.4
Computer Vision,Camouflaged Object Segmentation,CAMO,E-Measure,1,88.2
Computer Vision,Camouflaged Object Segmentation,CAMO,MAE,1,0.070
Computer Vision,Camouflaged Object Segmentation,CAMO,S-Measure,1,82.0
Computer Vision,Camouflaged Object Segmentation,CAMO,Weighted F-Measure,1,74.3
Computer Vision,Camouflaged Object Segmentation,CAMO,E-Measure,2,84.9
Computer Vision,Camouflaged Object Segmentation,CAMO,MAE,2,0.077
Computer Vision,Camouflaged Object Segmentation,CAMO,S-Measure,2,78.5
Computer Vision,Camouflaged Object Segmentation,CAMO,Weighted F-Measure,2,71.9
Computer Vision,Camouflaged Object Segmentation,COD,E-Measure,1,88.7
Computer Vision,Camouflaged Object Segmentation,COD,MAE,1,0.037
Computer Vision,Camouflaged Object Segmentation,COD,S-Measure,1,81.5
Computer Vision,Camouflaged Object Segmentation,COD,Weighted F-Measure,1,68.0
Computer Vision,Camouflaged Object Segmentation,COD,E-Measure,2,80.6
Computer Vision,Camouflaged Object Segmentation,COD,MAE,2,0.051
Computer Vision,Camouflaged Object Segmentation,COD,S-Measure,2,77.1
Computer Vision,Camouflaged Object Segmentation,COD,Weighted F-Measure,2,55.1
Computer Vision,One-Shot Object Detection,PASCAL VOC 2012 val,MAP,1,22.1
Computer Vision,One-Shot Object Detection,COCO,AP 0.5,1,22.0
Computer Vision,One-Shot Object Detection,COCO,AP 0.5,2,16.3
Computer Vision,Zero-Shot Object Detection,MS-COCO,Recall,1,43.56
Computer Vision,Zero-Shot Object Detection,MS-COCO,mAP,1,12.62
Computer Vision,Zero-Shot Object Detection,PASCAL VOC'07,mAP,1,64.9
Computer Vision,Zero-Shot Object Detection,ImageNet Detection,mAP,1,24.3
Computer Vision,Zero-Shot Object Detection,ImageNet Detection,mAP,2,16.4
Computer Vision,Medical Object Detection,Barrett’s Esophagus,Mean Accuracy,1,81
Computer Vision,Medical Object Detection,Barrett’s Esophagus,Mean Accuracy,2,74
Computer Vision,Surgical tool detection,Cholec80,mAP,1,92.9
Computer Vision,Surgical tool detection,Cholec80,mAP,2,89.1
Computer Vision,Semantic Part Detection,PASCAL Part 2010 - Animals,mAP@0.5,1,52.0
Computer Vision,Object Skeleton Detection,SK-LARGE,F-Measure,1,0.732
Computer Vision,Object Skeleton Detection,SK-LARGE,F-Measure,2,0.724
Computer Vision,Open World Object Detection,PASCAL VOC 2007,A-OSE,1,8234
Computer Vision,Open World Object Detection,PASCAL VOC 2007,MAP,1,56.34
Computer Vision,Open World Object Detection,PASCAL VOC 2007,WI,1,0.02193
Computer Vision,Open World Object Detection,"COCO 2017 (Sports, Food)",A-OSE,1,6634
Computer Vision,Open World Object Detection,"COCO 2017 (Sports, Food)",MAP,1,29.32
Computer Vision,Open World Object Detection,"COCO 2017 (Sports, Food)",WI,1,0.0081
Computer Vision,Open World Object Detection,"COCO 2017 (Electronic, Indoor, Kitchen, Furniture)",MAP,1,26.66
Computer Vision,Open World Object Detection,"COCO 2017 (Outdoor, Accessories, Appliance, Truck)",A-OSE,1,7772
Computer Vision,Open World Object Detection,"COCO 2017 (Outdoor, Accessories, Appliance, Truck)",MAP,1,38.98
Computer Vision,Open World Object Detection,"COCO 2017 (Outdoor, Accessories, Appliance, Truck)",WI,1,0.0154
"Adversarial', 'Natural Language Processing",Topic Models,NYT,MACC,1,90.91
"Adversarial', 'Natural Language Processing",Topic Models,NYT,Topic coherence@5,1,0.0166
"Adversarial', 'Natural Language Processing",Topic Models,arXiv,MACC,1,83.24
"Adversarial', 'Natural Language Processing",Topic Models,arXiv,Topic coherence@5,1,0.0074
"Adversarial', 'Natural Language Processing",Topic Models,arXiv,Topic Coherence@50,2,0.097
"Adversarial', 'Natural Language Processing",Topic Models,20 Newsgroups,Test perplexity,1,515
"Adversarial', 'Natural Language Processing",Topic Models,20 Newsgroups,Test perplexity,2,836
"Adversarial', 'Natural Language Processing",Document Classification,WOS-11967,Accuracy,1,86.07
"Adversarial', 'Natural Language Processing",Document Classification,HoC,F1,1,87.3
"Adversarial', 'Natural Language Processing",Document Classification,HoC,F1,2,86.08
"Adversarial', 'Natural Language Processing",Document Classification,Recipe,Accuracy,1,59.06
"Adversarial', 'Natural Language Processing",Document Classification,Recipe,Accuracy,2,56.80
"Adversarial', 'Natural Language Processing",Document Classification,Reuters En-De,Accuracy,1,86.5
"Adversarial', 'Natural Language Processing",Document Classification,IMDb-M,Accuracy,1,54.8
"Adversarial', 'Natural Language Processing",Document Classification,IMDb-M,Accuracy,2,52.8
"Adversarial', 'Natural Language Processing",Document Classification,Reuters De-En,Accuracy,1,75
"Adversarial', 'Natural Language Processing",Document Classification,Reuters-21578,Accuracy,1,97.44
"Adversarial', 'Natural Language Processing",Document Classification,Reuters-21578,Accuracy,2,97.17
"Adversarial', 'Natural Language Processing",Document Classification,Twitter,Accuracy,1,72.6
"Adversarial', 'Natural Language Processing",Document Classification,Twitter,Accuracy,2,71.05
"Adversarial', 'Natural Language Processing",Document Classification,Amazon,Accuracy,1,94.31
"Adversarial', 'Natural Language Processing",Document Classification,Amazon,Accuracy,2,93.42
"Adversarial', 'Natural Language Processing",Document Classification,WOS-5736,Accuracy,1,90.93
"Adversarial', 'Natural Language Processing",Document Classification,AAPD,F1,1,72.9
"Adversarial', 'Natural Language Processing",Document Classification,AAPD,F1,2,69.6
"Adversarial', 'Natural Language Processing",Document Classification,Classic,Accuracy,1,96.85
"Adversarial', 'Natural Language Processing",Document Classification,Classic,Accuracy,2,96.24
"Adversarial', 'Natural Language Processing",Document Classification,Cora,Accuracy,1,83.5
"Adversarial', 'Natural Language Processing",Document Classification,Cora,Accuracy,2,83.3
"Adversarial', 'Natural Language Processing",Document Classification,Yelp-14,Accuracy,1,69.4
"Adversarial', 'Natural Language Processing",Document Classification,WOS-46985,Accuracy,1,76.58
"Adversarial', 'Natural Language Processing",Document Classification,BBCSport,Accuracy,1,99.59
"Adversarial', 'Natural Language Processing",Document Classification,BBCSport,Accuracy,2,97.73
"Adversarial', 'Natural Language Processing",Document Classification,MPQA,Accuracy,1,89.81
"Adversarial', 'Natural Language Processing",Sentence Classification,ACL-ARC,F1,1,78.1
"Adversarial', 'Natural Language Processing",Sentence Classification,ACL-ARC,F1,2,70.98
"Adversarial', 'Natural Language Processing",Sentence Classification,ScienceCite,F1,1,84.99
"Adversarial', 'Natural Language Processing",Sentence Classification,ScienceCite,F1,2,84.43
"Adversarial', 'Natural Language Processing",Sentence Classification,CHIP-CTC,Macro F1,1,70.9
"Adversarial', 'Natural Language Processing",Sentence Classification,Paper Field,F1,1,65.71
"Adversarial', 'Natural Language Processing",Sentence Classification,Paper Field,F1,2,64.02
"Adversarial', 'Natural Language Processing",Sentence Classification,SciCite,F1,1,84.9
"Adversarial', 'Natural Language Processing",Sentence Classification,SciCite,F1,2,84.4
"Adversarial', 'Natural Language Processing",Sentence Classification,PubMed 20k RCT,F1,1,92.60
"Adversarial', 'Natural Language Processing",Sentence Classification,PubMed 20k RCT,F1,2,86.81
"Adversarial', 'Natural Language Processing",Emotion Classification,SemEval 2018 Task 1E-c,Accuracy,1,0.601
"Adversarial', 'Natural Language Processing",Emotion Classification,SemEval 2018 Task 1E-c,Macro-F1,1,0.578
"Adversarial', 'Natural Language Processing",Emotion Classification,SemEval 2018 Task 1E-c,Micro-F1,1,0.713
"Adversarial', 'Natural Language Processing",Emotion Classification,SemEval 2018 Task 1E-c,Accuracy,2,0.591
"Adversarial', 'Natural Language Processing",Emotion Classification,SemEval 2018 Task 1E-c,Macro-F1,2,0.549
"Adversarial', 'Natural Language Processing",Emotion Classification,SemEval 2018 Task 1E-c,Micro-F1,2,0.713
"Adversarial', 'Natural Language Processing",Emotion Classification,GoEmotions,Average F1,1,46
"Adversarial', 'Natural Language Processing",Emotion Classification,ROCStories,F1,1,65.88
"Adversarial', 'Natural Language Processing",Emotion Classification,ROCStories,F1,2,30.29
"Adversarial', 'Natural Language Processing",Emotion Classification,EWALK,Accuracy,1,82.4
"Adversarial', 'Natural Language Processing",Emotion Classification,EWALK,Accuracy,2,78.24
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,AAPD,P@1,1,84.48
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,AAPD,P@3,1,60.72
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,AAPD,P@5,1,41.19
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,AAPD,nDCG@3,1,80.11
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,AAPD,nDCG@5,1,83.7
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,AAPD,F1,2,69.6
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Freecode,F1-score,1,46
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Freecode,F1-score,2,45.3
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Slashdot,Micro-F1,1,56.8
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China,1:1 Accuracy,1,0.80352
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China,F1 - macro,1,0.20803
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China,Micro F1,1,0.85431
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MIMIC-III-50,Micro-F1,1,68.555
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MIMIC-III-50,Micro-F1,2,64.1
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,SVICTOR (theme),Average F1,1,0.8887
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,SVICTOR (theme),Weighted F1,1,0.8634
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,SVICTOR (theme),Average F1,2,0.8246
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,SVICTOR (theme),Weighted F1,2,0.8231
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Reuters-21578,Micro-F1,1,89.9
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MVICTOR (theme),Average F1,1,0.8882
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MVICTOR (theme),Weighted F1,1,0.9072
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MVICTOR (theme),Average F1,2,0.6642
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MVICTOR (theme),Weighted F1,2,0.8137
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Kan-Shan Cup,P@1,1,54.38
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Kan-Shan Cup,P@3,1,34.6
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Kan-Shan Cup,P@5,1,25.88
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Kan-Shan Cup,nDCG@3,1,51.7
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Kan-Shan Cup,nDCG@5,1,54.65
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,Micro F1,1,73.2
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,P@5,1,68.7
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,RP@5,1,79.6
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,nDCG@5,1,82.3
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,P@1,2,80.2
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,P@3,2,65.48
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,P@5,2,52.83
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,nDCG@1,2,80.2
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,nDCG@3,2,71.11
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,EUR-Lex,nDCG@5,2,68.8
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MIMIC-III,Micro-F1,1,40.7
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MIMIC-III,Precision,2,0.249
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,MIMIC-III,Recall,2,0.1138
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Amazon-12K,P@1,1,94.87
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Amazon-12K,P@3,1,79.16
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Amazon-12K,P@5,1,63.16
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Amazon-12K,nDCG@3,1,89.13
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Amazon-12K,nDCG@5,1,87.57
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,USPTO-3M,F1,1,66.83
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,BVICTOR,Average F1,1,0.8843
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,BVICTOR,Weighted F1,1,0.8957
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,BVICTOR,Average F1,2,0.7761
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,BVICTOR,Weighted F1,2,0.8235
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,RCV1-v2,Micro-F1,1,88.5
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Wiki-30K,P@1,1,84.18
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Wiki-30K,P@3,1,73.14
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Wiki-30K,P@5,1,62.87
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Wiki-30K,nDCG@3,1,75.64
"Adversarial', 'Natural Language Processing",Multi-Label Text Classification,Wiki-30K,nDCG@5,1,67.82
"Adversarial', 'Natural Language Processing",Semi-Supervised Text Classification,Yahoo! Answers (800 Labels),Accuracy (%),1,57.9
"Adversarial', 'Natural Language Processing",Semi-Supervised Text Classification,Yahoo! Answers (800 Labels),Accuracy (%),2,56.3
"Adversarial', 'Natural Language Processing",Semi-Supervised Text Classification,AG News (200 Labels),Accuracy (%),1,82.1
"Adversarial', 'Natural Language Processing",Semi-Supervised Text Classification,AG News (200 Labels),Accuracy (%),2,80.2
"Adversarial', 'Natural Language Processing",Citation Intent Classification,ACL-ARC,F1,1,67.9
"Adversarial', 'Natural Language Processing",Citation Intent Classification,ACL-ARC,F1,2,54.6
"Adversarial', 'Natural Language Processing",Citation Intent Classification,SciCite,F1,1,84.99
"Adversarial', 'Natural Language Processing",Citation Intent Classification,SciCite,F1,2,84.0
"Adversarial', 'Natural Language Processing",Coherence Evaluation,GCDC + RST - Accuracy,Accuracy,1,55.39
"Adversarial', 'Natural Language Processing",Coherence Evaluation,GCDC + RST - Accuracy,Accuracy,2,55.09
"Adversarial', 'Natural Language Processing",Coherence Evaluation,GCDC + RST - F1,Average F1,1,46.98
"Adversarial', 'Natural Language Processing",Coherence Evaluation,GCDC + RST - F1,Average F1,2,46.65
"Adversarial', 'Natural Language Processing",Hierarchical Text Classification of Blurbs (GermEval 2019),LOCAL DATASET,Accuracy (%),1,90.79
Natural Language Processing,Timeline Summarization,MTS,ROUGE-1,1,39.78
Natural Language Processing,Multimodal Abstractive Text Summarization,How2 300h,ROUGE-L,1,43.23
Natural Language Processing,Reader-Aware Summarization,RASG,ROUGE-1,1,30.33
Computer Vision,Unsupervised Facial Landmark Detection,AFLW (Zhang CVPR 2018 crops),NME,1,6.31
Computer Vision,Unsupervised Facial Landmark Detection,AFLW (Zhang CVPR 2018 crops),NME,2,6.54
Computer Vision,Unsupervised Facial Landmark Detection,CelebA,MSE normalized by inter-ocular distance,1,5.85
Computer Vision,Unsupervised Facial Landmark Detection,AFLW-MTFL,NME,1,7.53
Computer Vision,Unsupervised Facial Landmark Detection,AFLW-MTFL,NME,2,10.53
Computer Vision,Unsupervised Facial Landmark Detection,MAFL,NME,1,2.54
Computer Vision,Unsupervised Facial Landmark Detection,MAFL,NME,2,2.86
Computer Vision,Unsupervised Facial Landmark Detection,300W,NME,1,4.65
Computer Vision,Unsupervised Facial Landmark Detection,300W,NME,2,5.71
Computer Vision,3D Facial Landmark Localization,3DFAW,CVGTCE,1,3.46
Computer Vision,3D Facial Landmark Localization,3DFAW,GTE,1,4.35
Computer Vision,3D Facial Landmark Localization,AFLW2000-3D,GTE,1,7.28
Medical,Heart rate estimation,WESAD,"MAE [bpm, session-wise]",1,7.47
Medical,Heart rate estimation,WESAD,"MAE [bpm, session-wise]",2,8.42
Medical,Heart rate estimation,PPG-DaLiA,"MAE [bpm, session-wise]",1,20.45
Medical,Heart rate estimation,PPG-DaLiA,"MAE [bpm, session-wise]",2,15.56
Medical,Blood pressure estimation,Multi-day Continuous BP Prediction,RMSE,1,3.73
Medical,Blood pressure estimation,MIMIC-III,MAE for DBP [mmHg],1,6.7
Medical,Blood pressure estimation,MIMIC-III,MAE for SBP [mmHg],1,8.54
Medical,Blood pressure estimation,MIMIC-III,MAE for DBP [mmHg],2,6.88
Medical,Blood pressure estimation,MIMIC-III,MAE for SBP [mmHg],2,9.43
Audio,Audio Super-Resolution,Voice Bank corpus (VCTK),Log-Spectral Distance,1,2.5
Audio,Audio Super-Resolution,Voice Bank corpus (VCTK),Log-Spectral Distance,2,3.2
Audio,Audio Super-Resolution,Piano,Log-Spectral Distance,1,2
Audio,Audio Super-Resolution,Piano,Log-Spectral Distance,2,3.4
Audio,Audio Super-Resolution,DSD100,SNR,1,35.26
Audio,Audio Super-Resolution,VCTK Multi-Speaker,Log-Spectral Distance,1,1.8
Audio,Audio Super-Resolution,VCTK Multi-Speaker,Log-Spectral Distance,2,3.1
Computer Vision,Few-Shot Image Classification,CUB 200 50-way (0-shot),Accuracy,1,54.6
Computer Vision,Few-Shot Image Classification,CUB 200 50-way (0-shot),Accuracy,2,50.9
Computer Vision,Few-Shot Image Classification,Caltech-256 5-way (1-shot),Accuracy,1,74.7
Computer Vision,Few-Shot Image Classification,Caltech-256 5-way (1-shot),Accuracy,2,73.2
Computer Vision,Few-Shot Image Classification,ImageNet - 1-shot,Top 1 Accuracy,1,68.66
Computer Vision,Few-Shot Image Classification,ImageNet - 1-shot,Top 1 Accuracy,2,63.38
Computer Vision,Few-Shot Image Classification,AWA - 0-Shot,Accuracy,1,72.9
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 5-way",Accuracy,1,99.92
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 5-way",Accuracy,2,99.9
Computer Vision,Few-Shot Image Classification,AWA2 - 0-Shot,Accuracy,1,69.3
Computer Vision,Few-Shot Image Classification,CUB-200-2011 5-way (1-shot),Accuracy,1,67.33
Computer Vision,Few-Shot Image Classification,mini-ImageNet - 100-Way,Accuracy,1,39.14
Computer Vision,Few-Shot Image Classification,ImageNet - 5-shot,Top 1 Accuracy,1,82.78
Computer Vision,Few-Shot Image Classification,ImageNet - 5-shot,Top 1 Accuracy,2,78.21
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 10-way (5-shot),Accuracy,1,85.9
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 10-way (5-shot),Accuracy,2,83.1
Computer Vision,Few-Shot Image Classification,OMNIGLOT-EMNIST 5-way (1-shot),Accuracy,1,75.40
Computer Vision,Few-Shot Image Classification,iNaturalist (227-way multi-shot),Accuracy,1,74.97
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 10-way (1-shot),Accuracy,1,68.5
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 10-way (1-shot),Accuracy,2,63.5
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 5-way (10-shot),Accuracy,1,90.03
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 5-way (10-shot),Accuracy,2,81.57
Computer Vision,Few-Shot Image Classification,Stanford Dogs 5-way (5-shot),Accuracy,1,75.59
Computer Vision,Few-Shot Image Classification,Stanford Dogs 5-way (5-shot),Accuracy,2,70.29
Computer Vision,Few-Shot Image Classification,SUN - 0-Shot,Accuracy,1,62.7
Computer Vision,Few-Shot Image Classification,SUN - 0-Shot,Accuracy,2,60.9
Computer Vision,Few-Shot Image Classification,aPY - 0-Shot,Accuracy,1,42.2
Computer Vision,Few-Shot Image Classification,Oxford 102 Flower,ACCURACY,1,75.33
Computer Vision,Few-Shot Image Classification,CIFAR100 5-way (1-shot),Accuracy,1,89.6
Computer Vision,Few-Shot Image Classification,CIFAR100 5-way (1-shot),Accuracy,2,66.7
Computer Vision,Few-Shot Image Classification,FC100 5-way (1-shot),Accuracy,1,51.35
Computer Vision,Few-Shot Image Classification,FC100 5-way (1-shot),Accuracy,2,50.57
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 1000 way",Accuracy,1,68.9
Computer Vision,Few-Shot Image Classification,OMNIGLOT-EMNIST 5-way (5-shot),Accuracy,1,90.3
Computer Vision,Few-Shot Image Classification,CIFAR-FS 5-way (1-shot),Accuracy,1,87.79
Computer Vision,Few-Shot Image Classification,CIFAR-FS 5-way (1-shot),Accuracy,2,87.73
Computer Vision,Few-Shot Image Classification,miniImagenet → CUB (5-way 1-shot),Accuracy,1,55.46
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 5-way (1-shot),Accuracy,1,82.99
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 5-way (1-shot),Accuracy,2,82.92
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 20-way",Accuracy,1,99.63
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 20-way",Accuracy,2,99.11
Computer Vision,Few-Shot Image Classification,CUB 200 5-way 5-shot,Accuracy,1,96.28
Computer Vision,Few-Shot Image Classification,CUB 200 5-way 5-shot,Accuracy,2,94.09
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 5-way (5-shot),Accuracy,1,91.5
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 5-way (5-shot),Accuracy,2,90.98
Computer Vision,Few-Shot Image Classification,FC100 5-way (10-shot),Accuracy,1,63.4
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 20-way",Accuracy,1,99.65
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 20-way",Accuracy,2,99.63
Computer Vision,Few-Shot Image Classification,CIFAR-FS - 1-Shot Learning,Accuracy,1,81.87
Computer Vision,Few-Shot Image Classification,Stanford Dogs 5-way (1-shot),Accuracy,1,59.05
Computer Vision,Few-Shot Image Classification,Stanford Dogs 5-way (1-shot),Accuracy,2,55.63
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 1000 way",Accuracy,1,78.9
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 5-way",Accuracy,1,99.97
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 5-way",Accuracy,2,99.92
Computer Vision,Few-Shot Image Classification,Meta-Dataset,Accuracy,1,72.15
Computer Vision,Few-Shot Image Classification,Meta-Dataset,Accuracy,2,70.72
Computer Vision,Few-Shot Image Classification,Fewshot-CIFAR100 - 1-Shot Learning,Accuracy,1,50.57
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 20-way (5-shot),Accuracy,1,59.5
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 20-way (5-shot),Accuracy,2,47.31
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 10-way (5-shot),Accuracy,1,80.6
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 10-way (5-shot),Accuracy,2,78.5
Computer Vision,Few-Shot Image Classification,ImageNet (1-shot),Top-5 Accuracy,1,58.2
Computer Vision,Few-Shot Image Classification,ImageNet (1-shot),Top-5 Accuracy,2,59.2
Computer Vision,Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (1-shot),Accuracy,1,62.49
Computer Vision,Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (1-shot),Accuracy,2,49.44
Computer Vision,Few-Shot Image Classification,Flowers-102 - 0-Shot,AP50,1,59.6
Computer Vision,Few-Shot Image Classification,Flowers-102 - 0-Shot,Accuracy,1,65.6
Computer Vision,Few-Shot Image Classification,CUB-200-2011 5-way (5-shot),Accuracy,1,83.92
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 5-way (5-shot),Accuracy,1,90.44
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 5-way (5-shot),Accuracy,2,89.8
Computer Vision,Few-Shot Image Classification,CUB 200 5-way 1-shot,Accuracy,1,94.73
Computer Vision,Few-Shot Image Classification,CUB 200 5-way 1-shot,Accuracy,2,91.68
Computer Vision,Few-Shot Image Classification,miniImagenet → CUB (5-way 5-shot),Accuracy,1,66.33
Computer Vision,Few-Shot Image Classification,AWA1 - 0-Shot,Accuracy,1,70.8
Computer Vision,Few-Shot Image Classification,Stanford Cars 5-way (1-shot),Accuracy,1,73.15
Computer Vision,Few-Shot Image Classification,Stanford Cars 5-way (1-shot),Accuracy,2,72.43
Computer Vision,Few-Shot Image Classification,Stanford Cars 5-way (5-shot),Accuracy,1,91.89
Computer Vision,Few-Shot Image Classification,Stanford Cars 5-way (5-shot),Accuracy,2,91.05
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 10-way (1-shot),Accuracy,1,65.1
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 10-way (1-shot),Accuracy,2,57.1
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 5-Shot, 423 way",Accuracy,1,88
Computer Vision,Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (5-shot),Accuracy,1,76.51
Computer Vision,Few-Shot Image Classification,Mini-ImageNet-CUB 5-way (5-shot),Accuracy,2,68.33
Computer Vision,Few-Shot Image Classification,"OMNIGLOT - 1-Shot, 423 way",Accuracy,1,73.5
Computer Vision,Few-Shot Image Classification,CIFAR-FS - 5-Shot Learning,Accuracy,1,89.12
Computer Vision,Few-Shot Image Classification,Meta-Dataset Rank,Mean Rank,1,2.85
Computer Vision,Few-Shot Image Classification,Meta-Dataset Rank,Mean Rank,2,3.05
Computer Vision,Few-Shot Image Classification,FC100 5-way (5-shot),Accuracy,1,67.66
Computer Vision,Few-Shot Image Classification,FC100 5-way (5-shot),Accuracy,2,67.17
Computer Vision,Few-Shot Image Classification,CUB-200 - 0-Shot Learning,Accuracy,1,56.9
Computer Vision,Few-Shot Image Classification,CUB-200 - 0-Shot Learning,Accuracy,2,
Computer Vision,Few-Shot Image Classification,Mini-ImageNet - 1-Shot Learning,Accuracy,1,82.92
Computer Vision,Few-Shot Image Classification,Mini-ImageNet - 1-Shot Learning,Accuracy,2,78.55
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 5-way (1-shot),Accuracy,1,85.41
Computer Vision,Few-Shot Image Classification,Tiered ImageNet 5-way (1-shot),Accuracy,2,84.01
Computer Vision,Few-Shot Image Classification,Mini-ImageNet to CUB - 5 shot learning,Accuracy,1,71
Computer Vision,Few-Shot Image Classification,Mini-ImageNet to CUB - 5 shot learning,Accuracy,2,69.30
Computer Vision,Few-Shot Image Classification,ImageNet - 0-Shot,Accuracy,1,1.5
Computer Vision,Few-Shot Image Classification,ImageNet - 0-Shot,Accuracy,2,1.4
Computer Vision,Few-Shot Image Classification,CIFAR-FS 5-way (5-shot),Accuracy,1,91.09
Computer Vision,Few-Shot Image Classification,CIFAR-FS 5-way (5-shot),Accuracy,2,90.73
Computer Vision,Few-Shot Image Classification,Fewshot-CIFAR100 - 5-Shot Learning,Accuracy,1,61.58
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 20-way (1-shot),Accuracy,1,39.3
Computer Vision,Few-Shot Image Classification,Mini-Imagenet 20-way (1-shot),Accuracy,2,32.07
Computer Vision,Few-Shot Image Classification,ImageNet - 10-shot,Top 1 Accuracy,1,84.29
Computer Vision,Few-Shot Image Classification,ImageNet - 10-shot,Top 1 Accuracy,2,80.33
Computer Vision,Few-Shot Image Classification,CUB-200-2011 - 0-Shot,AP50,1,48.7
Computer Vision,Few-Shot Image Classification,CUB-200-2011 - 0-Shot,Top-1 Accuracy,1,56.8
Computer Vision,Few-Shot Image Classification,CUB-200-2011 - 0-Shot,Top-1 Accuracy,2,54.7
Computer Vision,Fine-Grained Image Classification,SUN397,Accuracy,1,62.5
Computer Vision,Fine-Grained Image Classification,DF20 - Mini,F1 - macro,1,66.4
Computer Vision,Fine-Grained Image Classification,DF20 - Mini,Top-1,1,75.96
Computer Vision,Fine-Grained Image Classification,DF20 - Mini,Top-3,1,89.37
Computer Vision,Fine-Grained Image Classification,DF20 - Mini,F1 - macro,2,63.5
Computer Vision,Fine-Grained Image Classification,DF20 - Mini,Top-1,2,72.39
Computer Vision,Fine-Grained Image Classification,DF20 - Mini,Top-3,2,86.57
Computer Vision,Fine-Grained Image Classification,EMNIST-Letters,Accuracy,1,95.86
Computer Vision,Fine-Grained Image Classification,QMNIST,Accuracy,1,99.6867
Computer Vision,Fine-Grained Image Classification,Imbalanced CUB-200-2011,Accuracy,1,89.73
Computer Vision,Fine-Grained Image Classification,Imbalanced CUB-200-2011,Average Per-Class Accuracy,1,87.69
Computer Vision,Fine-Grained Image Classification,STL-10,Accuracy,1,98.18
Computer Vision,Fine-Grained Image Classification,10 Monkey Species,Accuracy,1,95.00
Computer Vision,Fine-Grained Image Classification,CUB-200-2011,Accuracy,1,91.7
Computer Vision,Fine-Grained Image Classification,CUB-200-2011,Accuracy,2,91.6
Computer Vision,Fine-Grained Image Classification,MNIST,Accuracy,1,98.19
Computer Vision,Fine-Grained Image Classification,Con-Text,mAP,1,80.2
Computer Vision,Fine-Grained Image Classification,Oxford 102 Flowers,Accuracy,1,99.74
Computer Vision,Fine-Grained Image Classification,Oxford 102 Flowers,PARAMS,1,307M
Computer Vision,Fine-Grained Image Classification,Oxford 102 Flowers,Accuracy,2,99.68
Computer Vision,Fine-Grained Image Classification,Oxford 102 Flowers,PARAMS,2,632M
Computer Vision,Fine-Grained Image Classification, CUB-200-2011,Accuracy,1,91.7
Computer Vision,Fine-Grained Image Classification, CUB-200-2011,Accuracy,2,91.6
Computer Vision,Fine-Grained Image Classification,CarFlag-563,Accuracy,1,96.42
Computer Vision,Fine-Grained Image Classification,FGVC Aircraft,Accuracy,1,94.7
Computer Vision,Fine-Grained Image Classification,FGVC Aircraft,Accuracy,2,94.1
Computer Vision,Fine-Grained Image Classification,Kuzushiji-MNIST,Accuracy,1,98.98
Computer Vision,Fine-Grained Image Classification,NABirds,Accuracy,1,90.8
Computer Vision,Fine-Grained Image Classification,NABirds,Accuracy,2,89.2
Computer Vision,Fine-Grained Image Classification,BoxCars116K,Accuracy,1,86.57
Computer Vision,Fine-Grained Image Classification,Fruits-360,Accuracy (%),1,99.90
Computer Vision,Fine-Grained Image Classification,Fruits-360,Accuracy,2,99.97
Computer Vision,Fine-Grained Image Classification,Stanford Dogs,Accuracy,1,92.3
Computer Vision,Fine-Grained Image Classification,Stanford Dogs,Accuracy,2,90.3
Computer Vision,Fine-Grained Image Classification,Bottles,mAP,1,77.4
Computer Vision,Fine-Grained Image Classification,iNaturalist,Top 1 Accuracy,1,68.2
Computer Vision,Fine-Grained Image Classification,SOP,Recall@1,1,85.9
Computer Vision,Fine-Grained Image Classification,CompCars,Accuracy,1,97.6
Computer Vision,Fine-Grained Image Classification,CompCars,Accuracy,2,95.9
Computer Vision,Fine-Grained Image Classification,Birdsnap,Accuracy,1,90.07
Computer Vision,Fine-Grained Image Classification,Birdsnap,Accuracy,2,84.3
Computer Vision,Fine-Grained Image Classification,Bird-225,Accuracy,1,99.55
Computer Vision,Fine-Grained Image Classification,Bird-225,Accuracy,2,99.02
Computer Vision,Fine-Grained Image Classification,Oxford-IIIT Pets,Accuracy,1,97.56
Computer Vision,Fine-Grained Image Classification,Oxford-IIIT Pets,PARAMS,1,632M
Computer Vision,Fine-Grained Image Classification,Oxford-IIIT Pets,Accuracy,2,97.32
Computer Vision,Fine-Grained Image Classification,Oxford-IIIT Pets,PARAMS,2,307M
Computer Vision,Fine-Grained Image Classification,CarFlag-1532,Accuracy,1,96.70
Computer Vision,Fine-Grained Image Classification,Stanford Cars,Accuracy,1,96.32
Computer Vision,Fine-Grained Image Classification,Stanford Cars,Accuracy,2,96.2
Computer Vision,Fine-Grained Image Classification,Caltech-101,Top-1 Error Rate,1,2.68
Computer Vision,Fine-Grained Image Classification,Caltech-101,Top-1 Error Rate,2,2.89
Computer Vision,Fine-Grained Image Classification,Food-101,Accuracy,1,96.18
Computer Vision,Fine-Grained Image Classification,Food-101,Accuracy,2,95.88
Computer Vision,Fine-Grained Image Classification,EMNIST-Digits,Accuracy,1,99.82
Computer Vision,Fine-Grained Image Classification,DF20,F1 - macro,1,74.7
Computer Vision,Fine-Grained Image Classification,DF20,Top-1,1,81.25
Computer Vision,Fine-Grained Image Classification,DF20,Top-3,1,91.93
Computer Vision,Fine-Grained Image Classification,DF20,F1 - macro,2,72.4
Computer Vision,Fine-Grained Image Classification,DF20,Top-1,2,79.4
Computer Vision,Fine-Grained Image Classification,DF20,Top-3,2,90.93
Computer Vision,Semi-Supervised Image Classification,"CIFAR-100, 1000 Labels",Percentage correct,1,41.27
Computer Vision,Semi-Supervised Image Classification,ImageNet - 10% labeled data,Top 1 Accuracy,1,80.9
Computer Vision,Semi-Supervised Image Classification,ImageNet - 10% labeled data,Top 5 Accuracy,1,95.5
Computer Vision,Semi-Supervised Image Classification,ImageNet - 10% labeled data,Top 1 Accuracy,2,80.2
Computer Vision,Semi-Supervised Image Classification,ImageNet - 10% labeled data,Top 5 Accuracy,2,95.0
Computer Vision,Semi-Supervised Image Classification,"cifar-10, 10 Labels",Accuracy (Test),1,95.1
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 2000 Labels",Accuracy,1,92.97
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 2000 Labels",Accuracy,2,90.74
Computer Vision,Semi-Supervised Image Classification,"Caltech-256, 1024 Labels",Accuracy,1,77.40
Computer Vision,Semi-Supervised Image Classification,"cifar-100, 10000 Labels",Accuracy,1,77.89
Computer Vision,Semi-Supervised Image Classification,"cifar-100, 10000 Labels",Accuracy,2,77.08
Computer Vision,Semi-Supervised Image Classification,"cifar10, 250 Labels",Percentage correct,1,93.73
Computer Vision,Semi-Supervised Image Classification,"cifar10, 250 Labels",Percentage correct,2,92.4
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 1000 Labels",Accuracy,1,92.25
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 1000 Labels",Accuracy,2,91.82
Computer Vision,Semi-Supervised Image Classification,"SVHN, 4000 Labels",Accuracy,1,97.11
Computer Vision,Semi-Supervised Image Classification,"CIFAR-100, 5000Labels",Percentage correct,1,68.17
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 500 Labels",Accuracy,1,91.35
Computer Vision,Semi-Supervised Image Classification,"SVHN, 2000 Labels",Accuracy,1,96.96
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 40 Labels",Percentage error,1,6.81
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 40 Labels",Percentage error,2,7.45
Computer Vision,Semi-Supervised Image Classification,"SVHN, 1000 labels",Accuracy,1,98.01
Computer Vision,Semi-Supervised Image Classification,"SVHN, 1000 labels",Accuracy,2,97.64
Computer Vision,Semi-Supervised Image Classification,"SVHN, 40 Labels",Percentage error,1,7.65
Computer Vision,Semi-Supervised Image Classification,"Mini-ImageNet, 1000 Labels",Accuracy,1,44.65
Computer Vision,Semi-Supervised Image Classification,"Mini-ImageNet, 1000 Labels",Accuracy,2,40.65
Computer Vision,Semi-Supervised Image Classification,"SVHN, 250 Labels",Accuracy,1,96.79
Computer Vision,Semi-Supervised Image Classification,"SVHN, 250 Labels",Accuracy,2,96.52
Computer Vision,Semi-Supervised Image Classification,"STL-10, 1000 Labels",Accuracy,1,94.83
Computer Vision,Semi-Supervised Image Classification,"STL-10, 1000 Labels",Accuracy,2,93.82
Computer Vision,Semi-Supervised Image Classification,"CIFAR-100, 4000 Labels",Accuracy,1,59.23
Computer Vision,Semi-Supervised Image Classification,Caltech-256,Accuracy,1,77.40
Computer Vision,Semi-Supervised Image Classification,ImageNet - 1% labeled data,Top 1 Accuracy,1,76.6
Computer Vision,Semi-Supervised Image Classification,ImageNet - 1% labeled data,Top 5 Accuracy,1,93.4
Computer Vision,Semi-Supervised Image Classification,ImageNet - 1% labeled data,Top 1 Accuracy,2,75.9
Computer Vision,Semi-Supervised Image Classification,ImageNet - 1% labeled data,Top 5 Accuracy,2,93.0
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",Accuracy,1,97.13
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",Accuracy,2,96.2
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",Accuracy,1,95.13
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",Accuracy,2,94.93
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 80 Labels",Percentage error,1,5.98
Computer Vision,Semi-Supervised Image Classification,"Caltech-101, 202 Labels",Accuracy,1,91.00
Computer Vision,Semi-Supervised Image Classification,"Mini-ImageNet, 4000 Labels",Accuracy,1,66.55
Computer Vision,Semi-Supervised Image Classification,"Mini-ImageNet, 4000 Labels",Accuracy,2,60.95
Computer Vision,Semi-Supervised Image Classification,"SVHN, 500 Labels",Accuracy,1,96.39
Computer Vision,Semi-Supervised Image Classification,"SVHN, 500 Labels",Accuracy,2,96.36
Computer Vision,Semi-Supervised Image Classification,"Mini-ImageNet, 10000 Labels",Accuracy,1,65.21
Computer Vision,Semi-Supervised Image Classification,"Mini-ImageNet, 10000 Labels",Accuracy,2,58.75
Computer Vision,Semi-Supervised Image Classification,"CIFAR-100, 400 Labels",Percentage error,1,49.95
Computer Vision,Semi-Supervised Image Classification,STL-10,Accuracy,1,95.48
Computer Vision,Semi-Supervised Image Classification,STL-10,Accuracy,2,88.8
Computer Vision,Semi-Supervised Image Classification,Caltech-101,Accuracy,1,91.00
Computer Vision,Semi-Supervised Image Classification,"STL-10, 5000 Labels",Accuracy,1,94.41
Computer Vision,Semi-Supervised Image Classification,"CIFAR-100, 2500 Labels",Percentage error,1,28.64
Computer Vision,Semi-Supervised Image Classification,"CIFAR-10, 20 Labels",Percentage error,1,16.09
Computer Vision,Small Data Image Classification,"CUB-200-2011, 30 samples per class",Accuracy,1,77.75
Computer Vision,Small Data Image Classification,"CIFAR-10, 250 Labels",Top-1 accuracy %,1,43
Computer Vision,Small Data Image Classification,"CIFAR-10, 500 Labels",Accuracy (%),1,56.22
Computer Vision,Small Data Image Classification,"cifar10, 10 labels",% Test Accuracy,1,45.96
Computer Vision,Small Data Image Classification,"cifar10, 10 labels",% Test Accuracy,2,45.96
Computer Vision,Small Data Image Classification,"CIFAR-100, 1000 Labels",Accuracy,1,28.55
Computer Vision,Small Data Image Classification,"CUB-200-2011, 5 samples per class",Accuracy,1,51.52
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Overall Accuracy,1,95.36
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Average Accuracy,2,88.44
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Kappa,2,0.8555
Computer Vision,Hyperspectral Image Classification,CASI University of Houston,Overall Accuracy,2,86.61
Computer Vision,Hyperspectral Image Classification,Kennedy Space Center,Overall Accuracy,1,99.34
Computer Vision,Hyperspectral Image Classification,Salinas Scene,Overall Accuracy,1,100
Computer Vision,Hyperspectral Image Classification,Salinas Scene,Overall Accuracy,2,100
Computer Vision,Hyperspectral Image Classification,Salinas,AA@200,1,99.91
Computer Vision,Hyperspectral Image Classification,Salinas,Kappa@200,1,0.9991
Computer Vision,Hyperspectral Image Classification,Salinas,OA@200,1,99.92
Computer Vision,Hyperspectral Image Classification,Indian Pines,Overall Accuracy,1,99.86
Computer Vision,Hyperspectral Image Classification,Indian Pines,Overall Accuracy,2,99.81
Computer Vision,Hyperspectral Image Classification,Pavia University,Overall Accuracy,1,99.99
Computer Vision,Hyperspectral Image Classification,Pavia University,Kappa@1%,2,0.9996
Computer Vision,Hyperspectral Image Classification,Pavia University,Overall Accuracy,2,99.97
Computer Vision,Self-Supervised Image Classification,ImageNet (finetuned),Number of Params,1,1300M
Computer Vision,Self-Supervised Image Classification,ImageNet (finetuned),Top 1 Accuracy,1,84.2
Computer Vision,Self-Supervised Image Classification,ImageNet (finetuned),Number of Params,2,693M
Computer Vision,Self-Supervised Image Classification,ImageNet (finetuned),Top 1 Accuracy,2,83.8
Computer Vision,Self-Supervised Image Classification,ImageNet,Number of Params,1,87M
Computer Vision,Self-Supervised Image Classification,ImageNet,Top 1 Accuracy,1,81.3
Computer Vision,Self-Supervised Image Classification,ImageNet,"Top 1 Accuracy (kNN, k=20)",1,79.3
Computer Vision,Self-Supervised Image Classification,ImageNet,Top 5 Accuracy,1,95.5
Computer Vision,Self-Supervised Image Classification,ImageNet,Number of Params,2,304M
Computer Vision,Self-Supervised Image Classification,ImageNet,Top 1 Accuracy,2,81.0
Computer Vision,Learning with noisy labels,ANIMAL,Accuracy,1,84.1
Computer Vision,Learning with noisy labels,ANIMAL,ImageNet Pretrained,1,NO
Computer Vision,Learning with noisy labels,ANIMAL,Network,1,Vgg19BN
Computer Vision,Learning with noisy labels,ANIMAL,Accuracy,2,83.4
Computer Vision,Learning with noisy labels,ANIMAL,ImageNet Pretrained,2,NO
Computer Vision,Learning with noisy labels,ANIMAL,Network,2,Vgg19BN
Computer Vision,Sequential Image Classification,Sequential MNIST,Permuted Accuracy,1,98.54
Computer Vision,Sequential Image Classification,Sequential MNIST,Unpermuted Accuracy,1,99.32
Computer Vision,Sequential Image Classification,Sequential MNIST,Permuted Accuracy,2,98.49
Computer Vision,Sequential Image Classification,Sequential CIFAR-10,Unpermuted Accuracy,1,73.42
Computer Vision,Sequential Image Classification,Sequential CIFAR-10,Unpermuted Accuracy,2,64.2
Computer Vision,Genre classification,FMA,CNN,1,855
Computer Vision,Genre classification,Book Cover Dataset,Top 1 Accuracy,1,24.7
Computer Vision,Genre classification,Book Cover Dataset,Top 1 Accuracy,2,13.5
Computer Vision,Unsupervised Image Classification,MNIST,Accuracy,1,99.3
Computer Vision,Unsupervised Image Classification,MNIST,Accuracy,2,98.32
Computer Vision,Unsupervised Image Classification,STL-10,Accuracy,1,86.7
Computer Vision,Unsupervised Image Classification,STL-10,Accuracy,2,80.90
Computer Vision,Unsupervised Image Classification,CIFAR-20,Accuracy,1,54.3
Computer Vision,Unsupervised Image Classification,CIFAR-20,Accuracy,2,50.7
Computer Vision,Unsupervised Image Classification,SVHN,# of clusters (k),1,10
Computer Vision,Unsupervised Image Classification,SVHN,Acc,1,76.80
Computer Vision,Unsupervised Image Classification,SVHN,# of clusters (k),2,10
Computer Vision,Unsupervised Image Classification,SVHN,Acc,2,57.4
Computer Vision,Unsupervised Image Classification,CIFAR-10,Accuracy,1,90.3
Computer Vision,Unsupervised Image Classification,CIFAR-10,Accuracy,2,88.3
Computer Vision,Unsupervised Image Classification,ImageNet,ARI,1,27.5
Computer Vision,Unsupervised Image Classification,ImageNet,Accuracy (%),1,39.9
Computer Vision,Unsupervised Image Classification,ImageNet,ARI,2,23.94
Computer Vision,Unsupervised Image Classification,ImageNet,Accuracy (%),2,46.03
Computer Vision,Document Image Classification,Noisy Bangla Numeral,Accuracy,1,96.68
Computer Vision,Document Image Classification,Noisy Bangla Numeral,Accuracy,2,95.46
Computer Vision,Document Image Classification,RVL-CDIP,Accuracy,1,95.64
Computer Vision,Document Image Classification,RVL-CDIP,Accuracy,2,95.52
Computer Vision,Document Image Classification,n-MNIST,Accuracy,1,98.43
Computer Vision,Document Image Classification,n-MNIST,Accuracy,2,97.62
Computer Vision,Document Image Classification,Noisy Bangla Characters,Accuracy,1,89.54
Computer Vision,Document Image Classification,Noisy Bangla Characters,Accuracy,2,77.22
Computer Vision,Document Image Classification,Tobacco-3482,Accuracy,1,91.95
Computer Vision,Document Image Classification,Tobacco-3482,Accuracy,2,91
Computer Vision,Sparse Representation-based Classification,SVHN,Accuracy,1,67.75
Computer Vision,Satellite Image Classification,SAT-4,Accuracy,1,99.90
Computer Vision,Satellite Image Classification,SAT-4,Accuracy,2,98.74
Computer Vision,Satellite Image Classification,SAT-6,Accuracy,1,99.84
Computer Vision,Satellite Image Classification,SAT-6,Accuracy,2,93.92
Computer Vision,Satellite Image Classification,NASA Worldview,DSC,1,0.6611
Computer Vision,Superpixel Image Classification,75 Superpixel MNIST,Classification Error,1,0.95
Computer Vision,Superpixel Image Classification,75 Superpixel MNIST,Classification Error,2,1.24
Computer Vision,Photo geolocation estimation,Im2GPS,City level (25 km),1,43.0
Computer Vision,Photo geolocation estimation,Im2GPS,Continent level (2500 km),1,80.2
Computer Vision,Photo geolocation estimation,Im2GPS,Country level (750 km),1,66.7
Computer Vision,Photo geolocation estimation,Im2GPS,Reference images,1,0
Computer Vision,Photo geolocation estimation,Im2GPS,Region level (200 km),1,51.9
Computer Vision,Photo geolocation estimation,Im2GPS,Street level (1 km),1,16.9
Computer Vision,Photo geolocation estimation,Im2GPS,Training images,1,4.7M
Computer Vision,Photo geolocation estimation,Im2GPS,City level (25 km),2,37.1
Computer Vision,Photo geolocation estimation,Im2GPS,Continent level (2500 km),2,78.5
Computer Vision,Photo geolocation estimation,Im2GPS,Country level (750 km),2,62.0
Computer Vision,Photo geolocation estimation,Im2GPS,Reference images,2,0
Computer Vision,Photo geolocation estimation,Im2GPS,Region level (200 km),2,46.6
Computer Vision,Photo geolocation estimation,Im2GPS,Street level (1 km),2,16.5
Computer Vision,Photo geolocation estimation,Im2GPS,Training images,2,30.3M
Computer Vision,Photo geolocation estimation,Im2GPS3k,City level (25 km),1,28.0
Computer Vision,Photo geolocation estimation,Im2GPS3k,Continent level (2500 km),1,66.0
Computer Vision,Photo geolocation estimation,Im2GPS3k,Country level (750 km),1,49.7
Computer Vision,Photo geolocation estimation,Im2GPS3k,Region level (200 km),1,36.6
Computer Vision,Photo geolocation estimation,Im2GPS3k,Street level (1 km),1,10.5
Computer Vision,Photo geolocation estimation,Im2GPS3k,Training images,1,4.7M
Computer Vision,Photo geolocation estimation,Im2GPS3k,City level (25 km),2,26.5
Computer Vision,Photo geolocation estimation,Im2GPS3k,Continent level (2500 km),2,64.4
Computer Vision,Photo geolocation estimation,Im2GPS3k,Country level (750 km),2,48.6
Computer Vision,Photo geolocation estimation,Im2GPS3k,Region level (200 km),2,34.6
Computer Vision,Photo geolocation estimation,Im2GPS3k,Street level (1 km),2,10.2
Computer Vision,Photo geolocation estimation,Im2GPS3k,Training images,2,30.3M
Computer Vision,Classification Consistency,ImageNet,Consistency,1,91.31
Computer Vision,Artistic style classification,RASTA,Top-1 Accuracy,1,0.611
Computer Vision,Scale Generalisation,MNIST Large Scale dataset,Average Accuracy,1,99.32
Computer Vision,Scale Generalisation,MNIST Large Scale dataset,Average Accuracy,2,99.32
Computer Code,Annotated Code Search,PACS-CoNaLa,MRR,1,0.351
Computer Code,Annotated Code Search,PACS-CoNaLa,MRR,2,0.340
Computer Code,Annotated Code Search,PACS-StaQC-py,MRR,1,0.126
Computer Code,Annotated Code Search,PACS-StaQC-py,MRR,2,0.117
Computer Code,Annotated Code Search,PACS-SO-DS,MRR,1,0.323
Computer Code,Annotated Code Search,PACS-SO-DS,MRR,2,0.304
Computer Vision,Occluded Face Detection,MAFA,MAP,1,88.3
Computer Vision,Occluded Face Detection,MAFA,MAP,2,77.3
Computer Vision,Disguised Face Verification,Disguised Faces in the Wild,GAR @0.1% FAR,1,23.25
Computer Vision,Disguised Face Verification,Disguised Faces in the Wild,GAR @1% FAR,1,60.89
Computer Vision,Disguised Face Verification,Disguised Faces in the Wild,GAR @10% FAR,1,98.99
Computer Vision,Disguised Face Verification,Disguised Faces in the Wild,GAR @0.1% FAR,2,17.73
Computer Vision,Disguised Face Verification,Disguised Faces in the Wild,GAR @1% FAR,2,33.76
Computer Vision,Disguised Face Verification,MegaFace,Accuracy,1,86.47
Computer Vision,Multiple Object Forecasting,Citywalks,ADE,1,26.7
Computer Vision,Multiple Object Forecasting,Citywalks,AIOU,1,54.3
Methodology,Stroke Classification,CT Lesion Stroke Dataset,Average Class Accuracy ,1,98.86
Methodology,Stroke Classification,CT Lesion Stroke Dataset,Average Class Accuracy ,2,93.46
Computer Vision,3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.91
Computer Vision,3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,2.08
Computer Vision,3D Face Reconstruction,AFLW2000-3D,Mean NME ,1,3.56
Computer Vision,3D Face Reconstruction,AFLW2000-3D,Mean NME ,2,3.9625
Computer Vision,3D Face Reconstruction,Florence,Mean NME ,1,3.56
Computer Vision,3D Face Reconstruction,Florence,Mean NME ,2,3.7551
Computer Vision,3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.89
Computer Vision,3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,1.91
Computer Vision,3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),1,1.38
Computer Vision,3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),2,1.53
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),Dice,1,0.812
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),Grad Det-Jac,1,1.4
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),Hausdorff Distance (mm),1,7.3
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),RMSE,1,0.30
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),Dice,2,0.801
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),Grad Det-Jac,2,3.4
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),Hausdorff Distance (mm),2,8.1
Medical,Diffeomorphic Medical Image Registration,Automatic Cardiac Diagnosis Challenge (ACDC),RMSE,2,0.32
Medical,Diffeomorphic Medical Image Registration,CUMC12,Mean target overlap ratio,1,0.520
Medical,Diffeomorphic Medical Image Registration,CUMC12,Mean target overlap ratio,2,0.514
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,CPU (sec),1,2347
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,Dice (Average),1,0.755
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,Dice (SE),1,0.143
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,Neg Jacob Det,1,33838
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,CPU (sec),2,84.2
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,Dice (Average),2,0.754
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,Dice (SE),2,0.139
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,GPU sec,2,0.47
Medical,Diffeomorphic Medical Image Registration,OASIS+ADIBE+ADHD200+MCIC+PPMI+HABS+HarvardGSP,Neg Jacob Det,2,0.2
Medical,BIRL,CIMA-10k,AMrTRE,1,2.3
Medical,BIRL,CIMA-10k,MMrTRE,1,1.67
Medical,BIRL,CIMA-10k,AMrTRE,2,2.5
Medical,BIRL,CIMA-10k,MMrTRE,2,0.51
Computer Vision,Age-Invariant Face Recognition,CACDVS,Accuracy,1,99.76
Computer Vision,Age-Invariant Face Recognition,CACDVS,Accuracy,2,99.55
Computer Vision,Age-Invariant Face Recognition,FG-NET,Accuracy,1,94.78
Computer Vision,Age-Invariant Face Recognition,FG-NET,Accuracy,2,93.2
Computer Vision,Age-Invariant Face Recognition,CAFR,Accuracy,1,84.81
Computer Vision,Age-Invariant Face Recognition,CAFR,Accuracy,2,73.56
Computer Vision,Age-Invariant Face Recognition,MORPH Album2,Rank-1 Recognition Rate,1,99.65
Computer Vision,Age-Invariant Face Recognition,MORPH Album2,Rank-1 Recognition Rate,2,99.13
Computer Vision,Face Quality Assessement,Adience,Equal Error Rate,1,0.026
Computer Vision,Face Quality Assessement,LFW,Equal Error Rate,1,0.007
Computer Vision,3D Facial Expression Recognition,2017_test set,14 gestures accuracy,1,2
Computer Vision,Smile Recognition,DISFA,Accuracy,1,99.45
Natural Language Processing,Visual Storytelling,VIST,BLEU-1,1,63.8
Natural Language Processing,Visual Storytelling,VIST,BLEU-2,1,39.1
Natural Language Processing,Visual Storytelling,VIST,BLEU-3,1,23.2
Natural Language Processing,Visual Storytelling,VIST,BLEU-4,1,14.1
Natural Language Processing,Visual Storytelling,VIST,CIDEr,1,9.4
Natural Language Processing,Visual Storytelling,VIST,METEOR,1,35
Natural Language Processing,Visual Storytelling,VIST,ROUGE,1,29.5
"Computer Vision', 'Natural Language Processing', 'Methodology",Active Object Detection,COCO,AP,1,(7.3
"Computer Vision', 'Natural Language Processing', 'Methodology",Active Object Detection,PASCAL VOC 07+12,mAP,1,(47.18
"Computer Vision', 'Natural Language Processing', 'Methodology",Active Object Detection,PASCAL VOC 07+12,mAP,2,(53.62
Computer Vision,Semantic correspondence,PF-WILLOW,PCK,1,79.4
Computer Vision,Semantic correspondence,PF-WILLOW,PCK,2,79.2
Computer Vision,Semantic correspondence,Caltech-101,IoU,1,63
Computer Vision,Semantic correspondence,Caltech-101,LT-ACC,1,87
Computer Vision,Semantic correspondence,Caltech-101,IoU,2,62
Computer Vision,Semantic correspondence,Caltech-101,IoU (weak),2,61
Computer Vision,Semantic correspondence,Caltech-101,LT-ACC,2,87
Computer Vision,Semantic correspondence,Caltech-101,LT-ACC (weak),2,86
Computer Vision,Semantic correspondence,PF-PASCAL,PCK,1,92.6
Computer Vision,Semantic correspondence,PF-PASCAL,PCK,2,91.6
Computer Vision,Semantic correspondence,SPair-71k,PCK,1,49.9
Computer Vision,Semantic correspondence,SPair-71k,PCK,2,46.3
Computer Vision,Patch Matching,HPatches,Patch Matching,1,53.95
Computer Vision,Patch Matching,HPatches,Patch Retrieval,1,71.66
Computer Vision,Patch Matching,HPatches,Patch Verification,1,89.06
Computer Vision,Patch Matching,HPatches,Patch Matching,2,45.3
Computer Vision,Patch Matching,HPatches,Patch Retrieval,2,55.6
Computer Vision,Patch Matching,HPatches,Patch Verification,2,95.6
Computer Vision,Patch Matching,Brown Dataset,FPR95,1,0.9
Computer Vision,Patch Matching,Brown Dataset,FPR95,2,1.27
Computer Vision,Face Presentation Attack Detection,Replay Mobile,HTER,1,0
Computer Vision,Face Presentation Attack Detection,WMCA,ACER,1,0.097
Computer Vision,Face Presentation Attack Detection,WMCA,ACER,2,0.3
"Robots', 'Computer Vision",3D Reconstruction,Data3D−R2N2,3DIoU,1,0.642
"Robots', 'Computer Vision",3D Reconstruction,Data3D−R2N2,3DIoU,2,0.640
"Robots', 'Computer Vision",3D Reconstruction,ApolloCar3D,A3DP,1,20.21
"Robots', 'Computer Vision",3D Reconstruction,ShapeNet,Mean,1,2.82
"Robots', 'Computer Vision",3D Reconstruction,ShapeNet,Mean IoU,1,65.43
"Robots', 'Computer Vision",3D Reconstruction,ScanNet,3DIoU,1,89.4
"Robots', 'Computer Vision",3D Reconstruction,ScanNet,Chamfer Distance,1,37.2
"Robots', 'Computer Vision",3D Reconstruction,ScanNet,L1,1,21.1
"Robots', 'Computer Vision",3D Reconstruction,Scan2CAD,Average Accuracy,1,31.68
"Robots', 'Computer Vision",3D Reconstruction,Scan2CAD,Average Accuracy,2,10.29
"Robots', 'Computer Vision",3D Reconstruction,300W,1-of-100 Accuracy,1,cosine
"Robots', 'Computer Vision",Face Verification,IIIT-D Viewed Sketch,TAR @ FAR=0.01,1,97.86
"Robots', 'Computer Vision",Face Verification,MegaFace,Accuracy,1,98.95
"Robots', 'Computer Vision",Face Verification,MegaFace,Accuracy,2,98.48
"Robots', 'Computer Vision",Face Verification,Oulu-CASIA,Accuracy,1,96.50
"Robots', 'Computer Vision",Face Verification,BUAA-VisNir,TAR @ FAR=0.001,1,97.3
"Robots', 'Computer Vision",Face Verification,BUAA-VisNir,TAR @ FAR=0.01,1,98.5
"Robots', 'Computer Vision",Face Verification,BUAA-VisNir,TAR @ FAR=0.001,2,96.9
"Robots', 'Computer Vision",Face Verification,BUAA-VisNir,TAR @ FAR=0.01,2,98.5
"Robots', 'Computer Vision",Face Verification,CFP-FP,Accuracy,1,0.985
"Robots', 'Computer Vision",Face Verification,CFP-FP,Accuracy,2,0.9307
"Robots', 'Computer Vision",Face Verification,IJB-B,TAR @ FAR=0.01,1,96.5
"Robots', 'Computer Vision",Face Verification,IJB-B,TAR @ FAR=0.01,2,96.4
"Robots', 'Computer Vision",Face Verification,IJB-A,TAR @ FAR=0.01,1,97.60
"Robots', 'Computer Vision",Face Verification,IJB-A,TAR @ FAR=0.001,2,95.25
"Robots', 'Computer Vision",Face Verification,IJB-A,TAR @ FAR=0.01,2,97.5
"Robots', 'Computer Vision",Face Verification,IJB-C,TAR @ FAR=0.0001,1,97.7
"Robots', 'Computer Vision",Face Verification,IJB-C,TAR @ FAR=0.0001,2,97.30
"Robots', 'Computer Vision",Face Verification,IJB-C,TAR @ FAR=0.001,2,98.18
"Robots', 'Computer Vision",Face Verification,IJB-C,TAR @ FAR=0.01,2,98.73
"Robots', 'Computer Vision",Face Verification,CASIA NIR-VIS 2.0,TAR @ FAR=0.001,1,99.8
"Robots', 'Computer Vision",Face Verification,CASIA NIR-VIS 2.0,TAR @ FAR=0.001,2,99.6
"Robots', 'Computer Vision",Face Verification,2019_test set,99.46%,1,90
"Robots', 'Computer Vision",Face Verification,Trillion Pairs Dataset,Accuracy,1,72.71
"Robots', 'Computer Vision",Face Verification,Trillion Pairs Dataset,Accuracy,2,61.61
"Robots', 'Computer Vision",Face Verification,Labeled Faces in the Wild,Accuracy,1,99.85
"Robots', 'Computer Vision",Face Verification,Labeled Faces in the Wild,Accuracy,2,99.83
"Robots', 'Computer Vision",Face Verification,AgeDB-30,Accuracy,1,0.9815
"Robots', 'Computer Vision",Face Verification,AgeDB-30,Accuracy,2,0.97333
"Robots', 'Computer Vision",Face Verification,CK+,Accuracy,1,93.80
"Robots', 'Computer Vision",Face Verification,YouTube Faces DB,Accuracy,1,98.12
"Robots', 'Computer Vision",Face Verification,YouTube Faces DB,Accuracy,2,98.02
"Robots', 'Computer Vision",Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.001,1,92.9
"Robots', 'Computer Vision",Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.01,1,98.5
"Robots', 'Computer Vision",Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.001,2,84.9
"Robots', 'Computer Vision",Face Verification,Oulu-CASIA NIR-VIS,TAR @ FAR=0.01,2,97.2
"Robots', 'Computer Vision",3D Pose Estimation,Human3.6M,Average MPJPE (mm),1,18.7
"Robots', 'Computer Vision",3D Pose Estimation,Human3.6M,Average MPJPE (mm),2,44.8
"Robots', 'Computer Vision",3D Pose Estimation,CMU Panoptic,Average MPJPE (mm),1,7.3
"Robots', 'Computer Vision",3D Pose Estimation,CarFusion,3DPCK,1,93.2
"Robots', 'Computer Vision",3D Pose Estimation,K2HPD,FPS,1,93.78
"Robots', 'Computer Vision",3D Pose Estimation,ApolloCar3D,A3DP,1,20.21
"Robots', 'Computer Vision",3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.91
"Robots', 'Computer Vision",3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,2.08
"Robots', 'Computer Vision",3D Face Reconstruction,AFLW2000-3D,Mean NME ,1,3.56
"Robots', 'Computer Vision",3D Face Reconstruction,AFLW2000-3D,Mean NME ,2,3.9625
"Robots', 'Computer Vision",3D Face Reconstruction,Florence,Mean NME ,1,3.56
"Robots', 'Computer Vision",3D Face Reconstruction,Florence,Mean NME ,2,3.7551
"Robots', 'Computer Vision",3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.89
"Robots', 'Computer Vision",3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,1.91
"Robots', 'Computer Vision",3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),1,1.38
"Robots', 'Computer Vision",3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),2,1.53
"Robots', 'Computer Vision",3D Shape Reconstruction,ApolloCar3D,A3DP,1,20.21
"Robots', 'Computer Vision",3D Shape Reconstruction,Pix3D,CD,1,0.119
"Robots', 'Computer Vision",3D Shape Reconstruction,Pix3D,EMD,1,0.118
"Robots', 'Computer Vision",3D Shape Reconstruction,Pix3D,IoU,1,0.282
"Robots', 'Computer Vision",3D Shape Reconstruction,Pix3D,CD,2,0.125
"Robots', 'Computer Vision",3D Shape Reconstruction,Pix3D,EMD,2,0.128
"Robots', 'Computer Vision",3D Shape Reconstruction,Pix3D,IoU,2,N/A
"Robots', 'Computer Vision",3D Object Classification,3R-Scan,Top-10 Accuracy,1,0.8
"Robots', 'Computer Vision",3D Object Classification,3R-Scan,Top-5 Accuracy,1,0.7
"Robots', 'Computer Vision",3D Object Classification,3R-Scan,Top-10 Accuracy,2,0.78
"Robots', 'Computer Vision",3D Object Classification,3R-Scan,Top-5 Accuracy,2,0.68
"Robots', 'Computer Vision",3D Object Classification,ModelNet10,Accuracy,1,93.8
"Robots', 'Computer Vision",3D Object Classification,ModelNet10,Accuracy,2,90
"Robots', 'Computer Vision",3D Object Classification,ModelNet40,Classification Accuracy,1,89.9
"Robots', 'Computer Vision",3D Object Classification,ModelNet40,Classification Accuracy,2,89.3
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@1,1,0.53
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@16,1,0.85
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@2,1,0.62
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@32,1,0.90
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@4,1,0.71
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@8,1,0.78
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@1,2,0.42
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@16,2,0.71
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@2,2,0.51
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@32,2,0.78
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@4,2,0.57
"Robots', 'Computer Vision",3D Shape Classification,Pix3D,R@8,2,0.64
"Robots', 'Computer Vision",3D FACE MODELING,LFW,1-of-100 Accuracy,1,70
"Robots', 'Computer Vision",3D Scene Reconstruction,10-Monty-Hall,0..5sec,1,4
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),AED,1,0.152
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),AKD,1,5.58
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),L1,1,0.047
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),MKR,1,0.027
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),AED,2,0.172
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),AKD,2,6.53
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),L1,2,0.056
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (256),MKR,2,0.033
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,AED,1,0.163
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,AKD,1,7.07
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,L1,1,0.033
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,MKR,1,0.014
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,AED,2,0.114
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,AKD,2,3.75
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,L1,2,0.026
"Robots', 'Computer Vision",Video Reconstruction,TED-talks,MKR,2,0.007
"Robots', 'Computer Vision",Video Reconstruction,MGif,L1,1,0.0206
"Robots', 'Computer Vision",Video Reconstruction,MGif,L1,2,0.0223
"Robots', 'Computer Vision",Video Reconstruction,VoxCeleb,AED,1,0.133
"Robots', 'Computer Vision",Video Reconstruction,VoxCeleb,AKD,1,1.28
"Robots', 'Computer Vision",Video Reconstruction,VoxCeleb,L1,1,0.040
"Robots', 'Computer Vision",Video Reconstruction,VoxCeleb,AED,2,0.134
"Robots', 'Computer Vision",Video Reconstruction,VoxCeleb,AKD,2,1.27
"Robots', 'Computer Vision",Video Reconstruction,VoxCeleb,L1,2,0.041
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),AED,1,0.172
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),AKD,1,13.86
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),L1,1,0.064
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),MKR,1,0.043
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),AED,2,0.203
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),AKD,2,17.12
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),L1,2,0.075
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD (512),MKR,2,0.066
"Robots', 'Computer Vision",Video Reconstruction,Tai-Chi-HD,L1,1,0.063
"Robots', 'Computer Vision",3D Point Cloud Matching,Faust,L2,1,cm
"Robots', 'Computer Vision",3D Feature Matching,3DMatch Benchmark,Average Recall,1,0.9578
Computer Vision,License Plate Recognition,SSIG-SegPlate,Rank-1 Recognition Rate,1,98.2
Computer Vision,License Plate Recognition,SSIG-SegPlate,Rank-1 Recognition Rate,2,85.45
Computer Vision,License Plate Recognition,UCSD-Stills,Rank-1 Recognition Rate,1,98
Computer Vision,License Plate Recognition,AOLP,Rank-1 Recognition Rate,1,99.2
Computer Vision,License Plate Recognition,EnglishLP,Rank-1 Recognition Rate,1,95.7
Computer Vision,License Plate Recognition,OpenALPR-EU,Rank-1 Recognition Rate,1,97.8
Computer Vision,License Plate Recognition,AOLP-RP,Average Recall,1,99.18
Computer Vision,License Plate Recognition,AOLP-RP,Average Recall,2,98.36
Computer Vision,License Plate Recognition,ChineseLP,Rank-1 Recognition Rate,1,97.5
Computer Vision,License Plate Recognition,Chinese License Plates,GFLOPs,1,0.34
Computer Vision,License Plate Recognition,Chinese License Plates,GFLOPs,2,0.94
Computer Vision,License Plate Recognition,UFPR-ALPR,Rank-1 Recognition Rate,1,90
Computer Vision,License Plate Recognition,UFPR-ALPR,Rank-1 Recognition Rate,2,64.89
Computer Vision,License Plate Recognition,Caltech Cars,Rank-1 Recognition Rate,1,98.7
Computer Vision,Camera shot segmentation,SoccerNet-v2,mIoU,1,47.3
Computer Vision,Camera shot segmentation,SoccerNet-v2,mIoU,2,35.8
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",Accuracy (Test),1,71.56
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",Accuracy (Test),2,70.61
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",Accuracy (Val),2,71.14
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",Search time (s),2,28926
Methodology,Neural Architecture Search,Food-101,Accuracy (%),1,89.4
Methodology,Neural Architecture Search,Food-101,FLOPS,1,361M
Methodology,Neural Architecture Search,Food-101,PARAMS,1,4.5M
Methodology,Neural Architecture Search,Food-101,Accuracy (%),2,89.0
Methodology,Neural Architecture Search,Food-101,FLOPS,2,299M
Methodology,Neural Architecture Search,Food-101,PARAMS,2,3.9M
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-10",Acc. (test),1,93.29
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-10",Kendall's Tau,1,0.53
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-10",Pearson R,1,0.72
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-10",Spearman's Rho,1,0.73
Methodology,Neural Architecture Search,CIFAR-10 Image Classification,FLOPS,1,468M
Methodology,Neural Architecture Search,CIFAR-10 Image Classification,Params,1,6.9M
Methodology,Neural Architecture Search,CIFAR-10 Image Classification,Percentage error,1,1.6
Methodology,Neural Architecture Search,CIFAR-10 Image Classification,FLOPS,2,392M
Methodology,Neural Architecture Search,CIFAR-10 Image Classification,Params,2,6.2M
Methodology,Neural Architecture Search,CIFAR-10 Image Classification,Percentage error,2,1.8
Methodology,Neural Architecture Search,CIFAR-100,FLOPS,1,796M
Methodology,Neural Architecture Search,CIFAR-100,PARAMS,1,9.0M
Methodology,Neural Architecture Search,CIFAR-100,Percentage Error,1,11.7
Methodology,Neural Architecture Search,CIFAR-100,FLOPS,2,492M
Methodology,Neural Architecture Search,CIFAR-100,PARAMS,2,7.8M
Methodology,Neural Architecture Search,CIFAR-100,Percentage Error,2,12.3
Methodology,Neural Architecture Search,CIFAR-10,FLOPS,1,579M
Methodology,Neural Architecture Search,CIFAR-10,Parameters,1,3.6M
Methodology,Neural Architecture Search,CIFAR-10,Search Time (GPU days),1,0.8
Methodology,Neural Architecture Search,CIFAR-10,Top-1 Error Rate,1,1.98
Methodology,Neural Architecture Search,CIFAR-10,FLOPS,2,200M
Methodology,Neural Architecture Search,CIFAR-10,Parameters,2,2.1M
Methodology,Neural Architecture Search,CIFAR-10,Top-1 Error Rate,2,2.0
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",Accuracy (Test),1,93.51
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",Accuracy (val),1,90.00
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",Search time (s),1,28926
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",Accuracy (Test),2,92.63
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",Accuracy (val),2,89.90
Methodology,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",Search time (s),2,2.3
Methodology,Neural Architecture Search,Stanford Cars,Accuracy (%),1,92.9
Methodology,Neural Architecture Search,Stanford Cars,FLOPS,1,369M
Methodology,Neural Architecture Search,Stanford Cars,PARAMS,1,3.7M
Methodology,Neural Architecture Search,Stanford Cars,Accuracy (%),2,92.6
Methodology,Neural Architecture Search,Stanford Cars,FLOPS,2,289M
Methodology,Neural Architecture Search,Stanford Cars,PARAMS,2,3.5M
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-100",Acc. (test),1,70.86
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-100",Kendall's Tau,1,0.59
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-100",Pearson R,1,0.79
Methodology,Neural Architecture Search,"NATS-Bench Size, CIFAR-100",Spearman's Rho,1,0.76
Methodology,Neural Architecture Search,Oxford-IIIT Pets,Accuracy (%),1,94.3
Methodology,Neural Architecture Search,Oxford-IIIT Pets,FLOPS,1,744M
Methodology,Neural Architecture Search,Oxford-IIIT Pets,PARAMS,1,8.5M
Methodology,Neural Architecture Search,Oxford-IIIT Pets,Accuracy (%),2,94.1
Methodology,Neural Architecture Search,Oxford-IIIT Pets,FLOPS,2,471M
Methodology,Neural Architecture Search,Oxford-IIIT Pets,PARAMS,2,5.7M
Methodology,Neural Architecture Search,ImageNet,Accuracy,1,80.6
Methodology,Neural Architecture Search,ImageNet,MACs,1,596M
Methodology,Neural Architecture Search,ImageNet,Top-1 Error Rate,1,19.4
Methodology,Neural Architecture Search,ImageNet,Accuracy,2,80.5
Methodology,Neural Architecture Search,ImageNet,MACs,2,600M
Methodology,Neural Architecture Search,ImageNet,Params,2,9.1M
Methodology,Neural Architecture Search,ImageNet,Top-1 Error Rate,2,19.5
Methodology,Neural Architecture Search,Oxford 102 Flowers,Accuracy (%),1,98.3
Methodology,Neural Architecture Search,Oxford 102 Flowers,FLOPS,1,400M
Methodology,Neural Architecture Search,Oxford 102 Flowers,PARAMS,1,4.2M
Methodology,Neural Architecture Search,Oxford 102 Flowers,Accuracy (%),2,98.1
Methodology,Neural Architecture Search,Oxford 102 Flowers,FLOPS,2,250M
Methodology,Neural Architecture Search,Oxford 102 Flowers,PARAMS,2,3.7M
Methodology,Neural Architecture Search,MNIST,R2,1,0.9314
Methodology,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",Accuracy (Test),1,46.38
Methodology,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",Search time (s),1,151200
Methodology,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",Accuracy (Test),2,46.37
Methodology,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",Search time (s),2,75600
Methodology,Neural Architecture Search,DTD,Accuracy (%),1,79.1
Methodology,Neural Architecture Search,DTD,FLOPS,1,560M
Methodology,Neural Architecture Search,DTD,PARAMS,1,6.3M
Methodology,Neural Architecture Search,DTD,Accuracy (%),2,78.4
Methodology,Neural Architecture Search,DTD,FLOPS,2,347M
Methodology,Neural Architecture Search,DTD,PARAMS,2,4.1M
Methodology,Neural Architecture Search,FGVC Aircraft,Accuracy (%),1,90.8
Methodology,Neural Architecture Search,FGVC Aircraft,FLOPS,1,581M
Methodology,Neural Architecture Search,FGVC Aircraft,PARAMS,1,5.3M
Methodology,Neural Architecture Search,FGVC Aircraft,Accuracy (%),2,90.1
Methodology,Neural Architecture Search,FGVC Aircraft,FLOPS,2,388M
Methodology,Neural Architecture Search,FGVC Aircraft,PARAMS,2,5.1M
Methodology,Neural Architecture Search,STL-10,Accuracy (%),1,97.9
Methodology,Neural Architecture Search,STL-10,FLOPS,1,573M
Methodology,Neural Architecture Search,STL-10,PARAMS,1,7.5M
Methodology,Neural Architecture Search,STL-10,Accuracy (%),2,97.8
Methodology,Neural Architecture Search,STL-10,FLOPS,2,436M
Methodology,Neural Architecture Search,STL-10,PARAMS,2,7.5M
Methodology,Neural Architecture Search,CINIC-10,Accuracy (%),1,94.8
Methodology,Neural Architecture Search,CINIC-10,FLOPS,1,710M
Methodology,Neural Architecture Search,CINIC-10,PARAMS,1,9.1M
Methodology,Neural Architecture Search,CINIC-10,Accuracy (%),2,94.3
Methodology,Neural Architecture Search,CINIC-10,FLOPS,2,501M
Methodology,Neural Architecture Search,CINIC-10,PARAMS,2,8.1M
Methodology,Neural Architecture Search,LIDC-IDRI,F1 score,1,0.8929
Methodology,Neural Architecture Search,LIDC-IDRI,Specificity (VEB+),1,95.04
Methodology,Hyperparameter Optimization,Bayesmark,Mean,1,100.117
Methodology,Hyperparameter Optimization,Bayesmark,Mean,2,
Computer Vision,Vehicle Re-Identification,VRAI test-dev,CMC1,1,0.8
Computer Vision,Vehicle Re-Identification,VRAI test-dev,CMC10,1,0.95
Computer Vision,Vehicle Re-Identification,VRAI test-dev,CMC5,1,0.89
Computer Vision,Vehicle Re-Identification,VRAI test-dev,MAP,1,0.78
Computer Vision,Vehicle Re-Identification,VRAI test-dev,CMC1,2,0.78
Computer Vision,Vehicle Re-Identification,VRAI test-dev,CMC10,2,0.95
Computer Vision,Vehicle Re-Identification,VRAI test-dev,CMC5,2,0.89
Computer Vision,Vehicle Re-Identification,VRAI test-dev,MAP,2,0.78
Computer Vision,Vehicle Re-Identification,VeRi-Wild Small,Rank1,1,96.5
Computer Vision,Vehicle Re-Identification,VeRi-Wild Small,Rank5,1,99.2
Computer Vision,Vehicle Re-Identification,VeRi-Wild Small,mAP,1,86.9
Computer Vision,Vehicle Re-Identification,VRAI test,CMC1,1,0.81
Computer Vision,Vehicle Re-Identification,VRAI test,CMC10,1,0.94
Computer Vision,Vehicle Re-Identification,VRAI test,CMC5,1,0.9
Computer Vision,Vehicle Re-Identification,VRAI test,MAP,1,0.79
Computer Vision,Vehicle Re-Identification,VRAI test,CMC1,2,0.68
Computer Vision,Vehicle Re-Identification,VRAI test,CMC10,2,0.89
Computer Vision,Vehicle Re-Identification,VRAI test,CMC5,2,0.81
Computer Vision,Vehicle Re-Identification,VRAI test,MAP,2,0.69
Computer Vision,Vehicle Re-Identification,VeRi,Rank-1,1,96.78
Computer Vision,Vehicle Re-Identification,VeRi,mAP,1,83.41
Computer Vision,Vehicle Re-Identification,VeRi,mAP,2,82.2
Computer Vision,Vehicle Re-Identification,VehicleID Large,Rank-1,1,91.9
Computer Vision,Vehicle Re-Identification,VehicleID Large,Rank-5,1,96.2
Computer Vision,Vehicle Re-Identification,VehicleID Large,Rank-1,2,80.5
Computer Vision,Vehicle Re-Identification,VehicleID Large,Rank-5,2,94.6
Computer Vision,Vehicle Re-Identification,VehicleID Large,Rank1,2,80.5
Computer Vision,Vehicle Re-Identification,VehicleID Large,Rank5,2,94.6
Computer Vision,Vehicle Re-Identification,VeRi-Wild Medium,Rank1,1,95.2
Computer Vision,Vehicle Re-Identification,VeRi-Wild Medium,Rank5,1,98.3
Computer Vision,Vehicle Re-Identification,VeRi-Wild Medium,mAP,1,82.5
Computer Vision,Vehicle Re-Identification,CityFlow,mAP,1,61.34
Computer Vision,Vehicle Re-Identification,VeRi-776,mAP,1,87.1
Computer Vision,Vehicle Re-Identification,VeRi-776,Rank-1,2,96.78
Computer Vision,Vehicle Re-Identification,VeRi-776,mAP,2,83.41
Computer Vision,Vehicle Re-Identification,VeRi-Wild Large,Rank1,1,92.5
Computer Vision,Vehicle Re-Identification,VeRi-Wild Large,Rank5,1,97.2
Computer Vision,Vehicle Re-Identification,VeRi-Wild Large,mAP,1,75.9
Computer Vision,Vehicle Re-Identification,VehicleID Small,Rank-1,1,94.9
Computer Vision,Vehicle Re-Identification,VehicleID Small,Rank-5,1,97.6
Computer Vision,Vehicle Re-Identification,VehicleID Small,Rank-1,2,87.9
Computer Vision,Vehicle Re-Identification,VehicleID Small,Rank-5,2,97.8
Computer Vision,Vehicle Re-Identification,VehicleID Small,Rank1,2,87.9
Computer Vision,Vehicle Re-Identification,VehicleID Small,Rank5,2,97.8
Computer Vision,Vehicle Re-Identification,VehicleID Medium,Rank-1,1,93.3
Computer Vision,Vehicle Re-Identification,VehicleID Medium,Rank-5,1,96.4
Computer Vision,Vehicle Re-Identification,VehicleID Medium,Rank-1,2,82.8
Computer Vision,Vehicle Re-Identification,VehicleID Medium,Rank-5,2,96.2
Computer Vision,Vehicle Re-Identification,VehicleID Medium,Rank1,2,82.8
Computer Vision,Vehicle Re-Identification,VehicleID Medium,Rank5,2,96.2
"Robots', 'Computer Vision",Autonomous Flight (Dense Forest),mtrl-auto-uav,NI,1,31
Natural Language Processing,Unsupervised KG-to-text,WebNLG v2.1,BLEU,1,37.7
Natural Language Processing,Unsupervised KG-to-text,VG graph-text,BLEU,1,23.2
Playing Games,Game of Doom,ViZDoom Basic Scenario,Average Score,1,82.2
Playing Games,Game of Go,ELO Ratings,ELO Rating,1,5185
Playing Games,Game of Shogi,ELO Ratings,ELO Rating,1,4650
Computer Vision,Homography Estimation,COCO 2014,MACE,1,0.92
Playing Games,Starcraft II,CollectMineralShards,Max Score,1,137
Playing Games,Starcraft II,MoveToBeacon,Max Score,1,35
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Turkish),F1,1,81.9
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Turkish),F1,2,59.3
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1,F1,1,81.3
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1,F1,2,77.7
Natural Language Processing,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,Laptop (F1),1,87.4
Natural Language Processing,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant (F1),1,92.0
Natural Language Processing,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,Laptop (F1),2,86.09
Natural Language Processing,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,Mean F1 (Laptop + Restaurant),2,84.215
Natural Language Processing,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant (F1),2,82.34
Natural Language Processing,Aspect Extraction, SemEval 2015 Task 12,Restaurant (F1),1,80.3
Natural Language Processing,Aspect Extraction, SemEval 2015 Task 12,Restaurant (F1),2,72.7
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Spanish),F1,1,79.9
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Spanish),F1,2,74.3
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Dutch),F1,1,80.5
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Dutch),F1,2,72.9
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Russian),F1,1,79.4
Natural Language Processing,Aspect Extraction,SemEval-2016 Task 5 Subtask 1 (Russian),F1,2,71.8
Natural Language Processing,Extract Aspect, SemEval 2015 Task 12,F1 score,1,0.70
Natural Language Processing,Extract Aspect, SemEval 2015 Task 12,F1 score,2,0.63
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Laptop 2014 (F1),1,80.55
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant 2014 (F1),1,85.38
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant 2015 (F1),1,80.52
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant 2016 (F1),1,87.92
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Laptop 2014 (F1),2,79.90
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant 2014 (F1),2,83.73
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant 2015 (F1),2,74.50
Natural Language Processing,Aspect-oriented  Opinion Extraction,SemEval 2014 Task 4 Sub Task 2,Restaurant 2016 (F1),2,83.33
Natural Language Processing,Extract aspect-polarity tuple, SemEval 2015 Task 12,F1 score,1,0.51
Natural Language Processing,Abstract Anaphora Resolution,The ARRAU Corpus,Average Precision,1,43.83
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,DAC (K=6),1,0.9883
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,MR (K=1),1,0.5395
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,MR (K=6),1,0.1143
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,brier-minFDE (K=6),1,1.7568
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minADE (K=1),1,1.5599
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minADE (K=6),1,0.8014
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minFDE (K=1),1,3.3814
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minFDE (K=6),1,1.2139
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,DAC (K=6),2,0.9878
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,MR (K=1),2,0.5378
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,MR (K=6),2,0.1155
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,brier-minFDE (K=6),2,1.7654
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minADE (K=1),2,1.5349
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minADE (K=6),2,0.8053
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minFDE (K=1),2,3.3216
"Computer Vision', 'Miscellaneous",Motion Forecasting,Argoverse CVPR 2020,minFDE (K=6),2,1.1385
Computer Vision,3D Instance Segmentation,ScanNet(v2),Mean AP @ 0.5,1,63.8
Computer Vision,3D Instance Segmentation,ScanNet(v2),Mean AP @ 0.5,2,63.6
Computer Vision,3D Instance Segmentation,ScanNet(v2),mAP,2,40.7
Computer Vision,3D Instance Segmentation,ScanNet,mAP,1,0.447
Computer Vision,3D Instance Segmentation,S3DIS,mPrec,1,72.8
Computer Vision,3D Instance Segmentation,S3DIS,mRec,1,60.3
Computer Vision,3D Instance Segmentation,S3DIS,mPrec,2,69.6
Computer Vision,3D Instance Segmentation,S3DIS,mRec,2,69.2
Computer Vision,3D Instance Segmentation,MitoEM,AP75-H-Test,1,0.829
Computer Vision,3D Instance Segmentation,MitoEM,AP75-H-Val,1,0.828
Computer Vision,3D Instance Segmentation,MitoEM,AP75-R-Test,1,0.851
Computer Vision,3D Instance Segmentation,MitoEM,AP75-R-Val,1,0.917
Computer Vision,3D Instance Segmentation,SceneNN,mAP@0.5,1,47.1
Computer Vision,3D Instance Segmentation,SceneNN,mAP@0.5,2,12.1
Computer Vision,Referring Expression Segmentation,RefCOCO+ testA,Overall IoU,1,60.06
Computer Vision,Referring Expression Segmentation,RefCOCO+ testA,Overall IoU,2,53.44
Computer Vision,Referring Expression Segmentation,RefCOCO testA,Overall IoU,1,69.33
Computer Vision,Referring Expression Segmentation,RefCOCO testA,Overall IoU,2,64.53
Computer Vision,Referring Expression Segmentation,RefCOCO+ test B,Overall IoU,1,45.49
Computer Vision,Referring Expression Segmentation,RefCOCO+ test B,Overall IoU,2,43.23
Computer Vision,Referring Expression Segmentation,RefCOCOg-val,Overall IoU,1,49.49
Computer Vision,Referring Expression Segmentation,RefCoCo val,Overall IoU,1,65.76
Computer Vision,Referring Expression Segmentation,RefCoCo val,Precision@0.5,1,77.82
Computer Vision,Referring Expression Segmentation,RefCoCo val,Precision@0.6,1,72.99
Computer Vision,Referring Expression Segmentation,RefCoCo val,Precision@0.7,1,65.34
Computer Vision,Referring Expression Segmentation,RefCoCo val,Precision@0.8,1,50.73
Computer Vision,Referring Expression Segmentation,RefCoCo val,Precision@0.9,1,20.03
Computer Vision,Referring Expression Segmentation,RefCoCo val,Overall IoU,2,61.36
Computer Vision,Referring Expression Segmentation,CLEVR-Ref+,IoU,1,80.6
Computer Vision,Referring Expression Segmentation,A2D Sentences,AP,1,0.494
Computer Vision,Referring Expression Segmentation,A2D Sentences,IoU mean,1,0.655
Computer Vision,Referring Expression Segmentation,A2D Sentences,IoU overall,1,0.644
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.5,1,0.704
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.6,1,0.677
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.7,1,0.617
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.8,1,0.489
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.9,1,0.171
Computer Vision,Referring Expression Segmentation,A2D Sentences,AP,2,0.404
Computer Vision,Referring Expression Segmentation,A2D Sentences,IoU mean,2,0.573
Computer Vision,Referring Expression Segmentation,A2D Sentences,IoU overall,2,0.653
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.5,2,0.655
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.6,2,0.592
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.7,2,0.506
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.8,2,0.342
Computer Vision,Referring Expression Segmentation,A2D Sentences,Precision@0.9,2,0.098
Computer Vision,Referring Expression Segmentation,ReferIt,Overall IoU,1,68.58
Computer Vision,Referring Expression Segmentation,A2Dre test,Mean IoU,1,33.2
Computer Vision,Referring Expression Segmentation,A2Dre test,Overall IoU,1,47.5
Computer Vision,Referring Expression Segmentation,RefCOCO testB,Overall IoU,1,60.93
Computer Vision,Referring Expression Segmentation,RefCOCO testB,Overall IoU,2,59.64
Computer Vision,Referring Expression Segmentation,J-HMDB,AP,1,0.433
Computer Vision,Referring Expression Segmentation,J-HMDB,IoU mean,1,0.655
Computer Vision,Referring Expression Segmentation,J-HMDB,IoU overall,1,0.644
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.5,1,0.880
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.6,1,0.796
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.7,1,0.566
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.8,1,0.147
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.9,1,0.002
Computer Vision,Referring Expression Segmentation,J-HMDB,AP,2,0.342
Computer Vision,Referring Expression Segmentation,J-HMDB,IoU mean,2,0.617
Computer Vision,Referring Expression Segmentation,J-HMDB,IoU overall,2,0.616
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.5,2,0.813
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.6,2,0.657
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.7,2,0.371
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.8,2,0.07
Computer Vision,Referring Expression Segmentation,J-HMDB,Precision@0.9,2,0.000
Computer Vision,Referring Expression Segmentation,PhraseCut,Mean IoU,1,53.7
Computer Vision,Referring Expression Segmentation,PhraseCut,Pr@0.5,1,57.5
Computer Vision,Referring Expression Segmentation,PhraseCut,Pr@0.7,1,39.9
Computer Vision,Referring Expression Segmentation,PhraseCut,Pr@0.9,1,11.9
Computer Vision,Referring Expression Segmentation,PhraseCut,Mean IoU,2,41.3
Computer Vision,Referring Expression Segmentation,PhraseCut,Pr@0.5,2,42.9
Computer Vision,Referring Expression Segmentation,PhraseCut,Pr@0.7,2,27.8
Computer Vision,Referring Expression Segmentation,PhraseCut,Pr@0.9,2,5.9
Computer Vision,Referring Expression Segmentation,DAVIS 2017 (val),J&F 1st frame,1,44.5
Computer Vision,Referring Expression Segmentation,DAVIS 2017 (val),J&F Full video,1,45.1
Computer Vision,Referring Expression Segmentation,DAVIS 2017 (val),J&F 1st frame,2,44.1
Computer Vision,Referring Expression Segmentation,RefCOCO+ val,Overall IoU,1,53.97
Computer Vision,Referring Expression Segmentation,RefCOCO+ val,Overall IoU,2,49.56
Computer Vision,Real-time Instance Segmentation,MSCOCO,AP50,1,55.6
Computer Vision,Real-time Instance Segmentation,MSCOCO,AP75,1,37.6
Computer Vision,Real-time Instance Segmentation,MSCOCO,APL,1,56.8
Computer Vision,Real-time Instance Segmentation,MSCOCO,APM,1,38.3
Computer Vision,Real-time Instance Segmentation,MSCOCO,APS,1,11.2
Computer Vision,Real-time Instance Segmentation,MSCOCO,Frame (fps),1,27.0
Computer Vision,Real-time Instance Segmentation,MSCOCO,mask AP,1,35.4
Computer Vision,Real-time Instance Segmentation,MSCOCO,Frame (fps),2,33.3
Computer Vision,Real-time Instance Segmentation,MSCOCO,mask AP,2,35.2
Computer Vision,3D Semantic Instance Segmentation,ScanNetV2,mAP@0.50,1,61.1
Computer Vision,3D Semantic Instance Segmentation,ScanNetV2,mAP@0.50,2,54.9
Computer Vision,3D Semantic Instance Segmentation,ScanNetV1,mAP@0.25,1,35.1
Computer Vision,Unseen Object Instance Segmentation,WISDOM,mAP @0.5:0.95,1,51.6
Computer Vision,Human Instance Segmentation,OCHuman,AP,1,0.552
Computer Vision,One-Shot Instance Segmentation,COCO,AP 0.5,1,14.5
Computer Vision,MS-SSIM,DocUNet,MS-SSIM,1,0.47
Computer Vision,MS-SSIM,DocUNet,MS-SSIM,2,0.45
Computer Vision,3D Human Pose Tracking,CMU Panoptic,3DMOTA,1,94.1
Computer Vision,Activity Prediction,ActEV,mAP,1,0.192
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,F-Measure (Seen),1,87.9
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,F-Measure (Unseen),1,87.3
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Jaccard (Seen),1,83.2
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Jaccard (Unseen),1,79.0
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Overall,1,84.3
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Speed  (FPS),1,13.4
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,F-Measure (Seen),2,87.5
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,F-Measure (Unseen),2,86.7
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Jaccard (Seen),2,82.5
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Jaccard (Unseen),2,77.9
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Overall,2,83.7
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Params,2,8.3M
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube-VOS,Speed  (FPS),2,15.2
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Decay),1,85.3
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Mean),1,88.6
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Recall),1,94.6
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),J&F,1,85.3
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Decay),1,6.2
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Mean),1,82.0
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Recall),1,91.3
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Speed (FPS),1,20.2
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Decay),2,8.2
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Mean),2,87.4
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Recall),2,93.1
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),J&F,2,84.5
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Decay),2,7.0
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Mean),2,81.7
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Recall),2,90.9
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (val),Speed (FPS),2,11.2
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube,mIoU,1,0.821
Computer Vision,Semi-Supervised Video Object Segmentation,YouTube,mIoU,2,0.796
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Decay),1,10.3
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Mean),1,83.5
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Recall),1,89.7
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),J&F,1,79.9
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Decay),1,10.5
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Mean),1,76.3
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Recall),1,85.5
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Mean),2,81.6
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),J&F,2,78.0
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Mean),2,74.4
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,F-measure (Decay),1,4.3
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,F-measure (Mean),1,93.0
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,F-measure (Recall),1,97.1
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,J&F,1,91.7
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Jaccard (Decay),1,4.1
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Jaccard (Mean),1,90.4
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Jaccard (Recall),1,98.1
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Speed (FPS),1,26.9
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,F-measure (Decay),2,5.1
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,F-measure (Mean),2,92.4
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,F-measure (Recall),2,96.4
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,J&F,2,91.0
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Jaccard (Decay),2,6.6
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Jaccard (Mean),2,89.7
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Jaccard (Recall),2,97.5
Computer Vision,Semi-Supervised Video Object Segmentation,DAVIS 2016,Speed (FPS),2,16.9
Computer Vision,Unsupervised Video Object Segmentation,YouTube,mIoU,1,0.705
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Decay),1,6.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Mean),1,62.0
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Recall),1,66.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),J&F,1,58.0
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Decay),1,3.5
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Mean),1,54.0
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Recall),1,62.9
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Decay),2,2.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Mean),2,49.0
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),F-measure (Recall),2,51.5
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),J&F,2,45.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Decay),2,2.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Mean),2,42.1
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (test-dev),Jaccard (Recall),2,48.5
Computer Vision,Unsupervised Video Object Segmentation,DAVIS-2016,J&F,1,84.5
Computer Vision,Unsupervised Video Object Segmentation,FBMS,Jaccard (Mean),1,77.6
Computer Vision,Unsupervised Video Object Segmentation,FBMS,Jaccard (Mean),2,75.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,F-measure (Decay),1,4.3
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,F-measure (Mean),1,86.2
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,F-measure (Recall),1,94.1
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,J&F,1,86.1
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,Jaccard (Decay),1,5.7
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,Jaccard (Mean),1,86.0
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,Jaccard (Recall),1,96.1
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,F-measure (Decay),2,3.0
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,F-measure (Mean),2,85.4
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,F-measure (Recall),2,93.2
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,J&F,2,85.6
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,Jaccard (Decay),2,3.4
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,Jaccard (Mean),2,85.8
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2016,Jaccard (Recall),2,96.2
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Decay),1,1.5
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Mean),1,72.7
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Recall),1,80.3
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),J&F,1,70.7
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Decay),1,0.9
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Mean),1,68.7
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Recall),1,77.7
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Decay),2,0.01
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Mean),2,69.3
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),F-measure (Recall),2,76.9
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),J&F,2,67.9
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Decay),2,0.2
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Mean),2,66.4
Computer Vision,Unsupervised Video Object Segmentation,DAVIS 2017 (val),Jaccard (Recall),2,76.4
Computer Vision,Unsupervised Video Object Segmentation,SegTrack v2,Mean IoU,1,72.2
Computer Vision,Unsupervised Video Object Segmentation,SegTrack v2,Mean IoU,2,70.9
Computer Vision,Video Salient Object Detection,MCL,AVERAGE MAE,1,0.021
Computer Vision,Video Salient Object Detection,MCL,MAX E-MEASURE,1,0.911
Computer Vision,Video Salient Object Detection,MCL,S-Measure,1,0.856
Computer Vision,Video Salient Object Detection,MCL,AVERAGE MAE,2,0.026
Computer Vision,Video Salient Object Detection,MCL,MAX E-MEASURE,2,0.889
Computer Vision,Video Salient Object Detection,MCL,MAX F-MEASURE,2,0.773
Computer Vision,Video Salient Object Detection,MCL,S-Measure,2,0.819
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,Average MAE,1,0.114
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,S-Measure,1,0.619
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,max E-measure,1,0.696
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,Average MAE,2,0.131
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,S-Measure,2,0.608
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,max E-measure,2,0.698
Computer Vision,Video Salient Object Detection,ViSal,Average MAE,1,0.021
Computer Vision,Video Salient Object Detection,ViSal,S-Measure,1,0.942
Computer Vision,Video Salient Object Detection,ViSal,max E-measure,1,0.980
Computer Vision,Video Salient Object Detection,ViSal,Average MAE,2,0.032
Computer Vision,Video Salient Object Detection,ViSal,S-Measure,2,0.907
Computer Vision,Video Salient Object Detection,ViSal,max E-measure,2,0.846
Computer Vision,Video Salient Object Detection,FBMS-59,AVERAGE MAE,1,0.040
Computer Vision,Video Salient Object Detection,FBMS-59,MAX E-MEASURE,1,0.926
Computer Vision,Video Salient Object Detection,FBMS-59,MAX F-MEASURE,1,0.865
Computer Vision,Video Salient Object Detection,FBMS-59,S-Measure,1,0.879
Computer Vision,Video Salient Object Detection,FBMS-59,AVERAGE MAE,2,0.054
Computer Vision,Video Salient Object Detection,FBMS-59,MAX F-MEASURE,2,0.861
Computer Vision,Video Salient Object Detection,FBMS-59,S-Measure,2,0.870
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,Average MAE,1,0.084
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,S-Measure,1,0.755
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max E-Measure,1,0.806
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max F-Measure,1,0.659
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,Average MAE,2,0.114
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,S-Measure,2,0.706
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max E-Measure,2,0.749
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max F-Measure,2,0.591
Computer Vision,Video Salient Object Detection,UVSD,Average MAE,1,0.018
Computer Vision,Video Salient Object Detection,UVSD,S-Measure,1,0.901
Computer Vision,Video Salient Object Detection,UVSD,max E-measure,1,0.975
Computer Vision,Video Salient Object Detection,UVSD,Average MAE,2,0.025
Computer Vision,Video Salient Object Detection,UVSD,S-Measure,2,0.860
Computer Vision,Video Salient Object Detection,UVSD,max E-measure,2,0.939
Computer Vision,Video Salient Object Detection,SegTrack v2,AVERAGE MAE,1,0.024
Computer Vision,Video Salient Object Detection,SegTrack v2,S-Measure,1,0.864
Computer Vision,Video Salient Object Detection,SegTrack v2,max E-measure,1,0.935
Computer Vision,Video Salient Object Detection,SegTrack v2,AVERAGE MAE,2,0.023
Computer Vision,Video Salient Object Detection,SegTrack v2,MAX F-MEASURE,2,0.801
Computer Vision,Video Salient Object Detection,SegTrack v2,S-Measure,2,0.850
Computer Vision,Video Salient Object Detection,SegTrack v2,max E-measure,2,0.917
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,Average MAE,1,0.117
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,S-Measure,1,0.661
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,max E-measure,1,0.723
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,Average MAE,2,0.132
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,S-Measure,2,0.649
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,max E-measure,2,0.698
Computer Vision,Video Salient Object Detection,VOS-T,Average MAE,1,0.049
Computer Vision,Video Salient Object Detection,VOS-T,S-Measure,1,0.872
Computer Vision,Video Salient Object Detection,VOS-T,max E-measure,1,0.856
Computer Vision,Video Salient Object Detection,VOS-T,Average MAE,2,0.074
Computer Vision,Video Salient Object Detection,VOS-T,S-Measure,2,0.819
Computer Vision,Video Salient Object Detection,VOS-T,max E-measure,2,0.839
Computer Vision,Video Salient Object Detection,DAVIS-2016,AVERAGE MAE,1,0.028
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX E-MEASURE,1,0.948
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX F-MEASURE,1,0.861
Computer Vision,Video Salient Object Detection,DAVIS-2016,S-Measure,1,0.893
Computer Vision,Video Salient Object Detection,DAVIS-2016,AVERAGE MAE,2,0.031
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX E-MEASURE,2,0.966
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX F-MEASURE,2,0.862
Computer Vision,Video Salient Object Detection,DAVIS-2016,S-Measure,2,0.887
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,AUC-J,1,0.849
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,AUC-J&F,1,0.879
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,J&F@60s,1,0.885
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,J@60s,1,0.854
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,AUC-J,2,0.820
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,AUC-J&F,2,0.856
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,J&F@60s,2,0.866
Computer Vision,Interactive Video Object Segmentation,DAVIS 2017,J@60s,2,0.829
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,Conn,1,20.83
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,Grad,1,11.57
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,MSE(10^3),1,4.7
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,SAD,1,27.87
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,Conn,2,36.03
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,Grad,2,28.70
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,MSE(10^3),2,11.0
Computer Vision,Semantic Image Matting,Semantic Image Matting Dataset,SAD,2,39.28
"Speech', 'Methodology",Unsupervised MNIST,MNIST,Accuracy,1,99.3
"Speech', 'Methodology",Unsupervised MNIST,MNIST,Accuracy,2,98.7
"Speech', 'Methodology",Acoustic Unit Discovery,ZeroSpeech 2019 English,ABX-across,1,13.4
"Speech', 'Methodology",Acoustic Unit Discovery,ZeroSpeech 2019 English,ABX-across,2,14
"Adversarial', 'Methodology",Website Fingerprinting Defense,Website Traffic Data on Tor,Accuracy (%),1,42
Miscellaneous,Stress-Strain Relation,Non-Linear Elasticity Benchmark,Time (ms),1,3.5
Miscellaneous,Stress-Strain Relation,Non-Linear Elasticity Benchmark,Time (ms),2,7.18
Computer Vision,Displaced People Recognition,Human Righst Archive (HRA),coverage,1,58
"Natural Language Processing', 'Methodology",Dialogue Generation,Amazon-5,1 in 10 R@2,1,5
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Activity),F1,1,11.43
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Activity),Precision,1,16.84
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Activity),Recall,1,9.72
"Natural Language Processing', 'Methodology",Dialogue Generation,Reddit (multi-ref),interest (human),1,2.53
"Natural Language Processing', 'Methodology",Dialogue Generation,Reddit (multi-ref),relevance (human),1,2.72
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Entity),F1,1,3.72
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Entity),Precision,1,4.91
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Entity),Recall,1,3.36
"Natural Language Processing', 'Methodology",Dialogue Generation,Twitter Dialogue (Noun),F1,1,4.63
"Natural Language Processing', 'Methodology",Dialogue Generation,Twitter Dialogue (Noun),Precision,1,4.82
"Natural Language Processing', 'Methodology",Dialogue Generation,Twitter Dialogue (Noun),Recall,1,5.22
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Tense),Accuracy,1,29.01
"Natural Language Processing', 'Methodology",Dialogue Generation,Ubuntu Dialogue (Cmd),Accuracy,1,95.04
"Natural Language Processing', 'Methodology",Dialogue Generation,Persona-Chat,Avg F1,1,19.77
"Natural Language Processing', 'Methodology",Dialogue Generation,Persona-Chat,Avg F1,2,19.09
"Natural Language Processing', 'Methodology",Dialogue Generation,Twitter Dialogue (Tense),Accuracy,1,34.48
Computer Vision,3D Multi-Person Pose Estimation (root-relative),MuPoTS-3D,3DPCK,1,87.5
Computer Vision,3D Multi-Person Pose Estimation (root-relative),MuPoTS-3D,3DPCK,2,85.3
Computer Vision,3D Multi-Person Pose Estimation (root-relative),MuPoTS-3D,MPJPE,2,103
Computer Vision,3D Multi-Person Pose Estimation (absolute),MuPoTS-3D,3DPCK,1,45.7
Computer Vision,3D Multi-Person Pose Estimation (absolute),MuPoTS-3D,3DPCK,2,43.8
Natural Language Processing,KB-to-Language Generation,Wikipedia Person and Animal Dataset,BLEU,1,23.2
Natural Language Processing,KB-to-Language Generation,Wikipedia Person and Animal Dataset,METEOR,1,23.4
Natural Language Processing,KB-to-Language Generation,Wikipedia Person and Animal Dataset,ROUGE,1,42.0
Computer Vision,Image Generation,Indian Celebs 256 x 256,FID,1,28.44
Computer Vision,Image Generation,LSUN Bedroom 128 x 128,FID,1,14.3
Computer Vision,Image Generation,LSUN Bedroom 64 x 64,FID,1,9.5
Computer Vision,Image Generation,LSUN Bedroom 64 x 64,FID,2,11.4
Computer Vision,Image Generation,Oxford 102 Flowers 256 x 256,FID,1,19.60
Computer Vision,Image Generation,LSUN Car 512 x 384,FID,1,2.32
Computer Vision,Image Generation,ImageNet 128x128,FID,1,2.97
Computer Vision,Image Generation,ImageNet 128x128,FID,2,5.7
Computer Vision,Image Generation,ImageNet 128x128,IS,2,124.5
Computer Vision,Image Generation,CIFAR-10 (20% data),FID,1,12.15
Computer Vision,Image Generation,CIFAR-10 (20% data),FID,2,12.84
Computer Vision,Image Generation,FFHQ 1024 x 1024,FID,1,3.55
Computer Vision,Image Generation,FFHQ 1024 x 1024,bits/dimension,2,2.42
Computer Vision,Image Generation,CIFAR-100,FID,1,2.99
Computer Vision,Image Generation,CIFAR-100,FID,2,7.22
Computer Vision,Image Generation,FFHQ,FID,1,2.84
Computer Vision,Image Generation,FFHQ,FID,2,2.99
Computer Vision,Image Generation,FFHQ 256 x 256,FID,1,3.31
Computer Vision,Image Generation,FFHQ 256 x 256,FID,2,3.35
Computer Vision,Image Generation,Binarized MNIST,nats,1,76.93
Computer Vision,Image Generation,Binarized MNIST,bits/dimension,2,0.143
Computer Vision,Image Generation,Binarized MNIST,nats,2,77.58
Computer Vision,Image Generation,ImageNet 256x256,FID,1,3.94
Computer Vision,Image Generation,ImageNet 256x256,Inception score,1,215.84
Computer Vision,Image Generation,ImageNet 256x256,FID,2,4.59
Computer Vision,Image Generation,ImageNet 256x256,Inception score,2,186.7
Computer Vision,Image Generation,Landscapes 256 x 256,FID,1,3.61
Computer Vision,Image Generation,Oxford 102 Flowers 128x128,FID,1,115.838
Computer Vision,Image Generation,Oxford 102 Flowers 128x128,IS,1,3
Computer Vision,Image Generation,LSUN Cat 256 x 256,FID,1,5.57
Computer Vision,Image Generation,LSUN Cat 256 x 256,FID,2,6.93
Computer Vision,Image Generation,FFHQ 128 x 128,FID,1,3.98
Computer Vision,Image Generation,FFHQ 512 x 512,FID,1,3.08
Computer Vision,Image Generation,CelebA 128x128,FID,1,2.95
Computer Vision,Image Generation,CelebA 128x128,Inception score,1,3.43
Computer Vision,Image Generation,CelebA 128x128,FID,2,19.9
Computer Vision,Image Generation,ImageNet 64x64,Bits per dim,1,3.35
Computer Vision,Image Generation,ImageNet 64x64,Bits per dim,2,3.43
Computer Vision,Image Generation,CLEVR,FID-5k-training-steps,1,9.1679
Computer Vision,Image Generation,CLEVR,FID-5k-training-steps,2,16.0534
Computer Vision,Image Generation,MNIST,bits/dimension,1,0.65
Computer Vision,Image Generation,MNIST,bits/dimension,2,0.97
Computer Vision,Image Generation,CIFAR-10,FID,1,2.10
Computer Vision,Image Generation,CIFAR-10,bits/dimension,1,3.43
Computer Vision,Image Generation,CIFAR-10,FID,2,2.17
Computer Vision,Image Generation,CIFAR-10,bits/dimension,2,2.95
Computer Vision,Image Generation,LSUN Horse 256 x 256,FID,1,2.57
Computer Vision,Image Generation,LSUN Horse 256 x 256,FID,2,3.43
Computer Vision,Image Generation,CelebA-HQ 256x256,FID,1,7.16
Computer Vision,Image Generation,CelebA-HQ 256x256,FID,2,7.22
Computer Vision,Image Generation,RC-49,Intra-FID,1,0.307
Computer Vision,Image Generation,RC-49,Intra-FID,2,0.389
Computer Vision,Image Generation,25% ImageNet 128x128,FID,1,11.16
Computer Vision,Image Generation,25% ImageNet 128x128,IS,1,84.7
Computer Vision,Image Generation,ImageNet 512x512,FID,1,3.85
Computer Vision,Image Generation,ImageNet 512x512,Inception score,1,221.72
Computer Vision,Image Generation,ImageNet 512x512,FID,2,7.72
Computer Vision,Image Generation,ImageNet 512x512,Inception score,2,172.71
Computer Vision,Image Generation,CelebA-HQ 128x128,FID,1,2.03
Computer Vision,Image Generation,CelebA-HQ 128x128,Inception score,1,3.33
Computer Vision,Image Generation,CelebA-HQ 128x128,FID,2,5.74
Computer Vision,Image Generation,CelebA-HQ 1024x1024,FID,1,5.06
Computer Vision,Image Generation,CelebA-HQ 1024x1024,FID,2,5.5
Computer Vision,Image Generation,LSUN Car 256 x 256,FID,1,2.32
Computer Vision,Image Generation,Fashion-MNIST,FID,1,10.3
Computer Vision,Image Generation,Fashion-MNIST,FID,2,13.7
Computer Vision,Image Generation,LSUN Bedroom 256 x 256,FID,1,1.90
Computer Vision,Image Generation,LSUN Bedroom 256 x 256,FID,2,2.65
Computer Vision,Image Generation,CelebA 256x256,bpd,1,0.61
Computer Vision,Image Generation,CelebA 256x256,bpd,2,0.67
Computer Vision,Image Generation,CUB 128 x 128,FID,1,11.25
Computer Vision,Image Generation,CUB 128 x 128,Inception score,1,52.53
Computer Vision,Image Generation,CUB 128 x 128,FID,2,13.20
Computer Vision,Image Generation,CUB 128 x 128,Inception score,2,47.32
Computer Vision,Image Generation,Satellite-Landscapes 256 x 256,FID,1,48.47
Computer Vision,Image Generation,Stacked MNIST,FID,1,12.96
Computer Vision,Image Generation,Stacked MNIST,Inception score,1,8.15
Computer Vision,Image Generation,Stacked MNIST,FID,2,23.965
Computer Vision,Image Generation,Satellite-Buildings 256 x 256,FID,1,69.67
Computer Vision,Image Generation,CAT 256x256,FID,1,10.16
Computer Vision,Image Generation,CAT 256x256,FID,2,32.11
Computer Vision,Image Generation,LSUN Churches 256 x 256,FID,1,2.92
Computer Vision,Image Generation,LSUN Churches 256 x 256,FID,2,3.86
Computer Vision,Image Generation,Cityscapes-5K 256x512,FID,1,65.49
Computer Vision,Image Generation,ObjectsRoom,FID,1,52.6
Computer Vision,Image Generation,ObjectsRoom,FID,2,62.8
Computer Vision,Image Generation,STL-10,FID,1,15.17
Computer Vision,Image Generation,STL-10,Inception score,1,11.01
Computer Vision,Image Generation,STL-10,FID,2,17.68
Computer Vision,Image Generation,STL-10,Inception score,2,9.33
Computer Vision,Image Generation,Cityscapes,FID-10k-training-steps,1,5.7589
Computer Vision,Image Generation,Cityscapes,FID-10k-training-steps,2,8.35
Computer Vision,Image Generation,CelebA-HQ 64x64,FID,1,4.0
Computer Vision,Image Generation,CelebA-HQ 64x64,FID,2,5.31
Computer Vision,Image Generation,ImageNet 32x32,bpd,1,3.63
Computer Vision,Image Generation,ImageNet 32x32,bpd,2,3.76
Computer Vision,Image Generation,CelebA 64x64,FID,1,3.66
Computer Vision,Image Generation,CelebA 64x64,FID,2,5.25
Computer Vision,Image Generation,ShapeStacks,FID,1,112.7
Computer Vision,Image Generation,ShapeStacks,FID,2,186.8
Computer Vision,Image Generation,CIFAR-10 (10% data),FID,1,14.5
Computer Vision,Image Generation,CIFAR-10 (10% data),FID,2,18.7
Computer Vision,Image Generation,Stanford Dogs,FID,1,25.66
Computer Vision,Image Generation,Stanford Dogs,Inception score,1,46.92
Computer Vision,Image Generation,Stanford Dogs,FID,2,29.34
Computer Vision,Image Generation,Stanford Dogs,Inception score,2,43.16
Computer Vision,Image Generation,Cityscapes-25K 256x512,FID,1,62.97
Computer Vision,Image Generation,ImageNet - 10% labeled data,FID,1,24.38
Computer Vision,Image Generation,ImageNet - 10% labeled data,IS,1,42.3
Computer Vision,Image Generation,Stanford Cars,FID,1,16.03
Computer Vision,Image Generation,Stanford Cars,Inception score,1,32.62
Computer Vision,Image Generation,Stanford Cars,FID,2,17.63
Computer Vision,Image Generation,Stanford Cars,Inception score,2,28.62
Computer Vision,Image Generation,ADE-Indoor,FID,1,85.27
Computer Vision,Image Generation,CelebA 128 x 128,FID,1,5.74
Computer Vision,Image Generation,CelebA 128 x 128,FID,2,29.115
Computer Vision,Image Generation,Multi-dSprites,FID,1,24.9
Computer Vision,Image Generation,GQN,FID,1,80.5
Computer Vision,Image Generation,LSUN Bedroom,FID-50k,1,2.65
Computer Vision,Image Generation,LSUN Bedroom,FID-50k,2,4.9
Computer Vision,Real-Time 3D Semantic Segmentation,SemanticKITTI,Parameters (M),1,0.44
Computer Vision,Real-Time 3D Semantic Segmentation,SemanticKITTI,Speed  (FPS),1,98
Computer Vision,Real-Time 3D Semantic Segmentation,SemanticKITTI,mIoU,1,46.9
Computer Vision,Real-Time 3D Semantic Segmentation,SemanticKITTI,Parameters (M),2,1.0
Computer Vision,Real-Time 3D Semantic Segmentation,SemanticKITTI,Speed  (FPS),2,47
Computer Vision,Real-Time 3D Semantic Segmentation,SemanticKITTI,mIoU,2,55.2
Computer Vision,Multi-Frame Super-Resolution,PROBA-V,Normalized cPSNR,1,0.9336790819983855
Computer Vision,Multi-Frame Super-Resolution,PROBA-V,Normalized cPSNR,2,0.9411827883122681
Computer Vision,Self-Supervised Action Recognition,UCF101,3-fold Accuracy,1,95.5
Computer Vision,Self-Supervised Action Recognition,UCF101,Frozen,1,false
Computer Vision,Self-Supervised Action Recognition,UCF101,Pre-Training Dataset,1,IGKinetics
Computer Vision,Self-Supervised Action Recognition,UCF101,3-fold Accuracy,2,95.2
Computer Vision,Self-Supervised Action Recognition,UCF101,Frozen,2,false
Computer Vision,Self-Supervised Action Recognition,UCF101,Pre-Training Dataset,2,Audioset
Computer Vision,Self-Supervised Action Recognition,HMDB51 (finetuned),Top-1 Accuracy,1,77.8
Computer Vision,Self-Supervised Action Recognition,HMDB51 (finetuned),Top-1 Accuracy,2,70.1
Computer Vision,Self-Supervised Action Recognition,Kinetics-600,Top-1 Accuracy,1,71.4
Computer Vision,Self-Supervised Action Recognition,Kinetics-600,Top-1 Accuracy,2,70.4
Computer Vision,Self-Supervised Action Recognition,UCF101 (finetuned),3-fold Accuracy,1,95.7
Computer Vision,Self-Supervised Action Recognition,UCF101 (finetuned),3-fold Accuracy,2,95.5
Computer Vision,Self-Supervised Action Recognition,HMDB51,Frozen,1,false
Computer Vision,Self-Supervised Action Recognition,HMDB51,Pre-Training Dataset,1,Audioset
Computer Vision,Self-Supervised Action Recognition,HMDB51,Top-1 Accuracy,1,75.0
Computer Vision,Self-Supervised Action Recognition,HMDB51,Frozen,2,false
Computer Vision,Self-Supervised Action Recognition,HMDB51,Top-1 Accuracy,2,70.5
Computer Vision,3D Action Recognition,100 sleep nights of 8 caregivers,10%,1,4
Computer Vision,Action Triplet Recognition,CholecT40,mAP,1,18.95
Speech,Speech Dereverberation,Deep Noise Suppression (DNS) Challenge,PESQ,1,2.75
Speech,Speech Dereverberation,Deep Noise Suppression (DNS) Challenge,ΔPESQ,1,0.93
Speech,Speech Dereverberation,Deep Noise Suppression (DNS) Challenge,PESQ,2,1.82
Speech,Speech Dereverberation,WHAMR!,PESQ,1,3.16
Speech,Speech Dereverberation,WHAMR!,SI-SDR,1,10.4
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Macro F1,1,19.7
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Macro Precision,1,20.2
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Macro Recall,1,20.6
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Micro F1,1,25.8
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Micro Precision,1,27.4
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Micro Recall,1,24.4
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Macro F1,2,8.8
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Macro Precision,2,9.5
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Macro Recall,2,8.6
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Micro F1,2,7.5
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Micro Precision,2,6.8
Natural Language Processing,Scientific Results Extraction,"NLP-TDMS (Exp, arXiv only)",Micro Recall,2,8.4
Natural Language Processing,Scientific Results Extraction,PWC Leaderboards (restricted),Macro F1,1,21.1
Natural Language Processing,Scientific Results Extraction,PWC Leaderboards (restricted),Macro Precision,1,24
Natural Language Processing,Scientific Results Extraction,PWC Leaderboards (restricted),Macro Recall,1,21.8
Natural Language Processing,Scientific Results Extraction,PWC Leaderboards (restricted),Micro F1,1,28.7
Natural Language Processing,Scientific Results Extraction,PWC Leaderboards (restricted),Micro Precision,1,37.4
Natural Language Processing,Scientific Results Extraction,PWC Leaderboards (restricted),Micro Recall,1,23.2
Computer Vision,3D Room Layouts From A Single RGB Panorama,Realtor360,3DIoU,1,77.20
Computer Vision,3D Room Layouts From A Single RGB Panorama,Realtor360,3DIoU,2,62.77
Computer Vision,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,3DIoU,1,79.79
Computer Vision,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,3DIoU,2,79.36
Computer Vision,3D Room Layouts From A Single RGB Panorama,PanoContext,3DIoU,1,82.17
Computer Vision,3D Room Layouts From A Single RGB Panorama,PanoContext,3DIoU,2,78.79
Computer Vision,Outdoor Light Source Estimation,SUN360,Median Relighting Error,1,1.25
Computer Vision,3D Object Recognition,"SHREC11, Split10-10",Per-Class Accuracy,1,97.1
Computer Vision,3D Object Recognition,Cube Engraving,Accuracy,1,98.6
Computer Vision,3D Object Recognition,"SHREC11, Split16-4",Per-Class Accuracy,1,98.6
Computer Vision,3D Object Recognition,ModelNet40,Accuracy,1,93.8
Computer Vision,3D Object Recognition,ModelNet40,Accuracy,2,92.3
Computer Vision,Depiction Invariant Object Recognition,Photo-Art-50,Overall Accuracy,1,93.02
Computer Vision,Multi-Human Parsing,MHP v1.0,AP 0.5,1,57.09
Computer Vision,Multi-Human Parsing,MHP v1.0,AP 0.5,2,52.68
Computer Vision,Multi-Human Parsing,PASCAL-Part,AP 0.5,1,59.70
Computer Vision,Multi-Human Parsing,PASCAL-Part,AP 0.5,2,40.60
Computer Vision,Multi-Human Parsing,MHP v2.0,AP 0.5,1,25.14
Computer Vision,Multi-Human Parsing,MHP v2.0,AP 0.5,2,17.99
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Macro-F1 (20% training data),1,92.24
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Macro-F1 (60% training data),1,93.70
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Macro-F1 (80% training data),1,93.08
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Micro-F1 (20% training data),1,93.11
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Micro-F1 (80% training data),1,93.99
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Macro-F1 (20% training data),2,92.03
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Macro-F1 (60% training data),2,93.31
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Macro-F1 (80% training data),2,92.53
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Micro-F1 (20% training data),2,92.99
Graphs,Heterogeneous Node Classification,DBLP (PACT) 14k,Micro-F1 (80% training data),2,93.29
Medical,Radiologist Binary Classification,,AUC-ROC,1,0.54
Medical,Radiologist Binary Classification,,Average Precision,1,0.55
Methodology,Few-Shot Learning,Mini-ImageNet - 5-Shot Learning,Accuracy,1,92.7
Methodology,Few-Shot Learning,Mini-ImageNet - 5-Shot Learning,Accuracy,2,87.4
Methodology,Few-Shot Learning,Mini-ImageNet - 1-Shot Learning,Acc,1,67.6
"Adversarial', 'Miscellaneous",Website Fingerprinting Defense,Website Traffic Data on Tor,Accuracy (%),1,42
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),F1,1,93.38
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),Precision,1,92.98
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),Recall,1,93.85
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),F1,2,91.51
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),Precision,2,91.3
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (expanded corpus),Recall,2,91.79
Natural Language Processing,Semantic Similarity,SICK,MSE,1,0.2532
Natural Language Processing,Semantic Similarity,SICK,Pearson Correlation,1,0.8676
Natural Language Processing,Semantic Similarity,SICK,Spearman Correlation,1,0.8083
Natural Language Processing,Semantic Similarity,SICK,MSE,2,0.2687
Natural Language Processing,Semantic Similarity,SICK,Pearson Correlation,2,0.8584
Natural Language Processing,Semantic Similarity,SICK,Spearman Correlation,2,0.7916
Natural Language Processing,Semantic Similarity,BIOSSES,Pearson Correlation,1,0.9159999999999999
Natural Language Processing,Semantic Similarity,CHIP-STS,Macro F1,1,85.6
Natural Language Processing,Semantic Similarity,ClinicalSTS,Pearson Correlation,1,85.62
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),F1,1,89.75
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),Precision,1,88.93
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),Recall,1,90.76
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),F1,2,89.3
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),Precision,2,87.99
Natural Language Processing,Semantic Similarity,Annotated corpus for semantic similarity of clinical trial outcomes (original corpus),Recall,2,90.78
Natural Language Processing,Semantic Similarity,MedSTS,Pearson Correlation,1,0.848
Computer Vision,Video Salient Object Detection,MCL,AVERAGE MAE,1,0.021
Computer Vision,Video Salient Object Detection,MCL,MAX E-MEASURE,1,0.911
Computer Vision,Video Salient Object Detection,MCL,S-Measure,1,0.856
Computer Vision,Video Salient Object Detection,MCL,AVERAGE MAE,2,0.026
Computer Vision,Video Salient Object Detection,MCL,MAX E-MEASURE,2,0.889
Computer Vision,Video Salient Object Detection,MCL,MAX F-MEASURE,2,0.773
Computer Vision,Video Salient Object Detection,MCL,S-Measure,2,0.819
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,Average MAE,1,0.114
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,S-Measure,1,0.619
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,max E-measure,1,0.696
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,Average MAE,2,0.131
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,S-Measure,2,0.608
Computer Vision,Video Salient Object Detection,DAVSOD-Difficult20,max E-measure,2,0.698
Computer Vision,Video Salient Object Detection,ViSal,Average MAE,1,0.021
Computer Vision,Video Salient Object Detection,ViSal,S-Measure,1,0.942
Computer Vision,Video Salient Object Detection,ViSal,max E-measure,1,0.980
Computer Vision,Video Salient Object Detection,ViSal,Average MAE,2,0.032
Computer Vision,Video Salient Object Detection,ViSal,S-Measure,2,0.907
Computer Vision,Video Salient Object Detection,ViSal,max E-measure,2,0.846
Computer Vision,Video Salient Object Detection,FBMS-59,AVERAGE MAE,1,0.040
Computer Vision,Video Salient Object Detection,FBMS-59,MAX E-MEASURE,1,0.926
Computer Vision,Video Salient Object Detection,FBMS-59,MAX F-MEASURE,1,0.865
Computer Vision,Video Salient Object Detection,FBMS-59,S-Measure,1,0.879
Computer Vision,Video Salient Object Detection,FBMS-59,AVERAGE MAE,2,0.054
Computer Vision,Video Salient Object Detection,FBMS-59,MAX F-MEASURE,2,0.861
Computer Vision,Video Salient Object Detection,FBMS-59,S-Measure,2,0.870
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,Average MAE,1,0.084
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,S-Measure,1,0.755
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max E-Measure,1,0.806
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max F-Measure,1,0.659
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,Average MAE,2,0.114
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,S-Measure,2,0.706
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max E-Measure,2,0.749
Computer Vision,Video Salient Object Detection,DAVSOD-easy35,max F-Measure,2,0.591
Computer Vision,Video Salient Object Detection,UVSD,Average MAE,1,0.018
Computer Vision,Video Salient Object Detection,UVSD,S-Measure,1,0.901
Computer Vision,Video Salient Object Detection,UVSD,max E-measure,1,0.975
Computer Vision,Video Salient Object Detection,UVSD,Average MAE,2,0.025
Computer Vision,Video Salient Object Detection,UVSD,S-Measure,2,0.860
Computer Vision,Video Salient Object Detection,UVSD,max E-measure,2,0.939
Computer Vision,Video Salient Object Detection,SegTrack v2,AVERAGE MAE,1,0.024
Computer Vision,Video Salient Object Detection,SegTrack v2,S-Measure,1,0.864
Computer Vision,Video Salient Object Detection,SegTrack v2,max E-measure,1,0.935
Computer Vision,Video Salient Object Detection,SegTrack v2,AVERAGE MAE,2,0.023
Computer Vision,Video Salient Object Detection,SegTrack v2,MAX F-MEASURE,2,0.801
Computer Vision,Video Salient Object Detection,SegTrack v2,S-Measure,2,0.850
Computer Vision,Video Salient Object Detection,SegTrack v2,max E-measure,2,0.917
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,Average MAE,1,0.117
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,S-Measure,1,0.661
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,max E-measure,1,0.723
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,Average MAE,2,0.132
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,S-Measure,2,0.649
Computer Vision,Video Salient Object Detection,DAVSOD-Normal25,max E-measure,2,0.698
Computer Vision,Video Salient Object Detection,VOS-T,Average MAE,1,0.049
Computer Vision,Video Salient Object Detection,VOS-T,S-Measure,1,0.872
Computer Vision,Video Salient Object Detection,VOS-T,max E-measure,1,0.856
Computer Vision,Video Salient Object Detection,VOS-T,Average MAE,2,0.074
Computer Vision,Video Salient Object Detection,VOS-T,S-Measure,2,0.819
Computer Vision,Video Salient Object Detection,VOS-T,max E-measure,2,0.839
Computer Vision,Video Salient Object Detection,DAVIS-2016,AVERAGE MAE,1,0.028
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX E-MEASURE,1,0.948
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX F-MEASURE,1,0.861
Computer Vision,Video Salient Object Detection,DAVIS-2016,S-Measure,1,0.893
Computer Vision,Video Salient Object Detection,DAVIS-2016,AVERAGE MAE,2,0.031
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX E-MEASURE,2,0.966
Computer Vision,Video Salient Object Detection,DAVIS-2016,MAX F-MEASURE,2,0.862
Computer Vision,Video Salient Object Detection,DAVIS-2016,S-Measure,2,0.887
Computer Vision,Co-Salient Object Detection,CoSal2015,Average MAE,1,0.071
Computer Vision,Co-Salient Object Detection,CoSal2015,S-Measure,1,0.844
Computer Vision,Co-Salient Object Detection,CoSal2015,max E-Measure,1,0.887
Computer Vision,Co-Salient Object Detection,CoSal2015,max F-Measure,1,0.844
Computer Vision,Co-Salient Object Detection,CoSal2015,Average MAE,2,0.077
Computer Vision,Co-Salient Object Detection,CoSal2015,S-Measure,2,0.836
Computer Vision,Co-Salient Object Detection,CoSal2015,max E-Measure,2,0.882
Computer Vision,Co-Salient Object Detection,CoSal2015,max F-Measure,2,0.832
Computer Vision,Co-Salient Object Detection,CoCA,Mean F-measure,1,0.504
Computer Vision,Co-Salient Object Detection,CoCA,S-Measure,1,0.658
Computer Vision,Co-Salient Object Detection,CoCA,max F-Measure,1,0.513
Computer Vision,Co-Salient Object Detection,CoCA,mean E-Measure,1,0.701
Computer Vision,Co-Salient Object Detection,CoCA,Mean F-measure,2,0.390
Computer Vision,Co-Salient Object Detection,CoCA,S-Measure,2,0.627
Computer Vision,Co-Salient Object Detection,CoCA,max F-Measure,2,0.499
Computer Vision,Co-Salient Object Detection,CoCA,mean E-Measure,2,0.606
Computer Vision,Co-Salient Object Detection,iCoSeg,Average MAE,1,0.060
Computer Vision,Co-Salient Object Detection,iCoSeg,S-Measure,1,0.875
Computer Vision,Co-Salient Object Detection,iCoSeg,max E-Measure,1,0.912
Computer Vision,Co-Salient Object Detection,iCoSeg,max F-Measure,1,0.876
Computer Vision,Co-Salient Object Detection,CoSOD3k,Average MAE,1,0.092
Computer Vision,Co-Salient Object Detection,CoSOD3k,S-Measure,1,0.762
Computer Vision,Co-Salient Object Detection,CoSOD3k,max E-Measure,1,0.825
Computer Vision,Co-Salient Object Detection,CoSOD3k,max F-Measure,1,0.736
Computer Vision,Co-Salient Object Detection,CoSOD3k,Average MAE,2,0.119
Computer Vision,Co-Salient Object Detection,CoSOD3k,S-Measure,2,0.7619
Computer Vision,Co-Salient Object Detection,CoSOD3k,max E-Measure,2,0.793
Computer Vision,Co-Salient Object Detection,CoSOD3k,max F-Measure,2,0.702
"Computer Vision', 'Natural Language Processing",Multimodal Lexical Translation,MultiSubs English-French,ALI,1,0.81
"Computer Vision', 'Natural Language Processing",Multimodal Lexical Translation,MultiSubs English-German,ALI,1,0.94
"Computer Vision', 'Natural Language Processing",Multimodal Lexical Translation,MultiSubs English-Spanish,ALI,1,0.81
"Computer Vision', 'Natural Language Processing",Multimodal Lexical Translation,MultiSubs English-Portuguese,ALI,1,0.80
Natural Language Processing,Speculation Scope Resolution,BioScope : Abstracts,F1,1,97.87
Natural Language Processing,Speculation Scope Resolution,BioScope : Full Papers,F1,1,96.91
Natural Language Processing,Speculation Scope Resolution,SFU Review Corpus,F1,1,91.00
Computer Vision,3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.91
Computer Vision,3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,2.08
Computer Vision,3D Face Reconstruction,AFLW2000-3D,Mean NME ,1,3.56
Computer Vision,3D Face Reconstruction,AFLW2000-3D,Mean NME ,2,3.9625
Computer Vision,3D Face Reconstruction,Florence,Mean NME ,1,3.56
Computer Vision,3D Face Reconstruction,Florence,Mean NME ,2,3.7551
Computer Vision,3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.89
Computer Vision,3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,1.91
Computer Vision,3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),1,1.38
Computer Vision,3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),2,1.53
Computer Vision,3D Object Reconstruction From A Single Image,RenderPeople,Chamfer (cm),1,1.41
Computer Vision,3D Object Reconstruction From A Single Image,RenderPeople,Point-to-surface distance (cm),1,1.44
Computer Vision,3D Object Reconstruction From A Single Image,RenderPeople,Surface normal consistency,1,0.111
Computer Vision,3D Object Reconstruction From A Single Image,RenderPeople,Chamfer (cm),2,1.55
Computer Vision,3D Object Reconstruction From A Single Image,RenderPeople,Point-to-surface distance (cm),2,1.66
Computer Vision,3D Object Reconstruction From A Single Image,RenderPeople,Surface normal consistency,2,0.117
Computer Vision,3D Object Reconstruction From A Single Image,BUFF,Chamfer (cm),1,1.73
Computer Vision,3D Object Reconstruction From A Single Image,BUFF,Point-to-surface distance (cm),1,1.63
Computer Vision,3D Object Reconstruction From A Single Image,BUFF,Surface normal consistency,1,0.133
Computer Vision,3D Object Reconstruction From A Single Image,BUFF,Chamfer (cm),2,1.81
Computer Vision,3D Object Reconstruction From A Single Image,BUFF,Point-to-surface distance (cm),2,1.88
Computer Vision,3D Object Reconstruction From A Single Image,BUFF,Surface normal consistency,2,0.147
"Miscellaneous', 'Graphs",NMR J-coupling,QM9,avg. log MAE,1,3.241
"Miscellaneous', 'Graphs",NMR J-coupling,QM9,avg. log MAE,2,3.453
Computer Vision,Drone navigation,University-1652,AP,1,58.74
Computer Vision,Drone navigation,University-1652,recall@1,1,71.18
Computer Vision,Drone-view target localization,University-1652,AP,1,63.13
Computer Vision,Drone-view target localization,University-1652,recall@1,1,58.49
"Computer Vision', 'Natural Language Processing",Knowledge Graph Embedding,FB15k,MRR,1,0.815
Computer Vision,Lip to Speech Synthesis,LRW,ESTOI,1,0.344
Computer Vision,Lip to Speech Synthesis,LRW,PESQ,1,1.197
Computer Vision,Lip to Speech Synthesis,LRW,STOI,1,0.543
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (EH),ESTOI,1,0.22
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (EH),PESQ,1,1.367
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (EH),STOI,1,0.369
Computer Vision,Speaker-Specific Lip to Speech Synthesis,TCD-TIMIT corpus (mixed-speech),ESTOI,1,36.5
Computer Vision,Speaker-Specific Lip to Speech Synthesis,TCD-TIMIT corpus (mixed-speech),PESQ,1,1.35
Computer Vision,Speaker-Specific Lip to Speech Synthesis,TCD-TIMIT corpus (mixed-speech),STOI,1,0.558
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (Chem),ESTOI,1,0.284
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (Chem),PESQ,1,1.3
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (Chem),STOI,1,0.416
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (HS),ESTOI,1,0.311
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (HS),PESQ,1,1.29
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (HS),STOI,1,0.446
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (Chess),ESTOI,1,0.29
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (Chess),PESQ,1,1.4
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (Chess),STOI,1,0.418
Computer Vision,Speaker-Specific Lip to Speech Synthesis,GRID corpus (mixed-speech),ESTOI,1,0.535
Computer Vision,Speaker-Specific Lip to Speech Synthesis,GRID corpus (mixed-speech),PESQ,1,1.772
Computer Vision,Speaker-Specific Lip to Speech Synthesis,GRID corpus (mixed-speech),STOI,1,0.731
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (DL),ESTOI,1,0.183
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (DL),PESQ,1,1.671
Computer Vision,Speaker-Specific Lip to Speech Synthesis,Lip2Wav (DL),STOI,1,0.282
"Computer Vision', 'Speech",3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.91
"Computer Vision', 'Speech",3D Face Reconstruction,Stirling-LQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,2.08
"Computer Vision', 'Speech",3D Face Reconstruction,AFLW2000-3D,Mean NME ,1,3.56
"Computer Vision', 'Speech",3D Face Reconstruction,AFLW2000-3D,Mean NME ,2,3.9625
"Computer Vision', 'Speech",3D Face Reconstruction,Florence,Mean NME ,1,3.56
"Computer Vision', 'Speech",3D Face Reconstruction,Florence,Mean NME ,2,3.7551
"Computer Vision', 'Speech",3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),1,1.89
"Computer Vision', 'Speech",3D Face Reconstruction,Stirling-HQ (FG2018 3D face reconstruction challenge),Mean Reconstruction Error (mm),2,1.91
"Computer Vision', 'Speech",3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),1,1.38
"Computer Vision', 'Speech",3D Face Reconstruction,NoW Benchmark,Mean Reconstruction Error (mm),2,1.53
"Computer Vision', 'Speech",3D Face Animation,2D-3D-S,1*1,1,5
Natural Language Processing,Spoken Language Understanding,Fluent Speech Commands,Accuracy (%),1,98.8
Computer Vision,Monocular 3D Object Detection,KITTI Pedestrian Hard,AP Hard,1,6.76
Computer Vision,Monocular 3D Object Detection,KITTI Pedestrian Hard,AP Hard,2,4.82
Computer Vision,Monocular 3D Object Detection,Virtual KITTI 2,mAP@0.3,1,86.6
Computer Vision,Monocular 3D Object Detection,Virtual KITTI 2,mAP@0.5,1,66.7
Computer Vision,Monocular 3D Object Detection,KITTI Cyclist Moderate,AP Medium,1,3.41
Computer Vision,Monocular 3D Object Detection,KITTI Pedestrian Moderate,AP Medium,1,8.14
Computer Vision,Monocular 3D Object Detection,KITTI Cars Easy,AP Easy,1,19.17
Computer Vision,Monocular 3D Object Detection,KITTI Pedestrian Easy,AP Easy,1,12.87
Computer Vision,Monocular 3D Object Detection,KITTI Cars Moderate,AP Medium,1,13.41
Computer Vision,Monocular 3D Object Detection,KITTI Cars Moderate,AP Medium,2,13.17
Computer Vision,Monocular 3D Object Detection,KITTI Cyclist Easy,AP Easy,1,7.00
Computer Vision,Monocular 3D Object Detection,KITTI Cyclist Hard,AP Hard,1,3.30
Computer Vision,Monocular 3D Object Detection,KITTI Pedestrians Moderate val,AP Medium,1,5.43
Computer Vision,Monocular 3D Object Detection,Google Objectron,AP at 10' Elevation error,1,0.8584
Computer Vision,Monocular 3D Object Detection,Google Objectron,AP at 15' Azimuth error,1,0.7844
Computer Vision,Monocular 3D Object Detection,Google Objectron,Average Precision at 0.5 3D IoU,1,0.6512
Computer Vision,Monocular 3D Object Detection,Google Objectron,MPE,1,0.0467
Computer Vision,Monocular 3D Object Detection,Google Objectron,AP at 10' Elevation error,2,0.6658
Computer Vision,Monocular 3D Object Detection,Google Objectron,AP at 15' Azimuth error,2,0.5088
Computer Vision,Monocular 3D Object Detection,Google Objectron,Average Precision at 0.5 3D IoU,2,0.4624
Computer Vision,Monocular 3D Object Detection,Google Objectron,MPE,2,0.1001
Computer Vision,Monocular 3D Object Detection,SUN RGB-D,AP@0.15,1,44.91
Computer Vision,Monocular 3D Object Detection,SUN RGB-D,AP@0.15,2,39.09
Computer Vision,Monocular 3D Object Detection,KITTI Cars Hard,AP Hard,1,11.46
Computer Vision,Monocular 3D Object Detection,KITTI Cars Hard,AP Hard,2,9.94
Knowledge Base,Inductive knowledge graph completion,WN18RR-ind,Hit@10,1,0.58
Knowledge Base,Inductive knowledge graph completion,WN18RR-ind,Hits@3,1,0.361
Knowledge Base,Inductive knowledge graph completion,WN18RR-ind,MRR,1,0.285
Knowledge Base,Inductive knowledge graph completion,WN18RR-ind,Hits@1,2,0.156
Knowledge Base,Inductive knowledge graph completion,Wikidata5m-ind,Hits@1,1,0.289
Knowledge Base,Inductive knowledge graph completion,Wikidata5m-ind,MRR,1,0.493
Knowledge Base,Inductive knowledge graph completion,Wikidata5m-ind,Hits@1,2,0.222
Knowledge Base,Inductive knowledge graph completion,Wikidata5m-ind,Hits@10,2,0.73
Knowledge Base,Inductive knowledge graph completion,Wikidata5m-ind,Hits@3,2,0.514
Knowledge Base,Inductive knowledge graph completion,Wikidata5m-ind,MRR,2,0.402
Knowledge Base,Inductive knowledge graph completion,FB15k-237-ind,Hit@1,1,0.113
Knowledge Base,Inductive knowledge graph completion,FB15k-237-ind,Hits@10,1,0.363
Knowledge Base,Inductive knowledge graph completion,FB15k-237-ind,Hits@3,1,0.213
Knowledge Base,Inductive knowledge graph completion,FB15k-237-ind,MRR,1,0.195
Playing Games,NetHack Score,NetHack Learning Environment,Average Score,1,780
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Avg,1,81.7
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Question Answering,1,71.9
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Sentence Retrieval,1,90.8
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Sentence-pair Classification,1,88.3
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Structured Prediction,1,80.6
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Avg,2,81.6
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Question Answering,2,72.5
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Sentence Retrieval,2,93.7
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Sentence-pair Classification,2,88.4
Natural Language Processing,Zero-Shot Cross-Lingual Transfer,XTREME,Structured Prediction,2,76.2
Natural Language Processing,Cross-Lingual NER,CoNLL German,F1,1,75.33
Natural Language Processing,Cross-Lingual NER,CoNLL German,F1,2,74.97
Natural Language Processing,Cross-Lingual NER,MSRA,F1,1,77.89
Natural Language Processing,Cross-Lingual NER,MSRA,F1,2,76.42
Natural Language Processing,Cross-Lingual NER,NER,F1,1,69.2
Natural Language Processing,Cross-Lingual NER,NER,F1,2,68.9
Natural Language Processing,Cross-Lingual NER,Europeana French,F1,1,55.3
Natural Language Processing,Cross-Lingual NER,Europeana French,F1,2,50.89
Natural Language Processing,Cross-Lingual NER,NoDaLiDa Norwegian Bokmål,F1,1,81.17
Natural Language Processing,Cross-Lingual NER,CoNLL Spanish,F1,1,79.31
Natural Language Processing,Cross-Lingual NER,CoNLL Spanish,F1,2,78
Natural Language Processing,Cross-Lingual NER,CoNLL Dutch,F1,1,83.35
Natural Language Processing,Cross-Lingual NER,CoNLL Dutch,F1,2,82.9
Natural Language Processing,Cross-Lingual NER,WikiAnn NER,F1,1,67.7
Computer Vision,3D Canonical Hand Pose Estimation,Ego3DHands,AUC,1,0.681
Computer Vision,3D Canonical Hand Pose Estimation,RHP,AUC,1,0.942
Computer Vision,3D Canonical Hand Pose Estimation,STB,AUC,1,0.995
Computer Vision,3D Shape Reconstruction From A Single 2D Image,ApolloCar3D,A3DP,1,20.21
Computer Vision,Rice Grain Disease Detection,Rice Grain Disease Dataset,mAP,1,88.24
Computer Vision,One-shot visual object segmentation,YouTube-VOS,F-Measure (Seen),1,67.2
Computer Vision,One-shot visual object segmentation,YouTube-VOS,F-Measure (Unseen),1,51
Computer Vision,One-shot visual object segmentation,YouTube-VOS,Jaccard (Seen),1,63.6
Computer Vision,One-shot visual object segmentation,YouTube-VOS,Jaccard (Unseen),1,45.5
Computer Vision,One-shot visual object segmentation,YouTube-VOS,F-Measure (Seen),2,60.5
Computer Vision,One-shot visual object segmentation,YouTube-VOS,F-Measure (Unseen),2,60.7
Computer Vision,One-shot visual object segmentation,YouTube-VOS,Jaccard (Seen),2,59.8
Computer Vision,One-shot visual object segmentation,YouTube-VOS,Jaccard (Unseen),2,54.2
"Natural Language Processing', 'Methodology",Multimodal Text and Image Classification,CD18,Accuracy,1,88
"Natural Language Processing', 'Methodology",Multimodal Text and Image Classification,CD18,F-measure (%),1,88.3
"Natural Language Processing', 'Methodology",Multimodal Text and Image Classification,CUB-200-2011,Accuracy,1,96.81
"Natural Language Processing', 'Methodology",Multimodal Text and Image Classification,Food-101,Accuracy (%),1,92.5
"Natural Language Processing', 'Methodology",Multimodal Text and Image Classification,Food-101,Accuracy (%),2,84.59
Computer Vision,Camouflaged Object Segmentation,CAMO,E-Measure,1,88.2
Computer Vision,Camouflaged Object Segmentation,CAMO,MAE,1,0.070
Computer Vision,Camouflaged Object Segmentation,CAMO,S-Measure,1,82.0
Computer Vision,Camouflaged Object Segmentation,CAMO,Weighted F-Measure,1,74.3
Computer Vision,Camouflaged Object Segmentation,CAMO,E-Measure,2,84.9
Computer Vision,Camouflaged Object Segmentation,CAMO,MAE,2,0.077
Computer Vision,Camouflaged Object Segmentation,CAMO,S-Measure,2,78.5
Computer Vision,Camouflaged Object Segmentation,CAMO,Weighted F-Measure,2,71.9
Computer Vision,Camouflaged Object Segmentation,COD,E-Measure,1,88.7
Computer Vision,Camouflaged Object Segmentation,COD,MAE,1,0.037
Computer Vision,Camouflaged Object Segmentation,COD,S-Measure,1,81.5
Computer Vision,Camouflaged Object Segmentation,COD,Weighted F-Measure,1,68.0
Computer Vision,Camouflaged Object Segmentation,COD,E-Measure,2,80.6
Computer Vision,Camouflaged Object Segmentation,COD,MAE,2,0.051
Computer Vision,Camouflaged Object Segmentation,COD,S-Measure,2,77.1
Computer Vision,Camouflaged Object Segmentation,COD,Weighted F-Measure,2,55.1
Time Series,COVID-19 Modelling,WHO-COVID19 Dataset,KS-GoF,1,0.99
Computer Vision,Accident Anticipation,CCD,AP,1,99.6
Computer Vision,Accident Anticipation,CCD,TTA,1,4.87
Computer Vision,Accident Anticipation,CCD,AP,2,99.5
Computer Vision,Accident Anticipation,CCD,TTA,2,4.74
Methodology,Personalized Federated Learning,Omniglot,ACC@1-50Clients,1,81.89
Methodology,Personalized Federated Learning,Omniglot,ACC@1-50Clients,2,72.03
Methodology,Personalized Federated Learning,CIFAR-100,ACC@1-100Clients,1,52.40
Methodology,Personalized Federated Learning,CIFAR-100,ACC@1-10Clients,1,68.15
Methodology,Personalized Federated Learning,CIFAR-100,ACC@1-50Clients,1,60.17
Methodology,Personalized Federated Learning,CIFAR-100,ACC@1-100Clients,2,53.24
Methodology,Personalized Federated Learning,CIFAR-100,ACC@1-10Clients,2,65.74
Methodology,Personalized Federated Learning,CIFAR-100,ACC@1-50Clients,2,59.46
Methodology,Personalized Federated Learning,CIFAR-10,ACC@1-100Clients,1,88.09
Methodology,Personalized Federated Learning,CIFAR-10,ACC@1-10Clients,1,92.47
Methodology,Personalized Federated Learning,CIFAR-10,ACC@1-50Clients,1,90.08
Methodology,Personalized Federated Learning,CIFAR-10,ACC@1-100Clients,2,87.97
Methodology,Personalized Federated Learning,CIFAR-10,ACC@1-10Clients,2,90.83
Methodology,Personalized Federated Learning,CIFAR-10,ACC@1-50Clients,2,88.38
Methodology,Long-tail Learning,EGTEA,Average Precision,1,63.86
Methodology,Long-tail Learning,EGTEA,Average Recall,1,66.24
Methodology,Long-tail Learning,EGTEA,Average Precision,2,63.39
Methodology,Long-tail Learning,EGTEA,Average Recall,2,63.26
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=100),Error Rate,1,50.9
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=100),Error Rate,2,52.67
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=10),Error Rate,1,11.84
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=10),Error Rate,2,11.84
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=10),Error Rate,1,36.59
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=10),Error Rate,2,38.3
Methodology,Long-tail Learning,ImageNet-LT,Per-Class Accuracy,1,56.8
Methodology,Long-tail Learning,ImageNet-LT,Per-Class Accuracy,2,55.4
Methodology,Long-tail Learning,Places-LT,Per-Class Accuracy,1,38.8
Methodology,Long-tail Learning,Places-LT,Per-Class Accuracy,2,38.1
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=100),Error Rate,1,20.37
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=100),Error Rate,2,22.97
Methodology,Long-tail learning with class descriptors,SUN-LT,Long-Tailed Accuracy,1,38.5
Methodology,Long-tail learning with class descriptors,SUN-LT,Per-Class Accuracy,1,36.1
Methodology,Long-tail learning with class descriptors,SUN-LT,Long-Tailed Accuracy,2,40.4
Methodology,Long-tail learning with class descriptors,SUN-LT,Per-Class Accuracy,2,34.8
Methodology,Long-tail learning with class descriptors,AWA-LT,Long-Tailed Accuracy,1,92.2
Methodology,Long-tail learning with class descriptors,AWA-LT,Per-Class Accuracy,1,76.2
Methodology,Long-tail learning with class descriptors,AWA-LT,Long-Tailed Accuracy,2,94.1
Methodology,Long-tail learning with class descriptors,AWA-LT,Per-Class Accuracy,2,74.1
Methodology,Long-tail learning with class descriptors,CUB-LT,Long-Tailed Accuracy,1,66.5
Methodology,Long-tail learning with class descriptors,CUB-LT,Per-Class Accuracy,1,60.1
Methodology,Long-tail learning with class descriptors,CUB-LT,Long-Tailed Accuracy,2,67.7
Methodology,Long-tail learning with class descriptors,CUB-LT,Per-Class Accuracy,2,57.8
Methodology,Long-tail learning with class descriptors,ImageNet-LT-d,Per-Class Accuracy,1,53.5
Methodology,Long-tail learning with class descriptors,ImageNet-LT-d,Per-Class Accuracy,2,51.2
Methodology,Long-tail Learning,EGTEA,Average Precision,1,63.86
Methodology,Long-tail Learning,EGTEA,Average Recall,1,66.24
Methodology,Long-tail Learning,EGTEA,Average Precision,2,63.39
Methodology,Long-tail Learning,EGTEA,Average Recall,2,63.26
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=100),Error Rate,1,50.9
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=100),Error Rate,2,52.67
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=10),Error Rate,1,11.84
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=10),Error Rate,2,11.84
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=10),Error Rate,1,36.59
Methodology,Long-tail Learning,CIFAR-100-LT (ρ=10),Error Rate,2,38.3
Methodology,Long-tail Learning,ImageNet-LT,Per-Class Accuracy,1,56.8
Methodology,Long-tail Learning,ImageNet-LT,Per-Class Accuracy,2,55.4
Methodology,Long-tail Learning,Places-LT,Per-Class Accuracy,1,38.8
Methodology,Long-tail Learning,Places-LT,Per-Class Accuracy,2,38.1
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=100),Error Rate,1,20.37
Methodology,Long-tail Learning,CIFAR-10-LT (ρ=100),Error Rate,2,22.97
Computer Vision,Intubation Support Prediction,COVID chest X-ray,AUC-ROC,1,0.84
Computer Vision,Replay Grounding,SoccerNet-v2,Average-AP,1,41.8
Computer Vision,Replay Grounding,SoccerNet-v2,Average-AP,2,24.3
Computer Vision,Hand Gesture Recognition,MGB,Accuracy,1,98.04
Computer Vision,Hand Gesture Recognition,EgoGesture,Accuracy,1,94.03
Computer Vision,Hand Gesture Recognition,EgoGesture,Accuracy,2,93.87
Computer Vision,Hand Gesture Recognition,BUAA,Accuracy,1,99.25
Computer Vision,Hand Gesture Recognition,Cambridge,Accuracy,1,98.23
Computer Vision,Hand Gesture Recognition,Cambridge,Accuracy,2,93
Computer Vision,Hand Gesture Recognition,SHREC 2017,14 gestures accuracy,1,95.9
Computer Vision,Hand Gesture Recognition,SHREC 2017,28 gestures accuracy,1,94.7
Computer Vision,Hand Gesture Recognition,SHREC 2017,14 gestures accuracy,2,94.4
Computer Vision,Hand Gesture Recognition,SHREC 2017,28 gestures accuracy,2,90.7
Computer Vision,Hand Gesture Recognition,Jester test,Top 1 Accuracy,1,96.6
Computer Vision,Hand Gesture Recognition,Jester test,Top 1 Accuracy,2,94.78
Computer Vision,Hand Gesture Recognition,NVGesture,Accuracy,1,87.9
Computer Vision,Hand Gesture Recognition,NVGesture,Accuracy,2,86.93
Computer Vision,Hand Gesture Recognition,ChaLearn val,Accuracy,1,57.4
Computer Vision,Hand Gesture Recognition,ChaLearn val,Accuracy,2,39.23
Computer Vision,Hand Gesture Recognition,DHG-28,Accuracy,1,88
Computer Vision,Hand Gesture Recognition,Jester val,Top 1 Accuracy,1,96.33
Computer Vision,Hand Gesture Recognition,Jester val,Top 5 Accuracy,1,99.86
Computer Vision,Hand Gesture Recognition,ChaLean test,Accuracy,1,56.7
Computer Vision,Hand Gesture Recognition,DHG-14,Accuracy,1,91.9
Computer Vision,Hand Gesture Recognition,Northwestern University,Accuracy,1,96.89
Computer Vision,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,1,95.9
Computer Vision,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,14 gestures accuracy,2,94.6
Computer Vision,Hand Gesture Recognition,VIVA Hand Gestures Dataset,Accuracy,1,86.08
Computer Vision,Hand Gesture Recognition,VIVA Hand Gestures Dataset,Accuracy,2,83.1
Computer Vision,Hand Gesture Recognition,SmartWatch,Accuracy,1,97.4
Graphs,Knowledge Graph Embedding,FB15k,MRR,1,0.815
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,BLEU-1,1,65.1
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,BLEU-2,1,42.6
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,BLEU-3,1,27.8
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,BLEU-4,1,17.5
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,CIDEr,1,57.2
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,METEOR,1,29.7
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,ROUGE-L,1,43.4
Computer Vision,Image Captioning,BanglaLekhaImageCaptions,SPICE,1,35.7
Computer Vision,Image Captioning,COCO Captions test,BLEU-4,1,36.5
Computer Vision,Image Captioning,COCO Captions test,CIDEr,1,116.9
Computer Vision,Image Captioning,COCO Captions test,METEOR,1,28.4
Computer Vision,Image Captioning,COCO Captions test,SPICE,1,21.2
Computer Vision,Image Captioning,AIC-ICC,BLEU,1,66.1
Computer Vision,Image Captioning,AIC-ICC,CIDEr,1,220.7
Computer Vision,Image Captioning,AIC-ICC,METEOR,1,41.1
Computer Vision,Image Captioning,AIC-ICC,ROUGE-L,1,71.9
Computer Vision,Image Captioning,TextCaps 2020,B4,1,21.86
Computer Vision,Image Captioning,TextCaps 2020,CIDEr,1,103.22
Computer Vision,Image Captioning,TextCaps 2020,METEOR,1,21.85
Computer Vision,Image Captioning,TextCaps 2020,ROUGE-L,1,45.65
Computer Vision,Image Captioning,TextCaps 2020,SPICE,1,14.64
Computer Vision,Image Captioning,TextCaps 2020,B4,2,22.93
Computer Vision,Image Captioning,TextCaps 2020,CIDEr,2,100.82
Computer Vision,Image Captioning,TextCaps 2020,METEOR,2,21.32
Computer Vision,Image Captioning,TextCaps 2020,ROUGE-L,2,46.11
Computer Vision,Image Captioning,TextCaps 2020,SPICE,2,13.81
Computer Vision,Image Captioning,Localized Narratives,CIDEr,1,106.5
Computer Vision,Image Captioning,COCO,CIDEr,1,131.2
Computer Vision,Image Captioning,COCO,CIDEr,2,125.2
Computer Vision,Image Captioning,COCO Captions,BLEU-4,1,41.7
Computer Vision,Image Captioning,COCO Captions,CIDER,1,140
Computer Vision,Image Captioning,COCO Captions,METEOR,1,30.6
Computer Vision,Image Captioning,COCO Captions,SPICE,1,24.5
Computer Vision,Image Captioning,COCO Captions,BLEU-4,2,39.5
Computer Vision,Image Captioning,COCO Captions,CIDEr-D,2,131.6
Computer Vision,Image Captioning,COCO Captions,METEOR,2,29.3
Computer Vision,Image Captioning,COCO Captions,ROUGE-L,2,59.3
Computer Vision,Image Captioning,Flickr30k Captions test,BLEU-4,1,30.1
Computer Vision,Image Captioning,Flickr30k Captions test,CIDEr,1,67.4
Computer Vision,Image Captioning,Flickr30k Captions test,METEOR,1,23
Computer Vision,Image Captioning,Flickr30k Captions test,SPICE,1,17
Computer Vision,Image Captioning,nocaps in-domain,B1,1,83.24
Computer Vision,Image Captioning,nocaps in-domain,B2,1,68.04
Computer Vision,Image Captioning,nocaps in-domain,B3,1,49.68
Computer Vision,Image Captioning,nocaps in-domain,B4,1,30.62
Computer Vision,Image Captioning,nocaps in-domain,CIDEr,1,97.99
Computer Vision,Image Captioning,nocaps in-domain,METEOR,1,29.51
Computer Vision,Image Captioning,nocaps in-domain,ROUGE-L,1,58.54
Computer Vision,Image Captioning,nocaps in-domain,SPICE,1,13.63
Computer Vision,Image Captioning,nocaps in-domain,B1,2,80.84
Computer Vision,Image Captioning,nocaps in-domain,B2,2,64.35
Computer Vision,Image Captioning,nocaps in-domain,B3,2,44.47
Computer Vision,Image Captioning,nocaps in-domain,B4,2,26.48
Computer Vision,Image Captioning,nocaps in-domain,CIDEr,2,89.03
Computer Vision,Image Captioning,nocaps in-domain,METEOR,2,27.85
Computer Vision,Image Captioning,nocaps in-domain,ROUGE-L,2,56.13
Computer Vision,Image Captioning,nocaps in-domain,SPICE,2,12.95
Computer Vision,Image Captioning,nocaps near-domain,B1,1,82.77
Computer Vision,Image Captioning,nocaps near-domain,B2,1,66.94
Computer Vision,Image Captioning,nocaps near-domain,B3,1,47.02
Computer Vision,Image Captioning,nocaps near-domain,B4,1,27.97
Computer Vision,Image Captioning,nocaps near-domain,CIDEr,1,95.16
Computer Vision,Image Captioning,nocaps near-domain,METEOR,1,28.24
Computer Vision,Image Captioning,nocaps near-domain,ROUGE-L,1,57.95
Computer Vision,Image Captioning,nocaps near-domain,SPICE,1,13.36
Computer Vision,Image Captioning,nocaps near-domain,B1,2,80.35
Computer Vision,Image Captioning,nocaps near-domain,B2,2,62.87
Computer Vision,Image Captioning,nocaps near-domain,B3,2,42.13
Computer Vision,Image Captioning,nocaps near-domain,B4,2,23.52
Computer Vision,Image Captioning,nocaps near-domain,CIDEr,2,87.79
Computer Vision,Image Captioning,nocaps near-domain,METEOR,2,26.82
Computer Vision,Image Captioning,nocaps near-domain,ROUGE-L,2,55.27
Computer Vision,Image Captioning,nocaps near-domain,SPICE,2,12.58
Computer Vision,Image Captioning,nocaps out-of-domain,B1,1,74.84
Computer Vision,Image Captioning,nocaps out-of-domain,B2,1,53.9
Computer Vision,Image Captioning,nocaps out-of-domain,B3,1,33.51
Computer Vision,Image Captioning,nocaps out-of-domain,B4,1,16.6
Computer Vision,Image Captioning,nocaps out-of-domain,CIDEr,1,91.62
Computer Vision,Image Captioning,nocaps out-of-domain,METEOR,1,26.83
Computer Vision,Image Captioning,nocaps out-of-domain,ROUGE-L,1,51.5
Computer Vision,Image Captioning,nocaps out-of-domain,SPICE,1,14.21
Computer Vision,Image Captioning,nocaps out-of-domain,B1,2,75.71
Computer Vision,Image Captioning,nocaps out-of-domain,B2,2,56.39
Computer Vision,Image Captioning,nocaps out-of-domain,B3,2,35.94
Computer Vision,Image Captioning,nocaps out-of-domain,B4,2,17.96
Computer Vision,Image Captioning,nocaps out-of-domain,CIDEr,2,87.15
Computer Vision,Image Captioning,nocaps out-of-domain,METEOR,2,24.01
Computer Vision,Image Captioning,nocaps out-of-domain,ROUGE-L,2,51.75
Computer Vision,Image Captioning,nocaps out-of-domain,SPICE,2,11.43
Computer Vision,Image Captioning,nocaps entire,B1,1,81.59
Computer Vision,Image Captioning,nocaps entire,B2,1,65.15
Computer Vision,Image Captioning,nocaps entire,B3,1,45.04
Computer Vision,Image Captioning,nocaps entire,B4,1,26.15
Computer Vision,Image Captioning,nocaps entire,CIDEr,1,92.46
Computer Vision,Image Captioning,nocaps entire,METEOR,1,27.57
Computer Vision,Image Captioning,nocaps entire,ROUGE-L,1,56.96
Computer Vision,Image Captioning,nocaps entire,SPICE,1,13.07
Computer Vision,Image Captioning,nocaps entire,B1,2,79.0
Computer Vision,Image Captioning,nocaps entire,B2,2,61.95
Computer Vision,Image Captioning,nocaps entire,B3,2,42.36
Computer Vision,Image Captioning,nocaps entire,B4,2,24.62
Computer Vision,Image Captioning,nocaps entire,CIDEr,2,87.34
Computer Vision,Image Captioning,nocaps entire,METEOR,2,26.29
Computer Vision,Image Captioning,nocaps entire,ROUGE-L,2,55.03
Computer Vision,Image Captioning,nocaps entire,SPICE,2,12.01
Computer Vision,Image Captioning,nocaps-XD near-domain,B1,1,82.88
Computer Vision,Image Captioning,nocaps-XD near-domain,B2,1,67.01
Computer Vision,Image Captioning,nocaps-XD near-domain,B3,1,48.73
Computer Vision,Image Captioning,nocaps-XD near-domain,B4,1,30.21
Computer Vision,Image Captioning,nocaps-XD near-domain,CIDEr,1,101.2
Computer Vision,Image Captioning,nocaps-XD near-domain,METEOR,1,30.0
Computer Vision,Image Captioning,nocaps-XD near-domain,ROUGE-L,1,58.76
Computer Vision,Image Captioning,nocaps-XD near-domain,SPICE,1,14.27
Computer Vision,Image Captioning,nocaps-XD near-domain,B1,2,79.51
Computer Vision,Image Captioning,nocaps-XD near-domain,B2,2,62.65
Computer Vision,Image Captioning,nocaps-XD near-domain,B3,2,43.22
Computer Vision,Image Captioning,nocaps-XD near-domain,B4,2,24.97
Computer Vision,Image Captioning,nocaps-XD near-domain,CIDEr,2,85.73
Computer Vision,Image Captioning,nocaps-XD near-domain,METEOR,2,26.37
Computer Vision,Image Captioning,nocaps-XD near-domain,ROUGE-L,2,55.13
Computer Vision,Image Captioning,nocaps-XD near-domain,SPICE,2,11.96
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B1,1,79.44
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B2,1,61.15
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B3,1,41.03
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B4,1,21.79
Computer Vision,Image Captioning,nocaps-XD out-of-domain,CIDEr,1,95.5
Computer Vision,Image Captioning,nocaps-XD out-of-domain,METEOR,1,26.56
Computer Vision,Image Captioning,nocaps-XD out-of-domain,ROUGE-L,1,55.49
Computer Vision,Image Captioning,nocaps-XD out-of-domain,SPICE,1,12.66
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B1,2,74.84
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B2,2,53.9
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B3,2,33.51
Computer Vision,Image Captioning,nocaps-XD out-of-domain,B4,2,16.6
Computer Vision,Image Captioning,nocaps-XD out-of-domain,CIDEr,2,91.62
Computer Vision,Image Captioning,nocaps-XD out-of-domain,METEOR,2,26.83
Computer Vision,Image Captioning,nocaps-XD out-of-domain,ROUGE-L,2,51.5
Computer Vision,Image Captioning,nocaps-XD out-of-domain,SPICE,2,14.21
Computer Vision,Image Captioning,nocaps-XD entire,B1,1,82.27
Computer Vision,Image Captioning,nocaps-XD entire,B2,1,66.04
Computer Vision,Image Captioning,nocaps-XD entire,B3,1,47.48
Computer Vision,Image Captioning,nocaps-XD entire,B4,1,28.95
Computer Vision,Image Captioning,nocaps-XD entire,CIDEr,1,100.12
Computer Vision,Image Captioning,nocaps-XD entire,METEOR,1,29.47
Computer Vision,Image Captioning,nocaps-XD entire,ROUGE-L,1,58.26
Computer Vision,Image Captioning,nocaps-XD entire,SPICE,1,14.04
Computer Vision,Image Captioning,nocaps-XD entire,B1,2,76.64
Computer Vision,Image Captioning,nocaps-XD entire,B2,2,56.46
Computer Vision,Image Captioning,nocaps-XD entire,B3,2,36.37
Computer Vision,Image Captioning,nocaps-XD entire,B4,2,19.48
Computer Vision,Image Captioning,nocaps-XD entire,CIDEr,2,85.34
Computer Vision,Image Captioning,nocaps-XD entire,METEOR,2,28.15
Computer Vision,Image Captioning,nocaps-XD entire,ROUGE-L,2,52.83
Computer Vision,Image Captioning,nocaps-XD entire,SPICE,2,14.67
Computer Vision,Image Captioning,nocaps-XD in-domain,B1,1,82.94
Computer Vision,Image Captioning,nocaps-XD in-domain,B2,1,67.56
Computer Vision,Image Captioning,nocaps-XD in-domain,B3,1,49.66
Computer Vision,Image Captioning,nocaps-XD in-domain,B4,1,32.07
Computer Vision,Image Captioning,nocaps-XD in-domain,CIDEr,1,100.62
Computer Vision,Image Captioning,nocaps-XD in-domain,METEOR,1,30.62
Computer Vision,Image Captioning,nocaps-XD in-domain,ROUGE-L,1,59.43
Computer Vision,Image Captioning,nocaps-XD in-domain,SPICE,1,14.7
Computer Vision,Image Captioning,nocaps-XD in-domain,B1,2,79.14
Computer Vision,Image Captioning,nocaps-XD in-domain,B2,2,62.18
Computer Vision,Image Captioning,nocaps-XD in-domain,B3,2,43.04
Computer Vision,Image Captioning,nocaps-XD in-domain,B4,2,25.67
Computer Vision,Image Captioning,nocaps-XD in-domain,CIDEr,2,82.86
Computer Vision,Image Captioning,nocaps-XD in-domain,METEOR,2,26.82
Computer Vision,Image Captioning,nocaps-XD in-domain,ROUGE-L,2,55.37
Computer Vision,Image Captioning,nocaps-XD in-domain,SPICE,2,11.9
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B1,1,72.48
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B2,1,53.93
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B3,1,38.79
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B4,1,27.35
Computer Vision,Image Captioning,VizWiz 2020 test-dev,CIDEr,1,80.67
Computer Vision,Image Captioning,VizWiz 2020 test-dev,METEOR,1,22.21
Computer Vision,Image Captioning,VizWiz 2020 test-dev,ROUGE-L,1,50.11
Computer Vision,Image Captioning,VizWiz 2020 test-dev,SPICE,1,16.96
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B1,2,72.22
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B2,2,53.84
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B3,2,39.28
Computer Vision,Image Captioning,VizWiz 2020 test-dev,B4,2,28.27
Computer Vision,Image Captioning,VizWiz 2020 test-dev,CIDEr,2,79.15
Computer Vision,Image Captioning,VizWiz 2020 test-dev,METEOR,2,22.12
Computer Vision,Image Captioning,VizWiz 2020 test-dev,ROUGE-L,2,50.27
Computer Vision,Image Captioning,VizWiz 2020 test-dev,SPICE,2,17.9
Computer Vision,Image Captioning,VizWiz 2020 test,B1,1,72.77
Computer Vision,Image Captioning,VizWiz 2020 test,B2,1,54.17
Computer Vision,Image Captioning,VizWiz 2020 test,B3,1,38.97
Computer Vision,Image Captioning,VizWiz 2020 test,B4,1,27.44
Computer Vision,Image Captioning,VizWiz 2020 test,CIDEr,1,81.04
Computer Vision,Image Captioning,VizWiz 2020 test,METEOR,1,22.25
Computer Vision,Image Captioning,VizWiz 2020 test,ROUGE-L,1,50.2
Computer Vision,Image Captioning,VizWiz 2020 test,SPICE,1,17.0
Computer Vision,Image Captioning,VizWiz 2020 test,B1,2,71.97
Computer Vision,Image Captioning,VizWiz 2020 test,B2,2,53.59
Computer Vision,Image Captioning,VizWiz 2020 test,B3,2,38.94
Computer Vision,Image Captioning,VizWiz 2020 test,B4,2,27.96
Computer Vision,Image Captioning,VizWiz 2020 test,CIDEr,2,77.7
Computer Vision,Image Captioning,VizWiz 2020 test,METEOR,2,21.93
Computer Vision,Image Captioning,VizWiz 2020 test,ROUGE-L,2,49.9
Computer Vision,Image Captioning,VizWiz 2020 test,SPICE,2,17.79
Computer Vision,Image Denoising,SIDD,PSNR (sRGB),1,39.99
Computer Vision,Image Denoising,SIDD,SSIM (sRGB),1,0.958
Computer Vision,Image Denoising,SIDD,PSNR (sRGB),2,39.77
Computer Vision,Image Denoising,SIDD,SSIM (sRGB),2,0.970
Computer Vision,Image Denoising,"ultracold fermions Technion system, pixelfly",ODRMSE,1,0.0711
Computer Vision,Image Denoising,FMD,PSNR,1,810dB
Computer Vision,Image Denoising,FFHQ 64x64 - 4x upscaling,LPIPS,1,0.24
Computer Vision,Image Denoising,DND,PSNR (sRGB),1,39.96
Computer Vision,Image Denoising,DND,SSIM (sRGB),1,0.956
Computer Vision,Image Denoising,DND,PSNR (sRGB),2,39.88
Computer Vision,Image Denoising,DND,SSIM (sRGB),2,0.956
Computer Vision,Image Denoising,FFHQ,LPIPS,1,0.24
Natural Language Processing,Causal Emotion Entailment,RECCON,F1,1,77.06
Natural Language Processing,Causal Emotion Entailment,RECCON,Neg. F1,1,87.89
Natural Language Processing,Causal Emotion Entailment,RECCON,Pos. F1,1,66.23
Natural Language Processing,Causal Emotion Entailment,RECCON,F1,2,76.51
Natural Language Processing,Causal Emotion Entailment,RECCON,Neg. F1,2,88.74
Natural Language Processing,Causal Emotion Entailment,RECCON,Pos. F1,2,64.28
Natural Language Processing,Component Classification,CDCP,Macro F1,1,78.71
Computer Vision,Pose Estimation,COCO minival,AP,1,75.9
Computer Vision,Pose Estimation,ApolloCar3D,A3DP,1,20.21
Computer Vision,Pose Estimation,J-HMDB,Mean PCK@0.2,1,93.6
Computer Vision,Pose Estimation,J-HMDB,Mean PCK@0.2,2,92.1
Computer Vision,Pose Estimation,FLIC Elbows,PCK@0.2,1,99.0
Computer Vision,Pose Estimation,FLIC Elbows,PCK@0.2,2,97.59
Computer Vision,Pose Estimation,MPII Human Pose,PCKh-0.5,1,94.1
Computer Vision,Pose Estimation,MPII Human Pose,PCKh-0.5,2,93.9
Computer Vision,Pose Estimation,Leeds Sports Poses,PCK,1,99.5
Computer Vision,Pose Estimation,Leeds Sports Poses,PCK,2,94.8
Computer Vision,Pose Estimation,UPenn Action,Mean PCK@0.2,1,99.4
Computer Vision,Pose Estimation,UPenn Action,Mean PCK@0.2,2,99.3
Computer Vision,Pose Estimation,UAV-Human,mAP,1,56.9
Computer Vision,Pose Estimation,UAV-Human,mAP,2,56.5
Computer Vision,Pose Estimation,ITOP front-view,Mean mAP,1,88.0
Computer Vision,Pose Estimation,ITOP top-view,Mean mAP,1,83.44
Computer Vision,Pose Estimation,ITOP top-view,Mean mAP,2,75.5
Computer Vision,Pose Estimation,DensePose-COCO,AP,1,61.6
Computer Vision,Pose Estimation,DensePose-COCO,AP,2,55.8
Computer Vision,Pose Estimation,MPII Single Person,PCKh@0.5,1,92.1
Computer Vision,Pose Estimation,MPII Single Person,PCKh@0.1,2,34.0
Computer Vision,Pose Estimation,MPII Single Person,PCKh@0.5,2,91.2
Computer Vision,Pose Estimation, ITOP front-view,Mean mAP,1,88.74
Computer Vision,Pose Estimation, ITOP front-view,Mean mAP,2,84.9
Computer Vision,Pose Estimation,FLIC Wrists,PCK@0.2,1,97.0
Computer Vision,Pose Estimation,FLIC Wrists,PCK@0.2,2,
Computer Vision,Pose Estimation,COCO test-dev,AP,1,79.5
Computer Vision,Pose Estimation,COCO test-dev,AP50,1,93.6
Computer Vision,Pose Estimation,COCO test-dev,AP75,1,85.9
Computer Vision,Pose Estimation,COCO test-dev,APL,1,84.3
Computer Vision,Pose Estimation,COCO test-dev,APM,1,76.3
Computer Vision,Pose Estimation,COCO test-dev,AR,1,81.9
Computer Vision,Pose Estimation,COCO test-dev,AP,2,78.9
Computer Vision,Pose Estimation,COCO test-dev,AP50,2,93.6
Computer Vision,Pose Estimation,COCO test-dev,AP75,2,85.8
Computer Vision,Pose Estimation,COCO test-dev,APL,2,83.6
Computer Vision,Pose Estimation,COCO test-dev,APM,2,76.1
Computer Vision,Pose Estimation,COCO test-dev,AR,2,81.4
Computer Vision,Deblurring,REDS,Average PSNR,1,34.80
Computer Vision,Deblurring,REDS,Average PSNR,2,24.09
Computer Vision,Deblurring,RealBlur-R,PSNR (sRGB),1,39.31
Computer Vision,Deblurring,RealBlur-R,SSIM (sRGB),1,0.972
Computer Vision,Deblurring,RealBlur-R,PSNR (sRGB),2,38.65
Computer Vision,Deblurring,RealBlur-R,SSIM (sRGB),2,0.965
Computer Vision,Deblurring,RealBlur-R (trained on GoPro),PSNR (sRGB),1,35.99
Computer Vision,Deblurring,RealBlur-R (trained on GoPro),SSIM (sRGB),1,0.952
Computer Vision,Deblurring,RealBlur-R (trained on GoPro),PSNR (sRGB),2,35.70
Computer Vision,Deblurring,RealBlur-R (trained on GoPro),SSIM (sRGB),2,0.948
Computer Vision,Deblurring,HIDE (trained on GOPRO),PSNR (sRGB),1,30.96
Computer Vision,Deblurring,HIDE (trained on GOPRO),SSIM (sRGB),1,0.939
Computer Vision,Deblurring,HIDE (trained on GOPRO),PSNR (sRGB),2,29.98
Computer Vision,Deblurring,HIDE (trained on GOPRO),SSIM (sRGB),2,0.930
Computer Vision,Deblurring,GoPro,PSNR,1,32.71
Computer Vision,Deblurring,GoPro,PSNR,2,32.66
Computer Vision,Deblurring,GoPro,SSIM,2,0.959
Computer Vision,Deblurring,DVD ,PSNR,1,32.34
Computer Vision,Deblurring,DVD ,PSNR,2,32.13
Computer Vision,Deblurring,RealBlur-J,PSNR (sRGB),1,31.76
Computer Vision,Deblurring,RealBlur-J,SSIM (sRGB),1,0.922
Computer Vision,Deblurring,RealBlur-J,PSNR (sRGB),2,31.38
Computer Vision,Deblurring,RealBlur-J,SSIM (sRGB),2,0.909
Computer Vision,Deblurring,Second dialogue state tracking challenge,MAE,1,0.0377
Computer Vision,Deblurring,RealBlur-J (trained on GoPro),PSNR (sRGB),1,28.70
Computer Vision,Deblurring,RealBlur-J (trained on GoPro),SSIM (sRGB),1,0.873
Computer Vision,Deblurring,RealBlur-J (trained on GoPro),PSNR (sRGB),2,28.70
Computer Vision,Deblurring,RealBlur-J (trained on GoPro),SSIM (sRGB),2,0.866
Medical,Pancreas Segmentation,TCIA Pancreas-CT Dataset,Dice Score,1,0.876
Medical,Pancreas Segmentation,TCIA Pancreas-CT Dataset,Dice Score,2,0.831
Medical,Pancreas Segmentation,CT-150,Dice Score,1,0.840
Medical,Pancreas Segmentation,CT-150,Precision,1,0.849
Medical,Pancreas Segmentation,CT-150,Recall,1,0.841
Medical,Pancreas Segmentation,CT-150,Dice Score,2,0.814
Medical,Pancreas Segmentation,CT-150,Precision,2,0.848
Medical,Pancreas Segmentation,CT-150,Recall,2,0.806
"Reasoning', 'Time Series",Math Word Problem Solving,SVAMP,Execution Accuracy,1,43.8
"Reasoning', 'Time Series",Math Word Problem Solving,SVAMP,Execution Accuracy,2,41.0
"Reasoning', 'Time Series",Math Word Problem Solving,MATH,Accuracy,1,6.9
"Reasoning', 'Time Series",Math Word Problem Solving,MATH,Accuracy,2,6.4
"Reasoning', 'Time Series",Math Word Problem Solving,Math23K,Accuracy (5-fold),1,75.9
"Reasoning', 'Time Series",Math Word Problem Solving,Math23K,Accuracy (5-fold),2,75.5
"Reasoning', 'Time Series",Math Word Problem Solving,Math23K,Accuracy (training-test),2,77.4
Time Series,Lip password classification,MIRACL-VC1,2-Class Accuracy,1,0.981
Natural Language Processing,Temporal Information Extraction,TimeBank,F1 score,1,0.511
Natural Language Processing,Temporal Information Extraction,TimeBank,F1 score,2,0.507
Natural Language Processing,Temporal Information Extraction,TempEval-3,Temporal awareness,1,67.2
Natural Language Processing,Temporal Information Extraction,TempEval-3,Temporal awareness,2,30.98
Natural Language Processing,Document Dating,NYT,Accuracy,1,58.9
Natural Language Processing,Document Dating,NYT,Accuracy,2,42.3
Natural Language Processing,Document Dating,APW,Accuracy,1,64.1
Natural Language Processing,Document Dating,APW,Accuracy,2,52.5
Natural Language Processing,Timex normalization,TimeBank,F1-Score,1,0.89
Natural Language Processing,Timex normalization,TimeBank,F1-Score,2,0.876
Natural Language Processing,Timex normalization,PNT,F1-Score,1,0.764
Natural Language Processing,Timex normalization,PNT,F1-Score,2,0.74
Natural Language Processing,Hypernym Discovery,Music domain,MAP,1,40.97
Natural Language Processing,Hypernym Discovery,Music domain,MRR,1,60.93
Natural Language Processing,Hypernym Discovery,Music domain,P@5,1,41.31
Natural Language Processing,Hypernym Discovery,Music domain,MAP,2,33.32
Natural Language Processing,Hypernym Discovery,Music domain,MRR,2,51.48
Natural Language Processing,Hypernym Discovery,Music domain,P@5,2,35.76
Natural Language Processing,Hypernym Discovery,Medical domain,MAP,1,34.05
Natural Language Processing,Hypernym Discovery,Medical domain,MRR,1,54.64
Natural Language Processing,Hypernym Discovery,Medical domain,P@5,1,36.77
Natural Language Processing,Hypernym Discovery,Medical domain,MAP,2,28.93
Natural Language Processing,Hypernym Discovery,Medical domain,MRR,2,35.80
Natural Language Processing,Hypernym Discovery,Medical domain,P@5,2,34.20
Natural Language Processing,Hypernym Discovery,General,MAP,1,19.78
Natural Language Processing,Hypernym Discovery,General,MRR,1,36.10
Natural Language Processing,Hypernym Discovery,General,P@5,1,19.03
Natural Language Processing,Hypernym Discovery,General,MAP,2,10.60
Natural Language Processing,Hypernym Discovery,General,MRR,2,23.83
Natural Language Processing,Hypernym Discovery,General,P@5,2,9.91
Natural Language Processing,Chunking,CoNLL 2000,Exact Span F1,1,97.3
Natural Language Processing,Chunking,CoNLL 2000,Exact Span F1,2,97.04
Natural Language Processing,Chunking,CoNLL 2003 (English),F1,1,92.5
Natural Language Processing,Chunking,CoNLL 2003 (English),F1,2,92.0
Natural Language Processing,Chunking,CoNLL 2003 (German),F1,1,95.0
Natural Language Processing,Chunking,CoNLL 2003 (German),F1,2,94.4
Natural Language Processing,Chunking,Penn Treebank,F1 score,1,97.3
Natural Language Processing,Chunking,Penn Treebank,F1 score,2,96.72
Knowledge Base,Breast Cancer Detection,Breast cancer Wisconsin_class 4,Accuracy,1,96.49
Knowledge Base,Breast Cancer Detection,Breast cancer Wisconsin_class 4,Average Precision,1,0.95
Knowledge Base,Breast Cancer Detection,Breast Cancer Coimbra Data Set,Mean Accuracy,1,79.17
Natural Language Processing,Tweet-Reply Sentiment Analysis,RETWEET,Average F1,1,73.2
Natural Language Processing,Tweet-Reply Sentiment Analysis,RETWEET,Average F1,2,71.9
Playing Games,Acrobot,.,MRCP(70),1,1680±100
Computer Vision,Semi-supervised Anomaly Detection,UBI-Fights,AUC,1,0.846
Computer Vision,Semi-supervised Anomaly Detection,UBI-Fights,Decidability,1,1.108
Computer Vision,Semi-supervised Anomaly Detection,UBI-Fights,EER,1,0.216
Computer Vision,Semi-supervised Anomaly Detection,UBI-Fights,AUC,2,0.819
Computer Vision,Semi-supervised Anomaly Detection,UBI-Fights,Decidability,2,0.986
Computer Vision,Semi-supervised Anomaly Detection,UBI-Fights,EER,2,0.284
Speech,Phone-level pronunciation scoring,speechocean762,Pearson correlation coefficient (PCC),1,0.45
Natural Language Processing,Hope Speech Detection for English,HopeEDI,Weighted Average F1-score,1,0.93
Natural Language Processing,Hope Speech Detection for English,HopeEDI,Weighted Average F1-score,2,0.90
Natural Language Processing,Hope Speech Detection for Tamil,HopeEDI,Weighted Average F1-score,1,0.60
Natural Language Processing,Hope Speech Detection for Tamil,HopeEDI,Weighted Average F1-score,2,0.56
Natural Language Processing,Hope Speech Detection for Malayalam,HopeEDI,Weighted Average F1-score,1,0.87
Natural Language Processing,Hope Speech Detection for Malayalam,HopeEDI,Weighted Average F1-score,2,0.73
Computer Vision,Camera shot boundary detection,TRECVID,F-measure (Recall),1,0.94
Computer Vision,Camera shot boundary detection,SoccerNet-v2,mAP,1,78.5
Computer Vision,Camera shot boundary detection,SoccerNet-v2,mAP,2,64.0
"Computer Vision', 'Natural Language Processing",Learning with noisy labels,ANIMAL,Accuracy,1,84.1
"Computer Vision', 'Natural Language Processing",Learning with noisy labels,ANIMAL,ImageNet Pretrained,1,NO
"Computer Vision', 'Natural Language Processing",Learning with noisy labels,ANIMAL,Network,1,Vgg19BN
"Computer Vision', 'Natural Language Processing",Learning with noisy labels,ANIMAL,Accuracy,2,83.4
"Computer Vision', 'Natural Language Processing",Learning with noisy labels,ANIMAL,ImageNet Pretrained,2,NO
"Computer Vision', 'Natural Language Processing",Learning with noisy labels,ANIMAL,Network,2,Vgg19BN
Medical,SpO2 estimation,Video recordings of fingertip under mobile phone fla,ANS-F1,1,1.00
Computer Vision,Multimodal Patch Matching,VisNir,FPR95,1,1.44
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,CapS,1,0.17403
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-0,1,27.1
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-1,1,19.4
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-2,1,13.9
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-4,1,19.4
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-8,1,23.6
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,IS,1,18.2
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-0,2,27.5
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-1,2,28.0
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-2,2,45.5
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-4,2,83.5
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,FID-8,2,85.0
Natural Language Processing,Zero-Shot Text-to-Image Generation,COCO,IS,2,17.9
Computer Vision,Plan2Scene,Rent3D++,COLOR (All Surfaces),1,0.591
Computer Vision,Plan2Scene,Rent3D++,FID (All Surfaces),1,196.2
Computer Vision,Plan2Scene,Rent3D++,FREQ (All Surfaces),1,0.034
Computer Vision,Plan2Scene,Rent3D++,SUBS (All Surfaces),1,0.392
Computer Vision,Plan2Scene,Rent3D++,TILE (All Surfaces),1,17.6
"Medical', 'Computer Vision",intensity image denoising,FMD,PSNR,1,7.5dB
Computer Vision,Face Anti-Spoofing,CASIA-MFSD,EER,1,4.92
Computer Vision,Face Anti-Spoofing,CASIA-MFSD,EER,2,2.22
Computer Vision,Face Anti-Spoofing,CASIA-MFSD,HTER,2,1.67
Computer Vision,Face Anti-Spoofing,Replay-Attack,EER,1,2.14
Computer Vision,Face Anti-Spoofing,Replay-Attack,EER,2,0.40
Computer Vision,Face Anti-Spoofing,Replay-Attack,HTER,2,2.90
Computer Vision,Face Anti-Spoofing,MSU-MFSD,Equal Error Rate,1,7.5
Computer Vision,Face Anti-Spoofing,MSU-MFSD,Equal Error Rate,2,10.8
Computer Vision,Face Anti-Spoofing,MLFP,HTER,1,3.4
Computer Vision,Face Anti-Spoofing,Replay Mobile,HTER,1,0
