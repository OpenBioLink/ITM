,ds_count,task,ds,date,value,percent_of_max_sota,gain,ratio,max_sota,percent_of_max_metric,merge
0,1,Sentiment Analysis,1B Words,2012-06,93.0,100.0,93,1.0,93,1.0,1\\ in\\ 10\\ R\\-at\\-1
0,1,Citation Intent Classification,ACL-ARC,2013-06,41.0,60.38,41.0,0.6,67.9,0.42,F1
1,1,Citation Intent Classification,ACL-ARC,2016-06,51.8,76.29,10.8,0.16,67.9,0.53,F1
2,1,Citation Intent Classification,ACL-ARC,2018-01,53.0,78.06,1.2,0.02,67.9,0.54,F1
3,1,Citation Intent Classification,ACL-ARC,2018-02,54.6,80.41,1.6,0.02,67.9,0.55,F1
4,1,Citation Intent Classification,ACL-ARC,2019-03,65.8,96.91,11.2,0.16,67.9,0.67,F1
5,1,Citation Intent Classification,ACL-ARC,2019-04,67.9,100.0,2.1,0.03,67.9,0.69,F1
6,1,Semantic Textual Similarity,MRPC,2013-10,85.9,92.86,85.9,0.93,92.5,0.87,F1
7,1,Semantic Textual Similarity,MRPC,2019-10,92.4,99.89,6.5,0.07,92.5,0.94,F1
8,1,Semantic Textual Similarity,MRPC,2019-10,92.5,100.0,0.1,0.0,92.5,0.94,F1
9,1,Question Answering,WebQuestions,2014-04,29.7,70.38,29.7,0.7,42.2,0.3,F1
10,1,Question Answering,WebQuestions,2014-06,39.2,92.89,9.5,0.23,42.2,0.4,F1
11,1,Question Answering,WebQuestions,2015-06,42.2,100.0,3.0,0.07,42.2,0.43,F1
12,1,Named Entity Recognition,SciERC,2014-09,65.12,92.59,65.12,0.93,70.33,0.66,F1
13,1,Named Entity Recognition,SciERC,2019-03,65.5,93.13,0.4,0.01,70.33,0.67,F1
14,1,Named Entity Recognition,SciERC,2019-09,70.33,100.0,4.8,0.07,70.33,0.71,F1
15,1,Word Sense Disambiguation,SensEval 2 Lexical Sample,2015-05,66.2,86.51,66.2,0.87,76.52,0.67,F1
16,1,Word Sense Disambiguation,SensEval 2 Lexical Sample,2016-06,66.9,87.43,0.7,0.01,76.52,0.68,F1
17,1,Word Sense Disambiguation,SensEval 2 Lexical Sample,2019-09,76.52,100.0,9.6,0.13,76.52,0.78,F1
18,1,Word Sense Disambiguation,SensEval 3 Lexical Sample,2015-05,73.4,91.61,73.4,0.92,80.12,0.75,F1
19,1,Word Sense Disambiguation,SensEval 3 Lexical Sample,2019-09,80.12,100.0,6.7,0.08,80.12,0.81,F1
20,1,Question Answering,SimpleQuestions,2015-06,63.9,100.0,63.9,1.0,63.9,0.65,F1
21,1,Chinese Word Segmentation,MSRA,2015-09,97.4,100.0,97.4,1.0,97.4,0.99,F1
22,1,Sentence Compression,Google Dataset,2015-09,0.82,96.36,0.82,0.96,0.851,0.01,F1
23,1,Sentence Compression,Google Dataset,2018-07,0.851,100.0,0.0,0.0,0.851,0.01,F1
24,1,Word Sense Disambiguation,SensEval 3 Task 1,2016-03,69.2,88.95,69.2,0.89,77.8,0.7,F1
25,1,Word Sense Disambiguation,SensEval 3 Task 1,2016-03,71.8,92.29,2.6,0.03,77.8,0.73,F1
26,1,Word Sense Disambiguation,SensEval 3 Task 1,2019-05,77.8,100.0,6.0,0.08,77.8,0.79,F1
27,1,Word Sense Disambiguation,SemEval 2013 Task 12,2016-03,67.0,85.13,67.0,0.85,78.7,0.68,F1
28,1,Word Sense Disambiguation,SemEval 2013 Task 12,2016-03,69.5,88.31,2.5,0.03,78.7,0.71,F1
29,1,Word Sense Disambiguation,SemEval 2013 Task 12,2018-11,72.63,92.29,3.1,0.04,78.7,0.74,F1
30,1,Word Sense Disambiguation,SemEval 2013 Task 12,2019-05,78.7,100.0,6.1,0.08,78.7,0.8,F1
31,1,Word Sense Disambiguation,SemEval 2007 Task 7,2016-03,84.3,93.25,84.3,0.93,90.4,0.86,F1
32,1,Word Sense Disambiguation,SemEval 2007 Task 7,2018-11,86.02,95.15,1.7,0.02,90.4,0.87,F1
33,1,Word Sense Disambiguation,SemEval 2007 Task 7,2019-05,90.4,100.0,4.4,0.05,90.4,0.92,F1
34,1,Word Sense Disambiguation,SemEval 2007 Task 17,2016-03,64.2,87.47,64.2,0.87,73.4,0.65,F1
35,1,Word Sense Disambiguation,SemEval 2007 Task 17,2018-11,66.81,91.02,2.6,0.04,73.4,0.68,F1
36,1,Word Sense Disambiguation,SemEval 2007 Task 17,2019-05,73.4,100.0,6.6,0.09,73.4,0.75,F1
37,1,Word Sense Disambiguation,SensEval 2,2016-03,74.4,93.35,74.4,0.93,79.7,0.76,F1
38,1,Word Sense Disambiguation,SensEval 2,2018-11,75.15,94.29,0.8,0.01,79.7,0.76,F1
39,1,Word Sense Disambiguation,SensEval 2,2019-05,79.7,100.0,4.5,0.06,79.7,0.81,F1
40,1,Coreference Resolution,OntoNotes,2016-04,64.21,80.67,64.21,0.81,79.6,0.65,F1
41,1,Coreference Resolution,OntoNotes,2016-06,65.29,82.02,1.1,0.01,79.6,0.66,F1
42,1,Coreference Resolution,OntoNotes,2016-09,65.73,82.58,0.4,0.01,79.6,0.67,F1
43,1,Coreference Resolution,OntoNotes,2017-07,67.2,84.42,1.5,0.02,79.6,0.68,F1
44,1,Coreference Resolution,OntoNotes,2018-02,70.4,88.44,3.2,0.04,79.6,0.72,F1
45,1,Coreference Resolution,OntoNotes,2018-04,73.0,91.71,2.6,0.03,79.6,0.74,F1
46,1,Coreference Resolution,OntoNotes,2019-07,76.61,96.24,3.6,0.05,79.6,0.78,F1
47,1,Coreference Resolution,OntoNotes,2019-07,79.6,100.0,3.0,0.04,79.6,0.81,F1
48,1,Relation Extraction,SemEval-2010 Task 8,2016-08,88.0,96.7,88.0,0.97,91.0,0.89,F1
49,1,Relation Extraction,SemEval-2010 Task 8,2019-02,89.0,97.8,1.0,0.01,91.0,0.9,F1
50,1,Relation Extraction,SemEval-2010 Task 8,2019-05,89.25,98.08,0.2,0.0,91.0,0.91,F1
51,1,Relation Extraction,SemEval-2010 Task 8,2019-06,89.5,98.35,0.2,0.0,91.0,0.91,F1
52,1,Relation Extraction,SemEval-2010 Task 8,2019-11,90.2,99.12,0.7,0.01,91.0,0.92,F1
53,1,Relation Extraction,SemEval-2010 Task 8,2020-04,91.0,100.0,0.8,0.01,91.0,0.92,F1
54,1,Question Answering,SQuAD1.1 dev,2016-08,64.7,67.56,64.7,0.68,95.77,0.66,F1
55,1,Question Answering,SQuAD1.1 dev,2016-10,71.2,74.34,6.5,0.07,95.77,0.72,F1
56,1,Question Answering,SQuAD1.1 dev,2016-11,74.9,78.21,3.7,0.04,95.77,0.76,F1
57,1,Question Answering,SQuAD1.1 dev,2016-11,77.3,80.71,2.4,0.03,95.77,0.79,F1
58,1,Question Answering,SQuAD1.1 dev,2017-03,77.42,80.84,0.1,0.0,95.77,0.79,F1
59,1,Question Answering,SQuAD1.1 dev,2017-03,78.5,81.97,1.1,0.01,95.77,0.8,F1
60,1,Question Answering,SQuAD1.1 dev,2017-03,78.8,82.28,0.3,0.0,95.77,0.8,F1
61,1,Question Answering,SQuAD1.1 dev,2017-04,79.5,83.01,0.7,0.01,95.77,0.81,F1
62,1,Question Answering,SQuAD1.1 dev,2017-05,86.3,90.11,6.8,0.07,95.77,0.88,F1
63,1,Question Answering,SQuAD1.1 dev,2018-10,91.1,95.12,4.8,0.05,95.77,0.93,F1
64,1,Question Answering,SQuAD1.1 dev,2019-06,95.1,99.3,4.0,0.04,95.77,0.97,F1
65,1,Question Answering,SQuAD1.1 dev,2019-10,95.64,99.86,0.5,0.01,95.77,0.97,F1
66,1,Question Answering,SQuAD1.1 dev,2019-11,95.77,100.0,0.1,0.0,95.77,0.97,F1
67,1,Question Answering,SQuAD1.1,2016-08,77.022,81.01,77.022,0.81,95.08,0.78,F1
68,1,Question Answering,SQuAD1.1,2016-09,79.364,83.47,2.3,0.02,95.08,0.81,F1
69,1,Question Answering,SQuAD1.1,2016-09,82.552,86.82,3.2,0.03,95.08,0.84,F1
70,1,Question Answering,SQuAD1.1,2017-05,88.533,93.11,6.0,0.06,95.08,0.9,F1
71,1,Question Answering,SQuAD1.1,2018-10,91.835,96.59,3.3,0.03,95.08,0.93,F1
72,1,Question Answering,SQuAD1.1,2018-10,93.16,97.98,1.3,0.01,95.08,0.95,F1
73,1,Question Answering,SQuAD1.1,2019-06,95.08,100.0,1.9,0.02,95.08,0.97,F1
74,1,Question Answering,NewsQA,2017-03,56.1,76.22,56.1,0.76,73.6,0.57,F1
75,1,Question Answering,NewsQA,2018-01,63.7,86.55,7.6,0.1,73.6,0.65,F1
76,1,Question Answering,NewsQA,2018-11,66.3,90.08,2.6,0.04,73.6,0.67,F1
77,1,Question Answering,NewsQA,2019-07,73.6,100.0,7.3,0.1,73.6,0.75,F1
78,1,Question Answering,TriviaQA,2017-05,52.85,63.22,52.85,0.63,83.6,0.54,F1
79,1,Question Answering,TriviaQA,2017-06,56.73,67.86,3.9,0.05,83.6,0.58,F1
80,1,Question Answering,TriviaQA,2017-10,71.32,85.31,14.6,0.17,83.6,0.72,F1
81,1,Question Answering,TriviaQA,2018-10,73.26,87.63,1.9,0.02,83.6,0.74,F1
82,1,Question Answering,TriviaQA,2019-07,83.6,100.0,10.3,0.12,83.6,0.85,F1
83,1,Relation Extraction,WebNLG,2017-06,28.3,29.39,28.3,0.29,96.3,0.29,F1
84,1,Relation Extraction,WebNLG,2018-07,37.1,38.53,8.8,0.09,96.3,0.38,F1
85,1,Relation Extraction,WebNLG,2019-07,42.9,44.55,5.8,0.06,96.3,0.44,F1
86,1,Relation Extraction,WebNLG,2019-09,91.8,95.33,48.9,0.51,96.3,0.93,F1
87,1,Relation Extraction,WebNLG,2020-04,96.3,100.0,4.5,0.05,96.3,0.98,F1
88,1,Relation Extraction,NYT,2017-06,42.0,46.77,42.0,0.47,89.8,0.43,F1
89,1,Relation Extraction,NYT,2018-07,58.7,65.37,16.7,0.19,89.8,0.6,F1
90,1,Relation Extraction,NYT,2019-07,61.9,68.93,3.2,0.04,89.8,0.63,F1
91,1,Relation Extraction,NYT,2019-09,89.6,99.78,27.7,0.31,89.8,0.91,F1
92,1,Relation Extraction,NYT,2020-04,89.8,100.0,0.2,0.0,89.8,0.91,F1
93,1,Relation Extraction,NYT-single,2017-06,49.5,83.33,49.5,0.83,59.4,0.5,F1
94,1,Relation Extraction,NYT-single,2019-07,53.8,90.57,4.3,0.07,59.4,0.55,F1
95,1,Relation Extraction,NYT-single,2019-09,59.4,100.0,5.6,0.09,59.4,0.6,F1
96,1,Semantic Role Labeling,OntoNotes,2017-07,81.7,93.91,81.7,0.94,87.0,0.83,F1
97,1,Semantic Role Labeling,OntoNotes,2017-12,82.7,95.06,1.0,0.01,87.0,0.84,F1
98,1,Semantic Role Labeling,OntoNotes,2018-02,84.6,97.24,1.9,0.02,87.0,0.86,F1
99,1,Semantic Role Labeling,OntoNotes,2018-07,85.5,98.28,0.9,0.01,87.0,0.87,F1
100,1,Semantic Role Labeling,OntoNotes,2018-10,87.0,100.0,1.5,0.02,87.0,0.88,F1
101,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,56.19,87.55,56.19,0.88,64.18,0.57,F1
102,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,58.54,91.21,2.4,0.04,64.18,0.59,F1
103,1,Emotion Recognition in Conversation,IEMOCAP,2019-05,62.75,97.77,4.2,0.07,64.18,0.64,F1
104,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,64.18,100.0,1.4,0.02,64.18,0.65,F1
105,1,Predicate Detection,CoNLL 2005,2017-07,96.4,97.97,96.4,0.98,98.4,0.98,F1
106,1,Predicate Detection,CoNLL 2005,2018-04,98.4,100.0,2.0,0.02,98.4,1.0,F1
107,1,Question Answering,COMPLEXQUESTIONS,2017-07,53.6,100.0,53.6,1.0,53.6,0.54,F1
108,1,Sarcasm Detection,SCv1,2017-08,0.69,100.0,0.69,1.0,0.69,0.01,F1
109,1,Named Entity Recognition,Long-tail emerging entities,2017-09,40.78,81.24,40.78,0.81,50.2,0.41,F1
110,1,Named Entity Recognition,Long-tail emerging entities,2018-06,45.55,90.74,4.8,0.1,50.2,0.46,F1
111,1,Named Entity Recognition,Long-tail emerging entities,2018-08,50.2,100.0,4.7,0.09,50.2,0.51,F1
112,1,Relation Extraction,TACRED,2017-09,65.1,91.05,65.1,0.91,71.5,0.66,F1
113,1,Relation Extraction,TACRED,2018-09,67.1,93.85,2.0,0.03,71.5,0.68,F1
114,1,Relation Extraction,TACRED,2018-09,68.2,95.38,1.1,0.02,71.5,0.69,F1
115,1,Relation Extraction,TACRED,2019-05,69.4,97.06,1.2,0.02,71.5,0.71,F1
116,1,Relation Extraction,TACRED,2019-06,71.5,100.0,2.1,0.03,71.5,0.73,F1
117,1,Question Answering,SQuAD2.0,2017-11,72.484,77.96,72.484,0.78,92.978,0.74,F1
118,1,Question Answering,SQuAD2.0,2017-12,73.704,79.27,1.2,0.01,92.978,0.75,F1
119,1,Question Answering,SQuAD2.0,2018-08,74.295,79.91,0.6,0.01,92.978,0.76,F1
120,1,Question Answering,SQuAD2.0,2018-10,83.061,89.33,8.8,0.09,92.978,0.84,F1
121,1,Question Answering,SQuAD2.0,2019-06,90.689,97.54,7.6,0.08,92.978,0.92,F1
122,1,Question Answering,SQuAD2.0,2019-08,90.702,97.55,0.0,0.0,92.978,0.92,F1
123,1,Question Answering,SQuAD2.0,2019-09,92.215,99.18,1.5,0.02,92.978,0.94,F1
124,1,Question Answering,SQuAD2.0,2020-01,92.978,100.0,0.8,0.01,92.978,0.94,F1
125,1,Citation Intent Classification,SciCite,2018-01,79.6,93.66,79.6,0.94,84.99,0.81,F1
126,1,Citation Intent Classification,SciCite,2019-03,84.99,100.0,5.4,0.06,84.99,0.86,F1
127,1,Sentence Classification,ACL-ARC,2018-01,53.0,78.06,53.0,0.78,67.9,0.54,F1
128,1,Sentence Classification,ACL-ARC,2019-03,65.79,96.89,12.8,0.19,67.9,0.67,F1
129,1,Sentence Classification,ACL-ARC,2019-04,67.9,100.0,2.1,0.03,67.9,0.69,F1
130,1,Sentence Classification,SciCite,2018-01,79.6,93.76,79.6,0.94,84.9,0.81,F1
131,1,Sentence Classification,SciCite,2018-10,84.4,99.41,4.8,0.06,84.9,0.86,F1
132,1,Sentence Classification,SciCite,2019-03,84.9,100.0,0.5,0.01,84.9,0.86,F1
133,1,Semantic Role Labeling,CoNLL 2005,2018-04,86.04,97.22,86.04,0.97,88.5,0.87,F1
134,1,Semantic Role Labeling,CoNLL 2005,2018-10,88.5,100.0,2.5,0.03,88.5,0.9,F1
135,1,Entity Linking,WebQSP-WD,2018-04,0.73,100.0,0.73,1.0,0.73,0.01,F1
136,1,Predicate Detection,CoNLL 2012,2018-04,97.2,100.0,97.2,1.0,97.2,0.99,F1
137,1,Chinese Named Entity Recognition,MSRA,2018-05,93.18,96.34,93.18,0.96,96.72,0.95,F1
138,1,Chinese Named Entity Recognition,MSRA,2019-01,95.54,98.78,2.4,0.02,96.72,0.97,F1
139,1,Chinese Named Entity Recognition,MSRA,2019-10,95.75,99.0,0.2,0.0,96.72,0.97,F1
140,1,Chinese Named Entity Recognition,MSRA,2019-11,96.72,100.0,1.0,0.01,96.72,0.98,F1
141,1,Chinese Named Entity Recognition,OntoNotes 4,2018-05,73.88,87.46,73.88,0.87,84.47,0.75,F1
142,1,Chinese Named Entity Recognition,OntoNotes 4,2019-10,82.11,97.21,8.2,0.1,84.47,0.83,F1
143,1,Chinese Named Entity Recognition,OntoNotes 4,2019-11,84.47,100.0,2.4,0.03,84.47,0.86,F1
144,1,Chinese Named Entity Recognition,Weibo NER,2018-05,58.79,86.97,58.79,0.87,67.6,0.6,F1
145,1,Chinese Named Entity Recognition,Weibo NER,2019-01,67.6,100.0,8.8,0.13,67.6,0.69,F1
146,1,Chinese Named Entity Recognition,Resume NER,2018-05,94.46,97.85,94.46,0.98,96.54,0.96,F1
147,1,Chinese Named Entity Recognition,Resume NER,2019-01,96.54,100.0,2.1,0.02,96.54,0.98,F1
148,1,Word Sense Disambiguation,SemEval 2015 Task 13,2018-05,72.6,87.89,72.6,0.88,82.6,0.74,F1
149,1,Word Sense Disambiguation,SemEval 2015 Task 13,2018-11,74.46,90.15,1.9,0.02,82.6,0.76,F1
150,1,Word Sense Disambiguation,SemEval 2015 Task 13,2019-05,82.6,100.0,8.1,0.1,82.6,0.84,F1
151,1,Paraphrase Identification,MSRP,2018-05,81.3,100.0,81.3,1.0,81.3,0.83,F1
152,1,Named Entity Recognition,CoNLL 2000,2018-05,90.34,100.0,90.34,1.0,90.34,0.92,F1
153,1,Question Answering,CliCR,2018-06,33.9,100.0,33.9,1.0,33.9,0.34,F1
154,1,Nested Mention Recognition,ACE 2005,2018-06,72.2,83.1,72.2,0.83,86.88,0.73,F1
155,1,Nested Mention Recognition,ACE 2005,2018-10,74.5,85.75,2.3,0.03,86.88,0.76,F1
156,1,Nested Mention Recognition,ACE 2005,2019-06,74.9,86.21,0.4,0.0,86.88,0.76,F1
157,1,Nested Mention Recognition,ACE 2005,2019-06,78.2,90.01,3.3,0.04,86.88,0.79,F1
158,1,Nested Mention Recognition,ACE 2005,2019-06,82.4,94.84,4.2,0.05,86.88,0.84,F1
159,1,Nested Mention Recognition,ACE 2005,2019-08,84.33,97.06,1.9,0.02,86.88,0.86,F1
160,1,Nested Mention Recognition,ACE 2005,2019-10,86.88,100.0,2.5,0.03,86.88,0.88,F1
161,1,Nested Named Entity Recognition,GENIA,2018-06,74.7,89.19,74.7,0.89,83.75,0.76,F1
162,1,Nested Named Entity Recognition,GENIA,2018-10,75.1,89.67,0.4,0.0,83.75,0.76,F1
163,1,Nested Named Entity Recognition,GENIA,2019-08,78.31,93.5,3.2,0.04,83.75,0.8,F1
164,1,Nested Named Entity Recognition,GENIA,2019-10,83.75,100.0,5.4,0.06,83.75,0.85,F1
165,1,Named Entity Recognition,GENIA,2018-06,74.7,89.19,74.7,0.89,83.75,0.76,F1
166,1,Named Entity Recognition,GENIA,2018-10,75.1,89.67,0.4,0.0,83.75,0.76,F1
167,1,Named Entity Recognition,GENIA,2019-07,78.31,93.5,3.2,0.04,83.75,0.8,F1
168,1,Named Entity Recognition,GENIA,2019-10,83.75,100.0,5.4,0.06,83.75,0.85,F1
169,1,Named Entity Recognition,ACE 2005,2018-06,72.2,83.1,72.2,0.83,86.88,0.73,F1
170,1,Named Entity Recognition,ACE 2005,2018-10,74.5,85.75,2.3,0.03,86.88,0.76,F1
171,1,Named Entity Recognition,ACE 2005,2019-06,74.9,86.21,0.4,0.0,86.88,0.76,F1
172,1,Named Entity Recognition,ACE 2005,2019-06,78.2,90.01,3.3,0.04,86.88,0.79,F1
173,1,Named Entity Recognition,ACE 2005,2019-06,82.4,94.84,4.2,0.05,86.88,0.84,F1
174,1,Named Entity Recognition,ACE 2005,2019-07,84.33,97.06,1.9,0.02,86.88,0.86,F1
175,1,Named Entity Recognition,ACE 2005,2019-10,86.88,100.0,2.5,0.03,86.88,0.88,F1
176,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,0.768,100.0,0.768,1.0,0.768,0.01,F1
177,1,Open-Domain Question Answering,SearchQA,2018-07,64.5,76.06,64.5,0.76,84.8,0.66,F1
178,1,Open-Domain Question Answering,SearchQA,2019-07,84.8,100.0,20.3,0.24,84.8,0.86,F1
179,1,Dependency Parsing,GENIA,2018-08,91.92,100.0,91.92,1.0,91.92,0.93,F1
180,1,Dependency Parsing,GENIA,2018-08,92.84,100.0,92.84,1.0,92.84,0.94,F1
181,1,Question Answering,SQuAD2.0 dev,2018-08,74.8,82.56,74.8,0.83,90.6,0.76,F1
182,1,Question Answering,SQuAD2.0 dev,2018-10,81.9,90.4,7.1,0.08,90.6,0.83,F1
183,1,Question Answering,SQuAD2.0 dev,2019-06,90.6,100.0,8.7,0.1,90.6,0.92,F1
184,1,Sentence Classification,PubMed 20k RCT,2018-08,92.6,100.0,92.6,1.0,92.6,0.94,F1
185,1,Named Entity Recognition,JNLPBA,2018-09,78.58,100.0,78.58,1.0,78.58,0.8,F1
186,1,Named Entity Recognition,BC5CDR,2018-09,87.12,96.88,87.12,0.97,89.93,0.89,F1
187,1,Named Entity Recognition,BC5CDR,2019-03,88.94,98.9,1.8,0.02,89.93,0.9,F1
188,1,Named Entity Recognition,BC5CDR,2019-08,89.42,99.43,0.5,0.01,89.93,0.91,F1
189,1,Named Entity Recognition,BC5CDR,2019-11,89.93,100.0,0.5,0.01,89.93,0.91,F1
190,1,Chinese Named Entity Recognition,SighanNER,2018-10,90.64,100.0,90.64,1.0,90.64,0.92,F1
191,1,Nested Mention Recognition,ACE 2004,2018-10,75.1,87.35,75.1,0.87,85.98,0.76,F1
192,1,Nested Mention Recognition,ACE 2004,2019-06,79.5,92.46,4.4,0.05,85.98,0.81,F1
193,1,Nested Mention Recognition,ACE 2004,2019-08,84.4,98.16,4.9,0.06,85.98,0.86,F1
194,1,Nested Mention Recognition,ACE 2004,2019-09,84.97,98.83,0.6,0.01,85.98,0.86,F1
195,1,Nested Mention Recognition,ACE 2004,2019-10,85.98,100.0,1.0,0.01,85.98,0.87,F1
196,1,Nested Named Entity Recognition,ACE 2004,2018-10,75.1,87.35,75.1,0.87,85.98,0.76,F1
197,1,Nested Named Entity Recognition,ACE 2004,2019-06,79.5,92.46,4.4,0.05,85.98,0.81,F1
198,1,Nested Named Entity Recognition,ACE 2004,2019-08,84.4,98.16,4.9,0.06,85.98,0.86,F1
199,1,Nested Named Entity Recognition,ACE 2004,2019-09,84.97,98.83,0.6,0.01,85.98,0.86,F1
200,1,Nested Named Entity Recognition,ACE 2004,2019-10,85.98,100.0,1.0,0.01,85.98,0.87,F1
201,1,Named Entity Recognition,ACE 2004,2018-10,75.1,87.35,75.1,0.87,85.98,0.76,F1
202,1,Named Entity Recognition,ACE 2004,2019-06,79.5,92.46,4.4,0.05,85.98,0.81,F1
203,1,Named Entity Recognition,ACE 2004,2019-07,84.4,98.16,4.9,0.06,85.98,0.86,F1
204,1,Named Entity Recognition,ACE 2004,2019-09,84.97,98.83,0.6,0.01,85.98,0.86,F1
205,1,Named Entity Recognition,ACE 2004,2019-10,85.98,100.0,1.0,0.01,85.98,0.87,F1
206,1,Question Answering,QuAC,2018-10,64.1,100.0,64.1,1.0,64.1,0.65,F1
207,1,Slot Filling,SNIPS,2018-12,0.918,99.53,0.918,1.0,0.9223,0.01,F1
208,1,Slot Filling,SNIPS,2019-06,0.9223,100.0,0.0,0.0,0.9223,0.01,F1
209,1,Slot Filling,ATIS,2018-12,0.952,99.37,0.952,0.99,0.958,0.01,F1
210,1,Slot Filling,ATIS,2019-06,0.958,100.0,0.0,0.0,0.958,0.01,F1
211,1,Named Entity Recognition,NCBI-disease,2019-01,89.71,100.0,89.71,1.0,89.71,0.91,F1
212,1,Relation Extraction,ChemProt,2019-01,76.46,100.0,76.46,1.0,76.46,0.78,F1
213,1,Chinese Word Segmentation,MSR,2019-01,98.3,99.95,98.3,1.0,98.35,1.0,F1
214,1,Chinese Word Segmentation,MSR,2019-11,98.35,100.0,0.0,0.0,98.35,1.0,F1
215,1,Chinese Word Segmentation,AS,2019-01,96.7,100.0,96.7,1.0,96.7,0.98,F1
216,1,Chinese Word Segmentation,PKU,2019-01,96.7,100.0,96.7,1.0,96.7,0.98,F1
217,1,Chinese Word Segmentation,CITYU,2019-01,97.9,100.0,97.9,1.0,97.9,0.99,F1
218,1,Chinese Named Entity Recognition,OntoNotes,2019-01,80.62,100.0,80.62,1.0,80.62,0.82,F1
219,1,Document Classification,Reuters-21578,2019-02,89.3,100.0,89.3,1.0,89.3,0.91,F1
220,1,Sentence Classification,ScienceCite,2019-03,84.99,100.0,84.99,1.0,84.99,0.86,F1
221,1,Relation Extraction,SciERC,2019-03,74.64,100.0,74.64,1.0,74.64,0.76,F1
222,1,Sentence Classification,Paper Field,2019-03,64.07,100.0,64.07,1.0,64.07,0.65,F1
223,1,Named Entity Recognition,WetLab,2019-04,79.62,100.0,79.62,1.0,79.62,0.81,F1
224,1,Speech Emotion Recognition,IEMOCAP,2019-04,0.718,100.0,0.718,1.0,0.718,0.01,F1
225,1,Document Classification,AAPD,2019-04,72.9,100.0,72.9,1.0,72.9,0.74,F1
226,1,Chinese Named Entity Recognition,MSRA Dev,2019-04,95.0,98.65,95.0,0.99,96.3,0.97,F1
227,1,Chinese Named Entity Recognition,MSRA Dev,2019-07,96.3,100.0,1.3,0.01,96.3,0.98,F1
228,1,Entity Typing,Open Entity,2019-05,75.56,100.0,75.56,1.0,75.56,0.77,F1
229,1,Relation Extraction,FewRel,2019-05,88.32,100.0,88.32,1.0,88.32,0.9,F1
230,1,Relation Extraction,DocRED,2019-06,50.7,84.63,50.7,0.85,59.91,0.52,F1
231,1,Relation Extraction,DocRED,2019-06,51.06,85.23,0.4,0.01,59.91,0.52,F1
232,1,Relation Extraction,DocRED,2019-09,53.92,90.0,2.9,0.05,59.91,0.55,F1
233,1,Relation Extraction,DocRED,2020-03,55.6,92.81,1.7,0.03,59.91,0.57,F1
234,1,Relation Extraction,DocRED,2020-04,59.91,100.0,4.3,0.07,59.91,0.61,F1
235,1,Sentiment Analysis,ChnSentiCorp Dev,2019-06,95.8,100.0,95.8,1.0,95.8,0.97,F1
236,1,Sentiment Analysis,ChnSentiCorp,2019-06,95.8,100.0,95.8,1.0,95.8,0.97,F1
237,1,Question Answering,NaturalQA,2019-07,82.5,100.0,82.5,1.0,82.5,0.84,F1
238,1,Intent Detection,ATIS,2019-08,0.952,100.0,0.952,1.0,0.952,0.01,F1
239,1,Named Entity Recognition,LINNAEUS,2019-08,87.02,100.0,87.02,1.0,87.02,0.88,F1
240,1,Named Entity Recognition,Species-800,2019-08,82.44,100.0,82.44,1.0,82.44,0.84,F1
241,1,Named Entity Recognition,Code-Switching English-Spanish NER,2019-09,69.17,100.0,69.17,1.0,69.17,0.7,F1
242,1,Named Entity Recognition,ontontoes chinese v5,2019-09,79.92,100.0,79.92,1.0,79.92,0.81,F1
243,1,Question Answering,ReCoRD,2019-10,93.3,100.0,93.3,1.0,93.3,0.95,F1
244,1,Natural Language Inference,CommitmentBank,2019-10,93.0,100.0,93,1.0,93,0.95,F1
245,1,Named Entity Recognition,French Treebank,2019-11,87.93,100.0,87.93,1.0,87.93,0.89,F1
246,1,Negation Scope Resolution,SFU Review Corpus,2019-11,90.95,99.67,90.95,1.0,91.25,0.92,F1
247,1,Negation Scope Resolution,SFU Review Corpus,2020-01,91.25,100.0,0.3,0.0,91.25,0.93,F1
248,1,Negation Scope Resolution,_sem 2012 Shared Task: Sherlock Dataset,2019-11,92.36,100.0,92.36,1.0,92.36,0.94,F1
249,1,Negation Scope Resolution,BioScope : Abstracts,2019-11,95.68,99.94,95.68,1.0,95.74,0.97,F1
250,1,Negation Scope Resolution,BioScope : Abstracts,2020-01,95.74,100.0,0.1,0.0,95.74,0.97,F1
251,1,Negation Scope Resolution,BioScope : Full Papers,2019-11,91.24,96.65,91.24,0.97,94.4,0.93,F1
252,1,Negation Scope Resolution,BioScope : Full Papers,2020-01,94.4,100.0,3.2,0.03,94.4,0.96,F1
253,1,Intent Detection,ASOS.com user intent,2019-12,0.887,100.0,0.887,1.0,0.887,0.01,F1
254,1,Speculation Scope Resolution,BioScope : Full Papers,2020-01,96.91,100.0,96.91,1.0,96.91,0.98,F1
255,1,Speculation Scope Resolution,SFU Review Corpus,2020-01,91.0,100.0,91,1.0,91,0.92,F1
256,1,Speculation Scope Resolution,BioScope : Abstracts,2020-01,97.87,100.0,97.87,1.0,97.87,0.99,F1
257,1,Sentiment Analysis,DBRD,2020-01,94.422,100.0,94.422,1.0,94.422,0.96,F1
258,1,Question Answering,FQuAD,2020-02,88.0,100.0,88,1.0,88,0.89,F1
259,1,Named Entity Recognition,SoSciSoCi,2020-03,0.82,100.0,0.82,1.0,0.82,0.01,F1
0,1,Sentiment Analysis,SST-5 Fine-grained classification,2013-10,45.7,82.34,45.7,0.82,55.5,0.46,Accuracy
1,1,Sentiment Analysis,SST-5 Fine-grained classification,2014-06,49.6,89.37,3.9,0.07,55.5,0.5,Accuracy
2,1,Sentiment Analysis,SST-5 Fine-grained classification,2015-02,51.0,91.89,1.4,0.03,55.5,0.51,Accuracy
3,1,Sentiment Analysis,SST-5 Fine-grained classification,2017-08,53.7,96.76,2.7,0.05,55.5,0.54,Accuracy
4,1,Sentiment Analysis,SST-5 Fine-grained classification,2018-02,54.7,98.56,1.0,0.02,55.5,0.55,Accuracy
5,1,Sentiment Analysis,SST-5 Fine-grained classification,2019-10,55.5,100.0,0.8,0.01,55.5,0.56,Accuracy
6,1,Semantic Textual Similarity,MRPC,2013-10,80.4,86.08,80.4,0.86,93.4,0.81,Accuracy
7,1,Semantic Textual Similarity,MRPC,2019-05,88.2,94.43,7.8,0.08,93.4,0.89,Accuracy
8,1,Semantic Textual Similarity,MRPC,2019-06,90.8,97.22,2.6,0.03,93.4,0.91,Accuracy
9,1,Semantic Textual Similarity,MRPC,2019-07,90.9,97.32,0.1,0.0,93.4,0.91,Accuracy
10,1,Semantic Textual Similarity,MRPC,2019-07,92.3,98.82,1.4,0.01,93.4,0.93,Accuracy
11,1,Semantic Textual Similarity,MRPC,2019-09,93.4,100.0,1.1,0.01,93.4,0.94,Accuracy
12,1,Sentiment Analysis,SST-2 Binary classification,2013-10,85.4,87.68,85.4,0.88,97.4,0.86,Accuracy
13,1,Sentiment Analysis,SST-2 Binary classification,2014-08,88.1,90.45,2.7,0.03,97.4,0.88,Accuracy
14,1,Sentiment Analysis,SST-2 Binary classification,2015-06,88.6,90.97,0.5,0.01,97.4,0.89,Accuracy
15,1,Sentiment Analysis,SST-2 Binary classification,2016-03,89.3,91.68,0.7,0.01,97.4,0.9,Accuracy
16,1,Sentiment Analysis,SST-2 Binary classification,2016-07,89.7,92.09,0.4,0.0,97.4,0.9,Accuracy
17,1,Sentiment Analysis,SST-2 Binary classification,2017-04,91.8,94.25,2.1,0.02,97.4,0.92,Accuracy
18,1,Sentiment Analysis,SST-2 Binary classification,2017-12,93.2,95.69,1.4,0.01,97.4,0.94,Accuracy
19,1,Sentiment Analysis,SST-2 Binary classification,2019-01,95.6,98.15,2.4,0.02,97.4,0.96,Accuracy
20,1,Sentiment Analysis,SST-2 Binary classification,2019-06,97.0,99.59,1.4,0.01,97.4,0.97,Accuracy
21,1,Sentiment Analysis,SST-2 Binary classification,2019-09,97.1,99.69,0.1,0.0,97.4,0.97,Accuracy
22,1,Sentiment Analysis,SST-2 Binary classification,2019-10,97.4,100.0,0.3,0.0,97.4,0.98,Accuracy
23,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,2013-12,86.2,92.99,86.2,0.93,92.7,0.87,Accuracy
24,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,2014-04,88.1,95.04,1.9,0.02,92.7,0.88,Accuracy
25,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,2014-12,92.7,100.0,4.6,0.05,92.7,0.93,Accuracy
26,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,2013-12,76.9,91.11,76.9,0.91,84.4,0.77,Accuracy
27,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,2014-04,79.2,93.84,2.3,0.03,84.4,0.8,Accuracy
28,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,2014-12,84.4,100.0,5.2,0.06,84.4,0.85,Accuracy
29,1,Document Classification,Cora,2014-03,67.2,80.48,67.2,0.8,83.5,0.67,Accuracy
30,1,Document Classification,Cora,2016-03,75.7,90.66,8.5,0.1,83.5,0.76,Accuracy
31,1,Document Classification,Cora,2016-09,81.5,97.6,5.8,0.07,83.5,0.82,Accuracy
32,1,Document Classification,Cora,2016-11,81.7,97.84,0.2,0.0,83.5,0.82,Accuracy
33,1,Document Classification,Cora,2017-10,83.0,99.4,1.3,0.02,83.5,0.83,Accuracy
34,1,Document Classification,Cora,2018-08,83.3,99.76,0.3,0.0,83.5,0.84,Accuracy
35,1,Document Classification,Cora,2019-04,83.5,100.0,0.2,0.0,83.5,0.84,Accuracy
36,1,Question Answering,Reverb,2014-04,73.0,100.0,73,1.0,73,0.73,Accuracy
37,1,Text Classification,IMDb,2014-05,92.58,95.64,92.58,0.96,96.8,0.93,Accuracy
38,1,Text Classification,IMDb,2019-01,95.17,98.32,2.6,0.03,96.8,0.96,Accuracy
39,1,Text Classification,IMDb,2019-04,95.8,98.97,0.6,0.01,96.8,0.96,Accuracy
40,1,Text Classification,IMDb,2019-06,96.8,100.0,1.0,0.01,96.8,0.97,Accuracy
41,1,Document Classification,Reuters En-De,2014-10,86.5,100.0,86.5,1.0,86.5,0.87,Accuracy
42,1,Document Classification,Reuters De-En,2014-10,75.0,100.0,75,1.0,75,0.75,Accuracy
43,1,Semantic Parsing,ATIS,2014-11,84.2,97.68,84.2,0.98,86.2,0.85,Accuracy
44,1,Semantic Parsing,ATIS,2017-04,85.3,98.96,1.1,0.01,86.2,0.86,Accuracy
45,1,Semantic Parsing,ATIS,2018-10,86.2,100.0,0.9,0.01,86.2,0.87,Accuracy
46,1,Sentiment Analysis,IMDb,2014-12,92.33,94.79,92.33,0.95,97.4,0.93,Accuracy
47,1,Sentiment Analysis,IMDb,2016-02,94.1,96.61,1.8,0.02,97.4,0.94,Accuracy
48,1,Sentiment Analysis,IMDb,2017-12,94.99,97.53,0.9,0.01,97.4,0.95,Accuracy
49,1,Sentiment Analysis,IMDb,2018-01,95.4,97.95,0.4,0.0,97.4,0.96,Accuracy
50,1,Sentiment Analysis,IMDb,2019-02,95.68,98.23,0.3,0.0,97.4,0.96,Accuracy
51,1,Sentiment Analysis,IMDb,2019-04,95.8,98.36,0.1,0.0,97.4,0.96,Accuracy
52,1,Sentiment Analysis,IMDb,2019-06,96.0,98.56,0.2,0.0,97.4,0.96,Accuracy
53,1,Sentiment Analysis,IMDb,2019-07,97.4,100.0,1.4,0.01,97.4,0.98,Accuracy
54,1,Subjectivity Analysis,SUBJ,2015-04,95.5,100.0,95.5,1.0,95.5,0.96,Accuracy
55,1,Part-Of-Speech Tagging,Penn Treebank,2015-08,97.36,99.39,97.36,0.99,97.96,0.98,Accuracy
56,1,Part-Of-Speech Tagging,Penn Treebank,2015-08,97.78,99.82,0.4,0.0,97.96,0.98,Accuracy
57,1,Part-Of-Speech Tagging,Penn Treebank,2018-05,97.96,100.0,0.2,0.0,97.96,0.98,Accuracy
58,1,Machine Translation,20NEWS,2015-08,1.0,100.0,1,1.0,1,0.01,Accuracy
59,1,Entity Linking,AIDA-CoNLL,2016-01,93.1,98.31,93.1,0.98,94.7,0.93,Accuracy
60,1,Entity Linking,AIDA-CoNLL,2017-05,94.7,100.0,1.6,0.02,94.7,0.95,Accuracy
61,1,Text Classification,RCV1,2016-02,94.13,100.0,94.13,1.0,94.13,0.95,Accuracy
62,1,Dialog Act Classification,Switchboard corpus,2016-03,73.1,89.91,73.1,0.9,81.3,0.73,Accuracy
63,1,Dialog Act Classification,Switchboard corpus,2017-09,79.2,97.42,6.1,0.08,81.3,0.8,Accuracy
64,1,Dialog Act Classification,Switchboard corpus,2017-11,81.3,100.0,2.1,0.03,81.3,0.82,Accuracy
65,1,Question Answering,MCTest-160,2016-03,75.27,100.0,75.27,1.0,75.27,0.76,Accuracy
66,1,Question Answering,MCTest-500,2016-03,71.0,100.0,71.0,1.0,71.0,0.71,Accuracy
67,1,Question Answering,Story Cloze Test,2016-06,78.7,100.0,78.7,1.0,78.7,0.79,Accuracy
68,1,Phrase Grounding,Flickr30k Entities Test,2016-06,48.69,100.0,48.69,1.0,48.69,0.49,Accuracy
69,1,Phrase Grounding,ReferIt,2016-06,28.91,100.0,28.91,1.0,28.91,0.29,Accuracy
70,1,Sentiment Analysis,Amazon Review Full,2016-07,60.2,91.45,60.2,0.91,65.83,0.6,Accuracy
71,1,Sentiment Analysis,Amazon Review Full,2017-07,65.19,99.03,5.0,0.08,65.83,0.65,Accuracy
72,1,Sentiment Analysis,Amazon Review Full,2019-04,65.83,100.0,0.6,0.01,65.83,0.66,Accuracy
73,1,Text Classification,Yahoo! Answers,2016-07,72.3,93.15,72.3,0.93,77.62,0.73,Accuracy
74,1,Text Classification,Yahoo! Answers,2018-05,73.53,94.73,1.2,0.02,77.62,0.74,Accuracy
75,1,Text Classification,Yahoo! Answers,2018-07,76.26,98.25,2.7,0.03,77.62,0.77,Accuracy
76,1,Text Classification,Yahoo! Answers,2019-05,77.62,100.0,1.4,0.02,77.62,0.78,Accuracy
77,1,Sentiment Analysis,Amazon Review Polarity,2016-07,94.6,97.16,94.6,0.97,97.37,0.95,Accuracy
78,1,Sentiment Analysis,Amazon Review Polarity,2017-07,96.68,99.29,2.1,0.02,97.37,0.97,Accuracy
79,1,Sentiment Analysis,Amazon Review Polarity,2019-04,97.37,100.0,0.7,0.01,97.37,0.98,Accuracy
80,1,Sentiment Analysis,Sogou News,2016-07,96.8,100.0,96.8,1.0,96.8,0.97,Accuracy
81,1,Sentiment Analysis,MR,2017-02,78.26,90.16,78.26,0.9,86.8,0.79,Accuracy
82,1,Sentiment Analysis,MR,2018-02,83.8,96.54,5.5,0.06,86.8,0.84,Accuracy
83,1,Sentiment Analysis,MR,2018-05,86.8,100.0,3.0,0.03,86.8,0.87,Accuracy
84,1,Paraphrase Identification,Quora Question Pairs,2017-02,88.17,98.4,88.17,0.98,89.6,0.89,Accuracy
85,1,Paraphrase Identification,Quora Question Pairs,2017-04,88.4,98.66,0.2,0.0,89.6,0.89,Accuracy
86,1,Paraphrase Identification,Quora Question Pairs,2017-09,89.06,99.4,0.7,0.01,89.6,0.89,Accuracy
87,1,Paraphrase Identification,Quora Question Pairs,2019-01,89.6,100.0,0.5,0.01,89.6,0.9,Accuracy
88,1,Stance Detection,RumourEval,2017-04,0.784,100.0,0.784,1.0,0.784,0.01,Accuracy
89,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-French,2017-05,67.7,100.0,67.7,1.0,67.7,0.68,Accuracy
90,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,2017-05,68.7,92.46,68.7,0.92,74.3,0.69,Accuracy
91,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,2018-10,74.3,100.0,5.6,0.08,74.3,0.75,Accuracy
92,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,2017-05,67.7,96.03,67.7,0.96,70.5,0.68,Accuracy
93,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,2018-10,70.5,100.0,2.8,0.04,70.5,0.71,Accuracy
94,1,Multimodal Emotion Recognition,Monologue,2017-07,74.1,100.0,74.1,1.0,74.1,0.74,Accuracy
95,1,Multimodal Sentiment Analysis,MOSI,2017-07,80.3,97.56,80.3,0.98,82.31,0.81,Accuracy
96,1,Multimodal Sentiment Analysis,MOSI,2018-10,82.31,100.0,2.0,0.02,82.31,0.83,Accuracy
97,1,Text Classification,Ohsumed,2017-07,36.2,52.85,36.2,0.53,68.5,0.36,Accuracy
98,1,Text Classification,Ohsumed,2018-09,68.36,99.8,32.2,0.47,68.5,0.69,Accuracy
99,1,Text Classification,Ohsumed,2019-02,68.5,100.0,0.1,0.0,68.5,0.69,Accuracy
100,1,Document Classification,WOS-5736,2017-09,90.93,97.18,90.93,0.97,93.57,0.91,Accuracy
101,1,Document Classification,WOS-5736,2018-05,93.57,100.0,2.6,0.03,93.57,0.94,Accuracy
102,1,Document Classification,WOS-11967,2017-09,86.07,93.97,86.07,0.94,91.59,0.86,Accuracy
103,1,Document Classification,WOS-11967,2018-05,91.59,100.0,5.5,0.06,91.59,0.92,Accuracy
104,1,Document Classification,WOS-46985,2017-09,76.58,92.91,76.58,0.93,82.42,0.77,Accuracy
105,1,Document Classification,WOS-46985,2018-05,82.42,100.0,5.8,0.07,82.42,0.83,Accuracy
106,1,Lexical Normalization,LexNorm,2017-10,87.63,100.0,87.63,1.0,87.63,0.88,Accuracy
107,1,Sentiment Analysis,CR,2017-12,92.2,100.0,92.2,1.0,92.2,0.93,Accuracy
108,1,Natural Language Inference,SciTail,2017-12,83.3,88.52,83.3,0.89,94.1,0.84,Accuracy
109,1,Natural Language Inference,SciTail,2018-08,86.0,91.39,2.7,0.03,94.1,0.86,Accuracy
110,1,Natural Language Inference,SciTail,2018-10,92.0,97.77,6.0,0.06,94.1,0.92,Accuracy
111,1,Natural Language Inference,SciTail,2019-01,94.1,100.0,2.1,0.02,94.1,0.94,Accuracy
112,1,Sentiment Analysis,MPQA,2018-03,88.14,98.12,88.14,0.98,89.83,0.89,Accuracy
113,1,Sentiment Analysis,MPQA,2018-05,88.8,98.85,0.7,0.01,89.83,0.89,Accuracy
114,1,Sentiment Analysis,MPQA,2019-05,89.83,100.0,1.0,0.01,89.83,0.9,Accuracy
115,1,Text Classification,20NEWS,2018-05,87.91,99.33,87.91,0.99,88.5,0.88,Accuracy
116,1,Text Classification,20NEWS,2019-02,88.5,100.0,0.6,0.01,88.5,0.89,Accuracy
117,1,Document Classification,Reuters-21578,2018-05,90.69,93.07,90.69,0.93,97.44,0.91,Accuracy
118,1,Document Classification,Reuters-21578,2019-04,97.17,99.72,6.5,0.07,97.44,0.98,Accuracy
119,1,Document Classification,Reuters-21578,2019-08,97.44,100.0,0.3,0.0,97.44,0.98,Accuracy
120,1,Semantic Parsing,Geo,2018-05,88.2,100.0,88.2,1.0,88.2,0.89,Accuracy
121,1,Question Answering,Quora Question Pairs,2018-05,83.03,89.96,83.03,0.9,92.3,0.83,Accuracy
122,1,Question Answering,Quora Question Pairs,2019-06,92.3,100.0,9.3,0.1,92.3,0.93,Accuracy
123,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,2018-05,74.73,80.08,74.73,0.8,93.32,0.75,Accuracy
124,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,2019-09,82.48,88.38,7.8,0.08,93.32,0.83,Accuracy
125,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,2019-09,93.32,100.0,10.8,0.12,93.32,0.94,Accuracy
126,1,Cross-Lingual Document Classification,MLDoc Zero-Shot German-to-French,2018-05,75.45,100.0,75.45,1.0,75.45,0.76,Accuracy
127,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2018-05,72.5,74.9,72.5,0.75,96.8,0.73,Accuracy
128,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2018-12,77.33,79.89,4.8,0.05,96.8,0.78,Accuracy
129,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2019-09,79.1,81.71,1.8,0.02,96.8,0.79,Accuracy
130,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2019-09,96.8,100.0,17.7,0.18,96.8,0.97,Accuracy
131,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2018-05,74.52,77.58,74.52,0.78,96.05,0.75,Accuracy
132,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2018-12,77.95,81.16,3.4,0.04,96.05,0.78,Accuracy
133,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2019-09,89.42,93.1,11.5,0.12,96.05,0.9,Accuracy
134,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2019-09,96.05,100.0,6.6,0.07,96.05,0.96,Accuracy
135,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2018-05,61.42,68.47,61.42,0.68,89.7,0.62,Accuracy
136,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2018-12,67.78,75.56,6.4,0.07,89.7,0.68,Accuracy
137,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2019-09,67.83,75.62,0.0,0.0,89.7,0.68,Accuracy
138,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2019-09,89.7,100.0,21.9,0.24,89.7,0.9,Accuracy
139,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Japanese,2018-05,67.63,97.21,67.63,0.97,69.57,0.68,Accuracy
140,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Japanese,2019-09,69.57,100.0,1.9,0.03,69.57,0.7,Accuracy
141,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2018-05,81.2,83.75,81.2,0.84,96.95,0.82,Accuracy
142,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2018-12,84.78,87.45,3.6,0.04,96.95,0.85,Accuracy
143,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2019-09,91.62,94.5,6.8,0.07,96.95,0.92,Accuracy
144,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2019-09,96.95,100.0,5.3,0.05,96.95,0.97,Accuracy
145,1,Paraphrase Identification,MSRP,2018-05,71.5,100.0,71.5,1.0,71.5,0.72,Accuracy
146,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2018-05,69.38,91.27,69.38,0.91,76.02,0.7,Accuracy
147,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2018-12,69.43,91.33,0.1,0.0,76.02,0.7,Accuracy
148,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2019-09,76.02,100.0,6.6,0.09,76.02,0.76,Accuracy
149,1,Memex Question Answering,MemexQA,2018-06,0.357,100.0,0.357,1.0,0.357,0.0,Accuracy
150,1,Entity Typing,Freebase FIGER,2018-06,37.4,100.0,37.4,1.0,37.4,0.38,Accuracy
151,1,Text Classification,R8,2018-06,96.7,98.77,96.7,0.99,97.9,0.97,Accuracy
152,1,Text Classification,R8,2018-09,97.07,99.15,0.4,0.0,97.9,0.97,Accuracy
153,1,Text Classification,R8,2019-02,97.2,99.28,0.1,0.0,97.9,0.98,Accuracy
154,1,Text Classification,R8,2019-06,97.4,99.49,0.2,0.0,97.9,0.98,Accuracy
155,1,Text Classification,R8,2019-09,97.9,100.0,0.5,0.01,97.9,0.98,Accuracy
156,1,Text-To-Speech Synthesis,LJSpeech,2018-06,12.0,100.0,12,1.0,12,0.12,Accuracy
157,1,Natural Language Inference,V-SNLI,2018-06,86.99,100.0,86.99,1.0,86.99,0.87,Accuracy
158,1,Natural Language Inference,MultiNLI,2018-06,72.8,100.0,72.8,1.0,72.8,0.73,Accuracy
159,1,Multimodal Sentiment Analysis,CMU-MOSEI,2018-07,76.9,93.67,76.9,0.94,82.1,0.77,Accuracy
160,1,Multimodal Sentiment Analysis,CMU-MOSEI,2020-02,82.1,100.0,5.2,0.06,82.1,0.82,Accuracy
161,1,Question Answering,SWAG,2018-08,86.3,100.0,86.3,1.0,86.3,0.87,Accuracy
162,1,Query Wellformedness,Query Wellformedness,2018-08,70.7,100.0,70.7,1.0,70.7,0.71,Accuracy
163,1,Natural Language Inference,XNLI French,2018-09,68.3,84.11,68.3,0.84,81.2,0.69,Accuracy
164,1,Natural Language Inference,XNLI French,2019-01,80.2,98.77,11.9,0.15,81.2,0.81,Accuracy
165,1,Natural Language Inference,XNLI French,2019-11,81.2,100.0,1.0,0.01,81.2,0.82,Accuracy
166,1,Text Classification,R52,2018-09,93.56,98.48,93.56,0.98,95.0,0.94,Accuracy
167,1,Text Classification,R52,2019-02,94.0,98.95,0.4,0.0,95.0,0.94,Accuracy
168,1,Text Classification,R52,2019-06,95.0,100.0,1.0,0.01,95.0,0.95,Accuracy
169,1,Semantic Parsing,spider,2018-09,19.7,100.0,19.7,1.0,19.7,0.2,Accuracy
170,1,Text Classification,Sogou News,2018-10,97.25,99.16,97.25,0.99,98.07,0.98,Accuracy
171,1,Text Classification,Sogou News,2019-05,98.07,100.0,0.8,0.01,98.07,0.98,Accuracy
172,1,Natural Language Inference,Quora Question Pairs,2018-12,88.01,100.0,88.01,1.0,88.01,0.88,Accuracy
173,1,Hate Speech Detection,Automatic Misogynistic Identification,2018-12,0.704,100.0,0.704,1.0,0.704,0.01,Accuracy
174,1,Intent Detection,SNIPS,2018-12,0.977,100.0,0.977,1.0,0.977,0.01,Accuracy
175,1,Intent Detection,ATIS,2018-12,0.95,97.18,0.95,0.97,0.9776,0.01,Accuracy
176,1,Intent Detection,ATIS,2019-06,0.9776,100.0,0.0,0.0,0.9776,0.01,Accuracy
177,1,Text Classification,Yelp-5,2019-01,73.28,100.0,73.28,1.0,73.28,0.74,Accuracy
178,1,Linguistic Acceptability,CoLA,2019-01,68.4,96.61,68.4,0.97,70.8,0.69,Accuracy
179,1,Linguistic Acceptability,CoLA,2019-06,69.0,97.46,0.6,0.01,70.8,0.69,Accuracy
180,1,Linguistic Acceptability,CoLA,2019-09,69.1,97.6,0.1,0.0,70.8,0.69,Accuracy
181,1,Linguistic Acceptability,CoLA,2019-10,70.8,100.0,1.7,0.02,70.8,0.71,Accuracy
182,1,Sentiment Analysis,Twitter,2019-02,74.71,100.0,74.71,1.0,74.71,0.75,Accuracy
183,1,Document Classification,BBCSport,2019-04,95.73,96.12,95.73,0.96,99.59,0.96,Accuracy
184,1,Document Classification,BBCSport,2019-08,99.59,100.0,3.9,0.04,99.59,1.0,Accuracy
185,1,Document Classification,Classic,2019-04,96.24,99.37,96.24,0.99,96.85,0.97,Accuracy
186,1,Document Classification,Classic,2019-12,96.85,100.0,0.6,0.01,96.85,0.97,Accuracy
187,1,Document Classification,Twitter,2019-04,72.6,100.0,72.6,1.0,72.6,0.73,Accuracy
188,1,Document Classification,Amazon,2019-04,94.31,100.0,94.31,1.0,94.31,0.95,Accuracy
189,1,Document Classification,Recipe,2019-04,59.06,100.0,59.06,1.0,59.06,0.59,Accuracy
190,1,Question Answering,CODAH,2019-04,69.6,100.0,69.6,1.0,69.6,0.7,Accuracy
191,1,Document Classification,Yelp-14,2019-04,69.4,100.0,69.4,1.0,69.4,0.7,Accuracy
192,1,Natural Language Inference,XNLI Chinese Dev,2019-04,79.9,96.73,79.9,0.97,82.6,0.8,Accuracy
193,1,Natural Language Inference,XNLI Chinese Dev,2019-07,82.6,100.0,2.7,0.03,82.6,0.83,Accuracy
194,1,Natural Language Inference,XNLI Chinese,2019-04,78.4,96.79,78.4,0.97,81.0,0.79,Accuracy
195,1,Natural Language Inference,XNLI Chinese,2019-07,81.0,100.0,2.6,0.03,81.0,0.81,Accuracy
196,1,Text Classification,Yelp-2,2019-04,97.95,99.31,97.95,0.99,98.63,0.98,Accuracy
197,1,Text Classification,Yelp-2,2019-05,98.08,99.44,0.1,0.0,98.63,0.98,Accuracy
198,1,Text Classification,Yelp-2,2019-06,98.63,100.0,0.5,0.01,98.63,0.99,Accuracy
199,1,Emotion Recognition in Conversation,IEMOCAP,2019-05,63.4,97.16,63.4,0.97,65.25,0.64,Accuracy
200,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,65.25,100.0,1.9,0.03,65.25,0.66,Accuracy
201,1,Emotion Recognition,MPED,2019-05,40.34,100.0,40.34,1.0,40.34,0.41,Accuracy
202,1,Entity Linking,FIGER,2019-05,57.19,100.0,57.19,1.0,57.19,0.57,Accuracy
203,1,Natural Language Inference,QNLI,2019-05,91.3,92.04,91.3,0.92,99.2,0.92,Accuracy
204,1,Natural Language Inference,QNLI,2019-06,94.9,95.67,3.6,0.04,99.2,0.95,Accuracy
205,1,Natural Language Inference,QNLI,2019-07,98.9,99.7,4.0,0.04,99.2,0.99,Accuracy
206,1,Natural Language Inference,QNLI,2019-09,99.2,100.0,0.3,0.0,99.2,1.0,Accuracy
207,1,Natural Language Inference,RTE,2019-05,68.8,74.38,68.8,0.74,92.5,0.69,Accuracy
208,1,Natural Language Inference,RTE,2019-06,85.9,92.86,17.1,0.18,92.5,0.86,Accuracy
209,1,Natural Language Inference,RTE,2019-07,88.2,95.35,2.3,0.02,92.5,0.89,Accuracy
210,1,Natural Language Inference,RTE,2019-09,89.2,96.43,1.0,0.01,92.5,0.9,Accuracy
211,1,Natural Language Inference,RTE,2019-10,92.5,100.0,3.3,0.04,92.5,0.93,Accuracy
212,1,Document Classification,IMDb-M,2019-06,52.8,100.0,52.8,1.0,52.8,0.53,Accuracy
213,1,Reading Comprehension,RACE,2019-06,85.4,100.0,85.4,1.0,85.4,0.86,Accuracy
214,1,Emotion Recognition,SEED-IV,2019-07,79.37,100.0,79.37,1.0,79.37,0.8,Accuracy
215,1,Natural Language Inference,WNLI,2019-07,89.0,95.49,89.0,0.95,93.2,0.89,Accuracy
216,1,Natural Language Inference,WNLI,2019-09,91.8,98.5,2.8,0.03,93.2,0.92,Accuracy
217,1,Natural Language Inference,WNLI,2019-10,93.2,100.0,1.4,0.02,93.2,0.94,Accuracy
218,1,Prosody Prediction,Helsinki Prosody Corpus,2019-08,83.2,100.0,83.2,1.0,83.2,0.84,Accuracy
219,1,Document Classification,MPQA,2019-08,89.81,100.0,89.81,1.0,89.81,0.9,Accuracy
220,1,Sentiment Analysis,Financial PhraseBank,2019-08,86.0,100.0,86,1.0,86,0.86,Accuracy
221,1,Semantic Textual Similarity,MRPC Dev,2019-09,86.3,100.0,86.3,1.0,86.3,0.87,Accuracy
222,1,Linguistic Acceptability,CoLA Dev,2019-09,54.0,100.0,54,1.0,54,0.54,Accuracy
223,1,Semantic Parsing,WikiSQL,2019-10,89.0,100.0,89,1.0,89,0.89,Accuracy
224,1,Question Answering,BoolQ,2019-10,91.0,100.0,91,1.0,91,0.91,Accuracy
225,1,Word Sense Disambiguation,Words in Context,2019-10,76.1,100.0,76.1,1.0,76.1,0.76,Accuracy
226,1,Question Answering,COPA,2019-10,94.8,100.0,94.8,1.0,94.8,0.95,Accuracy
227,1,Entity Linking,CoNLL-Aida,2020-01,94.9,100.0,94.9,1.0,94.9,0.95,Accuracy
228,1,Entity Linking,TAC-KBP 2010,2020-01,89.8,100.0,89.8,1.0,89.8,0.9,Accuracy
229,1,Sentiment Analysis,DBRD,2020-01,94.422,100.0,94.422,1.0,94.422,0.95,Accuracy
230,1,Sentiment Analysis,AJGT,2020-02,93.8,100.0,93.8,1.0,93.8,0.94,Accuracy
231,1,Sentiment Analysis,HARD,2020-02,96.1,100.0,96.1,1.0,96.1,0.96,Accuracy
0,1,Language Modelling,One Billion Word,2013-12,51.3,96.98,51.3,0.97,52.9,0.06,PPL
1,1,Language Modelling,One Billion Word,2014-12,52.9,100.0,1.6,0.03,52.9,0.06,PPL
2,1,Document Summarization,CNN / Daily Mail,2017-09,23.6,72.06,23.6,0.72,32.75,0.03,PPL
3,1,Document Summarization,CNN / Daily Mail,2018-08,32.75,100.0,9.1,0.28,32.75,0.04,PPL
4,1,Topic Models,20NEWS,2019-08,851.0,100.0,851,1.0,851,1.0,PPL
0,1,Natural Language Inference,SNLI,2014-04,86.8,94.45,86.8,0.94,91.9,0.94,%\\ Test\\ Accuracy
1,1,Natural Language Inference,SNLI,2014-08,88.1,95.87,1.3,0.01,91.9,0.96,%\\ Test\\ Accuracy
2,1,Natural Language Inference,SNLI,2016-09,88.6,96.41,0.5,0.01,91.9,0.96,%\\ Test\\ Accuracy
3,1,Natural Language Inference,SNLI,2017-02,88.8,96.63,0.2,0.0,91.9,0.97,%\\ Test\\ Accuracy
4,1,Natural Language Inference,SNLI,2017-09,88.9,96.74,0.1,0.0,91.9,0.97,%\\ Test\\ Accuracy
5,1,Natural Language Inference,SNLI,2017-11,89.1,96.95,0.2,0.0,91.9,0.97,%\\ Test\\ Accuracy
6,1,Natural Language Inference,SNLI,2017-12,89.3,97.17,0.2,0.0,91.9,0.97,%\\ Test\\ Accuracy
7,1,Natural Language Inference,SNLI,2018-05,90.1,98.04,0.8,0.01,91.9,0.98,%\\ Test\\ Accuracy
8,1,Natural Language Inference,SNLI,2018-09,91.3,99.35,1.2,0.01,91.9,0.99,%\\ Test\\ Accuracy
9,1,Natural Language Inference,SNLI,2019-01,91.6,99.67,0.3,0.0,91.9,1.0,%\\ Test\\ Accuracy
10,1,Natural Language Inference,SNLI,2019-09,91.9,100.0,0.3,0.0,91.9,1.0,%\\ Test\\ Accuracy
0,1,Question Answering,QASent,2014-05,0.7514,92.57,0.7514,0.93,0.8117,0.01,MRR
1,1,Question Answering,QASent,2014-12,0.7846,96.66,0.0,0.0,0.8117,0.01,MRR
2,1,Question Answering,QASent,2015-11,0.8117,100.0,0.0,0.0,0.8117,0.01,MRR
3,1,Question Answering,WikiQA,2014-05,0.6058,64.93,0.6058,0.65,0.933,0.01,MRR
4,1,Question Answering,WikiQA,2014-12,0.6652,71.3,0.1,0.11,0.933,0.01,MRR
5,1,Question Answering,WikiQA,2015-11,0.6988,74.9,0.0,0.0,0.933,0.01,MRR
6,1,Question Answering,WikiQA,2015-11,0.7069,75.77,0.0,0.0,0.933,0.01,MRR
7,1,Question Answering,WikiQA,2016-02,0.7226,77.45,0.0,0.0,0.933,0.01,MRR
8,1,Question Answering,WikiQA,2016-06,0.7234,77.53,0.0,0.0,0.933,0.01,MRR
9,1,Question Answering,WikiQA,2016-06,0.7265,77.87,0.0,0.0,0.933,0.01,MRR
10,1,Question Answering,WikiQA,2017-07,0.727,77.92,0.0,0.0,0.933,0.01,MRR
11,1,Question Answering,WikiQA,2019-05,0.784,84.03,0.1,0.11,0.933,0.01,MRR
12,1,Question Answering,WikiQA,2019-11,0.933,100.0,0.1,0.11,0.933,0.01,MRR
13,1,Question Answering,TrecQA,2014-12,0.785,80.6,0.785,0.81,0.974,0.01,MRR
14,1,Question Answering,TrecQA,2016-06,0.8219,84.38,0.0,0.0,0.974,0.01,MRR
15,1,Question Answering,TrecQA,2017-07,0.825,84.7,0.0,0.0,0.974,0.01,MRR
16,1,Question Answering,TrecQA,2019-05,0.928,95.28,0.1,0.1,0.974,0.01,MRR
17,1,Question Answering,TrecQA,2019-11,0.974,100.0,0.0,0.0,0.974,0.01,MRR
18,1,Question Answering,YahooCQA,2016-02,0.731,84.9,0.731,0.85,0.861,0.01,MRR
19,1,Question Answering,YahooCQA,2017-07,0.801,93.03,0.1,0.12,0.861,0.01,MRR
20,1,Question Answering,YahooCQA,2020-02,0.861,100.0,0.1,0.12,0.861,0.01,MRR
21,1,Hypernym Discovery,Medical domain,2016-11,41.07,75.16,41.07,0.75,54.64,0.59,MRR
22,1,Hypernym Discovery,Medical domain,2018-06,54.64,100.0,13.6,0.25,54.64,0.79,MRR
23,1,Hypernym Discovery,Music domain,2016-11,39.36,64.6,39.36,0.65,60.93,0.57,MRR
24,1,Hypernym Discovery,Music domain,2018-06,60.93,100.0,21.6,0.35,60.93,0.88,MRR
25,1,Hypernym Discovery,General,2016-11,23.83,66.01,23.83,0.66,36.1,0.34,MRR
26,1,Hypernym Discovery,General,2018-06,36.1,100.0,12.3,0.34,36.1,0.52,MRR
27,1,Visual Dialog,VisDial v0.9 val,2017-09,62.27,90.35,62.27,0.9,68.92,0.9,MRR
28,1,Visual Dialog,VisDial v0.9 val,2017-11,63.98,92.83,1.7,0.02,68.92,0.92,MRR
29,1,Visual Dialog,VisDial v0.9 val,2019-02,66.38,96.31,2.4,0.03,68.92,0.96,MRR
30,1,Visual Dialog,VisDial v0.9 val,2019-04,68.92,100.0,2.5,0.04,68.92,0.99,MRR
31,1,Visual Dialog,VisDial v1.0 test-std,2018-09,61.5,88.74,61.5,0.89,69.3,0.89,MRR
32,1,Visual Dialog,VisDial v1.0 test-std,2019-02,63.2,91.2,1.7,0.02,69.3,0.91,MRR
33,1,Visual Dialog,VisDial v1.0 test-std,2019-04,69.3,100.0,6.1,0.09,69.3,1.0,MRR
34,1,Passage Re-Ranking,MS MARCO,2019-01,0.359,97.55,0.359,0.98,0.368,0.01,MRR
35,1,Passage Re-Ranking,MS MARCO,2019-04,0.368,100.0,0.0,0.0,0.368,0.01,MRR
36,1,Visual Dialog,Visual Dialog v1.0,2019-02,64.22,99.04,64.22,0.99,64.84,0.93,MRR
37,1,Visual Dialog,Visual Dialog v1.0,2020-04,64.84,100.0,0.6,0.01,64.84,0.94,MRR
0,1,Question Answering,QASent,2014-05,0.6762,92.14,0.6762,0.92,0.7339,0.02,MAP
1,1,Question Answering,QASent,2014-12,0.7113,96.92,0.0,0.0,0.7339,0.02,MAP
2,1,Question Answering,QASent,2015-11,0.7339,100.0,0.0,0.0,0.7339,0.02,MAP
3,1,Question Answering,WikiQA,2014-05,0.5976,64.96,0.5976,0.65,0.92,0.01,MAP
4,1,Question Answering,WikiQA,2014-12,0.652,70.87,0.1,0.11,0.92,0.02,MAP
5,1,Question Answering,WikiQA,2015-11,0.682,74.13,0.0,0.0,0.92,0.02,MAP
6,1,Question Answering,WikiQA,2015-11,0.6886,74.85,0.0,0.0,0.92,0.02,MAP
7,1,Question Answering,WikiQA,2016-02,0.7058,76.72,0.0,0.0,0.92,0.02,MAP
8,1,Question Answering,WikiQA,2016-06,0.709,77.07,0.0,0.0,0.92,0.02,MAP
9,1,Question Answering,WikiQA,2017-07,0.712,77.39,0.0,0.0,0.92,0.02,MAP
10,1,Question Answering,WikiQA,2019-05,0.764,83.04,0.1,0.11,0.92,0.02,MAP
11,1,Question Answering,WikiQA,2019-11,0.92,100.0,0.2,0.22,0.92,0.02,MAP
12,1,Question Answering,TrecQA,2014-12,0.711,75.4,0.711,0.75,0.943,0.02,MAP
13,1,Question Answering,TrecQA,2016-06,0.7588,80.47,0.0,0.0,0.943,0.02,MAP
14,1,Question Answering,TrecQA,2017-07,0.77,81.65,0.0,0.0,0.943,0.02,MAP
15,1,Question Answering,TrecQA,2019-05,0.868,92.05,0.1,0.11,0.943,0.02,MAP
16,1,Question Answering,TrecQA,2019-11,0.943,100.0,0.1,0.11,0.943,0.02,MAP
17,1,Question Answering,SemEvalCQA,2015-03,0.78,98.11,0.78,0.98,0.795,0.02,MAP
18,1,Question Answering,SemEvalCQA,2016-06,0.792,99.62,0.0,0.0,0.795,0.02,MAP
19,1,Question Answering,SemEvalCQA,2017-07,0.795,100.0,0.0,0.0,0.795,0.02,MAP
20,1,Hypernym Discovery,Medical domain,2016-11,18.84,55.33,18.84,0.55,34.05,0.46,MAP
21,1,Hypernym Discovery,Medical domain,2018-06,34.05,100.0,15.2,0.45,34.05,0.83,MAP
22,1,Hypernym Discovery,Music domain,2016-11,12.99,31.71,12.99,0.32,40.97,0.32,MAP
23,1,Hypernym Discovery,Music domain,2018-06,40.97,100.0,28.0,0.68,40.97,1.0,MAP
24,1,Hypernym Discovery,General,2016-11,10.6,53.59,10.6,0.54,19.78,0.26,MAP
25,1,Hypernym Discovery,General,2018-06,19.78,100.0,9.2,0.47,19.78,0.48,MAP
26,1,Ad-Hoc Information Retrieval,TREC Robust04,2017-04,0.2837,86.55,0.2837,0.87,0.3278,0.01,MAP
27,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,0.2856,87.13,0.0,0.0,0.3278,0.01,MAP
28,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,0.2971,90.63,0.0,0.0,0.3278,0.01,MAP
29,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-12,0.302,92.13,0.0,0.0,0.3278,0.01,MAP
30,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-03,0.3278,100.0,0.0,0.0,0.3278,0.01,MAP
0,1,Relation Extraction,ACE 2005,2014-06,52.1,82.44,52.1,0.82,63.2,0.73,Relation\\ F1
1,1,Relation Extraction,ACE 2005,2016-01,55.6,87.97,3.5,0.06,63.2,0.78,Relation\\ F1
2,1,Relation Extraction,ACE 2005,2017-07,55.9,88.45,0.3,0.0,63.2,0.78,Relation\\ F1
3,1,Relation Extraction,ACE 2005,2017-09,57.5,90.98,1.6,0.03,63.2,0.8,Relation\\ F1
4,1,Relation Extraction,ACE 2005,2018-10,59.6,94.3,2.1,0.03,63.2,0.83,Relation\\ F1
5,1,Relation Extraction,ACE 2005,2019-04,63.2,100.0,3.6,0.06,63.2,0.88,Relation\\ F1
6,1,Relation Extraction,CoNLL04,2014-10,61.0,85.35,61.0,0.85,71.47,0.85,Relation\\ F1
7,1,Relation Extraction,CoNLL04,2014-10,62.8,87.87,1.8,0.03,71.47,0.88,Relation\\ F1
8,1,Relation Extraction,CoNLL04,2017-09,67.8,94.86,5.0,0.07,71.47,0.95,Relation\\ F1
9,1,Relation Extraction,CoNLL04,2019-05,68.9,96.4,1.1,0.02,71.47,0.96,Relation\\ F1
10,1,Relation Extraction,CoNLL04,2019-09,71.47,100.0,2.6,0.04,71.47,1.0,Relation\\ F1
11,1,Joint Entity and Relation Extraction,SciERC,2018-08,39.3,77.3,39.3,0.77,50.84,0.55,Relation\\ F1
12,1,Joint Entity and Relation Extraction,SciERC,2019-04,41.6,81.83,2.3,0.05,50.84,0.58,Relation\\ F1
13,1,Joint Entity and Relation Extraction,SciERC,2019-09,48.4,95.2,6.8,0.13,50.84,0.68,Relation\\ F1
14,1,Joint Entity and Relation Extraction,SciERC,2019-09,50.84,100.0,2.4,0.05,50.84,0.71,Relation\\ F1
0,1,Relation Extraction,ACE 2004,2014-06,45.3,75.88,45.3,0.76,59.7,0.57,Entity\\+Relation\\ F1
1,1,Relation Extraction,ACE 2004,2016-01,48.4,81.07,3.1,0.05,59.7,0.61,Entity\\+Relation\\ F1
2,1,Relation Extraction,ACE 2004,2019-04,59.7,100.0,11.3,0.19,59.7,0.76,Entity\\+Relation\\ F1
3,1,Relation Extraction,ADE Corpus,2018-04,74.58,94.6,74.58,0.95,78.84,0.95,Entity\\+Relation\\ F1
4,1,Relation Extraction,ADE Corpus,2018-08,75.52,95.79,0.9,0.01,78.84,0.96,Entity\\+Relation\\ F1
5,1,Relation Extraction,ADE Corpus,2019-05,77.19,97.91,1.7,0.02,78.84,0.98,Entity\\+Relation\\ F1
6,1,Relation Extraction,ADE Corpus,2019-09,78.84,100.0,1.7,0.02,78.84,1.0,Entity\\+Relation\\ F1
0,1,Relation Extraction,ACE 2004,2014-06,79.7,91.19,79.7,0.91,87.4,0.86,Entity\\ F1
1,1,Relation Extraction,ACE 2004,2016-01,81.8,93.59,2.1,0.02,87.4,0.88,Entity\\ F1
2,1,Relation Extraction,ACE 2004,2019-04,87.4,100.0,5.6,0.06,87.4,0.94,Entity\\ F1
3,1,Relation Extraction,ACE 2005,2014-06,80.8,91.4,80.8,0.91,88.4,0.87,Entity\\ F1
4,1,Relation Extraction,ACE 2005,2016-01,83.4,94.34,2.6,0.03,88.4,0.9,Entity\\ F1
5,1,Relation Extraction,ACE 2005,2017-09,83.6,94.57,0.2,0.0,88.4,0.9,Entity\\ F1
6,1,Relation Extraction,ACE 2005,2019-04,88.4,100.0,4.8,0.05,88.4,0.96,Entity\\ F1
7,1,Relation Extraction,CoNLL04,2014-10,80.7,90.74,80.7,0.91,88.94,0.87,Entity\\ F1
8,1,Relation Extraction,CoNLL04,2017-09,85.6,96.24,4.9,0.06,88.94,0.93,Entity\\ F1
9,1,Relation Extraction,CoNLL04,2018-12,86.2,96.92,0.6,0.01,88.94,0.93,Entity\\ F1
10,1,Relation Extraction,CoNLL04,2019-05,87.8,98.72,1.6,0.02,88.94,0.95,Entity\\ F1
11,1,Relation Extraction,CoNLL04,2019-09,88.94,100.0,1.1,0.01,88.94,0.96,Entity\\ F1
12,1,Relation Extraction,ADE Corpus,2018-04,86.4,96.77,86.4,0.97,89.28,0.93,Entity\\ F1
13,1,Relation Extraction,ADE Corpus,2018-08,86.73,97.14,0.3,0.0,89.28,0.94,Entity\\ F1
14,1,Relation Extraction,ADE Corpus,2019-05,87.02,97.47,0.3,0.0,89.28,0.94,Entity\\ F1
15,1,Relation Extraction,ADE Corpus,2019-09,89.28,100.0,2.3,0.03,89.28,0.97,Entity\\ F1
16,1,Joint Entity and Relation Extraction,SciERC,2018-08,64.2,91.28,64.2,0.91,70.33,0.69,Entity\\ F1
17,1,Joint Entity and Relation Extraction,SciERC,2019-04,65.2,92.71,1.0,0.01,70.33,0.7,Entity\\ F1
18,1,Joint Entity and Relation Extraction,SciERC,2019-09,67.5,95.98,2.3,0.03,70.33,0.73,Entity\\ F1
19,1,Joint Entity and Relation Extraction,SciERC,2019-09,70.33,100.0,2.8,0.04,70.33,0.76,Entity\\ F1
20,1,Coreference Resolution,GAP,2019-08,92.5,100.0,92.5,1.0,92.5,1.0,Entity\\ F1
0,1,Machine Translation,WMT2014 English-French,2014-06,34.54,75.75,34.54,0.76,45.6,0.76,BLEU\\ score
1,1,Machine Translation,WMT2014 English-French,2014-09,36.2,79.39,1.7,0.04,45.6,0.79,BLEU\\ score
2,1,Machine Translation,WMT2014 English-French,2014-09,36.5,80.04,0.3,0.01,45.6,0.8,BLEU\\ score
3,1,Machine Translation,WMT2014 English-French,2014-10,37.5,82.24,1.0,0.02,45.6,0.82,BLEU\\ score
4,1,Machine Translation,WMT2014 English-French,2016-06,39.2,85.96,1.7,0.04,45.6,0.86,BLEU\\ score
5,1,Machine Translation,WMT2014 English-French,2016-09,39.9,87.5,0.7,0.02,45.6,0.87,BLEU\\ score
6,1,Machine Translation,WMT2014 English-French,2017-01,40.56,88.95,0.7,0.02,45.6,0.89,BLEU\\ score
7,1,Machine Translation,WMT2014 English-French,2017-05,41.3,90.57,0.7,0.02,45.6,0.91,BLEU\\ score
8,1,Machine Translation,WMT2014 English-French,2017-11,41.4,90.79,0.1,0.0,45.6,0.91,BLEU\\ score
9,1,Machine Translation,WMT2014 English-French,2018-03,41.5,91.01,0.1,0.0,45.6,0.91,BLEU\\ score
10,1,Machine Translation,WMT2014 English-French,2018-06,43.2,94.74,1.7,0.04,45.6,0.95,BLEU\\ score
11,1,Machine Translation,WMT2014 English-French,2018-08,45.6,100.0,2.4,0.05,45.6,1.0,BLEU\\ score
12,1,Machine Translation,IWSLT2015 German-English,2014-09,28.53,80.37,28.53,0.8,35.5,0.63,BLEU\\ score
13,1,Machine Translation,IWSLT2015 German-English,2016-07,29.98,84.45,1.4,0.04,35.5,0.66,BLEU\\ score
14,1,Machine Translation,IWSLT2015 German-English,2016-11,30.4,85.63,0.4,0.01,35.5,0.67,BLEU\\ score
15,1,Machine Translation,IWSLT2015 German-English,2017-05,32.31,91.01,1.9,0.05,35.5,0.71,BLEU\\ score
16,1,Machine Translation,IWSLT2015 German-English,2017-06,34.44,97.01,2.1,0.06,35.5,0.76,BLEU\\ score
17,1,Machine Translation,IWSLT2015 German-English,2019-06,35.18,99.1,0.7,0.02,35.5,0.77,BLEU\\ score
18,1,Machine Translation,IWSLT2015 German-English,2020-02,35.5,100.0,0.3,0.01,35.5,0.78,BLEU\\ score
19,1,Machine Translation,WMT2015 English-Russian,2015-08,20.9,100.0,20.9,1.0,20.9,0.46,BLEU\\ score
20,1,Machine Translation,WMT2015 English-German,2015-08,22.8,86.69,22.8,0.87,26.3,0.5,BLEU\\ score
21,1,Machine Translation,WMT2015 English-German,2016-03,23.5,89.35,0.7,0.03,26.3,0.52,BLEU\\ score
22,1,Machine Translation,WMT2015 English-German,2016-10,26.3,100.0,2.8,0.11,26.3,0.58,BLEU\\ score
23,1,Machine Translation,WMT2016 Czech-English,2016-06,31.4,100.0,31.4,1.0,31.4,0.69,BLEU\\ score
24,1,Machine Translation,WMT2016 English-German,2016-06,34.2,84.07,34.2,0.84,40.68,0.75,BLEU\\ score
25,1,Machine Translation,WMT2016 English-German,2019-05,40.68,100.0,6.5,0.16,40.68,0.89,BLEU\\ score
26,1,Machine Translation,WMT2016 English-Romanian,2016-06,28.1,86.86,28.1,0.87,32.35,0.62,BLEU\\ score
27,1,Machine Translation,WMT2016 English-Romanian,2016-08,28.9,89.34,0.8,0.02,32.35,0.63,BLEU\\ score
28,1,Machine Translation,WMT2016 English-Romanian,2017-05,29.9,92.43,1.0,0.03,32.35,0.66,BLEU\\ score
29,1,Machine Translation,WMT2016 English-Romanian,2019-09,32.35,100.0,2.5,0.08,32.35,0.71,BLEU\\ score
30,1,Machine Translation,WMT2016 Romanian-English,2016-06,33.3,94.33,33.3,0.94,35.3,0.73,BLEU\\ score
31,1,Machine Translation,WMT2016 Romanian-English,2019-01,35.3,100.0,2.0,0.06,35.3,0.77,BLEU\\ score
32,1,Machine Translation,WMT2016 English-Czech,2016-06,25.8,100.0,25.8,1.0,25.8,0.57,BLEU\\ score
33,1,Machine Translation,WMT2016 German-English,2016-06,38.6,100.0,38.6,1.0,38.6,0.85,BLEU\\ score
34,1,Machine Translation,WMT2016 Russian-English,2016-06,28.0,100.0,28,1.0,28,0.61,BLEU\\ score
35,1,Machine Translation,WMT2016 English-Russian,2016-06,26.0,100.0,26.0,1.0,26.0,0.57,BLEU\\ score
36,1,Machine Translation,WMT2014 English-German,2016-06,20.7,59.14,20.7,0.59,35.0,0.45,BLEU\\ score
37,1,Machine Translation,WMT2014 English-German,2016-09,26.3,75.14,5.6,0.16,35.0,0.58,BLEU\\ score
38,1,Machine Translation,WMT2014 English-German,2017-05,26.4,75.43,0.1,0.0,35.0,0.58,BLEU\\ score
39,1,Machine Translation,WMT2014 English-German,2017-06,28.4,81.14,2.0,0.06,35.0,0.62,BLEU\\ score
40,1,Machine Translation,WMT2014 English-German,2017-11,28.9,82.57,0.5,0.01,35.0,0.63,BLEU\\ score
41,1,Machine Translation,WMT2014 English-German,2018-03,29.2,83.43,0.3,0.01,35.0,0.64,BLEU\\ score
42,1,Machine Translation,WMT2014 English-German,2018-06,29.3,83.71,0.1,0.0,35.0,0.64,BLEU\\ score
43,1,Machine Translation,WMT2014 English-German,2018-08,35.0,100.0,5.7,0.16,35.0,0.77,BLEU\\ score
44,1,Machine Translation,IWSLT2015 Thai-English,2016-06,14.2,100.0,14.2,1.0,14.2,0.31,BLEU\\ score
45,1,Machine Translation,IWSLT2014 German-English,2016-07,28.53,78.6,28.53,0.79,36.3,0.63,BLEU\\ score
46,1,Machine Translation,IWSLT2014 German-English,2017-06,30.08,82.87,1.5,0.04,36.3,0.66,BLEU\\ score
47,1,Machine Translation,IWSLT2014 German-English,2017-11,32.84,90.47,2.8,0.08,36.3,0.72,BLEU\\ score
48,1,Machine Translation,IWSLT2014 German-English,2018-07,33.1,91.18,0.3,0.01,36.3,0.73,BLEU\\ score
49,1,Machine Translation,IWSLT2014 German-English,2019-01,35.2,96.97,2.1,0.06,36.3,0.77,BLEU\\ score
50,1,Machine Translation,IWSLT2014 German-English,2019-05,35.7,98.35,0.5,0.01,36.3,0.78,BLEU\\ score
51,1,Machine Translation,IWSLT2014 German-English,2020-01,36.3,100.0,0.6,0.02,36.3,0.8,BLEU\\ score
52,1,Machine Translation,IWSLT2015 English-German,2016-07,25.04,88.7,25.04,0.89,28.23,0.55,BLEU\\ score
53,1,Machine Translation,IWSLT2015 English-German,2017-05,26.73,94.69,1.7,0.06,28.23,0.59,BLEU\\ score
54,1,Machine Translation,IWSLT2015 English-German,2017-06,28.23,100.0,1.5,0.05,28.23,0.62,BLEU\\ score
55,1,Machine Translation,WMT2014 German-English,2017-11,23.2,82.01,23.2,0.82,28.29,0.51,BLEU\\ score
56,1,Machine Translation,WMT2014 German-English,2018-02,25.43,89.89,2.2,0.08,28.29,0.56,BLEU\\ score
57,1,Machine Translation,WMT2014 German-English,2019-09,28.29,100.0,2.9,0.1,28.29,0.62,BLEU\\ score
58,1,Machine Translation,WMT 2017 English-Chinese,2018-03,24.2,99.18,24.2,0.99,24.4,0.53,BLEU\\ score
59,1,Machine Translation,WMT 2017 English-Chinese,2019-01,24.4,100.0,0.2,0.01,24.4,0.54,BLEU\\ score
60,1,Machine Translation,WMT2014 French-English,2018-09,25.87,100.0,25.87,1.0,25.87,0.57,BLEU\\ score
61,1,Machine Translation,WMT2014 English-Czech,2019-01,28.2,100.0,28.2,1.0,28.2,0.62,BLEU\\ score
62,1,Machine Translation,WMT2019 English-German,2019-07,43.1,100.0,43.1,1.0,43.1,0.95,BLEU\\ score
0,1,Language Modelling,WikiText-2,2016-11,87.0,87.61,87.0,0.88,99.3,0.88,Test\\ perplexity
1,1,Language Modelling,WikiText-2,2016-11,87.7,88.32,0.7,0.01,99.3,0.88,Test\\ perplexity
2,1,Language Modelling,WikiText-2,2016-12,99.3,100.0,11.6,0.12,99.3,1.0,Test\\ perplexity
3,1,Language Modelling,WikiText-103,2016-12,48.7,100.0,48.7,1.0,48.7,0.49,Test\\ perplexity
4,1,Language Modelling,Yahoo! Answers,2020-02,12.62,69.46,12.62,0.69,18.17,0.13,Test\\ perplexity
5,1,Language Modelling,Yahoo! Answers,2020-02,18.17,100.0,5.6,0.31,18.17,0.18,Test\\ perplexity
6,1,Language Modelling,Yelp15,2020-02,8.19,82.06,8.19,0.82,9.98,0.08,Test\\ perplexity
7,1,Language Modelling,Yelp15,2020-02,9.98,100.0,1.8,0.18,9.98,0.1,Test\\ perplexity
0,1,Language Modelling,WikiText-2,2016-11,91.5,99.13,91.5,0.99,92.3,0.99,Validation\\ perplexity
1,1,Language Modelling,WikiText-2,2016-11,92.3,100.0,0.8,0.01,92.3,1.0,Validation\\ perplexity
2,1,Language Modelling,WikiText-103,2018-03,32.0,88.89,32.0,0.89,36.0,0.35,Validation\\ perplexity
3,1,Language Modelling,WikiText-103,2018-03,34.1,94.72,2.1,0.06,36.0,0.37,Validation\\ perplexity
4,1,Language Modelling,WikiText-103,2018-03,36.0,100.0,1.9,0.05,36.0,0.39,Validation\\ perplexity
5,1,Language Modelling,One Billion Word,2018-09,22.92,96.18,22.92,0.96,23.83,0.25,Validation\\ perplexity
6,1,Language Modelling,One Billion Word,2018-09,23.83,100.0,0.9,0.04,23.83,0.26,Validation\\ perplexity
0,1,Question Answering,NarrativeQA,2016-11,33.45,61.82,33.45,0.62,54.11,0.52,BLEU\\-1
1,1,Question Answering,NarrativeQA,2018-09,43.63,80.63,10.2,0.19,54.11,0.68,BLEU\\-1
2,1,Question Answering,NarrativeQA,2018-11,44.35,81.96,0.7,0.01,54.11,0.69,BLEU\\-1
3,1,Question Answering,NarrativeQA,2019-01,54.11,100.0,9.8,0.18,54.11,0.84,BLEU\\-1
4,1,Question Answering,MS MARCO,2016-11,10.64,19.47,10.64,0.19,54.64,0.17,BLEU\\-1
5,1,Question Answering,MS MARCO,2018-05,54.37,99.51,43.7,0.8,54.64,0.85,BLEU\\-1
6,1,Question Answering,MS MARCO,2018-11,54.64,100.0,0.3,0.01,54.64,0.85,BLEU\\-1
7,1,Paraphrase Generation,quora,2017-09,22.9,50.11,22.9,0.5,45.7,0.36,BLEU\\-1
8,1,Paraphrase Generation,quora,2018-06,45.7,100.0,22.8,0.5,45.7,0.71,BLEU\\-1
9,1,Question Generation,Visual Question Generation,2018-08,36.0,100.0,36,1.0,36,0.56,BLEU\\-1
10,1,Text Generation,DailyDialog,2018-08,14.17,100.0,14.17,1.0,14.17,0.22,BLEU\\-1
11,1,Image Captioning,COCO,2019-05,64.2,100.0,64.2,1.0,64.2,1.0,BLEU\\-1
0,1,Constituency Parsing,Penn Treebank,2014-12,92.1,96.34,92.1,0.96,95.6,0.95,F1\\ score
1,1,Constituency Parsing,Penn Treebank,2016-11,93.8,98.12,1.7,0.02,95.6,0.97,F1\\ score
2,1,Constituency Parsing,Penn Treebank,2017-01,94.2,98.54,0.4,0.0,95.6,0.97,F1\\ score
3,1,Constituency Parsing,Penn Treebank,2017-07,94.66,99.02,0.5,0.01,95.6,0.98,F1\\ score
4,1,Constituency Parsing,Penn Treebank,2018-05,95.13,99.51,0.5,0.01,95.6,0.98,F1\\ score
5,1,Constituency Parsing,Penn Treebank,2019-03,95.6,100.0,0.5,0.01,95.6,0.99,F1\\ score
6,1,Cross-Lingual Bitext Mining,BUCC German-to-English,2015-11,76.9,79.95,76.9,0.8,96.19,0.8,F1\\ score
7,1,Cross-Lingual Bitext Mining,BUCC German-to-English,2018-11,95.58,99.37,18.7,0.19,96.19,0.99,F1\\ score
8,1,Cross-Lingual Bitext Mining,BUCC German-to-English,2018-12,96.19,100.0,0.6,0.01,96.19,0.99,F1\\ score
9,1,Cross-Lingual Bitext Mining,BUCC French-to-English,2015-11,75.8,80.72,75.8,0.81,93.91,0.78,F1\\ score
10,1,Cross-Lingual Bitext Mining,BUCC French-to-English,2018-11,92.89,98.91,17.1,0.18,93.91,0.96,F1\\ score
11,1,Cross-Lingual Bitext Mining,BUCC French-to-English,2018-12,93.91,100.0,1.0,0.01,93.91,0.97,F1\\ score
12,1,Chunking,Penn Treebank,2016-08,95.57,98.81,95.57,0.99,96.72,0.99,F1\\ score
13,1,Chunking,Penn Treebank,2016-11,95.77,99.02,0.2,0.0,96.72,0.99,F1\\ score
14,1,Chunking,Penn Treebank,2018-08,96.72,100.0,1.0,0.01,96.72,1.0,F1\\ score
15,1,Temporal Information Extraction,TimeBank,2016-12,0.511,100.0,0.511,1.0,0.511,0.01,F1\\ score
16,1,Extract aspect-polarity tuple,SemEval 2015 Task 12,2017-10,0.51,100.0,0.51,1.0,0.51,0.01,F1\\ score
17,1,Extract Aspect,SemEval 2015 Task 12,2017-10,0.7,100.0,0.7,1.0,0.7,0.01,F1\\ score
18,1,Cross-Lingual Bitext Mining,BUCC Russian-to-English,2018-12,93.3,100.0,93.3,1.0,93.3,0.96,F1\\ score
19,1,Cross-Lingual Bitext Mining,BUCC Chinese-to-English,2018-12,92.27,100.0,92.27,1.0,92.27,0.95,F1\\ score
20,1,Low Resource Named Entity Recognition,CONLL 2003 German,2019-02,58.63,89.87,58.63,0.9,65.24,0.61,F1\\ score
21,1,Low Resource Named Entity Recognition,CONLL 2003 German,2019-11,65.24,100.0,6.6,0.1,65.24,0.67,F1\\ score
22,1,Low Resource Named Entity Recognition,Conll 2003 Spanish,2019-02,75.34,99.22,75.34,0.99,75.93,0.78,F1\\ score
23,1,Low Resource Named Entity Recognition,Conll 2003 Spanish,2019-11,75.93,100.0,0.6,0.01,75.93,0.79,F1\\ score
24,1,Low Resource Named Entity Recognition,CONLL 2003 Dutch,2019-02,75.1,100.0,75.1,1.0,75.1,0.78,F1\\ score
25,1,Low Resource Named Entity Recognition,Uyghur Unsequestered Set,2019-02,42.88,100.0,42.88,1.0,42.88,0.44,F1\\ score
26,1,Counterspeech Detection,Youtube counterspeech dataset,2019-07,0.715,100.0,0.715,1.0,0.715,0.01,F1\\ score
27,1,Sentiment Analysis,Financial PhraseBank,2019-08,84.0,100.0,84,1.0,84,0.87,F1\\ score
28,1,Question Similarity,Q2Q Arabic Benchmark,2019-12,0.94848,98.88,0.94848,0.99,0.95924,0.01,F1\\ score
29,1,Question Similarity,Q2Q Arabic Benchmark,2020-04,0.95924,100.0,0.0,0.0,0.95924,0.01,F1\\ score
0,1,Semantic Similarity Estimation,SICK,2015-02,0.8676,100.0,0.8676,1.0,0.8676,0.94,Pearson\\ Correlation
1,1,Semantic Textual Similarity,STS Benchmark,2018-03,0.782,84.54,0.782,0.85,0.925,0.85,Pearson\\ Correlation
2,1,Semantic Textual Similarity,STS Benchmark,2019-05,0.832,89.95,0.0,0.0,0.925,0.9,Pearson\\ Correlation
3,1,Semantic Textual Similarity,STS Benchmark,2019-06,0.925,100.0,0.1,0.11,0.925,1.0,Pearson\\ Correlation
0,1,Semantic Similarity Estimation,SICK,2015-02,0.8083,100.0,0.8083,1.0,0.8083,0.88,Spearman\\ Correlation
1,1,Semantic Textual Similarity,STS Benchmark,2019-10,0.921,100.0,0.921,1.0,0.921,1.0,Spearman\\ Correlation
0,1,Semantic Similarity Estimation,SICK,2015-02,0.2532,82.93,0.2532,0.83,0.3053,0.83,MSE
1,1,Semantic Similarity Estimation,SICK,2015-02,0.2736,89.62,0.0,0.0,0.3053,0.9,MSE
2,1,Semantic Similarity Estimation,SICK,2015-02,0.2831,92.73,0.0,0.0,0.3053,0.93,MSE
3,1,Semantic Similarity Estimation,SICK,2017-07,0.3053,100.0,0.0,0.0,0.3053,1.0,MSE
4,1,Sentiment Analysis,FiQA,2019-08,0.07,100.0,0.07,1.0,0.07,0.23,MSE
5,1,Community Question Answering,CrowdSource QA,2020-02,0.046,100.0,0.046,1.0,0.046,0.15,MSE
6,1,Question Quality Assessment,CrowdSource QA,2020-02,0.046,100.0,0.046,1.0,0.046,0.15,MSE
7,1,Reading Comprehension,CrowdSource QA,2020-02,0.046,100.0,0.046,1.0,0.046,0.15,MSE
0,1,Question Answering,SemEvalCQA,2015-03,0.753,93.08,0.753,0.93,0.809,0.01,P\\-at\\-1
1,1,Question Answering,SemEvalCQA,2016-02,0.755,93.33,0.0,0.0,0.809,0.01,P\\-at\\-1
2,1,Question Answering,SemEvalCQA,2017-07,0.809,100.0,0.1,0.12,0.809,0.01,P\\-at\\-1
3,1,Question Answering,YahooCQA,2016-02,0.568,75.43,0.568,0.75,0.753,0.01,P\\-at\\-1
4,1,Question Answering,YahooCQA,2017-07,0.683,90.7,0.1,0.13,0.753,0.01,P\\-at\\-1
5,1,Question Answering,YahooCQA,2020-02,0.753,100.0,0.1,0.13,0.753,0.01,P\\-at\\-1
6,1,Question Answering,AI2 Kaggle Dataset,2017-08,47.2,87.41,47.2,0.87,54.0,0.49,P\\-at\\-1
7,1,Question Answering,AI2 Kaggle Dataset,2017-08,50.54,93.59,3.3,0.06,54.0,0.52,P\\-at\\-1
8,1,Question Answering,AI2 Kaggle Dataset,2017-08,50.7,93.89,0.2,0.0,54.0,0.52,P\\-at\\-1
9,1,Question Answering,AI2 Kaggle Dataset,2017-08,54.0,100.0,3.3,0.06,54.0,0.56,P\\-at\\-1
10,1,Word Alignment,en-es,2017-10,81.7,100.0,81.7,1.0,81.7,0.84,P\\-at\\-1
11,1,Word Alignment,en-fr,2017-10,82.3,100.0,82.3,1.0,82.3,0.85,P\\-at\\-1
12,1,Word Alignment,fr-en,2017-10,82.1,100.0,82.1,1.0,82.1,0.85,P\\-at\\-1
13,1,Word Alignment,es-en,2017-10,83.3,100.0,83.3,1.0,83.3,0.86,P\\-at\\-1
14,1,Entity Typing,Freebase FIGER,2018-06,93.2,100.0,93.2,1.0,93.2,0.96,P\\-at\\-1
15,1,Multi-Label Text Classification,Wiki-30K,2019-05,84.18,100.0,84.18,1.0,84.18,0.87,P\\-at\\-1
16,1,Multi-Label Text Classification,AAPD,2019-05,84.48,100.0,84.48,1.0,84.48,0.87,P\\-at\\-1
17,1,Multi-Label Text Classification,EUR-Lex,2019-05,74.95,93.45,74.95,0.93,80.2,0.77,P\\-at\\-1
18,1,Multi-Label Text Classification,EUR-Lex,2019-06,80.2,100.0,5.2,0.06,80.2,0.83,P\\-at\\-1
19,1,Multi-Label Text Classification,Amazon-12K,2019-05,94.87,100.0,94.87,1.0,94.87,0.98,P\\-at\\-1
20,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,54.38,100.0,54.38,1.0,54.38,0.56,P\\-at\\-1
21,1,Text Classification,RCV1,2019-06,97.05,100.0,97.05,1.0,97.05,1.0,P\\-at\\-1
0,1,Question Answering,bAbi,2015-03,7.5,26.13,7.5,0.26,28.7,0.26,Mean\\ Error\\ Rate
1,1,Question Answering,bAbi,2016-10,28.7,100.0,21.2,0.74,28.7,1.0,Mean\\ Error\\ Rate
0,1,Question Answering,bAbi,2015-03,93.4,93.54,93.4,0.94,99.85,0.94,Accuracy\\ \\(trained\\ on\\ 10k\\)
1,1,Question Answering,bAbi,2016-06,99.7,99.85,6.3,0.06,99.85,1.0,Accuracy\\ \\(trained\\ on\\ 10k\\)
2,1,Question Answering,bAbi,2020-02,99.85,100.0,0.1,0.0,99.85,1.0,Accuracy\\ \\(trained\\ on\\ 10k\\)
0,1,Question Answering,bAbi,2015-03,86.1,95.56,86.1,0.96,90.1,0.96,Accuracy\\ \\(trained\\ on\\ 1k\\)
1,1,Question Answering,bAbi,2016-06,90.1,100.0,4.0,0.04,90.1,1.0,Accuracy\\ \\(trained\\ on\\ 1k\\)
0,1,Text Classification,TREC-6,2015-04,4.0,41.67,4.0,0.42,9.6,0.09,Error
1,1,Text Classification,TREC-6,2015-11,5.4,56.25,1.4,0.15,9.6,0.12,Error
2,1,Text Classification,TREC-6,2017-02,7.0,72.92,1.6,0.17,9.6,0.15,Error
3,1,Text Classification,TREC-6,2018-03,7.2,75.0,0.2,0.02,9.6,0.15,Error
4,1,Text Classification,TREC-6,2018-05,9.6,100.0,2.4,0.25,9.6,0.21,Error
5,1,Sentiment Analysis,Yelp Fine-grained classification,2015-09,37.95,81.09,37.95,0.81,46.8,0.81,Error
6,1,Sentiment Analysis,Yelp Fine-grained classification,2019-01,46.8,100.0,8.8,0.19,46.8,1.0,Error
7,1,Sentiment Analysis,Yelp Binary classification,2015-09,4.88,100.0,4.88,1.0,4.88,0.1,Error
8,1,Text Classification,AG News,2015-09,9.51,67.93,9.51,0.68,14.0,0.2,Error
9,1,Text Classification,AG News,2018-05,9.64,68.86,0.1,0.01,14.0,0.21,Error
10,1,Text Classification,AG News,2018-08,14.0,100.0,4.4,0.31,14.0,0.3,Error
11,1,Text Classification,DBpedia,2015-09,1.55,55.96,1.55,0.56,2.77,0.03,Error
12,1,Text Classification,DBpedia,2018-05,2.77,100.0,1.2,0.43,2.77,0.06,Error
13,1,Text Classification,TREC-50,2016-12,2.8,100.0,2.8,1.0,2.8,0.06,Error
14,1,Text Classification,Amazon-5,2019-04,37.12,100.0,37.12,1.0,37.12,0.79,Error
15,1,Text Classification,Amazon-2,2019-04,3.5,89.74,3.5,0.9,3.9,0.07,Error
16,1,Text Classification,Amazon-2,2019-09,3.9,100.0,0.4,0.1,3.9,0.08,Error
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,76.26,91.55,76.26,0.92,83.3,0.92,Average
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,78.36,94.07,2.1,0.03,83.3,0.94,Average
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2017-02,78.39,94.11,0.0,0.0,83.3,0.94,Average
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,79.15,95.02,0.8,0.01,83.3,0.95,Average
4,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,83.3,100.0,4.1,0.05,83.3,1.0,Average
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,75.4,93.09,75.4,0.93,81.0,0.93,DVD
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,76.57,94.53,1.2,0.01,81.0,0.95,DVD
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,78.14,96.47,1.6,0.02,81.0,0.96,DVD
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,81.0,100.0,2.9,0.04,81.0,1.0,DVD
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,71.43,87.75,71.43,0.88,81.4,0.88,Books
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,73.4,90.17,2.0,0.02,81.4,0.9,Books
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,74.86,91.97,1.5,0.02,81.4,0.92,Books
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,81.4,100.0,6.5,0.08,81.4,1.0,Books
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,77.67,95.36,77.67,0.95,81.45,0.95,Electronics
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,80.53,98.87,2.9,0.04,81.45,0.99,Electronics
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,81.45,100.0,0.9,0.01,81.45,1.0,Electronics
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,80.53,93.75,80.53,0.94,85.9,0.94,Kitchen
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,82.93,96.54,2.4,0.03,85.9,0.97,Kitchen
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2017-02,83.97,97.75,1.0,0.01,85.9,0.98,Kitchen
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,85.9,100.0,1.9,0.02,85.9,1.0,Kitchen
0,1,Question Answering,CNN / Daily Mail,2015-06,69.4,88.3,69.4,0.88,78.6,0.88,CNN
1,1,Question Answering,CNN / Daily Mail,2016-03,69.5,88.42,0.1,0.0,78.6,0.88,CNN
2,1,Question Answering,CNN / Daily Mail,2016-03,75.4,95.93,5.9,0.08,78.6,0.96,CNN
3,1,Question Answering,CNN / Daily Mail,2016-06,77.9,99.11,2.5,0.03,78.6,0.99,CNN
4,1,Question Answering,CNN / Daily Mail,2017-03,78.6,100.0,0.7,0.01,78.6,1.0,CNN
0,1,Question Answering,CNN / Daily Mail,2015-06,68.0,84.05,68.0,0.84,80.9,0.84,Daily\\ Mail
1,1,Question Answering,CNN / Daily Mail,2015-06,69.0,85.29,1.0,0.01,80.9,0.85,Daily\\ Mail
2,1,Question Answering,CNN / Daily Mail,2016-03,73.9,91.35,4.9,0.06,80.9,0.91,Daily\\ Mail
3,1,Question Answering,CNN / Daily Mail,2016-03,77.7,96.04,3.8,0.05,80.9,0.96,Daily\\ Mail
4,1,Question Answering,CNN / Daily Mail,2016-06,80.9,100.0,3.2,0.04,80.9,1.0,Daily\\ Mail
0,1,Dependency Parsing,Penn Treebank,2015-06,92.05,96.87,92.05,0.97,95.02,0.97,LAS
1,1,Dependency Parsing,Penn Treebank,2016-03,92.79,97.65,0.7,0.01,95.02,0.98,LAS
2,1,Dependency Parsing,Penn Treebank,2016-11,93.76,98.67,1.0,0.01,95.02,0.99,LAS
3,1,Dependency Parsing,Penn Treebank,2018-05,94.19,99.13,0.4,0.0,95.02,0.99,LAS
4,1,Dependency Parsing,Penn Treebank,2018-09,95.02,100.0,0.8,0.01,95.02,1.0,LAS
5,1,Dependency Parsing,Sequoia Treebank,2019-11,94.39,100.0,94.39,1.0,94.39,0.99,LAS
6,1,Dependency Parsing,Spoken Corpus,2019-11,80.07,100.0,80.07,1.0,80.07,0.84,LAS
7,1,Dependency Parsing,French GSD,2019-11,92.47,100.0,92.47,1.0,92.47,0.97,LAS
8,1,Dependency Parsing,ParTUT,2019-11,92.9,100.0,92.9,1.0,92.9,0.98,LAS
0,1,Dependency Parsing,Penn Treebank,2015-06,93.99,97.29,93.99,0.97,96.61,0.97,UAS
1,1,Dependency Parsing,Penn Treebank,2016-03,94.61,97.93,0.6,0.01,96.61,0.98,UAS
2,1,Dependency Parsing,Penn Treebank,2016-11,95.44,98.79,0.8,0.01,96.61,0.99,UAS
3,1,Dependency Parsing,Penn Treebank,2018-05,95.87,99.23,0.4,0.0,96.61,0.99,UAS
4,1,Dependency Parsing,Penn Treebank,2018-09,96.61,100.0,0.7,0.01,96.61,1.0,UAS
5,1,Dependency Grammar Induction,WSJ10,2019-07,75.6,100.0,75.6,1.0,75.6,0.78,UAS
6,1,Dependency Parsing,Sequoia Treebank,2019-11,95.56,100.0,95.56,1.0,95.56,0.99,UAS
7,1,Dependency Parsing,Spoken Corpus,2019-11,86.05,100.0,86.05,1.0,86.05,0.89,UAS
8,1,Dependency Parsing,French GSD,2019-11,94.82,100.0,94.82,1.0,94.82,0.98,UAS
9,1,Dependency Parsing,ParTUT,2019-11,95.21,100.0,95.21,1.0,95.21,0.99,UAS
0,1,Dependency Parsing,Penn Treebank,2015-06,97.44,99.46,97.44,0.99,97.97,0.99,POS
1,1,Dependency Parsing,Penn Treebank,2018-07,97.97,100.0,0.5,0.01,97.97,1.0,POS
0,1,Natural Language Inference,SNLI,2015-08,99.7,100.0,99.7,1.0,99.7,1.0,%\\ Train\\ Accuracy
0,1,Natural Language Inference,SNLI,2015-08,220000.0,0.06,220000,0.0,339000000,0.0,Parameters
1,1,Natural Language Inference,SNLI,2015-09,250000.0,0.07,30000,0.0,339000000,0.0,Parameters
2,1,Natural Language Inference,SNLI,2015-11,15000000.0,4.42,14750000,0.04,339000000,0.04,Parameters
3,1,Natural Language Inference,SNLI,2017-05,40000000.0,11.8,25000000,0.07,339000000,0.12,Parameters
4,1,Natural Language Inference,SNLI,2017-11,43000000.0,12.68,3000000,0.01,339000000,0.13,Parameters
5,1,Natural Language Inference,SNLI,2018-02,45000000.0,13.27,2000000,0.01,339000000,0.13,Parameters
6,1,Natural Language Inference,SNLI,2018-05,53300000.0,15.72,8300000,0.02,339000000,0.16,Parameters
7,1,Natural Language Inference,SNLI,2018-06,85000000.0,25.07,31700000,0.09,339000000,0.25,Parameters
8,1,Natural Language Inference,SNLI,2018-09,308000000.0,90.86,223000000,0.66,339000000,0.91,Parameters
9,1,Natural Language Inference,SNLI,2019-01,330000000.0,97.35,22000000,0.06,339000000,0.97,Parameters
10,1,Natural Language Inference,SNLI,2019-09,339000000.0,100.0,9000000,0.03,339000000,1.0,Parameters
0,1,Sentence Compression,Google Dataset,2015-09,0.38,88.37,0.38,0.88,0.43,0.88,CR
1,1,Sentence Compression,Google Dataset,2017-07,0.43,100.0,0.0,0.0,0.43,1.0,CR
0,1,Text Summarization,DUC 2004 Task 1,2015-09,28.18,85.78,28.18,0.86,32.85,0.53,ROUGE\\-1
1,1,Text Summarization,DUC 2004 Task 1,2016-02,28.61,87.09,0.4,0.01,32.85,0.54,ROUGE\\-1
2,1,Text Summarization,DUC 2004 Task 1,2016-06,28.97,88.19,0.4,0.01,32.85,0.55,ROUGE\\-1
3,1,Text Summarization,DUC 2004 Task 1,2017-04,32.28,98.26,3.3,0.1,32.85,0.61,ROUGE\\-1
4,1,Text Summarization,DUC 2004 Task 1,2019-04,32.85,100.0,0.6,0.02,32.85,0.62,ROUGE\\-1
5,1,Text Summarization,GigaWord,2016-02,36.4,92.13,36.4,0.92,39.51,0.69,ROUGE\\-1
6,1,Text Summarization,GigaWord,2017-11,37.27,94.33,0.9,0.02,39.51,0.7,ROUGE\\-1
7,1,Text Summarization,GigaWord,2019-05,38.73,98.03,1.5,0.04,39.51,0.73,ROUGE\\-1
8,1,Text Summarization,GigaWord,2019-05,38.9,98.46,0.2,0.01,39.51,0.73,ROUGE\\-1
9,1,Text Summarization,GigaWord,2019-12,39.12,99.01,0.2,0.01,39.51,0.74,ROUGE\\-1
10,1,Text Summarization,GigaWord,2020-01,39.51,100.0,0.4,0.01,39.51,0.74,ROUGE\\-1
11,1,Abstractive Text Summarization,CNN / Daily Mail,2017-04,39.53,89.43,39.53,0.89,44.2,0.74,ROUGE\\-1
12,1,Abstractive Text Summarization,CNN / Daily Mail,2019-05,43.08,97.47,3.5,0.08,44.2,0.81,ROUGE\\-1
13,1,Abstractive Text Summarization,CNN / Daily Mail,2019-12,44.17,99.93,1.1,0.02,44.2,0.83,ROUGE\\-1
14,1,Abstractive Text Summarization,CNN / Daily Mail,2020-01,44.2,100.0,0.0,0.0,44.2,0.83,ROUGE\\-1
15,1,Query-Based Extractive Summarization,Debatepedia,2017-04,41.26,77.72,41.26,0.78,53.09,0.78,ROUGE\\-1
16,1,Query-Based Extractive Summarization,Debatepedia,2018-01,53.09,100.0,11.8,0.22,53.09,1.0,ROUGE\\-1
17,1,Document Summarization,CNN / Daily Mail,2017-05,38.3,87.34,38.3,0.87,43.85,0.72,ROUGE\\-1
18,1,Document Summarization,CNN / Daily Mail,2017-05,39.87,90.92,1.6,0.04,43.85,0.75,ROUGE\\-1
19,1,Document Summarization,CNN / Daily Mail,2018-08,41.22,94.0,1.4,0.03,43.85,0.78,ROUGE\\-1
20,1,Document Summarization,CNN / Daily Mail,2019-03,43.25,98.63,2.0,0.05,43.85,0.81,ROUGE\\-1
21,1,Document Summarization,CNN / Daily Mail,2019-08,43.85,100.0,0.6,0.01,43.85,0.83,ROUGE\\-1
22,1,Extractive Document Summarization,CNN / Daily Mail,2018-09,30.8,70.24,30.8,0.7,43.85,0.58,ROUGE\\-1
23,1,Extractive Document Summarization,CNN / Daily Mail,2019-03,43.25,98.63,12.4,0.28,43.85,0.81,ROUGE\\-1
24,1,Extractive Document Summarization,CNN / Daily Mail,2019-08,43.85,100.0,0.6,0.01,43.85,0.83,ROUGE\\-1
25,1,Reader-Aware Summarization,RASG,2018-12,30.33,100.0,30.33,1.0,30.33,0.57,ROUGE\\-1
26,1,Sentence Summarization,GigaWord,2019-07,26.48,100.0,26.48,1.0,26.48,0.5,ROUGE\\-1
27,1,Unsupervised Sentence Summarization,GigaWord,2019-07,26.48,100.0,26.48,1.0,26.48,0.5,ROUGE\\-1
28,1,Timeline Summarization,MTS,2019-08,39.78,100.0,39.78,1.0,39.78,0.75,ROUGE\\-1
0,1,Text Summarization,DUC 2004 Task 1,2015-09,8.49,72.07,8.49,0.72,11.78,0.39,ROUGE\\-2
1,1,Text Summarization,DUC 2004 Task 1,2016-02,9.42,79.97,0.9,0.08,11.78,0.44,ROUGE\\-2
2,1,Text Summarization,DUC 2004 Task 1,2017-04,10.54,89.47,1.1,0.09,11.78,0.49,ROUGE\\-2
3,1,Text Summarization,DUC 2004 Task 1,2017-09,10.75,91.26,0.2,0.02,11.78,0.5,ROUGE\\-2
4,1,Text Summarization,DUC 2004 Task 1,2019-04,11.78,100.0,1.0,0.08,11.78,0.55,ROUGE\\-2
5,1,Text Summarization,GigaWord,2016-02,17.7,86.68,17.7,0.87,20.42,0.82,ROUGE\\-2
6,1,Text Summarization,GigaWord,2018-07,18.0,88.15,0.3,0.01,20.42,0.84,ROUGE\\-2
7,1,Text Summarization,GigaWord,2018-07,19.03,93.19,1.0,0.05,20.42,0.88,ROUGE\\-2
8,1,Text Summarization,GigaWord,2019-05,19.71,96.52,0.7,0.03,20.42,0.91,ROUGE\\-2
9,1,Text Summarization,GigaWord,2019-05,20.05,98.19,0.3,0.01,20.42,0.93,ROUGE\\-2
10,1,Text Summarization,GigaWord,2020-01,20.42,100.0,0.4,0.02,20.42,0.95,ROUGE\\-2
11,1,Abstractive Text Summarization,CNN / Daily Mail,2017-04,17.28,80.48,17.28,0.8,21.47,0.8,ROUGE\\-2
12,1,Abstractive Text Summarization,CNN / Daily Mail,2019-05,20.43,95.16,3.1,0.14,21.47,0.95,ROUGE\\-2
13,1,Abstractive Text Summarization,CNN / Daily Mail,2019-12,21.47,100.0,1.0,0.05,21.47,1.0,ROUGE\\-2
14,1,Document Summarization,CNN / Daily Mail,2017-05,14.81,68.72,14.81,0.69,21.55,0.69,ROUGE\\-2
15,1,Document Summarization,CNN / Daily Mail,2017-05,15.82,73.41,1.0,0.05,21.55,0.73,ROUGE\\-2
16,1,Document Summarization,CNN / Daily Mail,2018-08,18.68,86.68,2.9,0.13,21.55,0.87,ROUGE\\-2
17,1,Document Summarization,CNN / Daily Mail,2019-03,20.24,93.92,1.6,0.07,21.55,0.94,ROUGE\\-2
18,1,Document Summarization,CNN / Daily Mail,2019-05,20.43,94.8,0.2,0.01,21.55,0.95,ROUGE\\-2
19,1,Document Summarization,CNN / Daily Mail,2019-10,21.55,100.0,1.1,0.05,21.55,1.0,ROUGE\\-2
20,1,Extractive Document Summarization,CNN / Daily Mail,2018-09,12.6,61.95,12.6,0.62,20.34,0.58,ROUGE\\-2
21,1,Extractive Document Summarization,CNN / Daily Mail,2019-03,20.24,99.51,7.6,0.37,20.34,0.94,ROUGE\\-2
22,1,Extractive Document Summarization,CNN / Daily Mail,2019-08,20.34,100.0,0.1,0.0,20.34,0.94,ROUGE\\-2
23,1,Sentence Summarization,GigaWord,2019-07,10.05,100.0,10.05,1.0,10.05,0.47,ROUGE\\-2
24,1,Unsupervised Sentence Summarization,GigaWord,2019-07,10.05,100.0,10.05,1.0,10.05,0.47,ROUGE\\-2
0,1,Text Summarization,DUC 2004 Task 1,2015-09,23.81,83.49,23.81,0.83,28.52,0.34,ROUGE\\-L
1,1,Text Summarization,DUC 2004 Task 1,2016-02,25.24,88.5,1.4,0.05,28.52,0.36,ROUGE\\-L
2,1,Text Summarization,DUC 2004 Task 1,2017-04,27.8,97.48,2.6,0.09,28.52,0.39,ROUGE\\-L
3,1,Text Summarization,DUC 2004 Task 1,2019-04,28.52,100.0,0.7,0.02,28.52,0.4,ROUGE\\-L
4,1,Text Summarization,GigaWord,2016-02,33.71,91.88,33.71,0.92,36.69,0.48,ROUGE\\-L
5,1,Text Summarization,GigaWord,2017-04,33.88,92.34,0.2,0.01,36.69,0.48,ROUGE\\-L
6,1,Text Summarization,GigaWord,2017-11,34.24,93.32,0.4,0.01,36.69,0.48,ROUGE\\-L
7,1,Text Summarization,GigaWord,2018-06,34.93,95.2,0.7,0.02,36.69,0.49,ROUGE\\-L
8,1,Text Summarization,GigaWord,2019-05,35.96,98.01,1.0,0.03,36.69,0.51,ROUGE\\-L
9,1,Text Summarization,GigaWord,2019-05,36.0,98.12,0.0,0.0,36.69,0.51,ROUGE\\-L
10,1,Text Summarization,GigaWord,2019-12,36.24,98.77,0.2,0.01,36.69,0.51,ROUGE\\-L
11,1,Text Summarization,GigaWord,2020-01,36.69,100.0,0.4,0.01,36.69,0.52,ROUGE\\-L
12,1,Document Summarization,CNN / Daily Mail,2017-05,35.49,87.22,35.49,0.87,40.69,0.5,ROUGE\\-L
13,1,Document Summarization,CNN / Daily Mail,2017-05,36.9,90.69,1.4,0.03,40.69,0.52,ROUGE\\-L
14,1,Document Summarization,CNN / Daily Mail,2018-08,38.34,94.22,1.4,0.03,40.69,0.54,ROUGE\\-L
15,1,Document Summarization,CNN / Daily Mail,2019-03,39.63,97.39,1.3,0.03,40.69,0.56,ROUGE\\-L
16,1,Document Summarization,CNN / Daily Mail,2019-05,40.34,99.14,0.7,0.02,40.69,0.57,ROUGE\\-L
17,1,Document Summarization,CNN / Daily Mail,2019-10,40.69,100.0,0.3,0.01,40.69,0.57,ROUGE\\-L
18,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,66.45,93.82,66.45,0.94,70.83,0.94,ROUGE\\-L
19,1,Data-to-Text Generation,E2E NLG Challenge,2018-03,70.83,100.0,4.4,0.06,70.83,1.0,ROUGE\\-L
20,1,Paper generation,ACL Title and Abstract Dataset,2018-05,20.3,100.0,20.3,1.0,20.3,0.29,ROUGE\\-L
21,1,Extractive Document Summarization,CNN / Daily Mail,2019-03,39.63,99.32,39.63,0.99,39.9,0.56,ROUGE\\-L
22,1,Extractive Document Summarization,CNN / Daily Mail,2019-08,39.9,100.0,0.3,0.01,39.9,0.56,ROUGE\\-L
23,1,Abstractive Text Summarization,CNN / Daily Mail,2019-05,40.34,97.46,40.34,0.97,41.39,0.57,ROUGE\\-L
24,1,Abstractive Text Summarization,CNN / Daily Mail,2019-12,41.11,99.32,0.8,0.02,41.39,0.58,ROUGE\\-L
25,1,Abstractive Text Summarization,CNN / Daily Mail,2020-01,41.39,100.0,0.3,0.01,41.39,0.58,ROUGE\\-L
26,1,Sentence Summarization,GigaWord,2019-07,24.41,100.0,24.41,1.0,24.41,0.34,ROUGE\\-L
27,1,Unsupervised Sentence Summarization,GigaWord,2019-07,24.41,100.0,24.41,1.0,24.41,0.34,ROUGE\\-L
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2015-12,71.88,83.35,71.88,0.83,86.24,0.83,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
1,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2016-05,76.58,88.8,4.7,0.05,86.24,0.89,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
2,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2017-09,77.36,89.7,0.8,0.01,86.24,0.9,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
3,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-02,78.29,90.78,0.9,0.01,86.24,0.91,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
4,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-04,78.35,90.85,0.1,0.0,86.24,0.91,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
5,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-05,78.4,90.91,0.1,0.0,86.24,0.91,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
6,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-10,79.75,92.47,1.3,0.02,86.24,0.92,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
7,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,81.53,94.54,1.8,0.02,86.24,0.95,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
8,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,81.73,94.77,0.2,0.0,86.24,0.95,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
9,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-06,82.46,95.62,0.7,0.01,86.24,0.96,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
10,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-08,84.06,97.47,1.6,0.02,86.24,0.97,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
11,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-12,86.24,100.0,2.2,0.03,86.24,1.0,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2015-12,75.63,83.87,75.63,0.84,90.18,0.84,Restaurant\\ \\(Acc\\)
1,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2016-05,80.95,89.76,5.3,0.06,90.18,0.9,Restaurant\\ \\(Acc\\)
2,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-02,81.34,90.2,0.4,0.0,90.18,0.9,Restaurant\\ \\(Acc\\)
3,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-04,81.6,90.49,0.3,0.0,90.18,0.9,Restaurant\\ \\(Acc\\)
4,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-10,82.23,91.18,0.6,0.01,90.18,0.91,Restaurant\\ \\(Acc\\)
5,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,83.12,92.17,0.9,0.01,90.18,0.92,Restaurant\\ \\(Acc\\)
6,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,84.46,93.66,1.3,0.01,90.18,0.94,Restaurant\\ \\(Acc\\)
7,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-04,84.95,94.2,0.5,0.01,90.18,0.94,Restaurant\\ \\(Acc\\)
8,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-08,87.89,97.46,2.9,0.03,90.18,0.97,Restaurant\\ \\(Acc\\)
9,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-12,90.18,100.0,2.3,0.03,90.18,1.0,Restaurant\\ \\(Acc\\)
10,1,Aspect-Based Sentiment Analysis,SemEval-2016 Task 5 Subtask 1,2019-03,88.0,100.0,88,1.0,88,0.98,Restaurant\\ \\(Acc\\)
11,1,Aspect-Based Sentiment Analysis,SemEval 2015 Task 12,2019-03,80.6,98.65,80.6,0.99,81.7,0.89,Restaurant\\ \\(Acc\\)
12,1,Aspect-Based Sentiment Analysis,SemEval 2015 Task 12,2020-04,81.7,100.0,1.1,0.01,81.7,0.91,Restaurant\\ \\(Acc\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2015-12,68.13,82.79,68.13,0.83,82.29,0.83,Laptop\\ \\(Acc\\)
1,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2016-05,72.21,87.75,4.1,0.05,82.29,0.88,Laptop\\ \\(Acc\\)
2,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2017-09,74.49,90.52,2.3,0.03,82.29,0.91,Laptop\\ \\(Acc\\)
3,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-02,75.24,91.43,0.8,0.01,82.29,0.91,Laptop\\ \\(Acc\\)
4,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-05,76.01,92.37,0.8,0.01,82.29,0.92,Laptop\\ \\(Acc\\)
5,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-10,77.27,93.9,1.3,0.02,82.29,0.94,Laptop\\ \\(Acc\\)
6,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,79.93,97.13,2.7,0.03,82.29,0.97,Laptop\\ \\(Acc\\)
7,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-06,81.35,98.86,1.4,0.02,82.29,0.99,Laptop\\ \\(Acc\\)
8,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-12,82.29,100.0,0.9,0.01,82.29,1.0,Laptop\\ \\(Acc\\)
0,1,Machine Translation,IWSLT2015 English-Vietnamese,2015-12,26.4,79.35,26.4,0.79,33.27,0.38,BLEU
1,1,Machine Translation,IWSLT2015 English-Vietnamese,2018-06,28.47,85.57,2.1,0.06,33.27,0.42,BLEU
2,1,Machine Translation,IWSLT2015 English-Vietnamese,2018-08,29.12,87.53,0.7,0.02,33.27,0.42,BLEU
3,1,Machine Translation,IWSLT2015 English-Vietnamese,2018-09,29.6,88.97,0.5,0.02,33.27,0.43,BLEU
4,1,Machine Translation,IWSLT2015 English-Vietnamese,2019-10,32.8,98.59,3.2,0.1,33.27,0.48,BLEU
5,1,Machine Translation,IWSLT2015 English-Vietnamese,2019-10,33.27,100.0,0.5,0.02,33.27,0.48,BLEU
6,1,Table-to-Text Generation,WikiBio,2016-03,34.7,77.3,34.7,0.77,44.89,0.51,BLEU
7,1,Table-to-Text Generation,WikiBio,2017-11,44.89,100.0,10.2,0.23,44.89,0.65,BLEU
8,1,Data-to-Text Generation,RotoWire,2017-07,14.19,81.09,14.19,0.81,17.5,0.21,BLEU
9,1,Data-to-Text Generation,RotoWire,2018-09,16.5,94.29,2.3,0.13,17.5,0.24,BLEU
10,1,Data-to-Text Generation,RotoWire,2019-12,17.5,100.0,1.0,0.06,17.5,0.26,BLEU
11,1,Machine Translation,WMT 2017 Latvian-English,2017-09,20.8,85.35,20.8,0.85,24.37,0.3,BLEU
12,1,Machine Translation,WMT 2017 Latvian-English,2018-10,24.37,100.0,3.6,0.15,24.37,0.36,BLEU
13,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,64.22,93.62,64.22,0.94,68.6,0.94,BLEU
14,1,Data-to-Text Generation,E2E NLG Challenge,2018-03,65.45,95.41,1.2,0.02,68.6,0.95,BLEU
15,1,Data-to-Text Generation,E2E NLG Challenge,2018-04,65.61,95.64,0.2,0.0,68.6,0.96,BLEU
16,1,Data-to-Text Generation,E2E NLG Challenge,2018-05,66.19,96.49,0.6,0.01,68.6,0.96,BLEU
17,1,Data-to-Text Generation,E2E NLG Challenge,2019-04,68.6,100.0,2.4,0.03,68.6,1.0,BLEU
18,1,Unsupervised Machine Translation,WMT2014 French-English,2018-04,27.7,79.37,27.7,0.79,34.9,0.4,BLEU
19,1,Unsupervised Machine Translation,WMT2014 French-English,2019-01,28.9,82.81,1.2,0.03,34.9,0.42,BLEU
20,1,Unsupervised Machine Translation,WMT2014 French-English,2019-01,33.3,95.42,4.4,0.13,34.9,0.49,BLEU
21,1,Unsupervised Machine Translation,WMT2014 French-English,2019-02,33.5,95.99,0.2,0.01,34.9,0.49,BLEU
22,1,Unsupervised Machine Translation,WMT2014 French-English,2019-05,34.9,100.0,1.4,0.04,34.9,0.51,BLEU
23,1,Unsupervised Machine Translation,WMT2016 German-English,2018-04,25.2,71.59,25.2,0.72,35.2,0.37,BLEU
24,1,Unsupervised Machine Translation,WMT2016 German-English,2018-10,26.7,75.85,1.5,0.04,35.2,0.39,BLEU
25,1,Unsupervised Machine Translation,WMT2016 German-English,2019-01,34.3,97.44,7.6,0.22,35.2,0.5,BLEU
26,1,Unsupervised Machine Translation,WMT2016 German-English,2019-02,34.4,97.73,0.1,0.0,35.2,0.5,BLEU
27,1,Unsupervised Machine Translation,WMT2016 German-English,2019-05,35.2,100.0,0.8,0.02,35.2,0.51,BLEU
28,1,Unsupervised Machine Translation,WMT2016 English-German,2018-04,20.2,71.38,20.2,0.71,28.3,0.29,BLEU
29,1,Unsupervised Machine Translation,WMT2016 English-German,2019-01,21.7,76.68,1.5,0.05,28.3,0.32,BLEU
30,1,Unsupervised Machine Translation,WMT2016 English-German,2019-01,26.4,93.29,4.7,0.17,28.3,0.38,BLEU
31,1,Unsupervised Machine Translation,WMT2016 English-German,2019-02,26.9,95.05,0.5,0.02,28.3,0.39,BLEU
32,1,Unsupervised Machine Translation,WMT2016 English-German,2019-05,28.3,100.0,1.4,0.05,28.3,0.41,BLEU
33,1,Unsupervised Machine Translation,WMT2014 English-French,2018-04,27.6,73.6,27.6,0.74,37.5,0.4,BLEU
34,1,Unsupervised Machine Translation,WMT2014 English-French,2019-01,29.5,78.67,1.9,0.05,37.5,0.43,BLEU
35,1,Unsupervised Machine Translation,WMT2014 English-French,2019-01,33.4,89.07,3.9,0.1,37.5,0.49,BLEU
36,1,Unsupervised Machine Translation,WMT2014 English-French,2019-02,36.2,96.53,2.8,0.07,37.5,0.53,BLEU
37,1,Unsupervised Machine Translation,WMT2014 English-French,2019-05,37.5,100.0,1.3,0.03,37.5,0.55,BLEU
38,1,Machine Translation,ACCURAT balanced test corpus for under resourced languages Russian-Estonian,2018-05,18.03,100.0,18.03,1.0,18.03,0.26,BLEU
39,1,Machine Translation,ACCURAT balanced test corpus for under resourced languages Estonian-Russian,2018-05,19.18,100.0,19.18,1.0,19.18,0.28,BLEU
40,1,Graph-to-Sequence,LDC2015E86:,2018-05,33.6,100.0,33.6,1.0,33.6,0.49,BLEU
41,1,Text Generation,LDC2016E25,2018-05,22.0,100.0,22,1.0,22,0.32,BLEU
42,1,Table-to-Text Generation,Wikipedia Person and Animal Dataset,2018-09,23.2,100.0,23.2,1.0,23.2,0.34,BLEU
43,1,KB-to-Language Generation,Wikipedia Person and Animal Dataset,2018-09,23.2,100.0,23.2,1.0,23.2,0.34,BLEU
44,1,Machine Translation,WMT 2018 English-Estonian,2018-10,24.1,100.0,24.1,1.0,24.1,0.35,BLEU
45,1,Machine Translation,WMT 2018 Estonian-English,2018-10,29.0,100.0,29,1.0,29,0.42,BLEU
46,1,Machine Translation,WMT 2018 Finnish-English,2018-10,24.0,90.57,24.0,0.91,26.5,0.35,BLEU
47,1,Machine Translation,WMT 2018 Finnish-English,2019-06,26.5,100.0,2.5,0.09,26.5,0.39,BLEU
48,1,Machine Translation,WMT 2018 English-Finnish,2018-10,17.4,100.0,17.4,1.0,17.4,0.25,BLEU
49,1,Machine Translation,WMT 2017 English-Latvian,2018-10,22.89,100.0,22.89,1.0,22.89,0.33,BLEU
50,1,Data-to-Text Generation,SR11Deep,2018-10,0.666,100.0,0.666,1.0,0.666,0.01,BLEU
51,1,Data-to-Text Generation,WebNLG,2018-10,0.559,100.0,0.559,1.0,0.559,0.01,BLEU
52,1,Unsupervised Machine Translation,WMT2014 English-German,2019-01,17.0,75.56,17.0,0.76,22.5,0.25,BLEU
53,1,Unsupervised Machine Translation,WMT2014 English-German,2019-02,22.5,100.0,5.5,0.24,22.5,0.33,BLEU
54,1,Unsupervised Machine Translation,WMT2014 German-English,2019-01,20.4,75.56,20.4,0.76,27.0,0.3,BLEU
55,1,Unsupervised Machine Translation,WMT2014 German-English,2019-02,27.0,100.0,6.6,0.24,27.0,0.39,BLEU
56,1,Unsupervised Machine Translation,WMT2016 English-Romanian,2019-01,33.3,94.6,33.3,0.95,35.2,0.49,BLEU
57,1,Unsupervised Machine Translation,WMT2016 English-Romanian,2019-05,35.2,100.0,1.9,0.05,35.2,0.51,BLEU
58,1,Unsupervised Machine Translation,WMT2016 English--Romanian,2019-01,33.3,100.0,33.3,1.0,33.3,0.49,BLEU
59,1,Unsupervised Machine Translation,WMT2016 Romanian-English,2019-01,31.8,96.07,31.8,0.96,33.1,0.46,BLEU
60,1,Unsupervised Machine Translation,WMT2016 Romanian-English,2019-05,33.1,100.0,1.3,0.04,33.1,0.48,BLEU
61,1,Question Answering,JD Product Question Answer,2019-01,2.0189,100.0,2.0189,1.0,2.0189,0.03,BLEU
62,1,Machine Translation,WMT2019 Finnish-English,2019-06,34.1,100.0,34.1,1.0,34.1,0.5,BLEU
63,1,Machine Translation,WMT2017 Finnish-English,2019-06,35.5,100.0,35.5,1.0,35.5,0.52,BLEU
64,1,Machine Translation,WMT2016 Finnish-English,2019-06,32.4,100.0,32.4,1.0,32.4,0.47,BLEU
65,1,Data-to-Text Generation,WebNLG Full,2019-08,51.68,97.69,51.68,0.98,52.9,0.75,BLEU
66,1,Data-to-Text Generation,WebNLG Full,2020-04,52.9,100.0,1.2,0.02,52.9,0.77,BLEU
67,1,Data-to-Text Generation,LDC2017T10,2019-09,28.26,74.96,28.26,0.75,37.7,0.41,BLEU
68,1,Data-to-Text Generation,LDC2017T10,2020-04,37.7,100.0,9.4,0.25,37.7,0.55,BLEU
69,1,Data-to-Text Generation,ViGGO,2019-10,52.1,97.2,52.1,0.97,53.6,0.76,BLEU
70,1,Data-to-Text Generation,ViGGO,2020-04,53.6,100.0,1.5,0.03,53.6,0.78,BLEU
71,1,Data-to-Text Generation,Cleaned E2E NLG Challenge,2019-11,40.73,93.42,40.73,0.93,43.6,0.59,BLEU
72,1,Data-to-Text Generation,Cleaned E2E NLG Challenge,2020-04,43.6,100.0,2.9,0.07,43.6,0.64,BLEU
73,1,Machine Translation,IWSLT2015 Chinese-English,2019-11,19.84,100.0,19.84,1.0,19.84,0.29,BLEU
0,1,Entity Disambiguation,TAC2010,2016-01,85.2,97.15,85.2,0.97,87.7,0.88,Micro\\-F1
1,1,Entity Disambiguation,TAC2010,2017-05,87.7,100.0,2.5,0.03,87.7,0.91,Micro\\-F1
2,1,Entity Disambiguation,AIDA-CoNLL,2016-01,93.1,98.0,93.1,0.98,95.0,0.97,Micro\\-F1
3,1,Entity Disambiguation,AIDA-CoNLL,2017-05,94.7,99.68,1.6,0.02,95.0,0.98,Micro\\-F1
4,1,Entity Disambiguation,AIDA-CoNLL,2019-09,95.0,100.0,0.3,0.0,95.0,0.99,Micro\\-F1
5,1,Entity Disambiguation,ACE2004,2017-04,88.5,96.3,88.5,0.96,91.9,0.92,Micro\\-F1
6,1,Entity Disambiguation,ACE2004,2019-09,91.9,100.0,3.4,0.04,91.9,0.95,Micro\\-F1
7,1,Entity Disambiguation,MSNBC,2017-04,93.7,97.3,93.7,0.97,96.3,0.97,Micro\\-F1
8,1,Entity Disambiguation,MSNBC,2019-09,96.3,100.0,2.6,0.03,96.3,1.0,Micro\\-F1
9,1,Entity Disambiguation,AQUAINT,2017-04,88.5,94.45,88.5,0.94,93.7,0.92,Micro\\-F1
10,1,Entity Disambiguation,AQUAINT,2019-09,93.7,100.0,5.2,0.06,93.7,0.97,Micro\\-F1
11,1,Entity Disambiguation,WNED-CWEB,2017-04,77.9,98.73,77.9,0.99,78.9,0.81,Micro\\-F1
12,1,Entity Disambiguation,WNED-CWEB,2019-09,78.9,100.0,1.0,0.01,78.9,0.82,Micro\\-F1
13,1,Entity Disambiguation,WNED-WIKI,2017-04,77.5,86.98,77.5,0.87,89.1,0.8,Micro\\-F1
14,1,Entity Disambiguation,WNED-WIKI,2019-09,89.1,100.0,11.6,0.13,89.1,0.93,Micro\\-F1
15,1,Entity Linking,OKE-2015,2018-08,66.9,100.0,66.9,1.0,66.9,0.69,Micro\\-F1
16,1,Entity Linking,OKE-2016,2018-08,58.4,100.0,58.4,1.0,58.4,0.61,Micro\\-F1
17,1,Entity Linking,MSNBC,2018-08,72.4,100.0,72.4,1.0,72.4,0.75,Micro\\-F1
18,1,Entity Linking,N3-Reuters-128,2018-08,54.6,100.0,54.6,1.0,54.6,0.57,Micro\\-F1
19,1,Entity Linking,Derczynski,2018-08,42.3,100.0,42.3,1.0,42.3,0.44,Micro\\-F1
20,1,Emotion Recognition in Conversation,EC,2019-03,0.7709,99.28,0.7709,0.99,0.7765,0.01,Micro\\-F1
21,1,Emotion Recognition in Conversation,EC,2019-04,0.7765,100.0,0.0,0.0,0.7765,0.01,Micro\\-F1
22,1,Multi-Label Text Classification,RCV1-v2,2020-02,88.5,100.0,88.5,1.0,88.5,0.92,Micro\\-F1
23,1,Multi-Label Text Classification,Reuters-21578,2020-02,89.9,100.0,89.9,1.0,89.9,0.93,Micro\\-F1
24,1,Multi-Label Text Classification,Slashdot,2020-02,56.8,100.0,56.8,1.0,56.8,0.59,Micro\\-F1
0,1,Language Modelling,Text8,2016-02,1.63,100.0,1.63,1.0,1.63,1.0,Bit\\ per\\ Character\\ \\(BPC\\)
1,1,Language Modelling,Hutter Prize,2016-07,1.27,96.95,1.27,0.97,1.31,0.78,Bit\\ per\\ Character\\ \\(BPC\\)
2,1,Language Modelling,Hutter Prize,2016-07,1.31,100.0,0.0,0.0,1.31,0.8,Bit\\ per\\ Character\\ \\(BPC\\)
3,1,Language Modelling,enwiki8,2016-07,1.27,94.78,1.27,0.95,1.34,0.78,Bit\\ per\\ Character\\ \\(BPC\\)
4,1,Language Modelling,enwiki8,2016-09,1.32,98.51,0.1,0.07,1.34,0.81,Bit\\ per\\ Character\\ \\(BPC\\)
5,1,Language Modelling,enwiki8,2016-09,1.34,100.0,0.0,0.0,1.34,0.82,Bit\\ per\\ Character\\ \\(BPC\\)
0,1,Question Answering,Children's Book Test,2016-03,68.9,73.85,68.9,0.74,93.3,0.74,Accuracy\\-CN
1,1,Question Answering,Children's Book Test,2016-06,71.9,77.06,3.0,0.03,93.3,0.77,Accuracy\\-CN
2,1,Question Answering,Children's Book Test,2019-02,93.3,100.0,21.4,0.23,93.3,1.0,Accuracy\\-CN
0,1,Question Answering,Children's Book Test,2016-03,70.6,79.28,70.6,0.79,89.05,0.79,Accuracy\\-NE
1,1,Question Answering,Children's Book Test,2016-03,71.0,79.73,0.4,0.0,89.05,0.8,Accuracy\\-NE
2,1,Question Answering,Children's Book Test,2016-06,73.2,82.2,2.2,0.02,89.05,0.82,Accuracy\\-NE
3,1,Question Answering,Children's Book Test,2016-06,74.9,84.11,1.7,0.02,89.05,0.84,Accuracy\\-NE
4,1,Question Answering,Children's Book Test,2019-02,89.05,100.0,14.1,0.16,89.05,1.0,Accuracy\\-NE
0,1,Open-Domain Question Answering,SearchQA,2016-03,41.3,66.4,41.3,0.66,62.2,0.66,Unigram\\ Acc
1,1,Open-Domain Question Answering,SearchQA,2018-01,46.8,75.24,5.5,0.09,62.2,0.75,Unigram\\ Acc
2,1,Open-Domain Question Answering,SearchQA,2018-10,49.4,79.42,2.6,0.04,62.2,0.79,Unigram\\ Acc
3,1,Open-Domain Question Answering,SearchQA,2018-11,62.2,100.0,12.8,0.21,62.2,1.0,Unigram\\ Acc
0,1,Open-Domain Question Answering,SearchQA,2016-03,22.8,32.2,22.8,0.32,70.8,0.32,N\\-gram\\ F1
1,1,Open-Domain Question Answering,SearchQA,2018-01,56.6,79.94,33.8,0.48,70.8,0.8,N\\-gram\\ F1
2,1,Open-Domain Question Answering,SearchQA,2018-10,59.5,84.04,2.9,0.04,70.8,0.84,N\\-gram\\ F1
3,1,Open-Domain Question Answering,SearchQA,2018-11,70.8,100.0,11.3,0.16,70.8,1.0,N\\-gram\\ F1
0,1,Table-to-Text Generation,WikiBio,2016-03,25.8,61.94,25.8,0.62,41.65,0.53,ROUGE
1,1,Table-to-Text Generation,WikiBio,2017-11,41.21,98.94,15.4,0.37,41.65,0.84,ROUGE
2,1,Table-to-Text Generation,WikiBio,2017-11,41.65,100.0,0.4,0.01,41.65,0.85,ROUGE
3,1,Table-to-Text Generation,Wikipedia Person and Animal Dataset,2018-09,23.4,100.0,23.4,1.0,23.4,0.48,ROUGE
4,1,KB-to-Language Generation,Wikipedia Person and Animal Dataset,2018-09,42.0,100.0,42,1.0,42,0.86,ROUGE
5,1,Image Captioning,COCO,2019-05,49.0,100.0,49,1.0,49,1.0,ROUGE
0,1,Language Modelling,Text8,2016-03,16000000.0,5.78,16000000,0.06,277000000,0.0,Number\\ of\\ params
1,1,Language Modelling,Text8,2016-07,46000000.0,16.61,30000000,0.11,277000000,0.01,Number\\ of\\ params
2,1,Language Modelling,Text8,2018-08,235000000.0,84.84,189000000,0.68,277000000,0.03,Number\\ of\\ params
3,1,Language Modelling,Text8,2019-01,277000000.0,100.0,42000000,0.15,277000000,0.03,Number\\ of\\ params
4,1,Language Modelling,enwiki8,2016-07,46000000.0,2.98,46000000,0.03,1542000000,0.01,Number\\ of\\ params
5,1,Language Modelling,enwiki8,2017-05,47000000.0,3.05,1000000,0.0,1542000000,0.01,Number\\ of\\ params
6,1,Language Modelling,enwiki8,2018-04,95000000.0,6.16,48000000,0.03,1542000000,0.01,Number\\ of\\ params
7,1,Language Modelling,enwiki8,2018-08,235000000.0,15.24,140000000,0.09,1542000000,0.03,Number\\ of\\ params
8,1,Language Modelling,enwiki8,2019-01,277000000.0,17.96,42000000,0.03,1542000000,0.03,Number\\ of\\ params
9,1,Language Modelling,enwiki8,2019-02,1542000000.0,100.0,1265000000,0.82,1542000000,0.19,Number\\ of\\ params
10,1,Language Modelling,Hutter Prize,2016-07,46000000.0,16.61,46000000,0.17,277000000,0.01,Number\\ of\\ params
11,1,Language Modelling,Hutter Prize,2017-05,47000000.0,16.97,1000000,0.0,277000000,0.01,Number\\ of\\ params
12,1,Language Modelling,Hutter Prize,2018-08,235000000.0,84.84,188000000,0.68,277000000,0.03,Number\\ of\\ params
13,1,Language Modelling,Hutter Prize,2019-01,277000000.0,100.0,42000000,0.15,277000000,0.03,Number\\ of\\ params
14,1,Language Modelling,WikiText-2,2017-08,33000000.0,2.14,33000000,0.02,1542000000,0.0,Number\\ of\\ params
15,1,Language Modelling,WikiText-2,2017-10,34000000.0,2.2,1000000,0.0,1542000000,0.0,Number\\ of\\ params
16,1,Language Modelling,WikiText-2,2017-11,35000000.0,2.27,1000000,0.0,1542000000,0.0,Number\\ of\\ params
17,1,Language Modelling,WikiText-2,2018-08,37000000.0,2.4,2000000,0.0,1542000000,0.0,Number\\ of\\ params
18,1,Language Modelling,WikiText-2,2018-08,185000000.0,12.0,148000000,0.1,1542000000,0.02,Number\\ of\\ params
19,1,Language Modelling,WikiText-2,2019-02,1542000000.0,100.0,1357000000,0.88,1542000000,0.19,Number\\ of\\ params
20,1,Language Modelling,WikiText-103,2018-03,151000000.0,1.82,151000000,0.02,8300000000,0.02,Number\\ of\\ params
21,1,Language Modelling,WikiText-103,2018-09,247000000.0,2.98,96000000,0.01,8300000000,0.03,Number\\ of\\ params
22,1,Language Modelling,WikiText-103,2019-01,257000000.0,3.1,10000000,0.0,8300000000,0.03,Number\\ of\\ params
23,1,Language Modelling,WikiText-103,2019-02,774000000.0,9.33,517000000,0.06,8300000000,0.09,Number\\ of\\ params
24,1,Language Modelling,WikiText-103,2019-02,1542000000.0,18.58,768000000,0.09,8300000000,0.19,Number\\ of\\ params
25,1,Language Modelling,WikiText-103,2019-09,8300000000.0,100.0,6758000000,0.81,8300000000,1.0,Number\\ of\\ params
0,1,Part-Of-Speech Tagging,UD,2016-04,96.4,99.5,96.4,1.0,96.88,1.0,Avg\\ accuracy
1,1,Part-Of-Speech Tagging,UD,2017-11,96.73,99.85,0.3,0.0,96.88,1.0,Avg\\ accuracy
2,1,Part-Of-Speech Tagging,UD,2019-08,96.88,100.0,0.1,0.0,96.88,1.0,Avg\\ accuracy
0,1,Chinese Word Segmentation,MSR,2019-01,98.2,100.0,98.2,1.0,98.2,1.0,Precision
1,1,Chinese Word Segmentation,AS,2019-01,96.6,100.0,96.6,1.0,96.6,0.98,Precision
2,1,Chinese Word Segmentation,PKU,2019-01,97.1,100.0,97.1,1.0,97.1,0.99,Precision
3,1,Chinese Word Segmentation,CITYU,2019-01,97.9,100.0,97.9,1.0,97.9,1.0,Precision
4,1,Chinese Named Entity Recognition,OntoNotes,2019-01,81.87,100.0,81.87,1.0,81.87,0.83,Precision
5,1,Chinese Named Entity Recognition,Weibo NER,2019-01,67.68,100.0,67.68,1.0,67.68,0.69,Precision
6,1,Chinese Named Entity Recognition,Resume NER,2019-01,96.62,100.0,96.62,1.0,96.62,0.98,Precision
7,1,Chinese Named Entity Recognition,MSRA,2019-01,95.57,100.0,95.57,1.0,95.57,0.97,Precision
8,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2019-03,71.57,100.0,71.57,1.0,71.57,0.73,Precision
9,1,Entity Typing,Open Entity,2019-05,78.42,100.0,78.42,1.0,78.42,0.8,Precision
10,1,Relation Extraction,FewRel,2019-05,88.49,100.0,88.49,1.0,88.49,0.9,Precision
11,1,Relation Extraction,TACRED,2019-05,69.97,98.83,69.97,0.99,70.8,0.71,Precision
12,1,Relation Extraction,TACRED,2019-07,70.8,100.0,0.8,0.01,70.8,0.72,Precision
13,1,Named Entity Recognition,Long-tail emerging entities,2019-08,58.28,100.0,58.28,1.0,58.28,0.59,Precision
14,1,Named Entity Recognition,French Treebank,2019-11,88.35,100.0,88.35,1.0,88.35,0.9,Precision
15,1,Text Classification,20NEWS,2019-11,86.2,100.0,86.2,1.0,86.2,0.88,Precision
16,1,Named Entity Recognition,SoSciSoCi,2020-03,0.83,100.0,0.83,1.0,0.83,0.01,Precision
0,1,Chinese Word Segmentation,MSR,2019-01,98.3,100.0,98.3,1.0,98.3,1.0,Recall
1,1,Chinese Word Segmentation,AS,2019-01,96.8,100.0,96.8,1.0,96.8,0.98,Recall
2,1,Chinese Word Segmentation,PKU,2019-01,96.4,100.0,96.4,1.0,96.4,0.98,Recall
3,1,Chinese Word Segmentation,CITYU,2019-01,98.0,100.0,98,1.0,98,1.0,Recall
4,1,Chinese Named Entity Recognition,MSRA,2019-01,95.51,100.0,95.51,1.0,95.51,0.97,Recall
5,1,Chinese Named Entity Recognition,OntoNotes,2019-01,81.4,100.0,81.4,1.0,81.4,0.83,Recall
6,1,Chinese Named Entity Recognition,Weibo NER,2019-01,67.71,100.0,67.71,1.0,67.71,0.69,Recall
7,1,Chinese Named Entity Recognition,Resume NER,2019-01,96.48,100.0,96.48,1.0,96.48,0.98,Recall
8,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2019-03,38.65,100.0,38.65,1.0,38.65,0.39,Recall
9,1,Relation Extraction,FewRel,2019-05,88.44,100.0,88.44,1.0,88.44,0.9,Recall
10,1,Relation Extraction,TACRED,2019-05,66.08,93.2,66.08,0.93,70.9,0.67,Recall
11,1,Relation Extraction,TACRED,2019-07,70.9,100.0,4.8,0.07,70.9,0.72,Recall
12,1,Entity Typing,Open Entity,2019-05,72.9,100.0,72.9,1.0,72.9,0.74,Recall
13,1,Named Entity Recognition,Long-tail emerging entities,2019-08,33.92,100.0,33.92,1.0,33.92,0.35,Recall
14,1,Named Entity Recognition,French Treebank,2019-11,87.46,100.0,87.46,1.0,87.46,0.89,Recall
15,1,Text Classification,20NEWS,2019-11,86.18,100.0,86.18,1.0,86.18,0.88,Recall
16,1,Named Entity Recognition,SoSciSoCi,2020-03,0.82,100.0,0.82,1.0,0.82,0.01,Recall
0,1,Open-Domain Question Answering,Quasar,2016-06,26.4,62.41,26.4,0.62,42.3,0.62,EM\\ \\(Quasar\\-T\\)
1,1,Open-Domain Question Answering,Quasar,2017-11,42.3,100.0,15.9,0.38,42.3,1.0,EM\\ \\(Quasar\\-T\\)
0,1,Open-Domain Question Answering,Quasar,2016-06,26.4,53.23,26.4,0.53,49.6,0.53,F1\\ \\(Quasar\\-T\\)
1,1,Open-Domain Question Answering,Quasar,2016-11,28.5,57.46,2.1,0.04,49.6,0.57,F1\\ \\(Quasar\\-T\\)
2,1,Open-Domain Question Answering,Quasar,2017-11,49.6,100.0,21.1,0.43,49.6,1.0,F1\\ \\(Quasar\\-T\\)
0,1,Dialog State Tracking,Wizard-of-Oz,2016-06,84.4,94.94,84.4,0.95,88.9,0.95,Joint
1,1,Dialog State Tracking,Wizard-of-Oz,2018-05,88.1,99.1,3.7,0.04,88.9,0.99,Joint
2,1,Dialog State Tracking,Wizard-of-Oz,2018-10,88.9,100.0,0.8,0.01,88.9,1.0,Joint
3,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,73.4,97.22,73.4,0.97,75.5,0.83,Joint
4,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-05,74.5,98.68,1.1,0.01,75.5,0.84,Joint
5,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-10,75.5,100.0,1.0,0.01,75.5,0.85,Joint
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,90.0,100.0,90,1.0,90,1.0,Area
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,84.0,100.0,84,1.0,84,1.0,Food
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,94.0,100.0,94,1.0,94,1.0,Price
0,1,Dialog State Tracking,Wizard-of-Oz,2016-06,96.5,99.38,96.5,0.99,97.1,0.99,Request
1,1,Dialog State Tracking,Wizard-of-Oz,2018-05,97.1,100.0,0.6,0.01,97.1,1.0,Request
2,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,96.5,98.97,96.5,0.99,97.5,0.99,Request
3,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-05,97.5,100.0,1.0,0.01,97.5,1.0,Request
0,1,Grammatical Error Detection,CoNLL-2014 A2,2016-07,44.0,97.56,44.0,0.98,45.1,0.72,F0\\.5
1,1,Grammatical Error Detection,CoNLL-2014 A2,2017-07,45.1,100.0,1.1,0.02,45.1,0.74,F0\\.5
2,1,Grammatical Error Detection,FCE,2016-07,41.1,78.93,41.1,0.79,52.07,0.67,F0\\.5
3,1,Grammatical Error Detection,FCE,2016-11,41.88,80.43,0.8,0.02,52.07,0.68,F0\\.5
4,1,Grammatical Error Detection,FCE,2017-04,48.48,93.11,6.6,0.13,52.07,0.79,F0\\.5
5,1,Grammatical Error Detection,FCE,2017-07,49.11,94.32,0.6,0.01,52.07,0.8,F0\\.5
6,1,Grammatical Error Detection,FCE,2018-11,52.07,100.0,3.0,0.06,52.07,0.85,F0\\.5
7,1,Grammatical Error Detection,CoNLL-2014 A1,2016-07,34.3,95.01,34.3,0.95,36.1,0.56,F0\\.5
8,1,Grammatical Error Detection,CoNLL-2014 A1,2017-07,36.1,100.0,1.8,0.05,36.1,0.59,F0\\.5
9,1,Grammatical Error Correction,Restricted,2018-06,56.25,99.52,56.25,1.0,56.52,0.92,F0\\.5
10,1,Grammatical Error Correction,Restricted,2018-10,56.52,100.0,0.3,0.01,56.52,0.92,F0\\.5
11,1,Grammatical Error Correction,Unrestricted,2018-07,61.34,100.0,61.34,1.0,61.34,1.0,F0\\.5
12,1,Grammatical Error Detection,JFLEG,2018-11,52.52,100.0,52.52,1.0,52.52,0.86,F0\\.5
13,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2019-03,61.15,100.0,61.15,1.0,61.15,1.0,F0\\.5
0,1,Question Answering,SQuAD1.1,2016-08,60.474,67.27,60.474,0.67,89.898,0.67,EM
1,1,Question Answering,SQuAD1.1,2016-08,67.901,75.53,7.4,0.08,89.898,0.75,EM
2,1,Question Answering,SQuAD1.1,2016-09,75.034,83.47,7.1,0.08,89.898,0.83,EM
3,1,Question Answering,SQuAD1.1,2017-05,82.283,91.53,7.2,0.08,89.898,0.91,EM
4,1,Question Answering,SQuAD1.1,2018-10,85.083,94.64,2.8,0.03,89.898,0.94,EM
5,1,Question Answering,SQuAD1.1,2018-10,87.433,97.26,2.4,0.03,89.898,0.97,EM
6,1,Question Answering,SQuAD1.1,2019-06,89.898,100.0,2.5,0.03,89.898,0.99,EM
7,1,Question Answering,SQuAD1.1 dev,2016-08,64.1,71.17,64.1,0.71,90.06,0.71,EM
8,1,Question Answering,SQuAD1.1 dev,2016-11,66.4,73.73,2.3,0.03,90.06,0.73,EM
9,1,Question Answering,SQuAD1.1 dev,2016-11,67.7,75.17,1.3,0.01,90.06,0.75,EM
10,1,Question Answering,SQuAD1.1 dev,2017-03,67.89,75.38,0.2,0.0,90.06,0.75,EM
11,1,Question Answering,SQuAD1.1 dev,2017-03,70.3,78.06,2.4,0.03,90.06,0.78,EM
12,1,Question Answering,SQuAD1.1 dev,2017-04,70.6,78.39,0.3,0.0,90.06,0.78,EM
13,1,Question Answering,SQuAD1.1 dev,2017-05,78.9,87.61,8.3,0.09,90.06,0.87,EM
14,1,Question Answering,SQuAD1.1 dev,2018-10,84.2,93.49,5.3,0.06,90.06,0.93,EM
15,1,Question Answering,SQuAD1.1 dev,2019-06,89.7,99.6,5.5,0.06,90.06,0.99,EM
16,1,Question Answering,SQuAD1.1 dev,2019-10,90.06,100.0,0.4,0.0,90.06,0.99,EM
17,1,Open-Domain Question Answering,SQuAD1.1,2016-11,66.2,94.57,66.2,0.95,70.0,0.73,EM
18,1,Open-Domain Question Answering,SQuAD1.1,2017-03,70.0,100.0,3.8,0.05,70.0,0.77,EM
19,1,Question Answering,NewsQA,2017-03,43.7,82.3,43.7,0.82,53.1,0.48,EM
20,1,Question Answering,NewsQA,2018-01,48.4,91.15,4.7,0.09,53.1,0.53,EM
21,1,Question Answering,NewsQA,2018-05,50.1,94.35,1.7,0.03,53.1,0.55,EM
22,1,Question Answering,NewsQA,2018-11,53.1,100.0,3.0,0.06,53.1,0.59,EM
23,1,Question Answering,TriviaQA,2017-05,46.94,69.84,46.94,0.7,67.21,0.52,EM
24,1,Question Answering,TriviaQA,2017-06,50.56,75.23,3.6,0.05,67.21,0.56,EM
25,1,Question Answering,TriviaQA,2017-10,66.37,98.75,15.8,0.24,67.21,0.73,EM
26,1,Question Answering,TriviaQA,2018-10,67.21,100.0,0.8,0.01,67.21,0.74,EM
27,1,Question Answering,SQuAD2.0,2017-11,70.3,77.61,70.3,0.78,90.578,0.78,EM
28,1,Question Answering,SQuAD2.0,2017-12,71.316,78.73,1.0,0.01,90.578,0.79,EM
29,1,Question Answering,SQuAD2.0,2018-08,71.767,79.23,0.5,0.01,90.578,0.79,EM
30,1,Question Answering,SQuAD2.0,2018-10,80.005,88.33,8.2,0.09,90.578,0.88,EM
31,1,Question Answering,SQuAD2.0,2019-06,87.926,97.07,7.9,0.09,90.578,0.97,EM
32,1,Question Answering,SQuAD2.0,2019-08,88.174,97.35,0.2,0.0,90.578,0.97,EM
33,1,Question Answering,SQuAD2.0,2019-09,89.731,99.06,1.6,0.02,90.578,0.99,EM
34,1,Question Answering,SQuAD2.0,2020-01,90.578,100.0,0.8,0.01,90.578,1.0,EM
35,1,Open-Domain Question Answering,SearchQA,2018-07,58.8,100.0,58.8,1.0,58.8,0.65,EM
36,1,Question Answering,SQuAD2.0 dev,2018-08,72.3,82.25,72.3,0.82,87.9,0.8,EM
37,1,Question Answering,SQuAD2.0 dev,2018-10,78.7,89.53,6.4,0.07,87.9,0.87,EM
38,1,Question Answering,SQuAD2.0 dev,2019-06,87.9,100.0,9.2,0.1,87.9,0.97,EM
39,1,Open-Domain Question Answering,DuReader,2019-07,64.2,100.0,64.2,1.0,64.2,0.71,EM
40,1,Question Answering,FQuAD,2020-02,77.9,100.0,77.9,1.0,77.9,0.86,EM
0,1,Text Generation,EMNLP2017 WMT,2016-09,0.859,89.85,0.859,0.9,0.956,0.02,BLEU\\-2
1,1,Text Generation,EMNLP2017 WMT,2017-09,0.956,100.0,0.1,0.1,0.956,0.02,BLEU\\-2
2,1,Text Generation,Chinese Poems,2016-09,0.738,90.89,0.738,0.91,0.812,0.02,BLEU\\-2
3,1,Text Generation,Chinese Poems,2017-05,0.812,100.0,0.1,0.12,0.812,0.02,BLEU\\-2
4,1,Text Generation,COCO Captions,2016-09,0.831,87.47,0.831,0.87,0.95,0.02,BLEU\\-2
5,1,Text Generation,COCO Captions,2017-05,0.85,89.47,0.0,0.0,0.95,0.02,BLEU\\-2
6,1,Text Generation,COCO Captions,2017-09,0.95,100.0,0.1,0.11,0.95,0.02,BLEU\\-2
7,1,Text Generation,DailyDialog,2018-08,5.69,100.0,5.69,1.0,5.69,0.12,BLEU\\-2
8,1,Image Captioning,COCO,2019-05,46.3,100.0,46.3,1.0,46.3,1.0,BLEU\\-2
0,1,Text Generation,COCO Captions,2016-09,0.642,72.95,0.642,0.73,0.88,0.02,BLEU\\-3
1,1,Text Generation,COCO Captions,2017-05,0.672,76.36,0.0,0.0,0.88,0.02,BLEU\\-3
2,1,Text Generation,COCO Captions,2017-09,0.88,100.0,0.2,0.23,0.88,0.03,BLEU\\-3
3,1,Text Generation,EMNLP2017 WMT,2016-09,0.6015,73.44,0.6015,0.73,0.819,0.02,BLEU\\-3
4,1,Text Generation,EMNLP2017 WMT,2017-09,0.819,100.0,0.2,0.24,0.819,0.02,BLEU\\-3
5,1,Text Generation,DailyDialog,2018-08,3.78,100.0,3.78,1.0,3.78,0.11,BLEU\\-3
6,1,Text Generation,CMU-SE,2018-08,0.617,100.0,0.617,1.0,0.617,0.02,BLEU\\-3
7,1,Image Captioning,COCO,2019-05,33.6,100.0,33.6,1.0,33.6,1.0,BLEU\\-3
0,1,Text Generation,EMNLP2017 WMT,2016-09,0.4498,90.32,0.4498,0.9,0.498,0.66,BLEU\\-5
1,1,Text Generation,EMNLP2017 WMT,2017-05,0.463,92.97,0.0,0.0,0.498,0.67,BLEU\\-5
2,1,Text Generation,EMNLP2017 WMT,2017-09,0.498,100.0,0.0,0.0,0.498,0.73,BLEU\\-5
3,1,Text Generation,COCO Captions,2016-09,0.427,62.24,0.427,0.62,0.686,0.62,BLEU\\-5
4,1,Text Generation,COCO Captions,2017-05,0.544,79.3,0.1,0.15,0.686,0.79,BLEU\\-5
5,1,Text Generation,COCO Captions,2017-09,0.686,100.0,0.1,0.15,0.686,1.0,BLEU\\-5
0,1,Text Generation,EMNLP2017 WMT,2016-09,0.4541,72.42,0.4541,0.72,0.627,0.01,BLEU\\-4
1,1,Text Generation,EMNLP2017 WMT,2017-09,0.627,100.0,0.2,0.32,0.627,0.02,BLEU\\-4
2,1,Text Generation,COCO Captions,2016-09,0.521,66.97,0.521,0.67,0.778,0.01,BLEU\\-4
3,1,Text Generation,COCO Captions,2017-05,0.557,71.59,0.0,0.0,0.778,0.02,BLEU\\-4
4,1,Text Generation,COCO Captions,2017-09,0.778,100.0,0.2,0.26,0.778,0.02,BLEU\\-4
5,1,Question Answering,NarrativeQA,2016-11,15.69,51.56,15.69,0.52,30.43,0.43,BLEU\\-4
6,1,Question Answering,NarrativeQA,2018-09,21.07,69.24,5.4,0.18,30.43,0.58,BLEU\\-4
7,1,Question Answering,NarrativeQA,2018-10,22.49,73.91,1.4,0.05,30.43,0.62,BLEU\\-4
8,1,Question Answering,NarrativeQA,2018-11,27.61,90.73,5.1,0.17,30.43,0.76,BLEU\\-4
9,1,Question Answering,NarrativeQA,2019-01,30.43,100.0,2.8,0.09,30.43,0.83,BLEU\\-4
10,1,Question Generation,SQuAD1.1,2017-04,13.27,55.5,13.27,0.55,23.91,0.36,BLEU\\-4
11,1,Question Generation,SQuAD1.1,2018-06,13.91,58.18,0.6,0.03,23.91,0.38,BLEU\\-4
12,1,Question Generation,SQuAD1.1,2019-05,22.78,95.27,8.9,0.37,23.91,0.62,BLEU\\-4
13,1,Question Generation,SQuAD1.1,2020-01,23.91,100.0,1.1,0.05,23.91,0.66,BLEU\\-4
14,1,Text Generation,DailyDialog,2018-08,2.84,100.0,2.84,1.0,2.84,0.08,BLEU\\-4
15,1,Image Captioning,COCO,2019-05,24.9,100.0,24.9,1.0,24.9,0.68,BLEU\\-4
16,1,Image Captioning,Flickr30k Captions test,2019-09,30.1,100.0,30.1,1.0,30.1,0.82,BLEU\\-4
17,1,Image Captioning,COCO Captions test,2019-09,36.5,100.0,36.5,1.0,36.5,1.0,BLEU\\-4
0,1,Aspect-Based Sentiment Analysis,Sentihood,2016-10,69.3,78.84,69.3,0.79,87.9,0.79,Aspect
1,1,Aspect-Based Sentiment Analysis,Sentihood,2018-04,78.18,88.94,8.9,0.1,87.9,0.89,Aspect
2,1,Aspect-Based Sentiment Analysis,Sentihood,2018-06,78.5,89.31,0.3,0.0,87.9,0.89,Aspect
3,1,Aspect-Based Sentiment Analysis,Sentihood,2019-03,87.9,100.0,9.4,0.11,87.9,1.0,Aspect
0,1,Aspect-Based Sentiment Analysis,Sentihood,2016-10,81.9,87.5,81.9,0.88,93.6,0.88,Sentiment
1,1,Aspect-Based Sentiment Analysis,Sentihood,2018-04,89.32,95.43,7.4,0.08,93.6,0.95,Sentiment
2,1,Aspect-Based Sentiment Analysis,Sentihood,2018-06,91.0,97.22,1.7,0.02,93.6,0.97,Sentiment
3,1,Aspect-Based Sentiment Analysis,Sentihood,2019-03,93.3,99.68,2.3,0.02,93.6,1.0,Sentiment
4,1,Aspect-Based Sentiment Analysis,Sentihood,2019-03,93.6,100.0,0.3,0.0,93.6,1.0,Sentiment
0,1,Hypernym Discovery,Medical domain,2016-11,20.71,56.32,20.71,0.56,36.77,0.33,P\\-at\\-5
1,1,Hypernym Discovery,Medical domain,2018-06,36.77,100.0,16.1,0.44,36.77,0.58,P\\-at\\-5
2,1,Hypernym Discovery,Music domain,2016-11,12.41,30.04,12.41,0.3,41.31,0.2,P\\-at\\-5
3,1,Hypernym Discovery,Music domain,2018-06,41.31,100.0,28.9,0.7,41.31,0.65,P\\-at\\-5
4,1,Hypernym Discovery,General,2016-11,9.91,52.08,9.91,0.52,19.03,0.16,P\\-at\\-5
5,1,Hypernym Discovery,General,2018-06,19.03,100.0,9.1,0.48,19.03,0.3,P\\-at\\-5
6,1,Multi-Label Text Classification,EUR-Lex,2019-05,50.71,95.99,50.71,0.96,52.83,0.8,P\\-at\\-5
7,1,Multi-Label Text Classification,EUR-Lex,2019-06,52.83,100.0,2.1,0.04,52.83,0.84,P\\-at\\-5
8,1,Multi-Label Text Classification,Amazon-12K,2019-05,63.16,100.0,63.16,1.0,63.16,1.0,P\\-at\\-5
9,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,25.88,100.0,25.88,1.0,25.88,0.41,P\\-at\\-5
10,1,Multi-Label Text Classification,Wiki-30K,2019-05,62.87,100.0,62.87,1.0,62.87,1.0,P\\-at\\-5
11,1,Multi-Label Text Classification,AAPD,2019-05,41.19,100.0,41.19,1.0,41.19,0.65,P\\-at\\-5
12,1,Text Classification,RCV1,2019-06,56.33,100.0,56.33,1.0,56.33,0.89,P\\-at\\-5
0,1,Question Answering,NarrativeQA,2016-11,15.68,60.01,15.68,0.6,26.13,0.35,METEOR
1,1,Question Answering,NarrativeQA,2018-09,19.03,72.83,3.4,0.13,26.13,0.42,METEOR
2,1,Question Answering,NarrativeQA,2018-10,19.24,73.63,0.2,0.01,26.13,0.42,METEOR
3,1,Question Answering,NarrativeQA,2018-11,21.8,83.43,2.6,0.1,26.13,0.48,METEOR
4,1,Question Answering,NarrativeQA,2019-01,26.13,100.0,4.3,0.16,26.13,0.58,METEOR
5,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,44.69,98.68,44.69,0.99,45.29,0.99,METEOR
6,1,Data-to-Text Generation,E2E NLG Challenge,2018-04,45.17,99.74,0.5,0.01,45.29,1.0,METEOR
7,1,Data-to-Text Generation,E2E NLG Challenge,2018-11,45.29,100.0,0.1,0.0,45.29,1.0,METEOR
8,1,Paper generation,ACL Title and Abstract Dataset,2018-05,14.0,100.0,14,1.0,14,0.31,METEOR
9,1,Table-to-Text Generation,Wikipedia Person and Animal Dataset,2018-09,42.0,100.0,42,1.0,42,0.93,METEOR
10,1,KB-to-Language Generation,Wikipedia Person and Animal Dataset,2018-09,23.4,100.0,23.4,1.0,23.4,0.52,METEOR
11,1,Image Captioning,COCO,2019-05,23.1,100.0,23.1,1.0,23.1,0.51,METEOR
12,1,Image Captioning,Flickr30k Captions test,2019-09,23.0,100.0,23,1.0,23,0.51,METEOR
13,1,Image Captioning,COCO Captions test,2019-09,28.4,100.0,28.4,1.0,28.4,0.63,METEOR
0,1,Question Answering,MS MARCO,2016-11,23.96,45.9,23.96,0.46,52.2,0.4,Rouge\\-L
1,1,Question Answering,MS MARCO,2018-05,51.63,98.91,27.7,0.53,52.2,0.86,Rouge\\-L
2,1,Question Answering,MS MARCO,2018-11,52.01,99.64,0.4,0.01,52.2,0.87,Rouge\\-L
3,1,Question Answering,MS MARCO,2019-01,52.2,100.0,0.2,0.0,52.2,0.87,Rouge\\-L
4,1,Question Answering,NarrativeQA,2016-11,36.74,61.37,36.74,0.61,59.87,0.61,Rouge\\-L
5,1,Question Answering,NarrativeQA,2018-09,44.16,73.76,7.4,0.12,59.87,0.74,Rouge\\-L
6,1,Question Answering,NarrativeQA,2018-10,46.67,77.95,2.5,0.04,59.87,0.78,Rouge\\-L
7,1,Question Answering,NarrativeQA,2019-01,59.87,100.0,13.2,0.22,59.87,1.0,Rouge\\-L
0,1,Dialog Generation,Amazon-5,2017-01,5.0,100.0,5,1.0,5,1.0,1\\ in\\ 10\\ R\\-at\\-2
0,1,Text Generation,Yahoo Questions,2017-02,63.9,100.0,63.9,1.0,63.9,1.0,Perplexity
0,1,Text Generation,Yahoo Questions,2017-02,10.0,100.0,10.0,1.0,10.0,1.0,KL
0,1,Text Generation,Yahoo Questions,2017-02,332.1,100.0,332.1,1.0,332.1,1.0,NLL
0,1,Coreference Resolution,CoNLL 2012,2017-07,70.4,100.0,70.4,1.0,70.4,1.0,Avg\\ F1
1,1,Knowledge Base Question Answering,WebQSP-WD,2018-08,0.2588,100.0,0.2588,1.0,0.2588,0.0,Avg\\ F1
2,1,Dialog Generation,Persona-Chat,2020-04,19.77,100.0,19.77,1.0,19.77,0.28,Avg\\ F1
0,1,Sentiment Analysis,SemEval,2017-04,0.685,100.0,0.685,1.0,0.685,0.7,F1\\-score
1,1,Humor Detection,200k Short Texts for Humor Detection,2020-04,0.981,100.0,0.981,1.0,0.981,1.0,F1\\-score
0,1,Semantic Textual Similarity,SentEval,2017-05,86.3,98.29,86.3,0.98,87.8,0.98,SICK\\-E
1,1,Semantic Textual Similarity,SentEval,2018-03,87.8,100.0,1.5,0.02,87.8,1.0,SICK\\-E
0,1,Semantic Textual Similarity,SentEval,2017-05,0.884,99.55,0.884,1.0,0.888,1.0,SICK\\-R
1,1,Semantic Textual Similarity,SentEval,2018-03,0.888,100.0,0.0,0.0,0.888,1.0,SICK\\-R
0,1,Abstract Anaphora Resolution,The ARRAU Corpus,2017-06,43.83,100.0,43.83,1.0,43.83,1.0,Average\\ Precision
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,0.189,98.44,0.189,0.98,0.192,0.98,MAE\\ \\(Valence\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,0.192,100.0,0.0,0.0,0.192,1.0,MAE\\ \\(Valence\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,0.213,100.0,0.213,1.0,0.213,1.0,MAE\\ \\(Arousal\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,0.19,97.44,0.19,0.97,0.195,0.97,MAE\\ \\(Expectancy\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,0.195,100.0,0.0,0.0,0.195,1.0,MAE\\ \\(Expectancy\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,8.67,99.2,8.67,0.99,8.74,0.99,MAE\\ \\(Power\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,8.74,100.0,0.1,0.01,8.74,1.0,MAE\\ \\(Power\\)
0,1,Fake News Detection,FNC-1,2017-07,81.72,98.36,81.72,0.98,83.08,0.98,Weighted\\ Accuracy
1,1,Fake News Detection,FNC-1,2017-12,83.08,100.0,1.4,0.02,83.08,1.0,Weighted\\ Accuracy
0,1,Fake News Detection,FNC-1,2017-07,97.9,99.86,97.9,1.0,98.04,1.0,Per\\-class\\ Accuracy\\ \\(Unrelated\\)
1,1,Fake News Detection,FNC-1,2017-12,98.04,100.0,0.1,0.0,98.04,1.0,Per\\-class\\ Accuracy\\ \\(Unrelated\\)
0,1,Fake News Detection,FNC-1,2017-07,44.04,85.78,44.04,0.86,51.34,0.86,Per\\-class\\ Accuracy\\ \\(Agree\\)
1,1,Fake News Detection,FNC-1,2017-12,50.7,98.75,6.7,0.13,51.34,0.99,Per\\-class\\ Accuracy\\ \\(Agree\\)
2,1,Fake News Detection,FNC-1,2018-11,51.34,100.0,0.6,0.01,51.34,1.0,Per\\-class\\ Accuracy\\ \\(Agree\\)
0,1,Fake News Detection,FNC-1,2017-07,6.6,63.89,6.6,0.64,10.33,0.64,Per\\-class\\ Accuracy\\ \\(Disagree\\)
1,1,Fake News Detection,FNC-1,2017-12,9.61,93.03,3.0,0.29,10.33,0.93,Per\\-class\\ Accuracy\\ \\(Disagree\\)
2,1,Fake News Detection,FNC-1,2018-11,10.33,100.0,0.7,0.07,10.33,1.0,Per\\-class\\ Accuracy\\ \\(Disagree\\)
0,1,Fake News Detection,FNC-1,2017-07,81.38,94.98,81.38,0.95,85.68,0.95,Per\\-class\\ Accuracy\\ \\(Discuss\\)
1,1,Fake News Detection,FNC-1,2017-12,85.68,100.0,4.3,0.05,85.68,1.0,Per\\-class\\ Accuracy\\ \\(Discuss\\)
0,1,Relation Extraction,Wikipedia-Wikidata relations,2017-09,0.159,100.0,0.159,1.0,0.159,1.0,Error\\ rate
0,1,Temporal Information Extraction,TempEval-3,2017-09,67.2,100.0,67.2,1.0,67.2,1.0,Temporal\\ awareness
0,1,Word Sense Disambiguation,Supervised:,2017-09,72.0,90.34,72.0,0.9,79.7,0.9,Senseval\\ 2
1,1,Word Sense Disambiguation,Supervised:,2018-07,72.2,90.59,0.2,0.0,79.7,0.91,Senseval\\ 2
2,1,Word Sense Disambiguation,Supervised:,2018-11,75.15,94.29,3.0,0.04,79.7,0.94,Senseval\\ 2
3,1,Word Sense Disambiguation,Supervised:,2019-05,79.7,100.0,4.5,0.06,79.7,1.0,Senseval\\ 2
0,1,Word Sense Disambiguation,Supervised:,2017-09,69.4,89.2,69.4,0.89,77.8,0.89,Senseval\\ 3
1,1,Word Sense Disambiguation,Supervised:,2018-06,69.6,89.46,0.2,0.0,77.8,0.89,Senseval\\ 3
2,1,Word Sense Disambiguation,Supervised:,2018-07,70.5,90.62,0.9,0.01,77.8,0.91,Senseval\\ 3
3,1,Word Sense Disambiguation,Supervised:,2019-05,77.8,100.0,7.3,0.09,77.8,1.0,Senseval\\ 3
0,1,Word Sense Disambiguation,Supervised:,2017-09,66.4,84.37,66.4,0.84,78.7,0.84,SemEval\\ 2013
1,1,Word Sense Disambiguation,Supervised:,2017-09,66.9,85.01,0.5,0.01,78.7,0.85,SemEval\\ 2013
2,1,Word Sense Disambiguation,Supervised:,2018-07,67.2,85.39,0.3,0.0,78.7,0.85,SemEval\\ 2013
3,1,Word Sense Disambiguation,Supervised:,2018-11,72.63,92.29,5.4,0.07,78.7,0.92,SemEval\\ 2013
4,1,Word Sense Disambiguation,Supervised:,2019-05,78.7,100.0,6.1,0.08,78.7,1.0,SemEval\\ 2013
5,1,Word Sense Disambiguation,Knowledge-based:,2018-01,65.3,100.0,65.3,1.0,65.3,0.83,SemEval\\ 2013
0,1,Word Sense Disambiguation,Supervised:,2017-09,72.4,87.65,72.4,0.88,82.6,0.88,SemEval\\ 2015
1,1,Word Sense Disambiguation,Supervised:,2018-07,72.6,87.89,0.2,0.0,82.6,0.88,SemEval\\ 2015
2,1,Word Sense Disambiguation,Supervised:,2018-11,74.46,90.15,1.9,0.02,82.6,0.9,SemEval\\ 2015
3,1,Word Sense Disambiguation,Supervised:,2019-05,82.6,100.0,8.1,0.1,82.6,1.0,SemEval\\ 2015
4,1,Word Sense Disambiguation,Knowledge-based:,2018-01,69.6,100.0,69.6,1.0,69.6,0.84,SemEval\\ 2015
0,1,Named Entity Recognition,Long-tail emerging entities,2017-09,39.33,97.74,39.33,0.98,40.24,0.98,F1\\ \\(surface\\ form\\)
1,1,Named Entity Recognition,Long-tail emerging entities,2018-06,40.24,100.0,0.9,0.02,40.24,1.0,F1\\ \\(surface\\ form\\)
0,1,Machine Translation,20NEWS,2017-09,5.0,100.0,5,1.0,5,0.06,1\\-of\\-100\\ Accuracy
1,1,Conversational Response Selection,DSTC7 Ubuntu,2018-12,60.8,85.39,60.8,0.85,71.2,0.72,1\\-of\\-100\\ Accuracy
2,1,Conversational Response Selection,DSTC7 Ubuntu,2019-01,64.5,90.59,3.7,0.05,71.2,0.77,1\\-of\\-100\\ Accuracy
3,1,Conversational Response Selection,DSTC7 Ubuntu,2019-04,70.9,99.58,6.4,0.09,71.2,0.84,1\\-of\\-100\\ Accuracy
4,1,Conversational Response Selection,DSTC7 Ubuntu,2019-11,71.2,100.0,0.3,0.0,71.2,0.84,1\\-of\\-100\\ Accuracy
5,1,Conversational Response Selection,PolyAI AmazonQA,2019-04,71.3,84.58,71.3,0.85,84.3,0.85,1\\-of\\-100\\ Accuracy
6,1,Conversational Response Selection,PolyAI AmazonQA,2019-11,84.3,100.0,13.0,0.15,84.3,1.0,1\\-of\\-100\\ Accuracy
7,1,Conversational Response Selection,PolyAI Reddit,2019-04,61.3,85.38,61.3,0.85,71.8,0.73,1\\-of\\-100\\ Accuracy
8,1,Conversational Response Selection,PolyAI Reddit,2019-11,71.8,100.0,10.5,0.15,71.8,0.85,1\\-of\\-100\\ Accuracy
9,1,Conversational Response Selection,PolyAI OpenSubtitles,2019-04,30.6,100.0,30.6,1.0,30.6,0.36,1\\-of\\-100\\ Accuracy
0,1,Visual Dialog,VisDial v0.9 val,2017-09,48.53,87.98,48.53,0.88,55.16,0.68,R\\-at\\-1
1,1,Visual Dialog,VisDial v0.9 val,2017-11,50.29,91.17,1.8,0.03,55.16,0.71,R\\-at\\-1
2,1,Visual Dialog,VisDial v0.9 val,2019-02,53.33,96.68,3.0,0.05,55.16,0.75,R\\-at\\-1
3,1,Visual Dialog,VisDial v0.9 val,2019-04,55.16,100.0,1.8,0.03,55.16,0.77,R\\-at\\-1
4,1,Phrase Grounding,Flickr30k Entities Test,2018-05,69.69,97.7,69.69,0.98,71.33,0.98,R\\-at\\-1
5,1,Phrase Grounding,Flickr30k Entities Test,2019-08,71.33,100.0,1.6,0.02,71.33,1.0,R\\-at\\-1
6,1,Visual Dialog,VisDial v1.0 test-std,2018-09,47.55,85.44,47.55,0.85,55.65,0.67,R\\-at\\-1
7,1,Visual Dialog,VisDial v1.0 test-std,2019-02,49.63,89.18,2.1,0.04,55.65,0.7,R\\-at\\-1
8,1,Visual Dialog,VisDial v1.0 test-std,2019-04,55.65,100.0,6.0,0.11,55.65,0.78,R\\-at\\-1
9,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,70.4,100.0,70.4,1.0,70.4,0.99,R\\-at\\-1
0,1,Visual Dialog,VisDial v0.9 val,2017-09,87.43,94.06,87.43,0.94,92.95,0.93,R\\-at\\-10
1,1,Visual Dialog,VisDial v0.9 val,2017-11,88.81,95.55,1.4,0.02,92.95,0.94,R\\-at\\-10
2,1,Visual Dialog,VisDial v0.9 val,2019-02,90.38,97.24,1.6,0.02,92.95,0.96,R\\-at\\-10
3,1,Visual Dialog,VisDial v0.9 val,2019-04,92.95,100.0,2.6,0.03,92.95,0.99,R\\-at\\-10
4,1,Phrase Grounding,Flickr30k Entities Test,2018-05,86.35,99.82,86.35,1.0,86.51,0.92,R\\-at\\-10
5,1,Phrase Grounding,Flickr30k Entities Test,2019-08,86.51,100.0,0.2,0.0,86.51,0.92,R\\-at\\-10
6,1,Visual Dialog,VisDial v1.0 test-std,2018-09,88.8,94.42,88.8,0.94,94.05,0.94,R\\-at\\-10
7,1,Visual Dialog,VisDial v1.0 test-std,2019-02,89.35,95.0,0.5,0.01,94.05,0.95,R\\-at\\-10
8,1,Visual Dialog,VisDial v1.0 test-std,2019-04,94.05,100.0,4.7,0.05,94.05,1.0,R\\-at\\-10
9,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,86.31,100.0,86.31,1.0,86.31,0.92,R\\-at\\-10
0,1,Visual Dialog,VisDial v0.9 val,2017-09,78.66,91.19,78.66,0.91,86.26,0.91,R\\-at\\-5
1,1,Visual Dialog,VisDial v0.9 val,2017-11,80.71,93.57,2.0,0.02,86.26,0.93,R\\-at\\-5
2,1,Visual Dialog,VisDial v0.9 val,2019-02,82.42,95.55,1.7,0.02,86.26,0.95,R\\-at\\-5
3,1,Visual Dialog,VisDial v0.9 val,2019-04,86.26,100.0,3.8,0.04,86.26,0.99,R\\-at\\-5
4,1,Phrase Grounding,Flickr30k Entities Test,2018-05,84.22,99.11,84.22,0.99,84.98,0.97,R\\-at\\-5
5,1,Phrase Grounding,Flickr30k Entities Test,2019-08,84.98,100.0,0.8,0.01,84.98,0.98,R\\-at\\-5
6,1,Visual Dialog,VisDial v1.0 test-std,2018-09,78.1,90.05,78.1,0.9,86.73,0.9,R\\-at\\-5
7,1,Visual Dialog,VisDial v1.0 test-std,2019-02,79.75,91.95,1.7,0.02,86.73,0.92,R\\-at\\-5
8,1,Visual Dialog,VisDial v1.0 test-std,2019-04,86.73,100.0,7.0,0.08,86.73,1.0,R\\-at\\-5
9,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,84.49,100.0,84.49,1.0,84.49,0.97,R\\-at\\-5
0,1,Visual Dialog,VisDial v0.9 val,2017-09,4.86,100.0,4.86,1.0,4.86,1.0,Mean\\ Rank
1,1,Visual Dialog,VisDial v1.0 test-std,2018-09,4.4,100.0,4.4,1.0,4.4,0.91,Mean\\ Rank
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,4.2,97.67,4.2,0.98,4.3,0.86,Mean\\ Rank
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,4.3,100.0,0.1,0.02,4.3,0.88,Mean\\ Rank
0,1,Question Answering,WikiHop,2017-10,42.9,60.76,42.9,0.61,70.6,0.61,Test
1,1,Question Answering,WikiHop,2018-04,59.3,83.99,16.4,0.23,70.6,0.84,Test
2,1,Question Answering,WikiHop,2018-09,65.4,92.63,6.1,0.09,70.6,0.93,Test
3,1,Question Answering,WikiHop,2019-01,70.6,100.0,5.2,0.07,70.6,1.0,Test
4,1,Table-based Fact Verification,TabFact,2019-09,65.12,100.0,65.12,1.0,65.12,0.92,Test
0,1,Fine-Grained Opinion Analysis,MPQA,2017-11,83.8,98.69,83.8,0.99,84.91,0.99,Holder\\ Binary\\ F1
1,1,Fine-Grained Opinion Analysis,MPQA,2019-06,84.91,100.0,1.1,0.01,84.91,1.0,Holder\\ Binary\\ F1
0,1,Fine-Grained Opinion Analysis,MPQA,2017-11,72.06,98.32,72.06,0.98,73.29,0.98,Target\\ Binary\\ F1
1,1,Fine-Grained Opinion Analysis,MPQA,2019-06,73.29,100.0,1.2,0.02,73.29,1.0,Target\\ Binary\\ F1
0,1,Constituency Grammar Induction,PTB,2017-11,47.3,84.92,47.3,0.85,55.7,0.85,Mean\\ F1\\ \\(WSJ\\)
1,1,Constituency Grammar Induction,PTB,2018-08,47.9,86.0,0.6,0.01,55.7,0.86,Mean\\ F1\\ \\(WSJ\\)
2,1,Constituency Grammar Induction,PTB,2018-10,48.1,86.36,0.2,0.0,55.7,0.86,Mean\\ F1\\ \\(WSJ\\)
3,1,Constituency Grammar Induction,PTB,2019-06,55.7,100.0,7.6,0.14,55.7,1.0,Mean\\ F1\\ \\(WSJ\\)
0,1,Constituency Grammar Induction,PTB,2017-11,47.9,79.7,47.9,0.8,60.1,0.8,Max\\ F1\\ \\(WSJ\\)
1,1,Constituency Grammar Induction,PTB,2018-10,50.0,83.19,2.1,0.03,60.1,0.83,Max\\ F1\\ \\(WSJ\\)
2,1,Constituency Grammar Induction,PTB,2019-04,52.4,87.19,2.4,0.04,60.1,0.87,Max\\ F1\\ \\(WSJ\\)
3,1,Constituency Grammar Induction,PTB,2019-06,56.2,93.51,3.8,0.06,60.1,0.94,Max\\ F1\\ \\(WSJ\\)
4,1,Constituency Grammar Induction,PTB,2019-06,60.1,100.0,3.9,0.06,60.1,1.0,Max\\ F1\\ \\(WSJ\\)
0,1,Ad-Hoc Information Retrieval,TREC Robust04,2017-11,0.431,80.1,0.431,0.8,0.5381,0.01,nDCG\\-at\\-20
1,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-09,0.464,86.23,0.0,0.0,0.5381,0.01,nDCG\\-at\\-20
2,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-04,0.5381,100.0,0.1,0.19,0.5381,0.02,nDCG\\-at\\-20
3,1,Document Ranking,ClueWeb09-B,2019-06,31.1,100.0,31.1,1.0,31.1,1.0,nDCG\\-at\\-20
0,1,Ad-Hoc Information Retrieval,TREC Robust04,2017-11,0.382,81.85,0.382,0.82,0.4667,0.82,P\\-at\\-20
1,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-09,0.389,83.35,0.0,0.0,0.4667,0.83,P\\-at\\-20
2,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,0.3948,84.59,0.0,0.0,0.4667,0.85,P\\-at\\-20
3,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,0.4064,87.08,0.0,0.0,0.4667,0.87,P\\-at\\-20
4,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-03,0.4287,91.86,0.0,0.0,0.4667,0.92,P\\-at\\-20
5,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-04,0.4667,100.0,0.0,0.0,0.4667,1.0,P\\-at\\-20
0,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,8.3453,95.59,8.3453,0.96,8.73,0.96,NIST
1,1,Data-to-Text Generation,E2E NLG Challenge,2018-04,8.5105,97.49,0.2,0.02,8.73,0.97,NIST
2,1,Data-to-Text Generation,E2E NLG Challenge,2018-05,8.613,98.66,0.1,0.01,8.73,0.99,NIST
3,1,Data-to-Text Generation,E2E NLG Challenge,2019-04,8.73,100.0,0.1,0.01,8.73,1.0,NIST
0,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,2.2721,95.87,2.2721,0.96,2.37,0.02,CIDEr
1,1,Data-to-Text Generation,E2E NLG Challenge,2019-04,2.37,100.0,0.1,0.04,2.37,0.02,CIDEr
2,1,Image Captioning,COCO,2019-05,77.6,100.0,77.6,1.0,77.6,0.66,CIDEr
3,1,Image Captioning,Flickr30k Captions test,2019-09,67.4,100.0,67.4,1.0,67.4,0.58,CIDEr
4,1,Image Captioning,COCO Captions test,2019-09,116.9,100.0,116.9,1.0,116.9,1.0,CIDEr
5,1,Text Generation,CommonGen,2019-11,14.92,100.0,14.92,1.0,14.92,0.13,CIDEr
0,1,Word Sense Disambiguation,Knowledge-based:,2018-01,66.9,100.0,66.9,1.0,66.9,1.0,All
0,1,Grammatical Error Correction,_Restricted_,2018-01,57.47,93.45,57.47,0.93,61.5,0.92,GLEU
1,1,Grammatical Error Correction,_Restricted_,2018-06,61.5,100.0,4.0,0.07,61.5,0.99,GLEU
2,1,Grammatical Error Correction,Unrestricted,2018-07,62.37,100.0,62.37,1.0,62.37,1.0,GLEU
3,1,Grammatical Error Correction,JFLEG,2019-03,61.0,100.0,61,1.0,61,0.98,GLEU
0,1,Speech Emotion Recognition,IEMOCAP,2018-02,0.8,100.0,0.8,1.0,0.8,1.0,UA
1,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,0.765,100.0,0.765,1.0,0.765,0.96,UA
0,1,Question Answering,RACE,2018-03,60.2,100.0,60.2,1.0,60.2,1.0,RACE\\-m
0,1,Question Answering,RACE,2018-03,50.3,100.0,50.3,1.0,50.3,1.0,RACE\\-h
0,1,Question Answering,RACE,2018-03,53.3,100.0,53.3,1.0,53.3,1.0,RACE
0,1,Natural Language Inference,MultiNLI,2018-03,71.4,77.61,71.4,0.78,92.0,0.78,Matched
1,1,Natural Language Inference,MultiNLI,2018-04,72.2,78.48,0.8,0.01,92.0,0.78,Matched
2,1,Natural Language Inference,MultiNLI,2018-12,73.9,80.33,1.7,0.02,92.0,0.8,Matched
3,1,Natural Language Inference,MultiNLI,2019-01,86.7,94.24,12.8,0.14,92.0,0.94,Matched
4,1,Natural Language Inference,MultiNLI,2019-06,90.8,98.7,4.1,0.04,92.0,0.99,Matched
5,1,Natural Language Inference,MultiNLI,2019-09,91.3,99.24,0.5,0.01,92.0,0.99,Matched
6,1,Natural Language Inference,MultiNLI,2019-10,92.0,100.0,0.7,0.01,92.0,1.0,Matched
7,1,Natural Language Inference,MultiNLI Dev,2019-09,84.5,100.0,84.5,1.0,84.5,0.92,Matched
0,1,Natural Language Inference,MultiNLI,2018-03,71.3,77.75,71.3,0.78,91.7,0.78,Mismatched
1,1,Natural Language Inference,MultiNLI,2018-04,72.1,78.63,0.8,0.01,91.7,0.79,Mismatched
2,1,Natural Language Inference,MultiNLI,2018-11,72.2,78.74,0.1,0.0,91.7,0.79,Mismatched
3,1,Natural Language Inference,MultiNLI,2018-12,73.9,80.59,1.7,0.02,91.7,0.81,Mismatched
4,1,Natural Language Inference,MultiNLI,2019-01,86.0,93.78,12.1,0.13,91.7,0.94,Mismatched
5,1,Natural Language Inference,MultiNLI,2019-07,90.2,98.36,4.2,0.05,91.7,0.98,Mismatched
6,1,Natural Language Inference,MultiNLI,2019-10,91.7,100.0,1.5,0.02,91.7,1.0,Mismatched
7,1,Natural Language Inference,MultiNLI Dev,2019-09,84.5,100.0,84.5,1.0,84.5,0.92,Mismatched
0,1,Meeting Summarization,300W,2018-05,10.0,100.0,10,1.0,10,1.0,10%
0,1,Language Acquisition,SLAM 2018,2018-06,0.821,100.0,0.821,1.0,0.821,1.0,AUC
0,1,Word Sense Disambiguation,Supervised:,2018-06,62.2,84.74,62.2,0.85,73.4,0.85,SemEval\\ 2007
1,1,Word Sense Disambiguation,Supervised:,2018-11,66.81,91.02,4.6,0.06,73.4,0.91,SemEval\\ 2007
2,1,Word Sense Disambiguation,Supervised:,2019-05,73.4,100.0,6.6,0.09,73.4,1.0,SemEval\\ 2007
0,1,Entity Typing,Freebase FIGER,2018-06,94.8,100.0,94.8,1.0,94.8,1.0,BEP
0,1,Text Classification,20NEWS,2018-06,83.9,97.33,83.9,0.97,86.2,0.91,F\\-measure
1,1,Text Classification,20NEWS,2019-09,86.2,100.0,2.3,0.03,86.2,0.94,F\\-measure
2,1,Text Classification,R8,2018-06,91.0,99.24,91.0,0.99,91.7,0.99,F\\-measure
3,1,Text Classification,R8,2019-09,91.7,100.0,0.7,0.01,91.7,1.0,F\\-measure
0,1,Entity Typing,Freebase FIGER,2018-06,84.2,100.0,84.2,1.0,84.2,1.0,Macro\\ F1
1,1,Entity Linking,FIGER,2019-05,76.51,100.0,76.51,1.0,76.51,0.91,Macro\\ F1
2,1,Text Classification,RCV1,2019-08,60.1,100.0,60.1,1.0,60.1,0.71,Macro\\ F1
0,1,Entity Typing,Freebase FIGER,2018-06,85.7,100.0,85.7,1.0,85.7,1.0,Micro\\ F1
1,1,Entity Linking,FIGER,2019-05,73.39,100.0,73.39,1.0,73.39,0.86,Micro\\ F1
2,1,Multi-Label Text Classification,EUR-Lex,2019-06,73.2,100.0,73.2,1.0,73.2,0.85,Micro\\ F1
3,1,Text Classification,RCV1,2019-08,83.3,100.0,83.3,1.0,83.3,0.97,Micro\\ F1
0,1,Paraphrase Identification,2017_test set,2018-06,50.0,100.0,50,1.0,50,1.0,10\\ fold\\ Cross\\ validation
0,1,Multimodal Sentiment Analysis,CMU-MOSEI,2018-07,0.71,100.0,0.71,1.0,0.71,1.0,MAE
0,1,Question Answering,CoQA,2018-08,67.0,81.21,67.0,0.81,82.5,0.81,In\\-domain
1,1,Question Answering,CoQA,2018-09,69.4,84.12,2.4,0.03,82.5,0.84,In\\-domain
2,1,Question Answering,CoQA,2018-10,76.3,92.48,6.9,0.08,82.5,0.92,In\\-domain
3,1,Question Answering,CoQA,2018-10,82.5,100.0,6.2,0.08,82.5,1.0,In\\-domain
0,1,Question Answering,CoQA,2018-08,65.1,80.27,65.1,0.8,81.1,0.8,Overall
1,1,Question Answering,CoQA,2018-09,67.8,83.6,2.7,0.03,81.1,0.84,Overall
2,1,Question Answering,CoQA,2018-10,75.0,92.48,7.2,0.09,81.1,0.92,Overall
3,1,Question Answering,CoQA,2018-10,81.1,100.0,6.1,0.08,81.1,1.0,Overall
0,1,Question Answering,CoQA,2018-08,60.4,77.84,60.4,0.78,77.6,0.78,Out\\-of\\-domain
1,1,Question Answering,CoQA,2018-09,63.8,82.22,3.4,0.04,77.6,0.82,Out\\-of\\-domain
2,1,Question Answering,CoQA,2018-10,71.8,92.53,8.0,0.1,77.6,0.93,Out\\-of\\-domain
3,1,Question Answering,CoQA,2018-10,77.6,100.0,5.8,0.07,77.6,1.0,Out\\-of\\-domain
0,1,Machine Translation,WMT2014 English-German,2018-08,33.8,100.0,33.8,1.0,33.8,0.77,SacreBLEU
1,1,Machine Translation,WMT2014 English-French,2018-08,43.8,100.0,43.8,1.0,43.8,1.0,SacreBLEU
2,1,Machine Translation,WMT2019 English-German,2019-07,42.7,100.0,42.7,1.0,42.7,0.97,SacreBLEU
0,1,Constituency Grammar Induction,PTB,2018-08,60.2,88.92,60.2,0.89,67.7,0.89,Mean\\ F1\\ \\(WSJ10\\)
1,1,Constituency Grammar Induction,PTB,2018-10,65.1,96.16,4.9,0.07,67.7,0.96,Mean\\ F1\\ \\(WSJ10\\)
2,1,Constituency Grammar Induction,PTB,2019-06,67.7,100.0,2.6,0.04,67.7,1.0,Mean\\ F1\\ \\(WSJ10\\)
0,1,Visual Dialog,VisDial v1.0 test-std,2018-09,54.7,94.98,54.7,0.95,57.59,0.92,NDCG
1,1,Visual Dialog,VisDial v1.0 test-std,2019-02,57.59,100.0,2.9,0.05,57.59,0.97,NDCG
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,57.17,96.29,57.17,0.96,59.37,0.96,NDCG
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,57.59,97.0,0.4,0.01,59.37,0.97,NDCG
4,1,Visual Dialog,Visual Dialog v1.0,2020-04,59.37,100.0,1.8,0.03,59.37,1.0,NDCG
0,1,Question Answering,QuAC,2018-10,5.8,100.0,5.8,1.0,5.8,1.0,HEQD
0,1,Question Answering,QuAC,2018-10,59.6,100.0,59.6,1.0,59.6,1.0,HEQQ
0,1,Multimodal Emotion Recognition,IEMOCAP,2018-10,0.718,100.0,0.718,1.0,0.718,1.0,WAP
1,1,Speech Emotion Recognition,IEMOCAP,2018-10,0.718,100.0,0.718,1.0,0.718,1.0,WAP
0,1,Constituency Grammar Induction,PTB,2018-10,66.8,97.52,66.8,0.98,68.5,0.98,Max\\ F1\\ \\(WSJ10\\)
1,1,Constituency Grammar Induction,PTB,2019-06,68.5,100.0,1.7,0.02,68.5,1.0,Max\\ F1\\ \\(WSJ10\\)
0,1,Information Retrieval,TREC-PM,2018-11,0.5605,100.0,0.5605,1.0,0.5605,1.0,infNDCG
0,1,Phrase Grounding,Visual Genome,2018-11,55.16,100.0,55.16,1.0,55.16,0.8,Pointing\\ Game\\ Accuracy
1,1,Phrase Grounding,Flickr30k,2018-11,69.19,100.0,69.19,1.0,69.19,1.0,Pointing\\ Game\\ Accuracy
2,1,Phrase Grounding,ReferIt,2018-11,62.76,100.0,62.76,1.0,62.76,0.91,Pointing\\ Game\\ Accuracy
0,1,Emotion Classification,SemEval 2018 Task 1E-c,2018-12,56.1,100.0,56.1,1.0,56.1,1.0,Macro\\-F1
0,1,Question Answering,Natural Questions,2019-01,66.2,100.0,66.2,1.0,66.2,1.0,F1\\ \\(Long\\)
0,1,Question Answering,Natural Questions,2019-01,52.1,100.0,52.1,1.0,52.1,1.0,F1\\ \\(Short\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,2019-03,89.9,100.0,89.9,1.0,89.9,1.0,Accuracy\\ \\(3\\-way\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,2019-03,85.9,100.0,85.9,1.0,85.9,1.0,Accuracy\\ \\(4\\-way\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,2019-03,95.6,100.0,95.6,1.0,95.6,1.0,Binary\\ Accuracy
0,1,Text-To-Speech Synthesis,CMUDict 0.7b,2019-04,4.6,100.0,4.6,1.0,4.6,1.0,Phoneme\\ Error\\ Rate
0,1,Text-To-Speech Synthesis,CMUDict 0.7b,2019-04,19.88,100.0,19.88,1.0,19.88,1.0,Word\\ Error\\ Rate\\ \\(WER\\)
0,1,Passage Re-Ranking,TREC-PM,2019-04,36.5,100.0,36.5,1.0,36.5,1.0,mAP
0,1,Arabic Text Diacritization,Tashkeela,2019-04,0.0373,100.0,0.0373,1.0,0.0373,1.0,Diacritic\\ Error\\ Rate
0,1,Question Answering,HotpotQA,2019-05,59.82,72.07,59.82,0.72,83.0,0.72,Joint\\ F1
1,1,Question Answering,HotpotQA,2019-07,83.0,100.0,23.2,0.28,83.0,1.0,Joint\\ F1
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,270.0,100.0,270,1.0,270,1.0,Speedup
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,3.84,100.0,3.84,1.0,3.84,1.0,MOS
0,1,Multi-Label Text Classification,Wiki-30K,2019-05,67.82,100.0,67.82,1.0,67.82,0.73,nDCG\\-at\\-5
1,1,Multi-Label Text Classification,AAPD,2019-05,83.7,100.0,83.7,1.0,83.7,0.9,nDCG\\-at\\-5
2,1,Multi-Label Text Classification,EUR-Lex,2019-05,59.28,72.03,59.28,0.72,82.3,0.64,nDCG\\-at\\-5
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,82.3,100.0,23.0,0.28,82.3,0.88,nDCG\\-at\\-5
4,1,Multi-Label Text Classification,Amazon-12K,2019-05,87.57,100.0,87.57,1.0,87.57,0.94,nDCG\\-at\\-5
5,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,54.65,100.0,54.65,1.0,54.65,0.59,nDCG\\-at\\-5
6,1,Text Classification,RCV1,2019-06,93.11,100.0,93.11,1.0,93.11,1.0,nDCG\\-at\\-5
0,1,Multi-Label Text Classification,Wiki-30K,2019-05,75.64,100.0,75.64,1.0,75.64,0.82,nDCG\\-at\\-3
1,1,Multi-Label Text Classification,AAPD,2019-05,80.11,100.0,80.11,1.0,80.11,0.87,nDCG\\-at\\-3
2,1,Multi-Label Text Classification,EUR-Lex,2019-05,64.89,91.25,64.89,0.91,71.11,0.7,nDCG\\-at\\-3
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,71.11,100.0,6.2,0.09,71.11,0.77,nDCG\\-at\\-3
4,1,Multi-Label Text Classification,Amazon-12K,2019-05,89.13,100.0,89.13,1.0,89.13,0.96,nDCG\\-at\\-3
5,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,51.7,100.0,51.7,1.0,51.7,0.56,nDCG\\-at\\-3
6,1,Text Classification,RCV1,2019-06,92.47,100.0,92.47,1.0,92.47,1.0,nDCG\\-at\\-3
0,1,Multi-Label Text Classification,Wiki-30K,2019-05,73.14,100.0,73.14,1.0,73.14,0.9,P\\-at\\-3
1,1,Multi-Label Text Classification,AAPD,2019-05,60.72,100.0,60.72,1.0,60.72,0.75,P\\-at\\-3
2,1,Multi-Label Text Classification,EUR-Lex,2019-05,61.48,93.89,61.48,0.94,65.48,0.76,P\\-at\\-3
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,65.48,100.0,4.0,0.06,65.48,0.81,P\\-at\\-3
4,1,Multi-Label Text Classification,Amazon-12K,2019-05,79.16,100.0,79.16,1.0,79.16,0.97,P\\-at\\-3
5,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,34.6,100.0,34.6,1.0,34.6,0.43,P\\-at\\-3
6,1,Text Classification,RCV1,2019-06,81.27,100.0,81.27,1.0,81.27,1.0,P\\-at\\-3
0,1,Fake News Detection,Grover-Mega,2019-05,92.0,100.0,92.0,1.0,92.0,1.0,Unpaired\\ Accuracy
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,79.6,100.0,79.6,1.0,79.6,1.0,RP\\-at\\-5
0,1,Text Classification,RCV1,2019-06,97.05,100.0,97.05,1.0,97.05,1.0,nDCG\\-at\\-1
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,80.2,100.0,80.2,1.0,80.2,0.83,nDCG\\-at\\-1
0,1,Document Ranking,ClueWeb09-B,2019-06,20.28,100.0,20.28,1.0,20.28,1.0,ERR\\-at\\-20
0,1,Reading Comprehension,RACE,2019-06,84.0,100.0,84,1.0,84,1.0,Accuracy\\ \\(High\\)
0,1,Reading Comprehension,RACE,2019-06,88.6,100.0,88.6,1.0,88.6,1.0,Accuracy\\ \\(Middle\\)
0,1,Sentiment Analysis,ASTD,2019-08,0.62,100.0,0.62,1.0,0.62,0.69,Average\\ Recall
1,1,Sentiment Analysis,ArSAS,2019-08,0.9,100.0,0.9,1.0,0.9,1.0,Average\\ Recall
2,1,Sentiment Analysis,SemEval 2017 Task 4-A,2019-08,0.61,100.0,0.61,1.0,0.61,0.68,Average\\ Recall
0,1,Sentiment Analysis,FiQA,2019-08,0.55,100.0,0.55,1.0,0.55,1.0,R\\^2
0,1,Table-based Fact Verification,TabFact,2019-09,66.1,100.0,66.1,1.0,66.1,1.0,Val
0,1,Image Captioning,Flickr30k Captions test,2019-09,17.0,100.0,17,1.0,17,0.8,SPICE
1,1,Image Captioning,COCO Captions test,2019-09,21.2,100.0,21.2,1.0,21.2,1.0,SPICE
0,1,Question Answering,MultiRC,2019-10,88.2,100.0,88.2,1.0,88.2,1.0,F1a
0,1,Part-Of-Speech Tagging,French GSD,2019-11,98.19,100.0,98.19,1.0,98.19,0.99,UPOS
1,1,Part-Of-Speech Tagging,Sequoia Treebank,2019-11,99.21,100.0,99.21,1.0,99.21,1.0,UPOS
2,1,Part-Of-Speech Tagging,Spoken Corpus,2019-11,96.68,100.0,96.68,1.0,96.68,0.97,UPOS
3,1,Part-Of-Speech Tagging,ParTUT,2019-11,97.63,100.0,97.63,1.0,97.63,0.98,UPOS
0,1,Scientific Concept Extraction,STM-corpus,2020-01,65.5,98.64,65.5,0.99,66.4,0.99,Exact\\ Span\\ F1
1,1,Scientific Concept Extraction,STM-corpus,2020-01,66.4,100.0,0.9,0.01,66.4,1.0,Exact\\ Span\\ F1
0,1,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,2020-01,85.57,100.0,85.57,1.0,85.57,1.0,Laptop\\ \\(F1\\)
0,1,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,2020-01,83.54,100.0,83.54,1.0,83.54,1.0,Mean\\ F1\\ \\(Laptop\\ \\+\\ Restaurant\\)
0,1,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,2020-01,81.5,100.0,81.5,1.0,81.5,1.0,Restaurant\\ \\(F1\\)
0,1,Bias Detection,StereoSet,2020-04,72.97,100.0,72.97,1.0,72.97,1.0,ICAT\\ Score
0,1,Question Answering,SCDE,2020-04,0.299,100.0,0.299,1.0,0.299,1.0,PA
0,1,Question Answering,SCDE,2020-04,0.661,100.0,0.661,1.0,0.661,1.0,DE
0,1,Question Answering,SCDE,2020-04,0.717,100.0,0.717,1.0,0.717,1.0,BA
